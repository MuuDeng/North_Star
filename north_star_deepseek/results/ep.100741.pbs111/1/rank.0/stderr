[1,0]<stderr>:WARNING: CPU IP/backtrace sampling not supported, disabling.
[1,0]<stderr>:Try the 'nsys status --environment' command to learn more.
[1,0]<stderr>:
[1,0]<stderr>:WARNING: CPU context switch tracing not supported, disabling.
[1,0]<stderr>:Try the 'nsys status --environment' command to learn more.
[1,0]<stderr>:
[1,0]<stderr>:W1025 10:35:17.903000 3571928 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:17.903000 3571928 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:WARNING:sglang.srt.server_args:[33mNOTE: --enable-ep-moe is deprecated. Please set `--ep-size` to the same value as `--tp-size` instead.[0m
[1,0]<stderr>:WARNING:sglang.srt.server_args:Pipeline parallelism is incompatible with overlap schedule.
[1,0]<stderr>:WARNING:sglang.srt.server_args:[33mNOTE: --enable-ep-moe is deprecated. Please set `--ep-size` to the same value as `--tp-size` instead.[0m
[1,0]<stderr>:WARNING:sglang.srt.server_args:Pipeline parallelism is incompatible with overlap schedule.
[1,0]<stderr>:[2025-10-25 10:35:21] Using default HuggingFace chat template with detected content format: string
[1,0]<stderr>:W1025 10:35:45.551000 3573144 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:45.551000 3573144 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1025 10:35:45.559000 3573145 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:45.559000 3573145 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1025 10:35:45.828000 3573143 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:45.828000 3573143 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1025 10:35:46.192000 3573175 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:46.192000 3573175 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1025 10:35:46.192000 3573146 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:46.192000 3573146 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1025 10:35:46.336000 3573174 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:46.336000 3573174 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1025 10:35:46.340000 3573149 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:46.340000 3573149 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1025 10:35:46.432000 3573148 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:46.432000 3573148 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1025 10:35:46.472000 3573147 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1025 10:35:46.472000 3573147 /scratch/users/industry/ai-hpc/apacsc34/phattadon/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:[2025-10-25 10:35:47 TP0 EP0 PP0] Attention backend not explicitly specified. Use fa3 backend by default.
[1,0]<stderr>:[2025-10-25 10:35:47 TP0 EP0 PP0] Chunked prefix cache is turned on.
[1,0]<stderr>:[2025-10-25 10:35:47 TP0 EP0 PP0] Init torch distributed begin.
[1,0]<stderr>:[2025-10-25 10:35:58 TP0 EP0 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:02 TP0 EP0 PP0] Setup Custom allreduce failed with invalid literal for int() with base 10: 'GPU-7d092b58-1299-ec03-6af1-9308a58ce60d'. To silence this warning, specify --disable-custom-all-reduce explicitly.
[1,0]<stderr>:[2025-10-25 10:36:02 TP1 EP1 PP0] Setup Custom allreduce failed with invalid literal for int() with base 10: 'GPU-7d092b58-1299-ec03-6af1-9308a58ce60d'. To silence this warning, specify --disable-custom-all-reduce explicitly.
[1,0]<stderr>:[2025-10-25 10:36:02 TP2 EP2 PP0] Setup Custom allreduce failed with invalid literal for int() with base 10: 'GPU-7d092b58-1299-ec03-6af1-9308a58ce60d'. To silence this warning, specify --disable-custom-all-reduce explicitly.
[1,0]<stderr>:[2025-10-25 10:36:02 TP6 EP6 PP0] Setup Custom allreduce failed with invalid literal for int() with base 10: 'GPU-7d092b58-1299-ec03-6af1-9308a58ce60d'. To silence this warning, specify --disable-custom-all-reduce explicitly.
[1,0]<stderr>:[2025-10-25 10:36:02 TP7 EP7 PP0] Setup Custom allreduce failed with invalid literal for int() with base 10: 'GPU-7d092b58-1299-ec03-6af1-9308a58ce60d'. To silence this warning, specify --disable-custom-all-reduce explicitly.
[1,0]<stderr>:[2025-10-25 10:36:02 TP4 EP4 PP0] Setup Custom allreduce failed with invalid literal for int() with base 10: 'GPU-7d092b58-1299-ec03-6af1-9308a58ce60d'. To silence this warning, specify --disable-custom-all-reduce explicitly.
[1,0]<stderr>:[2025-10-25 10:36:02 TP3 EP3 PP0] Setup Custom allreduce failed with invalid literal for int() with base 10: 'GPU-7d092b58-1299-ec03-6af1-9308a58ce60d'. To silence this warning, specify --disable-custom-all-reduce explicitly.
[1,0]<stderr>:[2025-10-25 10:36:02 TP5 EP5 PP0] Setup Custom allreduce failed with invalid literal for int() with base 10: 'GPU-7d092b58-1299-ec03-6af1-9308a58ce60d'. To silence this warning, specify --disable-custom-all-reduce explicitly.
[1,0]<stderr>:[2025-10-25 10:36:03 TP0 EP0 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:06 TP2 EP2 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:06 TP6 EP6 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:06 TP0 EP0 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:06 TP7 EP7 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:06 TP4 EP4 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:06 TP3 EP3 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:06 TP5 EP5 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:06 TP1 EP1 PP0] sglang is using nccl==2.27.3
[1,0]<stderr>:[2025-10-25 10:36:08 TP0 EP0 PP0] Init torch distributed ends. mem usage=2.15 GB
[1,0]<stderr>:[2025-10-25 10:36:09 TP2 EP2 PP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-25 10:36:09 TP0 EP0 PP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-25 10:36:09 TP4 EP4 PP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-25 10:36:09 TP1 EP1 PP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-25 10:36:09 TP7 EP7 PP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-25 10:36:09 TP6 EP6 PP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-25 10:36:09 TP3 EP3 PP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-25 10:36:09 TP5 EP5 PP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-25 10:36:11 TP0 EP0 PP0] Load weight begin. avail mem=76.37 GB
[1,0]<stderr>:[2025-10-25 10:36:11 TP0 EP0 PP0] Detected fp8 checkpoint.
[1,0]<stderr>:[2025-10-25 10:36:11 TP0 EP0 PP0] Deepseek V3/R1 can not use shared experts fusion optimization under expert parallelism. Shared experts fusion optimization is disabled.
[1,0]<stderr>:[2025-10-25 10:36:12 TP0 EP0 PP0] Scheduler hit an exception: Traceback (most recent call last):
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2555, in run_scheduler_process
[1,0]<stderr>:    scheduler = Scheduler(
[1,0]<stderr>:                ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 315, in __init__
[1,0]<stderr>:    self.tp_worker = TpWorkerClass(
[1,0]<stderr>:                     ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker.py", line 84, in __init__
[1,0]<stderr>:    self.model_runner = ModelRunner(
[1,0]<stderr>:                        ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 242, in __init__
[1,0]<stderr>:    self.initialize(min_per_gpu_memory)
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 288, in initialize
[1,0]<stderr>:    self.load_model()
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 679, in load_model
[1,0]<stderr>:    self.model = get_model(
[1,0]<stderr>:                 ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/__init__.py", line 22, in get_model
[1,0]<stderr>:    return loader.load_model(
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 571, in load_model
[1,0]<stderr>:    model = _initialize_model(
[1,0]<stderr>:            ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 186, in _initialize_model
[1,0]<stderr>:    return model_class(
[1,0]<stderr>:           ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2155, in __init__
[1,0]<stderr>:    self.model = DeepseekV2Model(
[1,0]<stderr>:                 ^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2057, in __init__
[1,0]<stderr>:    DeepseekV2DecoderLayer(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 1836, in __init__
[1,0]<stderr>:    self.mlp = DeepseekV2MoE(
[1,0]<stderr>:               ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 327, in __init__
[1,0]<stderr>:    self.experts = get_moe_impl_class()(
[1,0]<stderr>:                   ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/ep_moe/layer.py", line 100, in __init__
[1,0]<stderr>:    super().__init__(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/layer.py", line 220, in __init__
[1,0]<stderr>:    self.quant_method.create_weights(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/quantization/fp8.py", line 581, in create_weights
[1,0]<stderr>:    torch.empty(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1,0]<stderr>:    return func(*args, **kwargs)
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.10 GiB of which 318.00 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 76.02 GiB is allocated by PyTorch, and 67.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLO[1,0]<stderr>:C_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1,0]<stderr>:
[1,0]<stderr>:[2025-10-25 10:36:12 TP7 EP7 PP0] Scheduler hit an exception: Traceback (most recent call last):
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2555, in run_scheduler_process
[1,0]<stderr>:    scheduler = Scheduler(
[1,0]<stderr>:                ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 315, in __init__
[1,0]<stderr>:    self.tp_worker = TpWorkerClass(
[1,0]<stderr>:                     ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker.py", line 84, in __init__
[1,0]<stderr>:    self.model_runner = ModelRunner(
[1,0]<stderr>:                        ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 242, in __init__
[1,0]<stderr>:    self.initialize(min_per_gpu_memory)
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 288, in initialize
[1,0]<stderr>:    self.load_model()
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 679, in load_model
[1,0]<stderr>:    self.model = get_model(
[1,0]<stderr>:                 ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/__init__.py", line 22, in get_model
[1,0]<stderr>:    return loader.load_model(
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 571, in load_model
[1,0]<stderr>:    model = _initialize_model(
[1,0]<stderr>:            ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 186, in _initialize_model
[1,0]<stderr>:    return model_class(
[1,0]<stderr>:           ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2155, in __init__
[1,0]<stderr>:    self.model = DeepseekV2Model(
[1,0]<stderr>:                 ^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2057, in __init__
[1,0]<stderr>:    DeepseekV2DecoderLayer(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 1836, in __init__
[1,0]<stderr>:    self.mlp = DeepseekV2MoE(
[1,0]<stderr>:               ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 327, in __init__
[1,0]<stderr>:    self.experts = get_moe_impl_class()(
[1,0]<stderr>:                   ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/ep_moe/layer.py", line 100, in __init__
[1,0]<stderr>:    super().__init__(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/layer.py", line 220, in __init__
[1,0]<stderr>:    self.quant_method.create_weights(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/quantization/fp8.py", line 575, in create_weights
[1,0]<stderr>:    torch.empty(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1,0]<stderr>:    return func(*args, **kwargs)
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 896.00 MiB. GPU 7 has a total capacity of 79.10 GiB of which 314.00 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocate[1,0]<stderr>:d memory 76.50 GiB is allocated by PyTorch, and 58.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1,0]<stderr>:
[1,0]<stderr>:[2025-10-25 10:36:12 TP2 EP2 PP0] Scheduler hit an exception: Traceback (most recent call last):
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2555, in run_scheduler_process
[1,0]<stderr>:    scheduler = Scheduler(
[1,0]<stderr>:                ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 315, in __init__
[1,0]<stderr>:    self.tp_worker = TpWorkerClass(
[1,0]<stderr>:                     ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker.py", line 84, in __init__
[1,0]<stderr>:    self.model_runner = ModelRunner(
[1,0]<stderr>:                        ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 242, in __init__
[1,0]<stderr>:    self.initialize(min_per_gpu_memory)
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 288, in initialize
[1,0]<stderr>:    self.load_model()
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 679, in load_model
[1,0]<stderr>:    self.model = get_model(
[1,0]<stderr>:                 ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/__init__.py", line 22, in get_model
[1,0]<stderr>:    return loader.load_model(
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 571, in load_model
[1,0]<stderr>:    model = _initialize_model(
[1,0]<stderr>:            ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 186, in _initialize_model
[1,0]<stderr>:    return model_class(
[1,0]<stderr>:           ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2155, in __init__
[1,0]<stderr>:    self.model = DeepseekV2Model(
[1,0]<stderr>:                 ^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2057, in __init__
[1,0]<stderr>:    DeepseekV2DecoderLayer(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 1836, in __init__
[1,0]<stderr>:    self.mlp = DeepseekV2MoE(
[1,0]<stderr>:               ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 327, in __init__
[1,0]<stderr>:    self.experts = get_moe_impl_class()(
[1,0]<stderr>:                   ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/ep_moe/layer.py", line 100, in __init__
[1,0]<stderr>:    super().__init__(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/layer.py", line 220, in __init__
[1,0]<stderr>:    self.quant_method.create_weights(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/quantization/fp8.py", line 581, in create_weights
[1,0]<stderr>:    torch.empty(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1,0]<stderr>:    return func(*args, **kwargs)
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:torch.OutOfMemoryError: CUDA out of memory. Tried to alloca[1,0]<stderr>:te 448.00 MiB. GPU 2 has a total capacity of 79.10 GiB of which 318.00 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 76.02 GiB is allocated by PyTorch, and 67.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1,0]<stderr>:
[1,0]<stderr>:[2025-10-25 10:36:12 TP1 EP1 PP0] Scheduler hit an exception: Traceback (most recent call last):
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2555, in run_scheduler_process
[1,0]<stderr>:    scheduler = Scheduler(
[1,0]<stderr>:                ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 315, in __init__
[1,0]<stderr>:    self.tp_worker = TpWorkerClass(
[1,0]<stderr>:                     ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker.py", line 84, in __init__
[1,0]<stderr>:    self.model_runner = ModelRunner(
[1,0]<stderr>:                        ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 242, in __init__
[1,0]<stderr>:    self.initialize(min_per_gpu_memory)
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 288, in initialize
[1,0]<stderr>:    self.load_model()
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 679, in load_model
[1,0]<stderr>:    self.model = get_model(
[1,0]<stderr>:                 ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/__init__.py", line 22, in get_model
[1,0]<stderr>:    return loader.load_model(
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 571, in load_model
[1,0]<stderr>:    model = _initialize_model(
[1,0]<stderr>:            ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 186, in _initialize_model
[1,0]<stderr>:    return model_class(
[1,0]<stderr>:           ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2155, in __init__
[1,0]<stderr>:    self.model = DeepseekV2Model(
[1,0]<stderr>:                 ^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2057, in __init__
[1,0]<stderr>:    DeepseekV2DecoderLayer(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 1836, in __init__
[1,0]<stderr>:    self.mlp = DeepseekV2MoE(
[1,0]<stderr>:               ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 327, in __init__
[1,0]<stderr>:    self.experts = get_moe_impl_class()(
[1,0]<stderr>:                   ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/ep_moe/layer.py", line 100, in __init__
[1,0]<stderr>:    super().__init__(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/layer.py", line 220, in __init__
[1,0]<stderr>:    self.quant_method.create_weights(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/quantization/fp8.py", line 581, in create_weights
[1,0]<stderr>:    torch.empty(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/torch/utils[1,0]<stderr>:/_device.py", line 103, in __torch_function__
[1,0]<stderr>:    return func(*args, **kwargs)
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 1 has a total capacity of 79.10 GiB of which 414.00 MiB is free. Including non-PyTorch memory, this process has 78.68 GiB memory in use. Of the allocated memory 76.02 GiB is allocated by PyTorch, and 67.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1,0]<stderr>:
[1,0]<stderr>:[2025-10-25 10:36:12 TP6 EP6 PP0] Scheduler hit an exception: Traceback (most recent call last):
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2555, in run_scheduler_process
[1,0]<stderr>:    scheduler = Scheduler(
[1,0]<stderr>:                ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 315, in __init__
[1,0]<stderr>:    self.tp_worker = TpWorkerClass(
[1,0]<stderr>:                     ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker.py", line 84, in __init__
[1,0]<stderr>:    self.model_runner = ModelRunner(
[1,0]<stderr>:                        ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 242, in __init__
[1,0]<stderr>:    self.initialize(min_per_gpu_memory)
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 288, in initialize
[1,0]<stderr>:    self.load_model()
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 679, in load_model
[1,0]<stderr>:    self.model = get_model(
[1,0]<stderr>:                 ^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/__init__.py", line 22, in get_model
[1,0]<stderr>:    return loader.load_model(
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 571, in load_model
[1,0]<stderr>:    model = _initialize_model(
[1,0]<stderr>:            ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/model_loader/loader.py", line 186, in _initialize_model
[1,0]<stderr>:    return model_class(
[1,0]<stderr>:           ^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2155, in __init__
[1,0]<stderr>:    self.model = DeepseekV2Model(
[1,0]<stderr>:                 ^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 2057, in __init__
[1,0]<stderr>:    DeepseekV2DecoderLayer(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 1836, in __init__
[1,0]<stderr>:    self.mlp = DeepseekV2MoE(
[1,0]<stderr>:               ^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/models/deepseek_v2.py", line 327, in __init__
[1,0]<stderr>:    self.experts = get_moe_impl_class()(
[1,0]<stderr>:                   ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/ep_moe/layer.py", line 100, in __init__
[1,0]<stderr>:    super().__init__(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/layer.py", line 220, in __init__
[1,0]<stderr>:    self.quant_method.create_weights(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/sglang/srt/layers/quant[1,0]<stderr>:ization/fp8.py", line 581, in create_weights
[1,0]<stderr>:    torch.empty(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/phattadon/py312/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1,0]<stderr>:    return func(*args, **kwargs)
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 6 has a total capacity of 79.10 GiB of which 318.00 MiB is free. Including non-PyTorch memory, this process has 78.78 GiB memory in use. Of the allocated memory 76.02 GiB is allocated by PyTorch, and 67.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1,0]<stderr>:
[1,0]<stderr>:[2025-10-25 10:36:12] Received sigquit from a child process. It usually means the child failed.
[1,0]<stderr>:[2025-10-25 10:36:12] Received sigquit from a child process. It usually means the child failed.
[1,0]<stderr>:The target application terminated. One or more process it created re-parented.
[1,0]<stderr>:Waiting for termination of re-parented processes.
[1,0]<stderr>:Use the `--wait` option to modify this behavior.
