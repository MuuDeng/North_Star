========== SU SUMMARY ==========
Prepaid SU: 341.334 | 420s SU: 238.934 | Balance: 50215.752
N/A
Job ID: 96714.pbs111 | Timestamp: 20251010_082639
================================
[08:26:39] Starting 16-GPU inference with ZMQ PORT FIX
[08:26:39] Master: a2ap-dgx008.asp2p.nscc.sg:30137
[08:26:39] SGLang ports: 47369+[0,100,200,300]
[08:26:39] Job ID: 96714.pbs111
[08:26:39] Logs: /home/users/industry/ai-hpc/apacsc34/run/sglang_20251010_082639_96714.pbs111.log

========================   JOB MAP   ========================
Data for JOB prterun-a2ap-dgx008-3292172@1 offset 0 Total slots allocated 16
    Mapping policy: BYNODE:NOOVERSUBSCRIBE  Ranking policy: NODE Binding policy: CORE
    Cpu set: N/A  PPR: 8:node  Cpus-per-rank: 14  Cpu Type: CORE


Data for node: a2ap-dgx008	Num slots: 8	Max slots: 0	Num procs: 8
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 0 Bound: package[0][core:0-13]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 2 Bound: package[0][core:14-27]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 4 Bound: package[0][core:28-41]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 6 Bound: package[0][core:42-55]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 8 Bound: package[1][core:56-69]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 10 Bound: package[1][core:70-83]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 12 Bound: package[1][core:84-97]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 14 Bound: package[1][core:98-111]

Data for node: a2ap-dgx024	Num slots: 8	Max slots: 0	Num procs: 8
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 1 Bound: package[0][core:0-13]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 3 Bound: package[0][core:14-27]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 5 Bound: package[0][core:28-41]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 7 Bound: package[0][core:42-55]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 9 Bound: package[1][core:56-69]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 11 Bound: package[1][core:70-83]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 13 Bound: package[1][core:84-97]
        Process jobid: prterun-a2ap-dgx008-3292172@1 App: 0 Process rank: 15 Bound: package[1][core:98-111]

=============================================================
[1,0]<stderr>: [a2ap-dgx008:3292172] Rank 0 bound to package[0][core:0-13]
[1,2]<stderr>: [a2ap-dgx008:3292172] Rank 2 bound to package[0][core:14-27]
[1,4]<stderr>: [a2ap-dgx008:3292172] Rank 4 bound to package[0][core:28-41]
[1,6]<stderr>: [a2ap-dgx008:3292172] Rank 6 bound to package[0][core:42-55]
[1,8]<stderr>: [a2ap-dgx008:3292172] Rank 8 bound to package[1][core:56-69]
[1,10]<stderr>: [a2ap-dgx008:3292172] Rank 10 bound to package[1][core:70-83]
[1,12]<stderr>: [a2ap-dgx008:3292172] Rank 12 bound to package[1][core:84-97]
[1,14]<stderr>: [a2ap-dgx008:3292172] Rank 14 bound to package[1][core:98-111]
[1,3]<stderr>: [a2ap-dgx024:2380517] Rank 3 bound to package[0][core:14-27]
[1,1]<stderr>: [a2ap-dgx024:2380517] Rank 1 bound to package[0][core:0-13]
[1,9]<stderr>: [a2ap-dgx024:2380517] Rank 9 bound to package[1][core:56-69]
[1,15]<stderr>: [a2ap-dgx024:2380517] Rank 15 bound to package[1][core:98-111]
[1,13]<stderr>: [a2ap-dgx024:2380517] Rank 13 bound to package[1][core:84-97]
[1,5]<stderr>: [a2ap-dgx024:2380517] Rank 5 bound to package[0][core:28-41]
[1,7]<stderr>: [a2ap-dgx024:2380517] Rank 7 bound to package[0][core:42-55]
[1,11]<stderr>: [a2ap-dgx024:2380517] Rank 11 bound to package[1][core:70-83]
[1,0]<stdout>: [INFO] Validation passed on rank 0
[1,0]<stdout>: [INFO] Model: /home/users/industry/ai-hpc/apacsc34/scratch/model/DeepSeek-R1
[1,0]<stdout>: [INFO] Data: /home/users/industry/ai-hpc/apacsc34/scratch/ShareGPT_V3_unfiltered_cleaned_split.json
[1,0]<stdout>: [INFO] Cache: /home/users/industry/ai-hpc/apacsc34/.cache/sglang/96714.pbs111
[1,0]<stdout>: [INFO] RAM disk: /dev/shm/sglang_96714.pbs111
[1,0]<stdout>: [INFO] SGLang ports: 47369+[0,100,200,300]
[1,1]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,1]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,1]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,1]<stderr>:                                    [--skip-tokenizer-init]
[1,1]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,1]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,1]<stderr>:                                    [--trust-remote-code]
[1,1]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,1]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,1]<stderr>:                                    [--revision REVISION]
[1,1]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,1]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,1]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,1]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,1]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,1]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,1]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,1]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,1]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,1]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,1]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,1]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,1]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,1]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,1]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,1]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,1]<stderr>:                                    [--page-size PAGE_SIZE]
[1,1]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,1]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,1]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,1]<stderr>:                                    [--device DEVICE]
[1,1]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,1]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,1]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,1]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,1]<stderr>:                                    [--stream-output]
[1,1]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,1]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,1]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,1]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,1]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,1]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,1]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,1]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,1]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,1]<stderr>:                                    [--log-requests]
[1,1]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,1]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,1]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,1]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,1]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,1]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,1]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,1]<stderr>:                                    [--collect-tokens-histogram]
[1,1]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,1]<stderr>:                                    [--enable-request-time-stats-logging]
[1,1]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,1]<stderr>:                                    [--api-key API_KEY]
[1,1]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,1]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,1]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,1]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,1]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,1]<stderr>:                                    [--enable-cache-report]
[1,1]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,1]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,1]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,1]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,1]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,1]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,1]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,1]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,1]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,1]<stderr>:                                    [--enable-lora]
[1,1]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,1]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,1]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,1]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,1]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,1]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,1]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,1]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,1]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,1]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,1]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,1]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,1]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,1]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,1]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,1]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,1]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,1]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,1]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,1]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,1]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,1]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,1]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,1]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,1]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,1]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,1]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,1]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,1]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,1]<stderr>:                                    [--enable-eplb]
[1,1]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,1]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,1]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,1]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,1]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,1]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,1]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,1]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,1]<stderr>:                                    [--enable-hierarchical-cache]
[1,1]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,1]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,1]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,1]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,1]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,1]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,1]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,1]<stderr>:                                    [--enable-double-sparsity]
[1,1]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,1]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,1]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,1]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,1]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,1]<stderr>:                                    [--disable-radix-cache]
[1,1]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,1]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,1]<stderr>:                                    [--disable-cuda-graph]
[1,1]<stderr>:                                    [--disable-cuda-graph-padding]
[1,1]<stderr>:                                    [--enable-profile-cuda-graph]
[1,1]<stderr>:                                    [--enable-cudagraph-gc]
[1,1]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,1]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,1]<stderr>:                                    [--disable-outlines-disk-cache]
[1,1]<stderr>:                                    [--disable-custom-all-reduce]
[1,1]<stderr>:                                    [--enable-mscclpp]
[1,1]<stderr>:                                    [--disable-overlap-schedule]
[1,1]<stderr>:                                    [--enable-mixed-chunk]
[1,1]<stderr>:                                    [--enable-dp-attention]
[1,1]<stderr>:                                    [--enable-dp-lm-head]
[1,1]<stderr>:                                    [--enable-two-batch-overlap]
[1,1]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,1]<stderr>:                                    [--enable-torch-compile]
[1,1]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,1]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,1]<stderr>:                                    [--enable-nan-detection]
[1,1]<stderr>:                                    [--enable-p2p-check]
[1,1]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,1]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,1]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,1]<stderr>:                                    [--delete-ckpt-after-loading]
[1,1]<stderr>:                                    [--enable-memory-saver]
[1,1]<stderr>:                                    [--allow-auto-truncate]
[1,1]<stderr>:                                    [--enable-custom-logit-processor]
[1,1]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,1]<stderr>:                                    [--disable-shared-experts-fusion]
[1,1]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,1]<stderr>:                                    [--disable-fast-image-processor]
[1,1]<stderr>:                                    [--enable-return-hidden-states]
[1,1]<stderr>:                                    [--enable-triton-kernel-moe]
[1,1]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,1]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,1]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,1]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,1]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,1]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,1]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,1]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,1]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,1]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,1]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,1]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,1]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,1]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,1]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,1]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,1]<stderr>:                                    [--enable-pdmux]
[1,1]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,1]<stderr>:                                    [--weight-loader-disable-mmap]
[1,1]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,1]<stderr>:                                    [--backend BACKEND]
[1,1]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,1]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,1]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,1]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,1]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,1]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,1]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,1]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,1]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,1]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,1]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,1]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,1]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,1]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,1]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,1]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,1]<stderr>:                                    [--apply-chat-template] [--profile]
[1,1]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,1]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,1]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47470
[1,5]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,5]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,5]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,5]<stderr>:                                    [--skip-tokenizer-init]
[1,5]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,5]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,5]<stderr>:                                    [--trust-remote-code]
[1,5]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,5]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,5]<stderr>:                                    [--revision REVISION]
[1,5]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,5]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,5]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,5]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,5]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,5]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,5]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,5]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,5]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,5]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,5]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,5]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,5]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,5]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,5]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,5]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,5]<stderr>:                                    [--page-size PAGE_SIZE]
[1,5]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,5]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,5]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,5]<stderr>:                                    [--device DEVICE]
[1,5]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,5]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,5]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,5]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,5]<stderr>:                                    [--stream-output]
[1,5]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,5]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,5]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,5]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,5]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,5]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,5]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,5]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,5]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,5]<stderr>:                                    [--log-requests]
[1,5]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,5]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,5]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,5]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,5]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,5]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,5]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,5]<stderr>:                                    [--collect-tokens-histogram]
[1,5]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,5]<stderr>:                                    [--enable-request-time-stats-logging]
[1,5]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,5]<stderr>:                                    [--api-key API_KEY]
[1,5]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,5]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,5]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,5]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,5]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,5]<stderr>:                                    [--enable-cache-report]
[1,5]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,5]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,5]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,5]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,5]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,5]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,5]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,5]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,5]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,5]<stderr>:                                    [--enable-lora]
[1,5]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,5]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,5]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,5]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,5]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,5]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,5]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,5]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,5]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,5]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,5]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,5]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,5]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,5]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,5]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,5]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,5]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,5]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,5]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,5]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,5]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,5]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,5]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,5]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,5]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,5]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,5]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,5]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,5]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,5]<stderr>:                                    [--enable-eplb]
[1,5]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,5]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,5]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,5]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,5]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,5]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,5]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,5]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,5]<stderr>:                                    [--enable-hierarchical-cache]
[1,5]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,5]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,5]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,5]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,5]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,5]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,5]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,5]<stderr>:                                    [--enable-double-sparsity]
[1,5]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,5]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,5]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,5]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,5]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,5]<stderr>:                                    [--disable-radix-cache]
[1,5]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,5]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,5]<stderr>:                                    [--disable-cuda-graph]
[1,5]<stderr>:                                    [--disable-cuda-graph-padding]
[1,5]<stderr>:                                    [--enable-profile-cuda-graph]
[1,5]<stderr>:                                    [--enable-cudagraph-gc]
[1,5]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,5]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,5]<stderr>:                                    [--disable-outlines-disk-cache]
[1,5]<stderr>:                                    [--disable-custom-all-reduce]
[1,5]<stderr>:                                    [--enable-mscclpp]
[1,5]<stderr>:                                    [--disable-overlap-schedule]
[1,5]<stderr>:                                    [--enable-mixed-chunk]
[1,5]<stderr>:                                    [--enable-dp-attention]
[1,5]<stderr>:                                    [--enable-dp-lm-head]
[1,5]<stderr>:                                    [--enable-two-batch-overlap]
[1,5]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,5]<stderr>:                                    [--enable-torch-compile]
[1,5]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,5]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,5]<stderr>:                                    [--enable-nan-detection]
[1,5]<stderr>:                                    [--enable-p2p-check]
[1,5]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,5]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,5]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,5]<stderr>:                                    [--delete-ckpt-after-loading]
[1,5]<stderr>:                                    [--enable-memory-saver]
[1,5]<stderr>:                                    [--allow-auto-truncate]
[1,5]<stderr>:                                    [--enable-custom-logit-processor]
[1,5]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,5]<stderr>:                                    [--disable-shared-experts-fusion]
[1,5]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,5]<stderr>:                                    [--disable-fast-image-processor]
[1,5]<stderr>:                                    [--enable-return-hidden-states]
[1,5]<stderr>:                                    [--enable-triton-kernel-moe]
[1,5]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,5]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,5]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,5]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,5]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,5]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,5]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,5]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,5]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,5]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,5]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,5]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,5]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,5]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,5]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,5]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,5]<stderr>:                                    [--enable-pdmux]
[1,5]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,5]<stderr>:                                    [--weight-loader-disable-mmap]
[1,5]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,5]<stderr>:                                    [--backend BACKEND]
[1,5]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,5]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,5]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,5]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,5]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,5]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,5]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,5]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,5]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,5]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,5]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,5]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,5]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,5]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,5]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,5]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,5]<stderr>:                                    [--apply-chat-template] [--profile]
[1,5]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,5]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,5]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47474
[1,2]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,2]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,2]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,2]<stderr>:                                    [--skip-tokenizer-init]
[1,2]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,2]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,2]<stderr>:                                    [--trust-remote-code]
[1,2]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,2]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,2]<stderr>:                                    [--revision REVISION]
[1,2]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,2]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,2]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,2]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,2]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,2]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,2]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,2]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,2]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,2]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,2]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,2]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,2]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,2]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,2]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,2]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,2]<stderr>:                                    [--page-size PAGE_SIZE]
[1,2]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,2]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,2]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,2]<stderr>:                                    [--device DEVICE]
[1,2]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,2]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,2]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,2]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,2]<stderr>:                                    [--stream-output]
[1,2]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,2]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,2]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,2]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,2]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,2]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,2]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,2]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,2]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,2]<stderr>:                                    [--log-requests]
[1,2]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,2]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,2]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,2]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,2]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,2]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,2]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,2]<stderr>:                                    [--collect-tokens-histogram]
[1,2]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,2]<stderr>:                                    [--enable-request-time-stats-logging]
[1,2]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,2]<stderr>:                                    [--api-key API_KEY]
[1,2]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,2]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,2]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,2]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,2]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,2]<stderr>:                                    [--enable-cache-report]
[1,2]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,2]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,2]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,2]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,2]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,2]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,2]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,2]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,2]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,2]<stderr>:                                    [--enable-lora]
[1,2]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,2]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,2]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,2]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,2]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,2]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,2]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,2]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,2]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,2]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,2]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,2]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,2]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,2]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,2]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,2]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,2]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,2]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,2]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,2]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,2]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,2]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,2]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,2]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,2]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,2]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,2]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,2]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,2]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,2]<stderr>:                                    [--enable-eplb]
[1,2]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,2]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,2]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,2]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,2]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,2]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,2]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,2]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,2]<stderr>:                                    [--enable-hierarchical-cache]
[1,2]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,2]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,2]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,2]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,2]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,2]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,2]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,2]<stderr>:                                    [--enable-double-sparsity]
[1,2]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,2]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,2]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,2]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,2]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,2]<stderr>:                                    [--disable-radix-cache]
[1,2]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,2]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,2]<stderr>:                                    [--disable-cuda-graph]
[1,2]<stderr>:                                    [--disable-cuda-graph-padding]
[1,2]<stderr>:                                    [--enable-profile-cuda-graph]
[1,2]<stderr>:                                    [--enable-cudagraph-gc]
[1,2]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,2]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,2]<stderr>:                                    [--disable-outlines-disk-cache]
[1,2]<stderr>:                                    [--disable-custom-all-reduce]
[1,2]<stderr>:                                    [--enable-mscclpp]
[1,2]<stderr>:                                    [--disable-overlap-schedule]
[1,2]<stderr>:                                    [--enable-mixed-chunk]
[1,2]<stderr>:                                    [--enable-dp-attention]
[1,2]<stderr>:                                    [--enable-dp-lm-head]
[1,2]<stderr>:                                    [--enable-two-batch-overlap]
[1,2]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,2]<stderr>:                                    [--enable-torch-compile]
[1,2]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,2]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,2]<stderr>:                                    [--enable-nan-detection]
[1,2]<stderr>:                                    [--enable-p2p-check]
[1,2]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,2]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,2]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,2]<stderr>:                                    [--delete-ckpt-after-loading]
[1,2]<stderr>:                                    [--enable-memory-saver]
[1,2]<stderr>:                                    [--allow-auto-truncate]
[1,2]<stderr>:                                    [--enable-custom-logit-processor]
[1,2]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,2]<stderr>:                                    [--disable-shared-experts-fusion]
[1,2]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,2]<stderr>:                                    [--disable-fast-image-processor]
[1,2]<stderr>:                                    [--enable-return-hidden-states]
[1,2]<stderr>:                                    [--enable-triton-kernel-moe]
[1,2]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,2]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,2]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,2]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,2]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,2]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,2]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,2]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,2]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,2]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,2]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,2]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,2]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,2]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,2]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,2]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,2]<stderr>:                                    [--enable-pdmux]
[1,2]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,2]<stderr>:                                    [--weight-loader-disable-mmap]
[1,2]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,2]<stderr>:                                    [--backend BACKEND]
[1,2]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,2]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,2]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,2]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,2]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,2]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,2]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,2]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,2]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,2]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,2]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,2]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,2]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,2]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,2]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,2]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,2]<stderr>:                                    [--apply-chat-template] [--profile]
[1,2]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,2]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,2]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47471
[1,0]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,0]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,0]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,0]<stderr>:                                    [--skip-tokenizer-init]
[1,0]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,0]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,0]<stderr>:                                    [--trust-remote-code]
[1,0]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,0]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,0]<stderr>:                                    [--revision REVISION]
[1,0]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,0]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,0]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,0]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,0]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,0]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,0]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,0]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,0]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,0]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,0]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,0]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,0]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,0]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,0]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,0]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,0]<stderr>:                                    [--page-size PAGE_SIZE]
[1,0]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,0]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,0]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,0]<stderr>:                                    [--device DEVICE]
[1,0]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,0]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,0]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,0]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,0]<stderr>:                                    [--stream-output]
[1,0]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,0]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,0]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,0]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,0]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,0]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,0]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,0]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,0]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,0]<stderr>:                                    [--log-requests]
[1,0]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,0]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,0]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,0]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,0]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,0]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,0]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,0]<stderr>:                                    [--collect-tokens-histogram]
[1,0]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,0]<stderr>:                                    [--enable-request-time-stats-logging]
[1,0]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,0]<stderr>:                                    [--api-key API_KEY]
[1,0]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,0]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,0]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,0]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,0]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,0]<stderr>:                                    [--enable-cache-report]
[1,0]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,0]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,0]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,0]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,0]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,0]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,0]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,0]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,0]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,0]<stderr>:                                    [--enable-lora]
[1,0]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,0]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,0]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,0]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,0]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,0]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,0]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,0]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,0]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,0]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,0]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,0]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,0]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,0]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,0]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,0]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,0]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,0]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,0]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,0]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,0]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,0]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,0]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,0]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,0]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,0]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,0]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,0]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,0]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,0]<stderr>:                                    [--enable-eplb]
[1,0]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,0]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,0]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,0]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,0]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,0]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,0]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,0]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,0]<stderr>:                                    [--enable-hierarchical-cache]
[1,0]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,0]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,0]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,0]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,0]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,0]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,0]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,0]<stderr>:                                    [--enable-double-sparsity]
[1,0]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,0]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,0]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,0]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,0]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,0]<stderr>:                                    [--disable-radix-cache]
[1,0]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,0]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,0]<stderr>:                                    [--disable-cuda-graph]
[1,0]<stderr>:                                    [--disable-cuda-graph-padding]
[1,0]<stderr>:                                    [--enable-profile-cuda-graph]
[1,0]<stderr>:                                    [--enable-cudagraph-gc]
[1,0]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,0]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,0]<stderr>:                                    [--disable-outlines-disk-cache]
[1,0]<stderr>:                                    [--disable-custom-all-reduce]
[1,0]<stderr>:                                    [--enable-mscclpp]
[1,0]<stderr>:                                    [--disable-overlap-schedule]
[1,0]<stderr>:                                    [--enable-mixed-chunk]
[1,0]<stderr>:                                    [--enable-dp-attention]
[1,0]<stderr>:                                    [--enable-dp-lm-head]
[1,0]<stderr>:                                    [--enable-two-batch-overlap]
[1,0]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,0]<stderr>:                                    [--enable-torch-compile]
[1,0]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,0]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,0]<stderr>:                                    [--enable-nan-detection]
[1,0]<stderr>:                                    [--enable-p2p-check]
[1,0]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,0]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,0]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,0]<stderr>:                                    [--delete-ckpt-after-loading]
[1,0]<stderr>:                                    [--enable-memory-saver]
[1,0]<stderr>:                                    [--allow-auto-truncate]
[1,0]<stderr>:                                    [--enable-custom-logit-processor]
[1,0]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,0]<stderr>:                                    [--disable-shared-experts-fusion]
[1,0]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,0]<stderr>:                                    [--disable-fast-image-processor]
[1,0]<stderr>:                                    [--enable-return-hidden-states]
[1,0]<stderr>:                                    [--enable-triton-kernel-moe]
[1,0]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,0]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,0]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,0]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,0]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,0]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,0]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,0]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,0]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,0]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,0]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,0]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,0]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,0]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,0]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,0]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,0]<stderr>:                                    [--enable-pdmux]
[1,0]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,0]<stderr>:                                    [--weight-loader-disable-mmap]
[1,0]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,0]<stderr>:                                    [--backend BACKEND]
[1,0]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,0]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,0]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,0]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,0]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,0]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,0]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,0]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,0]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,0]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,0]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,0]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,0]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,0]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,0]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,0]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,0]<stderr>:                                    [--apply-chat-template] [--profile]
[1,0]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,0]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,0]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47469
[1,9]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,9]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,9]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,9]<stderr>:                                    [--skip-tokenizer-init]
[1,9]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,9]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,9]<stderr>:                                    [--trust-remote-code]
[1,9]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,9]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,9]<stderr>:                                    [--revision REVISION]
[1,9]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,9]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,9]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,9]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,9]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,9]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,9]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,9]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,9]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,9]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,9]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,9]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,9]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,9]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,9]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,9]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,9]<stderr>:                                    [--page-size PAGE_SIZE]
[1,9]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,9]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,9]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,9]<stderr>:                                    [--device DEVICE]
[1,9]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,9]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,9]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,9]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,9]<stderr>:                                    [--stream-output]
[1,9]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,9]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,9]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,9]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,9]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,9]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,9]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,9]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,9]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,9]<stderr>:                                    [--log-requests]
[1,9]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,9]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,9]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,9]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,9]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,9]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,9]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,9]<stderr>:                                    [--collect-tokens-histogram]
[1,9]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,9]<stderr>:                                    [--enable-request-time-stats-logging]
[1,9]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,9]<stderr>:                                    [--api-key API_KEY]
[1,9]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,9]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,9]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,9]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,9]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,9]<stderr>:                                    [--enable-cache-report]
[1,9]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,9]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,9]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,9]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,9]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,9]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,9]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,9]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,9]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,9]<stderr>:                                    [--enable-lora]
[1,9]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,9]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,9]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,9]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,9]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,9]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,9]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,9]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,9]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,9]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,9]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,9]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,9]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,9]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,9]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,9]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,9]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,9]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,9]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,9]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,9]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,9]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,9]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,9]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,9]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,9]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,9]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,9]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,9]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,9]<stderr>:                                    [--enable-eplb]
[1,9]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,9]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,9]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,9]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,9]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,9]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,9]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,9]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,9]<stderr>:                                    [--enable-hierarchical-cache]
[1,9]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,9]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,9]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,9]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,9]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,9]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,9]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,9]<stderr>:                                    [--enable-double-sparsity]
[1,9]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,9]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,9]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,9]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,9]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,9]<stderr>:                                    [--disable-radix-cache]
[1,9]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,9]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,9]<stderr>:                                    [--disable-cuda-graph]
[1,9]<stderr>:                                    [--disable-cuda-graph-padding]
[1,9]<stderr>:                                    [--enable-profile-cuda-graph]
[1,9]<stderr>:                                    [--enable-cudagraph-gc]
[1,9]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,9]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,9]<stderr>:                                    [--disable-outlines-disk-cache]
[1,9]<stderr>:                                    [--disable-custom-all-reduce]
[1,9]<stderr>:                                    [--enable-mscclpp]
[1,9]<stderr>:                                    [--disable-overlap-schedule]
[1,9]<stderr>:                                    [--enable-mixed-chunk]
[1,9]<stderr>:                                    [--enable-dp-attention]
[1,9]<stderr>:                                    [--enable-dp-lm-head]
[1,9]<stderr>:                                    [--enable-two-batch-overlap]
[1,9]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,9]<stderr>:                                    [--enable-torch-compile]
[1,9]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,9]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,9]<stderr>:                                    [--enable-nan-detection]
[1,9]<stderr>:                                    [--enable-p2p-check]
[1,9]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,9]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,9]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,9]<stderr>:                                    [--delete-ckpt-after-loading]
[1,9]<stderr>:                                    [--enable-memory-saver]
[1,9]<stderr>:                                    [--allow-auto-truncate]
[1,9]<stderr>:                                    [--enable-custom-logit-processor]
[1,9]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,9]<stderr>:                                    [--disable-shared-experts-fusion]
[1,9]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,9]<stderr>:                                    [--disable-fast-image-processor]
[1,9]<stderr>:                                    [--enable-return-hidden-states]
[1,9]<stderr>:                                    [--enable-triton-kernel-moe]
[1,9]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,9]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,9]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,9]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,9]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,9]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,9]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,9]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,9]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,9]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,9]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,9]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,9]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,9]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,9]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,9]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,9]<stderr>:                                    [--enable-pdmux]
[1,9]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,9]<stderr>:                                    [--weight-loader-disable-mmap]
[1,9]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,9]<stderr>:                                    [--backend BACKEND]
[1,9]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,9]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,9]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,9]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,9]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,9]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,9]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,9]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,9]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,9]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,9]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,9]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,9]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,9]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,9]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,9]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,9]<stderr>:                                    [--apply-chat-template] [--profile]
[1,9]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,9]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,9]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47478
[1,7]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,7]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,7]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,7]<stderr>:                                    [--skip-tokenizer-init]
[1,7]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,7]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,7]<stderr>:                                    [--trust-remote-code]
[1,7]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,7]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,7]<stderr>:                                    [--revision REVISION]
[1,7]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,7]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,7]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,7]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,7]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,7]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,7]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,7]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,7]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,7]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,7]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,7]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,7]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,7]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,7]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,7]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,7]<stderr>:                                    [--page-size PAGE_SIZE]
[1,7]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,7]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,7]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,7]<stderr>:                                    [--device DEVICE]
[1,7]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,7]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,7]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,7]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,7]<stderr>:                                    [--stream-output]
[1,7]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,7]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,7]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,7]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,7]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,7]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,7]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,7]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,7]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,7]<stderr>:                                    [--log-requests]
[1,7]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,7]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,7]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,7]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,7]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,7]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,7]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,7]<stderr>:                                    [--collect-tokens-histogram]
[1,7]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,7]<stderr>:                                    [--enable-request-time-stats-logging]
[1,7]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,7]<stderr>:                                    [--api-key API_KEY]
[1,7]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,7]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,7]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,7]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,7]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,7]<stderr>:                                    [--enable-cache-report]
[1,7]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,7]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,7]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,7]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,7]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,7]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,7]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,7]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,7]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,7]<stderr>:                                    [--enable-lora]
[1,7]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,7]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,7]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,7]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,7]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,7]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,7]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,7]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,7]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,7]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,7]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,7]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,7]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,7]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,7]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,7]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,7]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,7]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,7]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,7]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,7]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,7]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,7]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,7]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,7]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,7]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,7]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,7]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,7]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,7]<stderr>:                                    [--enable-eplb]
[1,7]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,7]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,7]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,7]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,7]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,7]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,7]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,7]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,7]<stderr>:                                    [--enable-hierarchical-cache]
[1,7]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,7]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,7]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,7]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,7]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,7]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,7]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,7]<stderr>:                                    [--enable-double-sparsity]
[1,7]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,7]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,7]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,7]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,7]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,7]<stderr>:                                    [--disable-radix-cache]
[1,7]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,7]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,7]<stderr>:                                    [--disable-cuda-graph]
[1,7]<stderr>:                                    [--disable-cuda-graph-padding]
[1,7]<stderr>:                                    [--enable-profile-cuda-graph]
[1,7]<stderr>:                                    [--enable-cudagraph-gc]
[1,7]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,7]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,7]<stderr>:                                    [--disable-outlines-disk-cache]
[1,7]<stderr>:                                    [--disable-custom-all-reduce]
[1,7]<stderr>:                                    [--enable-mscclpp]
[1,7]<stderr>:                                    [--disable-overlap-schedule]
[1,7]<stderr>:                                    [--enable-mixed-chunk]
[1,7]<stderr>:                                    [--enable-dp-attention]
[1,7]<stderr>:                                    [--enable-dp-lm-head]
[1,7]<stderr>:                                    [--enable-two-batch-overlap]
[1,7]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,7]<stderr>:                                    [--enable-torch-compile]
[1,7]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,7]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,7]<stderr>:                                    [--enable-nan-detection]
[1,7]<stderr>:                                    [--enable-p2p-check]
[1,7]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,7]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,7]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,7]<stderr>:                                    [--delete-ckpt-after-loading]
[1,7]<stderr>:                                    [--enable-memory-saver]
[1,7]<stderr>:                                    [--allow-auto-truncate]
[1,7]<stderr>:                                    [--enable-custom-logit-processor]
[1,7]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,7]<stderr>:                                    [--disable-shared-experts-fusion]
[1,7]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,7]<stderr>:                                    [--disable-fast-image-processor]
[1,7]<stderr>:                                    [--enable-return-hidden-states]
[1,7]<stderr>:                                    [--enable-triton-kernel-moe]
[1,7]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,7]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,7]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,7]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,7]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,7]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,7]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,7]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,7]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,7]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,7]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,7]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,7]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,7]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,7]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,7]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,7]<stderr>:                                    [--enable-pdmux]
[1,7]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,7]<stderr>:                                    [--weight-loader-disable-mmap]
[1,7]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,7]<stderr>:                                    [--backend BACKEND]
[1,7]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,7]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,7]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,7]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,7]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,7]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,7]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,7]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,7]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,7]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,7]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,7]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,7]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,7]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,7]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,7]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,7]<stderr>:                                    [--apply-chat-template] [--profile]
[1,7]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,7]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,7]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47476
[1,3]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,3]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,3]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,3]<stderr>:                                    [--skip-tokenizer-init]
[1,3]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,3]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,3]<stderr>:                                    [--trust-remote-code]
[1,3]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,3]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,3]<stderr>:                                    [--revision REVISION]
[1,3]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,3]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,3]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,3]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,3]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,3]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,3]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,3]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,3]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,3]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,3]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,3]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,3]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,3]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,3]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,3]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,3]<stderr>:                                    [--page-size PAGE_SIZE]
[1,3]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,3]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,3]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,3]<stderr>:                                    [--device DEVICE]
[1,3]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,3]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,3]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,3]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,3]<stderr>:                                    [--stream-output]
[1,3]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,3]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,3]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,3]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,3]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,3]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,3]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,3]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,3]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,3]<stderr>:                                    [--log-requests]
[1,3]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,3]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,3]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,3]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,3]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,3]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,3]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,3]<stderr>:                                    [--collect-tokens-histogram]
[1,3]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,3]<stderr>:                                    [--enable-request-time-stats-logging]
[1,3]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,3]<stderr>:                                    [--api-key API_KEY]
[1,3]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,3]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,3]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,3]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,3]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,3]<stderr>:                                    [--enable-cache-report]
[1,3]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,3]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,3]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,3]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,3]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,3]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,3]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,3]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,3]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,3]<stderr>:                                    [--enable-lora]
[1,3]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,3]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,3]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,3]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,3]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,3]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,3]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,3]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,3]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,3]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,3]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,3]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,3]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,3]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,3]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,3]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,3]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,3]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,3]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,3]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,3]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,3]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,3]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,3]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,3]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,3]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,3]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,3]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,3]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,3]<stderr>:                                    [--enable-eplb]
[1,3]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,3]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,3]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,3]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,3]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,3]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,3]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,3]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,3]<stderr>:                                    [--enable-hierarchical-cache]
[1,3]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,3]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,3]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,3]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,3]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,3]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,3]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,3]<stderr>:                                    [--enable-double-sparsity]
[1,3]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,3]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,3]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,3]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,3]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,3]<stderr>:                                    [--disable-radix-cache]
[1,3]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,3]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,3]<stderr>:                                    [--disable-cuda-graph]
[1,3]<stderr>:                                    [--disable-cuda-graph-padding]
[1,3]<stderr>:                                    [--enable-profile-cuda-graph]
[1,3]<stderr>:                                    [--enable-cudagraph-gc]
[1,3]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,3]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,3]<stderr>:                                    [--disable-outlines-disk-cache]
[1,3]<stderr>:                                    [--disable-custom-all-reduce]
[1,3]<stderr>:                                    [--enable-mscclpp]
[1,3]<stderr>:                                    [--disable-overlap-schedule]
[1,3]<stderr>:                                    [--enable-mixed-chunk]
[1,3]<stderr>:                                    [--enable-dp-attention]
[1,3]<stderr>:                                    [--enable-dp-lm-head]
[1,3]<stderr>:                                    [--enable-two-batch-overlap]
[1,3]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,3]<stderr>:                                    [--enable-torch-compile]
[1,3]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,3]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,3]<stderr>:                                    [--enable-nan-detection]
[1,3]<stderr>:                                    [--enable-p2p-check]
[1,3]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,3]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,3]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,3]<stderr>:                                    [--delete-ckpt-after-loading]
[1,3]<stderr>:                                    [--enable-memory-saver]
[1,3]<stderr>:                                    [--allow-auto-truncate]
[1,3]<stderr>:                                    [--enable-custom-logit-processor]
[1,3]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,3]<stderr>:                                    [--disable-shared-experts-fusion]
[1,3]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,3]<stderr>:                                    [--disable-fast-image-processor]
[1,3]<stderr>:                                    [--enable-return-hidden-states]
[1,3]<stderr>:                                    [--enable-triton-kernel-moe]
[1,3]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,3]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,3]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,3]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,3]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,3]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,3]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,3]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,3]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,3]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,3]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,3]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,3]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,3]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,3]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,3]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,3]<stderr>:                                    [--enable-pdmux]
[1,3]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,3]<stderr>:                                    [--weight-loader-disable-mmap]
[1,3]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,3]<stderr>:                                    [--backend BACKEND]
[1,3]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,3]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,3]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,3]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,3]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,3]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,3]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,3]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,3]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,3]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,3]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,3]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,3]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,3]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,3]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,3]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,3]<stderr>:                                    [--apply-chat-template] [--profile]
[1,3]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,3]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,3]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47472
[1,11]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,11]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,11]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,11]<stderr>:                                    [--skip-tokenizer-init]
[1,11]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,11]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,11]<stderr>:                                    [--trust-remote-code]
[1,11]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,11]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,11]<stderr>:                                    [--revision REVISION]
[1,11]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,11]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,11]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,11]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,11]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,11]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,11]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,11]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,11]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,11]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,11]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,11]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,11]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,11]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,11]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,11]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,11]<stderr>:                                    [--page-size PAGE_SIZE]
[1,11]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,11]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,11]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,11]<stderr>:                                    [--device DEVICE]
[1,11]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,11]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,11]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,11]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,11]<stderr>:                                    [--stream-output]
[1,11]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,11]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,11]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,11]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,11]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,11]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,11]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,11]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,11]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,11]<stderr>:                                    [--log-requests]
[1,11]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,11]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,11]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,11]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,11]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,11]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,11]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,11]<stderr>:                                    [--collect-tokens-histogram]
[1,11]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,11]<stderr>:                                    [--enable-request-time-stats-logging]
[1,11]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,11]<stderr>:                                    [--api-key API_KEY]
[1,11]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,11]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,11]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,11]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,11]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,11]<stderr>:                                    [--enable-cache-report]
[1,11]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,11]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,11]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,11]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,11]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,11]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,11]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,11]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,11]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,11]<stderr>:                                    [--enable-lora]
[1,11]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,11]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,11]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,11]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,11]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,11]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,11]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,11]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,11]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,11]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,11]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,11]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,11]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,11]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,11]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,11]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,11]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,11]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,11]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,11]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,11]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,11]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,11]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,11]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,11]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,11]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,11]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,11]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,11]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,11]<stderr>:                                    [--enable-eplb]
[1,11]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,11]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,11]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,11]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,11]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,11]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,11]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,11]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,11]<stderr>:                                    [--enable-hierarchical-cache]
[1,11]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,11]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,11]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,11]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,11]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,11]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,11]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,11]<stderr>:                                    [--enable-double-sparsity]
[1,11]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,11]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,11]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,11]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,11]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,11]<stderr>:                                    [--disable-radix-cache]
[1,11]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,11]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,11]<stderr>:                                    [--disable-cuda-graph]
[1,11]<stderr>:                                    [--disable-cuda-graph-padding]
[1,11]<stderr>:                                    [--enable-profile-cuda-graph]
[1,11]<stderr>:                                    [--enable-cudagraph-gc]
[1,11]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,11]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,11]<stderr>:                                    [--disable-outlines-disk-cache]
[1,11]<stderr>:                                    [--disable-custom-all-reduce]
[1,11]<stderr>:                                    [--enable-mscclpp]
[1,11]<stderr>:                                    [--disable-overlap-schedule]
[1,11]<stderr>:                                    [--enable-mixed-chunk]
[1,11]<stderr>:                                    [--enable-dp-attention]
[1,11]<stderr>:                                    [--enable-dp-lm-head]
[1,11]<stderr>:                                    [--enable-two-batch-overlap]
[1,11]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,11]<stderr>:                                    [--enable-torch-compile]
[1,11]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,11]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,11]<stderr>:                                    [--enable-nan-detection]
[1,11]<stderr>:                                    [--enable-p2p-check]
[1,11]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,11]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,11]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,11]<stderr>:                                    [--delete-ckpt-after-loading]
[1,11]<stderr>:                                    [--enable-memory-saver]
[1,11]<stderr>:                                    [--allow-auto-truncate]
[1,11]<stderr>:                                    [--enable-custom-logit-processor]
[1,11]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,11]<stderr>:                                    [--disable-shared-experts-fusion]
[1,11]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,11]<stderr>:                                    [--disable-fast-image-processor]
[1,11]<stderr>:                                    [--enable-return-hidden-states]
[1,11]<stderr>:                                    [--enable-triton-kernel-moe]
[1,11]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,11]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,11]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,11]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,11]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,11]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,11]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,11]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,11]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,11]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,11]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,11]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,11]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,11]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,11]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,11]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,11]<stderr>:                                    [--enable-pdmux]
[1,11]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,11]<stderr>:                                    [--weight-loader-disable-mmap]
[1,11]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,11]<stderr>:                                    [--backend BACKEND]
[1,11]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,11]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,11]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,11]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,11]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,11]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,11]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,11]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,11]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,11]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,11]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,11]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,11]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,11]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,11]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,11]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,11]<stderr>:                                    [--apply-chat-template] [--profile]
[1,11]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,11]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,11]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47480
[1,8]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,8]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,8]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,8]<stderr>:                                    [--skip-tokenizer-init]
[1,8]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,8]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,8]<stderr>:                                    [--trust-remote-code]
[1,8]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,8]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,8]<stderr>:                                    [--revision REVISION]
[1,8]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,8]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,8]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,8]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,8]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,8]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,8]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,8]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,8]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,8]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,8]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,8]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,8]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,8]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,8]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,8]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,8]<stderr>:                                    [--page-size PAGE_SIZE]
[1,8]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,8]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,8]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,8]<stderr>:                                    [--device DEVICE]
[1,8]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,8]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,8]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,8]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,8]<stderr>:                                    [--stream-output]
[1,8]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,8]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,8]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,8]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,8]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,8]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,8]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,8]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,8]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,8]<stderr>:                                    [--log-requests]
[1,8]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,8]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,8]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,8]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,8]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,8]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,8]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,8]<stderr>:                                    [--collect-tokens-histogram]
[1,8]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,8]<stderr>:                                    [--enable-request-time-stats-logging]
[1,8]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,8]<stderr>:                                    [--api-key API_KEY]
[1,8]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,8]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,8]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,8]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,8]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,8]<stderr>:                                    [--enable-cache-report]
[1,8]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,8]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,8]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,8]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,8]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,8]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,8]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,8]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,8]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,8]<stderr>:                                    [--enable-lora]
[1,8]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,8]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,8]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,8]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,8]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,8]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,8]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,8]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,8]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,8]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,8]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,8]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,8]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,8]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,8]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,8]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,8]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,8]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,8]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,8]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,8]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,8]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,8]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,8]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,8]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,8]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,8]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,8]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,8]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,8]<stderr>:                                    [--enable-eplb]
[1,8]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,8]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,8]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,8]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,8]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,8]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,8]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,8]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,8]<stderr>:                                    [--enable-hierarchical-cache]
[1,8]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,8]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,8]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,8]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,8]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,8]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,8]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,8]<stderr>:                                    [--enable-double-sparsity]
[1,8]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,8]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,8]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,8]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,8]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,8]<stderr>:                                    [--disable-radix-cache]
[1,8]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,8]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,8]<stderr>:                                    [--disable-cuda-graph]
[1,8]<stderr>:                                    [--disable-cuda-graph-padding]
[1,8]<stderr>:                                    [--enable-profile-cuda-graph]
[1,8]<stderr>:                                    [--enable-cudagraph-gc]
[1,8]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,8]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,8]<stderr>:                                    [--disable-outlines-disk-cache]
[1,8]<stderr>:                                    [--disable-custom-all-reduce]
[1,8]<stderr>:                                    [--enable-mscclpp]
[1,8]<stderr>:                                    [--disable-overlap-schedule]
[1,8]<stderr>:                                    [--enable-mixed-chunk]
[1,8]<stderr>:                                    [--enable-dp-attention]
[1,8]<stderr>:                                    [--enable-dp-lm-head]
[1,8]<stderr>:                                    [--enable-two-batch-overlap]
[1,8]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,8]<stderr>:                                    [--enable-torch-compile]
[1,8]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,8]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,8]<stderr>:                                    [--enable-nan-detection]
[1,8]<stderr>:                                    [--enable-p2p-check]
[1,8]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,8]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,8]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,8]<stderr>:                                    [--delete-ckpt-after-loading]
[1,8]<stderr>:                                    [--enable-memory-saver]
[1,8]<stderr>:                                    [--allow-auto-truncate]
[1,8]<stderr>:                                    [--enable-custom-logit-processor]
[1,8]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,8]<stderr>:                                    [--disable-shared-experts-fusion]
[1,8]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,8]<stderr>:                                    [--disable-fast-image-processor]
[1,8]<stderr>:                                    [--enable-return-hidden-states]
[1,8]<stderr>:                                    [--enable-triton-kernel-moe]
[1,8]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,8]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,8]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,8]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,8]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,8]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,8]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,8]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,8]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,8]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,8]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,8]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,8]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,8]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,8]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,8]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,8]<stderr>:                                    [--enable-pdmux]
[1,8]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,8]<stderr>:                                    [--weight-loader-disable-mmap]
[1,8]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,8]<stderr>:                                    [--backend BACKEND]
[1,8]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,8]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,8]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,8]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,8]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,8]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,8]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,8]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,8]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,8]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,8]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,8]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,8]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,8]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,8]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,8]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,8]<stderr>:                                    [--apply-chat-template] [--profile]
[1,8]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,8]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,8]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47477
[1,15]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,15]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,15]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,15]<stderr>:                                    [--skip-tokenizer-init]
[1,15]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,15]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,15]<stderr>:                                    [--trust-remote-code]
[1,15]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,15]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,15]<stderr>:                                    [--revision REVISION]
[1,15]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,15]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,15]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,15]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,15]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,15]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,15]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,15]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,15]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,15]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,15]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,15]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,15]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,15]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,15]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,15]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,15]<stderr>:                                    [--page-size PAGE_SIZE]
[1,15]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,15]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,15]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,15]<stderr>:                                    [--device DEVICE]
[1,15]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,15]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,15]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,15]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,15]<stderr>:                                    [--stream-output]
[1,15]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,15]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,15]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,15]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,15]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,15]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,15]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,15]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,15]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,15]<stderr>:                                    [--log-requests]
[1,15]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,15]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,15]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,15]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,15]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,15]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,15]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,15]<stderr>:                                    [--collect-tokens-histogram]
[1,15]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,15]<stderr>:                                    [--enable-request-time-stats-logging]
[1,15]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,15]<stderr>:                                    [--api-key API_KEY]
[1,15]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,15]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,15]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,15]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,15]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,15]<stderr>:                                    [--enable-cache-report]
[1,15]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,15]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,15]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,15]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,15]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,15]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,15]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,15]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,15]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,15]<stderr>:                                    [--enable-lora]
[1,15]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,15]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,15]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,15]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,15]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,15]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,15]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,15]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,15]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,15]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,15]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,15]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,15]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,15]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,15]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,15]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,15]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,15]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,15]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,15]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,15]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,15]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,15]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,15]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,15]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,15]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,15]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,15]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,15]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,15]<stderr>:                                    [--enable-eplb]
[1,15]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,15]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,15]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,15]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,15]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,15]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,15]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,15]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,15]<stderr>:                                    [--enable-hierarchical-cache]
[1,15]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,15]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,15]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,15]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,15]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,15]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,15]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,15]<stderr>:                                    [--enable-double-sparsity]
[1,15]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,15]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,15]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,15]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,15]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,15]<stderr>:                                    [--disable-radix-cache]
[1,15]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,15]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,15]<stderr>:                                    [--disable-cuda-graph]
[1,15]<stderr>:                                    [--disable-cuda-graph-padding]
[1,15]<stderr>:                                    [--enable-profile-cuda-graph]
[1,15]<stderr>:                                    [--enable-cudagraph-gc]
[1,15]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,15]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,15]<stderr>:                                    [--disable-outlines-disk-cache]
[1,15]<stderr>:                                    [--disable-custom-all-reduce]
[1,15]<stderr>:                                    [--enable-mscclpp]
[1,15]<stderr>:                                    [--disable-overlap-schedule]
[1,15]<stderr>:                                    [--enable-mixed-chunk]
[1,15]<stderr>:                                    [--enable-dp-attention]
[1,15]<stderr>:                                    [--enable-dp-lm-head]
[1,15]<stderr>:                                    [--enable-two-batch-overlap]
[1,15]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,15]<stderr>:                                    [--enable-torch-compile]
[1,15]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,15]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,15]<stderr>:                                    [--enable-nan-detection]
[1,15]<stderr>:                                    [--enable-p2p-check]
[1,15]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,15]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,15]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,15]<stderr>:                                    [--delete-ckpt-after-loading]
[1,15]<stderr>:                                    [--enable-memory-saver]
[1,15]<stderr>:                                    [--allow-auto-truncate]
[1,15]<stderr>:                                    [--enable-custom-logit-processor]
[1,15]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,15]<stderr>:                                    [--disable-shared-experts-fusion]
[1,15]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,15]<stderr>:                                    [--disable-fast-image-processor]
[1,15]<stderr>:                                    [--enable-return-hidden-states]
[1,15]<stderr>:                                    [--enable-triton-kernel-moe]
[1,15]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,15]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,15]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,15]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,15]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,15]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,15]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,15]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,15]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,15]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,15]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,15]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,15]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,15]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,15]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,15]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,15]<stderr>:                                    [--enable-pdmux]
[1,15]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,15]<stderr>:                                    [--weight-loader-disable-mmap]
[1,15]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,15]<stderr>:                                    [--backend BACKEND]
[1,15]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,15]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,15]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,15]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,15]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,15]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,15]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,15]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,15]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,15]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,15]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,15]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,15]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,15]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,15]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,15]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,15]<stderr>:                                    [--apply-chat-template] [--profile]
[1,15]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,15]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,15]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47484
[1,13]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,13]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,13]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,13]<stderr>:                                    [--skip-tokenizer-init]
[1,13]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,13]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,13]<stderr>:                                    [--trust-remote-code]
[1,13]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,13]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,13]<stderr>:                                    [--revision REVISION]
[1,13]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,13]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,13]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,13]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,13]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,13]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,13]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,13]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,13]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,13]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,13]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,13]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,13]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,13]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,13]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,13]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,13]<stderr>:                                    [--page-size PAGE_SIZE]
[1,13]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,13]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,13]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,13]<stderr>:                                    [--device DEVICE]
[1,13]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,13]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,13]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,13]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,13]<stderr>:                                    [--stream-output]
[1,13]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,13]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,13]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,13]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,13]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,13]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,13]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,13]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,13]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,13]<stderr>:                                    [--log-requests]
[1,13]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,13]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,13]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,13]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,13]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,13]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,13]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,13]<stderr>:                                    [--collect-tokens-histogram]
[1,13]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,13]<stderr>:                                    [--enable-request-time-stats-logging]
[1,13]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,13]<stderr>:                                    [--api-key API_KEY]
[1,13]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,13]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,13]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,13]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,13]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,13]<stderr>:                                    [--enable-cache-report]
[1,13]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,13]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,13]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,13]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,13]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,13]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,13]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,13]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,13]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,13]<stderr>:                                    [--enable-lora]
[1,13]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,13]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,13]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,13]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,13]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,13]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,13]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,13]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,13]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,13]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,13]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,13]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,13]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,13]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,13]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,13]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,13]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,13]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,13]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,13]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,13]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,13]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,13]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,13]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,13]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,13]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,13]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,13]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,13]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,13]<stderr>:                                    [--enable-eplb]
[1,13]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,13]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,13]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,13]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,13]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,13]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,13]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,13]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,13]<stderr>:                                    [--enable-hierarchical-cache]
[1,13]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,13]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,13]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,13]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,13]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,13]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,13]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,13]<stderr>:                                    [--enable-double-sparsity]
[1,13]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,13]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,13]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,13]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,13]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,13]<stderr>:                                    [--disable-radix-cache]
[1,13]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,13]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,13]<stderr>:                                    [--disable-cuda-graph]
[1,13]<stderr>:                                    [--disable-cuda-graph-padding]
[1,13]<stderr>:                                    [--enable-profile-cuda-graph]
[1,13]<stderr>:                                    [--enable-cudagraph-gc]
[1,13]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,13]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,13]<stderr>:                                    [--disable-outlines-disk-cache]
[1,13]<stderr>:                                    [--disable-custom-all-reduce]
[1,13]<stderr>:                                    [--enable-mscclpp]
[1,13]<stderr>:                                    [--disable-overlap-schedule]
[1,13]<stderr>:                                    [--enable-mixed-chunk]
[1,13]<stderr>:                                    [--enable-dp-attention]
[1,13]<stderr>:                                    [--enable-dp-lm-head]
[1,13]<stderr>:                                    [--enable-two-batch-overlap]
[1,13]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,13]<stderr>:                                    [--enable-torch-compile]
[1,13]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,13]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,13]<stderr>:                                    [--enable-nan-detection]
[1,13]<stderr>:                                    [--enable-p2p-check]
[1,13]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,13]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,13]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,13]<stderr>:                                    [--delete-ckpt-after-loading]
[1,13]<stderr>:                                    [--enable-memory-saver]
[1,13]<stderr>:                                    [--allow-auto-truncate]
[1,13]<stderr>:                                    [--enable-custom-logit-processor]
[1,13]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,13]<stderr>:                                    [--disable-shared-experts-fusion]
[1,13]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,13]<stderr>:                                    [--disable-fast-image-processor]
[1,13]<stderr>:                                    [--enable-return-hidden-states]
[1,13]<stderr>:                                    [--enable-triton-kernel-moe]
[1,13]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,13]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,13]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,13]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,13]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,13]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,13]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,13]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,13]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,13]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,13]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,13]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,13]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,13]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,13]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,13]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,13]<stderr>:                                    [--enable-pdmux]
[1,13]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,13]<stderr>:                                    [--weight-loader-disable-mmap]
[1,13]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,13]<stderr>:                                    [--backend BACKEND]
[1,13]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,13]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,13]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,13]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,13]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,13]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,13]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,13]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,13]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,13]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,13]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,13]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,13]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,13]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,13]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,13]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,13]<stderr>:                                    [--apply-chat-template] [--profile]
[1,13]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,13]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,13]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47482
[1,6]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,6]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,6]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,6]<stderr>:                                    [--skip-tokenizer-init]
[1,6]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,6]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,6]<stderr>:                                    [--trust-remote-code]
[1,6]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,6]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,6]<stderr>:                                    [--revision REVISION]
[1,6]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,6]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,6]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,6]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,6]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,6]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,6]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,6]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,6]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,6]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,6]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,6]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,6]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,6]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,6]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,6]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,6]<stderr>:                                    [--page-size PAGE_SIZE]
[1,6]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,6]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,6]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,6]<stderr>:                                    [--device DEVICE]
[1,6]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,6]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,6]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,6]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,6]<stderr>:                                    [--stream-output]
[1,6]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,6]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,6]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,6]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,6]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,6]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,6]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,6]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,6]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,6]<stderr>:                                    [--log-requests]
[1,6]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,6]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,6]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,6]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,6]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,6]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,6]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,6]<stderr>:                                    [--collect-tokens-histogram]
[1,6]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,6]<stderr>:                                    [--enable-request-time-stats-logging]
[1,6]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,6]<stderr>:                                    [--api-key API_KEY]
[1,6]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,6]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,6]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,6]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,6]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,6]<stderr>:                                    [--enable-cache-report]
[1,6]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,6]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,6]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,6]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,6]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,6]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,6]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,6]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,6]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,6]<stderr>:                                    [--enable-lora]
[1,6]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,6]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,6]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,6]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,6]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,6]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,6]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,6]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,6]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,6]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,6]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,6]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,6]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,6]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,6]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,6]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,6]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,6]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,6]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,6]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,6]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,6]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,6]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,6]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,6]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,6]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,6]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,6]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,6]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,6]<stderr>:                                    [--enable-eplb]
[1,6]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,6]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,6]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,6]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,6]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,6]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,6]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,6]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,6]<stderr>:                                    [--enable-hierarchical-cache]
[1,6]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,6]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,6]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,6]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,6]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,6]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,6]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,6]<stderr>:                                    [--enable-double-sparsity]
[1,6]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,6]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,6]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,6]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,6]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,6]<stderr>:                                    [--disable-radix-cache]
[1,6]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,6]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,6]<stderr>:                                    [--disable-cuda-graph]
[1,6]<stderr>:                                    [--disable-cuda-graph-padding]
[1,6]<stderr>:                                    [--enable-profile-cuda-graph]
[1,6]<stderr>:                                    [--enable-cudagraph-gc]
[1,6]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,6]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,6]<stderr>:                                    [--disable-outlines-disk-cache]
[1,6]<stderr>:                                    [--disable-custom-all-reduce]
[1,6]<stderr>:                                    [--enable-mscclpp]
[1,6]<stderr>:                                    [--disable-overlap-schedule]
[1,6]<stderr>:                                    [--enable-mixed-chunk]
[1,6]<stderr>:                                    [--enable-dp-attention]
[1,6]<stderr>:                                    [--enable-dp-lm-head]
[1,6]<stderr>:                                    [--enable-two-batch-overlap]
[1,6]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,6]<stderr>:                                    [--enable-torch-compile]
[1,6]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,6]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,6]<stderr>:                                    [--enable-nan-detection]
[1,6]<stderr>:                                    [--enable-p2p-check]
[1,6]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,6]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,6]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,6]<stderr>:                                    [--delete-ckpt-after-loading]
[1,6]<stderr>:                                    [--enable-memory-saver]
[1,6]<stderr>:                                    [--allow-auto-truncate]
[1,6]<stderr>:                                    [--enable-custom-logit-processor]
[1,6]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,6]<stderr>:                                    [--disable-shared-experts-fusion]
[1,6]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,6]<stderr>:                                    [--disable-fast-image-processor]
[1,6]<stderr>:                                    [--enable-return-hidden-states]
[1,6]<stderr>:                                    [--enable-triton-kernel-moe]
[1,6]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,6]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,6]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,6]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,6]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,6]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,6]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,6]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,6]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,6]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,6]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,6]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,6]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,6]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,6]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,6]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,6]<stderr>:                                    [--enable-pdmux]
[1,6]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,6]<stderr>:                                    [--weight-loader-disable-mmap]
[1,6]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,6]<stderr>:                                    [--backend BACKEND]
[1,6]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,6]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,6]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,6]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,6]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,6]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,6]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,6]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,6]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,6]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,6]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,6]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,6]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,6]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,6]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,6]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,6]<stderr>:                                    [--apply-chat-template] [--profile]
[1,6]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,6]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,6]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47475
[1,12]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,12]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,12]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,12]<stderr>:                                    [--skip-tokenizer-init]
[1,12]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,12]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,12]<stderr>:                                    [--trust-remote-code]
[1,12]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,12]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,12]<stderr>:                                    [--revision REVISION]
[1,12]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,12]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,12]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,12]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,12]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,12]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,12]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,12]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,12]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,12]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,12]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,12]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,12]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,12]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,12]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,12]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,12]<stderr>:                                    [--page-size PAGE_SIZE]
[1,12]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,12]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,12]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,12]<stderr>:                                    [--device DEVICE]
[1,12]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,12]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,12]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,12]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,12]<stderr>:                                    [--stream-output]
[1,12]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,12]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,12]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,12]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,12]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,12]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,12]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,12]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,12]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,12]<stderr>:                                    [--log-requests]
[1,12]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,12]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,12]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,12]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,12]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,12]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,12]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,12]<stderr>:                                    [--collect-tokens-histogram]
[1,12]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,12]<stderr>:                                    [--enable-request-time-stats-logging]
[1,12]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,12]<stderr>:                                    [--api-key API_KEY]
[1,12]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,12]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,12]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,12]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,12]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,12]<stderr>:                                    [--enable-cache-report]
[1,12]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,12]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,12]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,12]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,12]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,12]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,12]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,12]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,12]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,12]<stderr>:                                    [--enable-lora]
[1,12]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,12]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,12]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,12]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,12]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,12]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,12]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,12]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,12]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,12]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,12]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,12]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,12]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,12]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,12]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,12]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,12]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,12]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,12]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,12]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,12]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,12]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,12]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,12]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,12]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,12]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,12]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,12]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,12]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,12]<stderr>:                                    [--enable-eplb]
[1,12]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,12]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,12]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,12]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,12]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,12]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,12]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,12]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,12]<stderr>:                                    [--enable-hierarchical-cache]
[1,12]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,12]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,12]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,12]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,12]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,12]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,12]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,12]<stderr>:                                    [--enable-double-sparsity]
[1,12]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,12]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,12]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,12]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,12]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,12]<stderr>:                                    [--disable-radix-cache]
[1,12]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,12]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,12]<stderr>:                                    [--disable-cuda-graph]
[1,12]<stderr>:                                    [--disable-cuda-graph-padding]
[1,12]<stderr>:                                    [--enable-profile-cuda-graph]
[1,12]<stderr>:                                    [--enable-cudagraph-gc]
[1,12]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,12]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,12]<stderr>:                                    [--disable-outlines-disk-cache]
[1,12]<stderr>:                                    [--disable-custom-all-reduce]
[1,12]<stderr>:                                    [--enable-mscclpp]
[1,12]<stderr>:                                    [--disable-overlap-schedule]
[1,12]<stderr>:                                    [--enable-mixed-chunk]
[1,12]<stderr>:                                    [--enable-dp-attention]
[1,12]<stderr>:                                    [--enable-dp-lm-head]
[1,12]<stderr>:                                    [--enable-two-batch-overlap]
[1,12]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,12]<stderr>:                                    [--enable-torch-compile]
[1,12]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,12]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,12]<stderr>:                                    [--enable-nan-detection]
[1,12]<stderr>:                                    [--enable-p2p-check]
[1,12]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,12]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,12]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,12]<stderr>:                                    [--delete-ckpt-after-loading]
[1,12]<stderr>:                                    [--enable-memory-saver]
[1,12]<stderr>:                                    [--allow-auto-truncate]
[1,12]<stderr>:                                    [--enable-custom-logit-processor]
[1,12]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,12]<stderr>:                                    [--disable-shared-experts-fusion]
[1,12]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,12]<stderr>:                                    [--disable-fast-image-processor]
[1,12]<stderr>:                                    [--enable-return-hidden-states]
[1,12]<stderr>:                                    [--enable-triton-kernel-moe]
[1,12]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,12]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,12]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,12]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,12]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,12]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,12]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,12]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,12]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,12]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,12]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,12]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,12]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,12]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,12]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,12]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,12]<stderr>:                                    [--enable-pdmux]
[1,12]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,12]<stderr>:                                    [--weight-loader-disable-mmap]
[1,12]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,12]<stderr>:                                    [--backend BACKEND]
[1,12]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,12]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,12]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,12]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,12]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,12]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,12]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,12]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,12]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,12]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,12]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,12]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,12]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,12]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,12]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,12]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,12]<stderr>:                                    [--apply-chat-template] [--profile]
[1,12]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,12]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,12]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47481
[1,10]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,10]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,10]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,10]<stderr>:                                    [--skip-tokenizer-init]
[1,10]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,10]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,10]<stderr>:                                    [--trust-remote-code]
[1,10]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,10]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,10]<stderr>:                                    [--revision REVISION]
[1,10]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,10]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,10]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,10]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,10]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,10]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,10]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,10]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,10]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,10]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,10]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,10]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,10]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,10]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,10]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,10]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,10]<stderr>:                                    [--page-size PAGE_SIZE]
[1,10]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,10]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,10]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,10]<stderr>:                                    [--device DEVICE]
[1,10]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,10]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,10]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,10]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,10]<stderr>:                                    [--stream-output]
[1,10]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,10]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,10]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,10]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,10]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,10]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,10]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,10]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,10]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,10]<stderr>:                                    [--log-requests]
[1,10]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,10]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,10]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,10]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,10]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,10]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,10]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,10]<stderr>:                                    [--collect-tokens-histogram]
[1,10]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,10]<stderr>:                                    [--enable-request-time-stats-logging]
[1,10]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,10]<stderr>:                                    [--api-key API_KEY]
[1,10]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,10]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,10]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,10]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,10]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,10]<stderr>:                                    [--enable-cache-report]
[1,10]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,10]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,10]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,10]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,10]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,10]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,10]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,10]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,10]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,10]<stderr>:                                    [--enable-lora]
[1,10]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,10]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,10]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,10]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,10]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,10]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,10]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,10]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,10]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,10]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,10]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,10]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,10]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,10]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,10]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,10]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,10]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,10]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,10]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,10]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,10]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,10]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,10]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,10]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,10]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,10]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,10]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,10]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,10]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,10]<stderr>:                                    [--enable-eplb]
[1,10]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,10]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,10]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,10]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,10]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,10]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,10]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,10]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,10]<stderr>:                                    [--enable-hierarchical-cache]
[1,10]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,10]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,10]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,10]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,10]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,10]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,10]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,10]<stderr>:                                    [--enable-double-sparsity]
[1,10]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,10]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,10]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,10]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,10]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,10]<stderr>:                                    [--disable-radix-cache]
[1,10]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,10]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,10]<stderr>:                                    [--disable-cuda-graph]
[1,10]<stderr>:                                    [--disable-cuda-graph-padding]
[1,10]<stderr>:                                    [--enable-profile-cuda-graph]
[1,10]<stderr>:                                    [--enable-cudagraph-gc]
[1,10]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,10]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,10]<stderr>:                                    [--disable-outlines-disk-cache]
[1,10]<stderr>:                                    [--disable-custom-all-reduce]
[1,10]<stderr>:                                    [--enable-mscclpp]
[1,10]<stderr>:                                    [--disable-overlap-schedule]
[1,10]<stderr>:                                    [--enable-mixed-chunk]
[1,10]<stderr>:                                    [--enable-dp-attention]
[1,10]<stderr>:                                    [--enable-dp-lm-head]
[1,10]<stderr>:                                    [--enable-two-batch-overlap]
[1,10]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,10]<stderr>:                                    [--enable-torch-compile]
[1,10]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,10]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,10]<stderr>:                                    [--enable-nan-detection]
[1,10]<stderr>:                                    [--enable-p2p-check]
[1,10]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,10]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,10]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,10]<stderr>:                                    [--delete-ckpt-after-loading]
[1,10]<stderr>:                                    [--enable-memory-saver]
[1,10]<stderr>:                                    [--allow-auto-truncate]
[1,10]<stderr>:                                    [--enable-custom-logit-processor]
[1,10]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,10]<stderr>:                                    [--disable-shared-experts-fusion]
[1,10]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,10]<stderr>:                                    [--disable-fast-image-processor]
[1,10]<stderr>:                                    [--enable-return-hidden-states]
[1,10]<stderr>:                                    [--enable-triton-kernel-moe]
[1,10]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,10]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,10]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,10]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,10]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,10]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,10]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,10]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,10]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,10]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,10]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,10]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,10]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,10]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,10]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,10]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,10]<stderr>:                                    [--enable-pdmux]
[1,10]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,10]<stderr>:                                    [--weight-loader-disable-mmap]
[1,10]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,10]<stderr>:                                    [--backend BACKEND]
[1,10]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,10]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,10]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,10]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,10]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,10]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,10]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,10]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,10]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,10]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,10]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,10]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,10]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,10]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,10]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,10]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,10]<stderr>:                                    [--apply-chat-template] [--profile]
[1,10]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,10]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,10]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47479
[1,14]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,14]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,14]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,14]<stderr>:                                    [--skip-tokenizer-init]
[1,14]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,14]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,14]<stderr>:                                    [--trust-remote-code]
[1,14]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,14]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,14]<stderr>:                                    [--revision REVISION]
[1,14]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,14]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,14]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,14]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,14]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,14]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,14]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,14]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,14]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,14]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,14]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,14]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,14]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,14]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,14]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,14]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,14]<stderr>:                                    [--page-size PAGE_SIZE]
[1,14]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,14]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,14]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,14]<stderr>:                                    [--device DEVICE]
[1,14]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,14]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,14]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,14]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,14]<stderr>:                                    [--stream-output]
[1,14]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,14]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,14]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,14]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,14]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,14]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,14]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,14]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,14]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,14]<stderr>:                                    [--log-requests]
[1,14]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,14]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,14]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,14]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,14]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,14]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,14]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,14]<stderr>:                                    [--collect-tokens-histogram]
[1,14]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,14]<stderr>:                                    [--enable-request-time-stats-logging]
[1,14]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,14]<stderr>:                                    [--api-key API_KEY]
[1,14]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,14]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,14]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,14]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,14]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,14]<stderr>:                                    [--enable-cache-report]
[1,14]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,14]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,14]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,14]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,14]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,14]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,14]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,14]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,14]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,14]<stderr>:                                    [--enable-lora]
[1,14]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,14]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,14]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,14]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,14]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,14]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,14]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,14]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,14]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,14]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,14]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,14]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,14]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,14]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,14]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,14]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,14]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,14]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,14]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,14]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,14]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,14]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,14]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,14]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,14]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,14]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,14]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,14]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,14]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,14]<stderr>:                                    [--enable-eplb]
[1,14]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,14]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,14]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,14]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,14]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,14]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,14]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,14]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,14]<stderr>:                                    [--enable-hierarchical-cache]
[1,14]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,14]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,14]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,14]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,14]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,14]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,14]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,14]<stderr>:                                    [--enable-double-sparsity]
[1,14]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,14]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,14]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,14]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,14]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,14]<stderr>:                                    [--disable-radix-cache]
[1,14]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,14]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,14]<stderr>:                                    [--disable-cuda-graph]
[1,14]<stderr>:                                    [--disable-cuda-graph-padding]
[1,14]<stderr>:                                    [--enable-profile-cuda-graph]
[1,14]<stderr>:                                    [--enable-cudagraph-gc]
[1,14]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,14]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,14]<stderr>:                                    [--disable-outlines-disk-cache]
[1,14]<stderr>:                                    [--disable-custom-all-reduce]
[1,14]<stderr>:                                    [--enable-mscclpp]
[1,14]<stderr>:                                    [--disable-overlap-schedule]
[1,14]<stderr>:                                    [--enable-mixed-chunk]
[1,14]<stderr>:                                    [--enable-dp-attention]
[1,14]<stderr>:                                    [--enable-dp-lm-head]
[1,14]<stderr>:                                    [--enable-two-batch-overlap]
[1,14]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,14]<stderr>:                                    [--enable-torch-compile]
[1,14]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,14]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,14]<stderr>:                                    [--enable-nan-detection]
[1,14]<stderr>:                                    [--enable-p2p-check]
[1,14]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,14]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,14]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,14]<stderr>:                                    [--delete-ckpt-after-loading]
[1,14]<stderr>:                                    [--enable-memory-saver]
[1,14]<stderr>:                                    [--allow-auto-truncate]
[1,14]<stderr>:                                    [--enable-custom-logit-processor]
[1,14]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,14]<stderr>:                                    [--disable-shared-experts-fusion]
[1,14]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,14]<stderr>:                                    [--disable-fast-image-processor]
[1,14]<stderr>:                                    [--enable-return-hidden-states]
[1,14]<stderr>:                                    [--enable-triton-kernel-moe]
[1,14]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,14]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,14]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,14]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,14]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,14]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,14]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,14]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,14]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,14]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,14]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,14]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,14]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,14]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,14]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,14]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,14]<stderr>:                                    [--enable-pdmux]
[1,14]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,14]<stderr>:                                    [--weight-loader-disable-mmap]
[1,14]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,14]<stderr>:                                    [--backend BACKEND]
[1,14]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,14]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,14]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,14]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,14]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,14]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,14]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,14]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,14]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,14]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,14]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,14]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,14]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,14]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,14]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,14]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,14]<stderr>:                                    [--apply-chat-template] [--profile]
[1,14]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,14]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,14]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47483
[1,4]<stderr>: usage: bench_offline_throughput.py [-h] --model-path MODEL_PATH
[1,4]<stderr>:                                    [--tokenizer-path TOKENIZER_PATH]
[1,4]<stderr>:                                    [--tokenizer-mode {auto,slow}]
[1,4]<stderr>:                                    [--skip-tokenizer-init]
[1,4]<stderr>:                                    [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
[1,4]<stderr>:                                    [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG]
[1,4]<stderr>:                                    [--trust-remote-code]
[1,4]<stderr>:                                    [--context-length CONTEXT_LENGTH]
[1,4]<stderr>:                                    [--is-embedding] [--enable-multimodal]
[1,4]<stderr>:                                    [--revision REVISION]
[1,4]<stderr>:                                    [--model-impl MODEL_IMPL] [--host HOST]
[1,4]<stderr>:                                    [--port PORT] [--skip-server-warmup]
[1,4]<stderr>:                                    [--warmups WARMUPS] [--nccl-port NCCL_PORT]
[1,4]<stderr>:                                    [--dtype {auto,half,float16,bfloat16,float,float32}]
[1,4]<stderr>:                                    [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
[1,4]<stderr>:                                    [--quantization-param-path QUANTIZATION_PARAM_PATH]
[1,4]<stderr>:                                    [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
[1,4]<stderr>:                                    [--mem-fraction-static MEM_FRACTION_STATIC]
[1,4]<stderr>:                                    [--max-running-requests MAX_RUNNING_REQUESTS]
[1,4]<stderr>:                                    [--max-queued-requests MAX_QUEUED_REQUESTS]
[1,4]<stderr>:                                    [--max-total-tokens MAX_TOTAL_TOKENS]
[1,4]<stderr>:                                    [--chunked-prefill-size CHUNKED_PREFILL_SIZE]
[1,4]<stderr>:                                    [--max-prefill-tokens MAX_PREFILL_TOKENS]
[1,4]<stderr>:                                    [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}]
[1,4]<stderr>:                                    [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS]
[1,4]<stderr>:                                    [--cpu-offload-gb CPU_OFFLOAD_GB]
[1,4]<stderr>:                                    [--page-size PAGE_SIZE]
[1,4]<stderr>:                                    [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]]
[1,4]<stderr>:                                    [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO]
[1,4]<stderr>:                                    [--disable-hybrid-swa-memory]
[1,4]<stderr>:                                    [--device DEVICE]
[1,4]<stderr>:                                    [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
[1,4]<stderr>:                                    [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
[1,4]<stderr>:                                    [--max-micro-batch-size MAX_MICRO_BATCH_SIZE]
[1,4]<stderr>:                                    [--stream-interval STREAM_INTERVAL]
[1,4]<stderr>:                                    [--stream-output]
[1,4]<stderr>:                                    [--random-seed RANDOM_SEED]
[1,4]<stderr>:                                    [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN]
[1,4]<stderr>:                                    [--watchdog-timeout WATCHDOG_TIMEOUT]
[1,4]<stderr>:                                    [--dist-timeout DIST_TIMEOUT]
[1,4]<stderr>:                                    [--download-dir DOWNLOAD_DIR]
[1,4]<stderr>:                                    [--base-gpu-id BASE_GPU_ID]
[1,4]<stderr>:                                    [--gpu-id-step GPU_ID_STEP]
[1,4]<stderr>:                                    [--sleep-on-idle] [--log-level LOG_LEVEL]
[1,4]<stderr>:                                    [--log-level-http LOG_LEVEL_HTTP]
[1,4]<stderr>:                                    [--log-requests]
[1,4]<stderr>:                                    [--log-requests-level {0,1,2,3}]
[1,4]<stderr>:                                    [--crash-dump-folder CRASH_DUMP_FOLDER]
[1,4]<stderr>:                                    [--show-time-cost] [--enable-metrics]
[1,4]<stderr>:                                    [--enable-metrics-for-all-schedulers]
[1,4]<stderr>:                                    [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
[1,4]<stderr>:                                    [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
[1,4]<stderr>:                                    [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]]
[1,4]<stderr>:                                    [--collect-tokens-histogram]
[1,4]<stderr>:                                    [--decode-log-interval DECODE_LOG_INTERVAL]
[1,4]<stderr>:                                    [--enable-request-time-stats-logging]
[1,4]<stderr>:                                    [--kv-events-config KV_EVENTS_CONFIG]
[1,4]<stderr>:                                    [--api-key API_KEY]
[1,4]<stderr>:                                    [--served-model-name SERVED_MODEL_NAME]
[1,4]<stderr>:                                    [--weight-version WEIGHT_VERSION]
[1,4]<stderr>:                                    [--chat-template CHAT_TEMPLATE]
[1,4]<stderr>:                                    [--completion-template COMPLETION_TEMPLATE]
[1,4]<stderr>:                                    [--file-storage-path FILE_STORAGE_PATH]
[1,4]<stderr>:                                    [--enable-cache-report]
[1,4]<stderr>:                                    [--reasoning-parser {deepseek-r1,qwen3,qwen3-thinking,glm45,kimi,step3,gpt-oss}]
[1,4]<stderr>:                                    [--tool-call-parser {qwen25,mistral,llama3,deepseekv3,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
[1,4]<stderr>:                                    [--tool-server TOOL_SERVER]
[1,4]<stderr>:                                    [--data-parallel-size DATA_PARALLEL_SIZE]
[1,4]<stderr>:                                    [--load-balance-method {round_robin,shortest_queue,minimum_tokens}]
[1,4]<stderr>:                                    [--dist-init-addr DIST_INIT_ADDR]
[1,4]<stderr>:                                    [--nnodes NNODES] [--node-rank NODE_RANK]
[1,4]<stderr>:                                    [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
[1,4]<stderr>:                                    [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS]
[1,4]<stderr>:                                    [--enable-lora]
[1,4]<stderr>:                                    [--max-lora-rank MAX_LORA_RANK]
[1,4]<stderr>:                                    [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,all} ...]]
[1,4]<stderr>:                                    [--lora-paths [LORA_PATHS ...]]
[1,4]<stderr>:                                    [--max-loras-per-batch MAX_LORAS_PER_BATCH]
[1,4]<stderr>:                                    [--max-loaded-loras MAX_LOADED_LORAS]
[1,4]<stderr>:                                    [--lora-backend LORA_BACKEND]
[1,4]<stderr>:                                    [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,4]<stderr>:                                    [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,4]<stderr>:                                    [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,aiter,wave,intel_amx,ascend}]
[1,4]<stderr>:                                    [--sampling-backend {flashinfer,pytorch}]
[1,4]<stderr>:                                    [--grammar-backend {xgrammar,outlines,llguidance,none}]
[1,4]<stderr>:                                    [--mm-attention-backend {sdpa,fa3,triton_attn}]
[1,4]<stderr>:                                    [--speculative-algorithm {EAGLE,EAGLE3,NEXTN}]
[1,4]<stderr>:                                    [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH]
[1,4]<stderr>:                                    [--speculative-num-steps SPECULATIVE_NUM_STEPS]
[1,4]<stderr>:                                    [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
[1,4]<stderr>:                                    [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
[1,4]<stderr>:                                    [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
[1,4]<stderr>:                                    [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC]
[1,4]<stderr>:                                    [--speculative-token-map SPECULATIVE_TOKEN_MAP]
[1,4]<stderr>:                                    [--expert-parallel-size EXPERT_PARALLEL_SIZE]
[1,4]<stderr>:                                    [--moe-a2a-backend {deepep}]
[1,4]<stderr>:                                    [--enable-flashinfer-cutlass-moe]
[1,4]<stderr>:                                    [--enable-flashinfer-trtllm-moe]
[1,4]<stderr>:                                    [--enable-flashinfer-allreduce-fusion]
[1,4]<stderr>:                                    [--deepep-mode {normal,low_latency,auto}]
[1,4]<stderr>:                                    [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS]
[1,4]<stderr>:                                    [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
[1,4]<stderr>:                                    [--init-expert-location INIT_EXPERT_LOCATION]
[1,4]<stderr>:                                    [--enable-eplb]
[1,4]<stderr>:                                    [--eplb-algorithm EPLB_ALGORITHM]
[1,4]<stderr>:                                    [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS]
[1,4]<stderr>:                                    [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
[1,4]<stderr>:                                    [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
[1,4]<stderr>:                                    [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE]
[1,4]<stderr>:                                    [--enable-expert-distribution-metrics]
[1,4]<stderr>:                                    [--deepep-config DEEPEP_CONFIG]
[1,4]<stderr>:                                    [--moe-dense-tp-size MOE_DENSE_TP_SIZE]
[1,4]<stderr>:                                    [--enable-hierarchical-cache]
[1,4]<stderr>:                                    [--hicache-ratio HICACHE_RATIO]
[1,4]<stderr>:                                    [--hicache-size HICACHE_SIZE]
[1,4]<stderr>:                                    [--hicache-write-policy {write_back,write_through,write_through_selective}]
[1,4]<stderr>:                                    [--hicache-io-backend {direct,kernel}]
[1,4]<stderr>:                                    [--hicache-mem-layout {layer_first,page_first}]
[1,4]<stderr>:                                    [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
[1,4]<stderr>:                                    [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
[1,4]<stderr>:                                    [--enable-double-sparsity]
[1,4]<stderr>:                                    [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH]
[1,4]<stderr>:                                    [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
[1,4]<stderr>:                                    [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM]
[1,4]<stderr>:                                    [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
[1,4]<stderr>:                                    [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD]
[1,4]<stderr>:                                    [--disable-radix-cache]
[1,4]<stderr>:                                    [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS]
[1,4]<stderr>:                                    [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
[1,4]<stderr>:                                    [--disable-cuda-graph]
[1,4]<stderr>:                                    [--disable-cuda-graph-padding]
[1,4]<stderr>:                                    [--enable-profile-cuda-graph]
[1,4]<stderr>:                                    [--enable-cudagraph-gc]
[1,4]<stderr>:                                    [--enable-nccl-nvls] [--enable-symm-mem]
[1,4]<stderr>:                                    [--enable-tokenizer-batch-encode]
[1,4]<stderr>:                                    [--disable-outlines-disk-cache]
[1,4]<stderr>:                                    [--disable-custom-all-reduce]
[1,4]<stderr>:                                    [--enable-mscclpp]
[1,4]<stderr>:                                    [--disable-overlap-schedule]
[1,4]<stderr>:                                    [--enable-mixed-chunk]
[1,4]<stderr>:                                    [--enable-dp-attention]
[1,4]<stderr>:                                    [--enable-dp-lm-head]
[1,4]<stderr>:                                    [--enable-two-batch-overlap]
[1,4]<stderr>:                                    [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
[1,4]<stderr>:                                    [--enable-torch-compile]
[1,4]<stderr>:                                    [--torch-compile-max-bs TORCH_COMPILE_MAX_BS]
[1,4]<stderr>:                                    [--torchao-config TORCHAO_CONFIG]
[1,4]<stderr>:                                    [--enable-nan-detection]
[1,4]<stderr>:                                    [--enable-p2p-check]
[1,4]<stderr>:                                    [--triton-attention-reduce-in-fp32]
[1,4]<stderr>:                                    [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
[1,4]<stderr>:                                    [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS]
[1,4]<stderr>:                                    [--delete-ckpt-after-loading]
[1,4]<stderr>:                                    [--enable-memory-saver]
[1,4]<stderr>:                                    [--allow-auto-truncate]
[1,4]<stderr>:                                    [--enable-custom-logit-processor]
[1,4]<stderr>:                                    [--flashinfer-mla-disable-ragged]
[1,4]<stderr>:                                    [--disable-shared-experts-fusion]
[1,4]<stderr>:                                    [--disable-chunked-prefix-cache]
[1,4]<stderr>:                                    [--disable-fast-image-processor]
[1,4]<stderr>:                                    [--enable-return-hidden-states]
[1,4]<stderr>:                                    [--enable-triton-kernel-moe]
[1,4]<stderr>:                                    [--enable-flashinfer-mxfp4-moe]
[1,4]<stderr>:                                    [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL]
[1,4]<stderr>:                                    [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER]
[1,4]<stderr>:                                    [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
[1,4]<stderr>:                                    [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT]
[1,4]<stderr>:                                    [--debug-tensor-dump-prefill-only]
[1,4]<stderr>:                                    [--disaggregation-mode {null,prefill,decode}]
[1,4]<stderr>:                                    [--disaggregation-transfer-backend {mooncake,nixl,ascend}]
[1,4]<stderr>:                                    [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
[1,4]<stderr>:                                    [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP]
[1,4]<stderr>:                                    [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
[1,4]<stderr>:                                    [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP]
[1,4]<stderr>:                                    [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
[1,4]<stderr>:                                    [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS]
[1,4]<stderr>:                                    [--pdlb-url PDLB_URL]
[1,4]<stderr>:                                    [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
[1,4]<stderr>:                                    [--enable-pdmux]
[1,4]<stderr>:                                    [--sm-group-num SM_GROUP_NUM]
[1,4]<stderr>:                                    [--weight-loader-disable-mmap]
[1,4]<stderr>:                                    [--enable-ep-moe] [--enable-deepep-moe]
[1,4]<stderr>:                                    [--backend BACKEND]
[1,4]<stderr>:                                    [--result-filename RESULT_FILENAME]
[1,4]<stderr>:                                    [--dataset-name {sharegpt,random,generated-shared-prefix}]
[1,4]<stderr>:                                    [--dataset-path DATASET_PATH]
[1,4]<stderr>:                                    [--num-prompts NUM_PROMPTS]
[1,4]<stderr>:                                    [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
[1,4]<stderr>:                                    [--sharegpt-context-len SHAREGPT_CONTEXT_LEN]
[1,4]<stderr>:                                    [--random-input-len RANDOM_INPUT_LEN]
[1,4]<stderr>:                                    [--random-output-len RANDOM_OUTPUT_LEN]
[1,4]<stderr>:                                    [--random-range-ratio RANDOM_RANGE_RATIO]
[1,4]<stderr>:                                    [--gsp-num-groups GSP_NUM_GROUPS]
[1,4]<stderr>:                                    [--gsp-prompts-per-group GSP_PROMPTS_PER_GROUP]
[1,4]<stderr>:                                    [--gsp-system-prompt-len GSP_SYSTEM_PROMPT_LEN]
[1,4]<stderr>:                                    [--gsp-question-len GSP_QUESTION_LEN]
[1,4]<stderr>:                                    [--gsp-output-len GSP_OUTPUT_LEN]
[1,4]<stderr>:                                    [--seed SEED] [--disable-ignore-eos]
[1,4]<stderr>:                                    [--extra-request-body {"key1": "value1", "key2": "value2"}]
[1,4]<stderr>:                                    [--apply-chat-template] [--profile]
[1,4]<stderr>:                                    [--skip-warmup] [--do-not-exit]
[1,4]<stderr>:                                    [--prompt-suffix PROMPT_SUFFIX]
[1,4]<stderr>: bench_offline_throughput.py: error: unrecognized arguments: --detokenizer-port 47473
--------------------------------------------------------------------------
prterun detected that one or more processes exited with non-zero status,
thus causing the job to be terminated. The first process to do so was:

   Process name: [prterun-a2ap-dgx008-3292172@1,1] Exit code:    2
--------------------------------------------------------------------------

real	0m56.985s
user	0m0.274s
sys	0m7.651s
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-10 08:27:46.772606:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 96714.pbs111
	Project: 50000128
	Exit Status: 2
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 00:02:30
	Memory: Requested(3760gb), Used(7192008kb)
	Vmem Used: 271715500kb
	Walltime: Requested(00:10:00), Used(00:01:04)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx008:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx024:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 1.21mins
	GPU Power Consumed: 120.93W
	GPU Max GPU Memory Used: 0.0B
	Memory Throughput Rate (Average): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	Memory Throughput Rate (Max): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	Memory Throughput Rate (Min): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Max): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Min): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: All GPUs have a percentage of 0 utilisation.
GPU application profile: Idle
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

