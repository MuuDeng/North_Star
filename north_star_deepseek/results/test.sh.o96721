========== 2-NODE TP16 OPTIMIZED ==========
Prepaid SU: 341.334 | 420s SU: 238.934 | Balance: 49804.445
N/A
Job ID: 96721.pbs111 | GPUs: 16 | Master: a2ap-dgx008.asp2p.nscc.sg:5000
============================================
[09:08:40] Launching optimized 2-node TP16 benchmark...
 Data for JOB [26519,1] offset 0 Total slots allocated 4

 ========================   JOB MAP   ========================

 Data for node: a2ap-dgx008	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [26519,1] App: 0 Process rank: 0 Bound: N/A

 Data for node: a2ap-dgx024	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [26519,1] App: 0 Process rank: 1 Bound: N/A

 =============================================================
 Data for JOB [26519,1] offset 0 Total slots allocated 4

 ========================   JOB MAP   ========================

 Data for node: a2ap-dgx008	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [26519,1] App: 0 Process rank: 0 Bound: N/A

 Data for node: a2ap-dgx024	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [26519,1] App: 0 Process rank: 1 Bound: N/A

 =============================================================
[1,1]<stderr>:W1010 09:08:56.494000 2469556 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:08:56.494000 2469556 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:08:56.614000 3384052 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:08:56.614000 3384052 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:[2025-10-10 09:08:59] Using default HuggingFace chat template with detected content format: string
[1,1]<stderr>:W1010 09:09:17.213000 2470009 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:09:17.213000 2470009 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:09:19.001000 2470007 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:09:19.001000 2470007 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:09:19.615000 2470014 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:09:19.615000 2470014 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:09:19.619000 2470008 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:09:19.619000 2470008 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:09:19.622000 2470012 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:09:19.622000 2470012 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:09:19.625000 2470013 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:09:19.625000 2470013 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:09:19.714000 2470011 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:09:19.714000 2470011 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:09:19.715000 2470010 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:09:19.715000 2470010 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:09:19.883000 3384725 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:09:19.883000 3384725 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:09:21.263000 3384723 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:09:21.263000 3384723 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:09:21.355000 3384724 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:09:21.355000 3384724 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:09:21.364000 3384719 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:09:21.364000 3384719 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:09:21.470000 3384720 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:09:21.470000 3384720 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:09:21.476000 3384721 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:09:21.476000 3384721 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:09:21.478000 3384718 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:09:21.478000 3384718 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:09:21.533000 3384726 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:09:21.533000 3384726 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:09:21.672000 3384722 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:09:21.672000 3384722 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:[2025-10-10 09:09:23 TP0] MLA optimization is turned on. Use flashinfer backend.
[1,0]<stderr>:[2025-10-10 09:09:23 TP0] Chunked prefix cache is turned on.
[1,0]<stderr>:[2025-10-10 09:09:23 TP0] Init torch distributed begin.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 09:09:29 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:NCCL version 2.27.3+cuda12.9
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470011:2470011 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470011:2470011 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470014:2470014 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470014:2470014 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470013:2470013 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470013:2470013 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384723:3384723 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384723:3384723 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470010:2470010 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470010:2470010 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470012:2470012 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470012:2470012 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470009:2470009 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470009:2470009 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470007:2470007 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470007:2470007 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470008:2470008 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:09:34] a2ap-dgx024:2470008:2470008 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384724:3384724 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384724:3384724 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384718:3384718 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384718:3384718 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384721:3384721 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384721:3384721 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384725:3384725 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384725:3384725 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384720:3384720 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384720:3384720 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384719:3384719 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384719:3384719 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384722:3384722 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:09:34] a2ap-dgx008:3384722:3384722 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stderr>:[2025-10-10 09:09:35 TP4] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:09:35 TP3] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:09:35 TP1] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:09:35 TP0] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:09:35 TP2] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:09:35 TP6] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:09:35 TP5] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:09:35 TP7] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:09:35 TP15] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:09:35 TP13] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:09:35 TP11] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:09:35 TP12] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:09:35 TP9] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:09:35 TP14] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:09:35 TP8] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:09:35 TP10] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 09:09:35 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 09:09:38 TP0] Init torch distributed ends. mem usage=1.75 GB
[1,0]<stderr>:[2025-10-10 09:09:38 TP3] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:09:38 TP10] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:09:38 TP2] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:09:38 TP6] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:09:38 TP5] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:09:38 TP12] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:09:38 TP15] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:09:38 TP9] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:09:38 TP13] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:09:38 TP11] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:09:38 TP7] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:09:38 TP1] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:09:38 TP4] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:09:38 TP14] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:09:38 TP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:09:38 TP8] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:09:39 TP0] Load weight begin. avail mem=76.80 GB
[1,0]<stderr>:[2025-10-10 09:09:39 TP0] Detected fp8 checkpoint.
[1,0]<stderr>:[2025-10-10 09:09:41 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=36.24 GB, mem usage=40.55 GB.
[1,1]<stderr>:[2025-10-10 09:09:41 TP8] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:09:41 TP14] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:09:41 TP10] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:09:41 TP12] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:09:41 TP13] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:09:41 TP9] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:09:41 TP2] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:09:41 TP11] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:09:41 TP6] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:09:41 TP4] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:09:41 TP1] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:09:41 TP15] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:09:41 TP7] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:09:42 TP0] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:09:42 TP0] Memory pool end. avail mem=31.52 GB
[1,0]<stderr>:[2025-10-10 09:09:42 TP3] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:09:42 TP5] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:09:42 TP0] max_total_num_tokens=65536, chunked_prefill_size=1024, max_prefill_tokens=4096, max_running_requests=512, context_len=163840, available_gpu_mem=31.01 GB
[1,1]<stderr>:[2025-10-10 09:09:43] Starting dummy health check server at 127.0.0.1:30000
[1,0]<stdout>:#Input tokens: 626729
[1,0]<stdout>:#Output tokens: 388685
[1,0]<stdout>:#Input tokens: 4096
[1,0]<stdout>:#Output tokens: 256
[1,0]<stderr>:[2025-10-10 09:09:56] 
[1,0]<stderr>:Warmup...
[1,0]<stderr>:[2025-10-10 09:09:56 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 12, 
[1,0]<stderr>:[2025-10-10 09:09:56 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 8, token usage: 0.02, #running-req: 3, #queue-req: 8, 
[1,1]<stderr>:[2025-10-10 09:09:58 TP8] TpModelWorkerClient hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker_overlap_thread.py", line 141, in forward_thread_func
[1,1]<stderr>:    self.forward_thread_func_()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker_overlap_thread.py", line 176, in forward_thread_func_
[1,1]<stderr>:    self.worker.forward_batch_generation(
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker.py", line 238, in forward_batch_generation
[1,1]<stderr>:    logits_output, can_run_cuda_graph = self.model_runner.forward(
[1,1]<stderr>:                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 1741, in forward
[1,1]<stderr>:    output = self._forward_raw(
[1,1]<stderr>:             ^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 1786, in _forward_raw
[1,1]<stderr>:    ret = self.forward_extend(
[1,1]<stderr>:          ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 1677, in forward_extend
[1,1]<stderr>:    self.attn_backend.init_forward_metadata(forward_batch)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/attention/flashinfer_mla_backend.py", line 190, in init_forward_metadata
[1,1]<stderr>:    self.indices_updater_prefill.update(
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/attention/flashinfer_mla_backend.py", line 650, in update
[1,1]<stderr>:    self.call_begin_forward(
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/attention/flashinfer_mla_backend.py", line 718, in call_begin_forward
[1,1]<stderr>:    wrapper_ragged.begin_forward(
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/prefill.py", line 2676, in plan
[1,1]<stderr>:    self._cached_module = get_batch_prefill_module(
[1,1]<stderr>:                          ^^^^^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/prefill.py", line 357, in get_batch_prefill_module
[1,1]<stderr>:    module = gen_batch_prefill_module(backend, *args).build_and_load()
[1,1]<stderr>:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/jit/core.py", line 147, in build_and_load
[1,1]<stderr>:    self.build(verbose, need_lock=False)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/jit/core.py", line 127, in build
[1,1]<stderr>:    run_ninja(jit_env.FLASHINFER_JIT_DIR, self.ninja_path, verbose)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/jit/cpp_ext.py", line 199, in run_ninja
[1,1]<stderr>:    subprocess.run(
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/subprocess.py", line 548, in run
[1,1]<stderr>:    with Popen(*popenargs, **kwargs) as process:
[1,1]<stderr>:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/subprocess.py", line 1026, in __init__
[1,1]<stderr>:    self._execute_child(args, executable, preexec_fn, close_fds,
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/subprocess.py", line 1955, in _execute_child
[1,1]<stderr>:    raise child_exception_type(errno_num, err_msg, err_filename)
[1,1]<stderr>:FileN[1,1]<stderr>:otFoundError: [Errno 2] No such file or directory: 'ninja'
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:09:58] Received sigquit from a child process. It usually means the child failed.
[1,0]<stderr>:[2025-10-10 09:09:58 TP0] TpModelWorkerClient hit an exception: Traceback (most recent call last):
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker_overlap_thread.py", line 141, in forward_thread_func
[1,0]<stderr>:    self.forward_thread_func_()
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,0]<stderr>:    return func(*args, **kwargs)
[1,0]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker_overlap_thread.py", line 176, in forward_thread_func_
[1,0]<stderr>:    self.worker.forward_batch_generation(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/tp_worker.py", line 238, in forward_batch_generation
[1,0]<stderr>:    logits_output, can_run_cuda_graph = self.model_runner.forward(
[1,0]<stderr>:                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 1741, in forward
[1,0]<stderr>:    output = self._forward_raw(
[1,0]<stderr>:             ^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 1786, in _forward_raw
[1,0]<stderr>:    ret = self.forward_extend(
[1,0]<stderr>:          ^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/model_executor/model_runner.py", line 1677, in forward_extend
[1,0]<stderr>:    self.attn_backend.init_forward_metadata(forward_batch)
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/attention/flashinfer_mla_backend.py", line 190, in init_forward_metadata
[1,0]<stderr>:    self.indices_updater_prefill.update(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/attention/flashinfer_mla_backend.py", line 650, in update
[1,0]<stderr>:    self.call_begin_forward(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/attention/flashinfer_mla_backend.py", line 718, in call_begin_forward
[1,0]<stderr>:    wrapper_ragged.begin_forward(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/prefill.py", line 2676, in plan
[1,0]<stderr>:    self._cached_module = get_batch_prefill_module(
[1,0]<stderr>:                          ^^^^^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/prefill.py", line 357, in get_batch_prefill_module
[1,0]<stderr>:    module = gen_batch_prefill_module(backend, *args).build_and_load()
[1,0]<stderr>:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/jit/core.py", line 147, in build_and_load
[1,0]<stderr>:    self.build(verbose, need_lock=False)
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/jit/core.py", line 127, in build
[1,0]<stderr>:    run_ninja(jit_env.FLASHINFER_JIT_DIR, self.ninja_path, verbose)
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/flashinfer/jit/cpp_ext.py", line 199, in run_ninja
[1,0]<stderr>:    subprocess.run(
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/subprocess.py", line 548, in run
[1,0]<stderr>:    with Popen(*popenargs, **kwargs) as process:
[1,0]<stderr>:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/subprocess.py", line 1026, in __init__
[1,0]<stderr>:    self._execute_child(args, executable, preexec_fn, close_fds,
[1,0]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/subprocess.py", line 1955, in _execute_child
[1,0]<stderr>:    raise child_exception_type(errno_num, err_msg, err_filename)
[1,0]<stderr>:FileN[1,0]<stderr>:otFoundError: [Errno 2] No such file or directory: 'ninja'
[1,0]<stderr>:
[1,0]<stderr>:[2025-10-10 09:09:58] Received sigquit from a child process. It usually means the child failed.
[1,1]<stderr>:bash: line 4: 2469556 Killed                  '/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/bin/python3' -m sglang.bench_offline_throughput --model-path '/home/users/industry/ai-hpc/apacsc34/scratch/model/DeepSeek-R1' --dataset-path '/home/users/industry/ai-hpc/apacsc34/scratch/ShareGPT_V3_unfiltered_cleaned_split.json' --num-prompts 2000 --load-format dummy --seed 2025 --dtype bfloat16 --tp 16 --nnodes 2 --trust-remote-code --dist-init-addr ${DIST_INIT_ADDR}:5000 --node-rank ${OMPI_COMM_WORLD_RANK} --max-running-requests 512 --max-total-tokens 65536 --chunked-prefill-size 1024 --max-prefill-tokens 4096 --schedule-policy lpm --attention-backend flashinfer --disable-cuda-graph
[1,1]<stderr>:
[1,1]<stderr>:real	1m17.685s
[1,1]<stderr>:user	0m21.364s
[1,1]<stderr>:sys	0m6.795s
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[1,0]<stderr>:bash: line 4: 3384052 Killed                  '/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/bin/python3' -m sglang.bench_offline_throughput --model-path '/home/users/industry/ai-hpc/apacsc34/scratch/model/DeepSeek-R1' --dataset-path '/home/users/industry/ai-hpc/apacsc34/scratch/ShareGPT_V3_unfiltered_cleaned_split.json' --num-prompts 2000 --load-format dummy --seed 2025 --dtype bfloat16 --tp 16 --nnodes 2 --trust-remote-code --dist-init-addr ${DIST_INIT_ADDR}:5000 --node-rank ${OMPI_COMM_WORLD_RANK} --max-running-requests 512 --max-total-tokens 65536 --chunked-prefill-size 1024 --max-prefill-tokens 4096 --schedule-policy lpm --attention-backend flashinfer --disable-cuda-graph
[1,0]<stderr>:
[1,0]<stderr>:real	1m17.687s
[1,0]<stderr>:user	0m31.855s
[1,0]<stderr>:sys	0m10.584s
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[26519,1],1]
  Exit code:    137
--------------------------------------------------------------------------

real	1m21.735s
user	0m31.877s
sys	0m10.687s
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-10 09:10:12.260138:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 96721.pbs111
	Project: 50000128
	Exit Status: 137
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 00:09:10
	Memory: Requested(3760gb), Used(21056432kb)
	Vmem Used: 20060504052kb
	Walltime: Requested(00:10:00), Used(00:01:26)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx008:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx024:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 1.6mins
	GPU Power Consumed: 171.76W
	GPU Max GPU Memory Used: 770.05GB
	Memory Throughput Rate (Average): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:2%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	Memory Throughput Rate (Max): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:20%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:4%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:4%)
	Memory Throughput Rate (Min): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx008:(gpu1:0%+gpu0:1%+gpu2:0%+gpu3:1%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:5%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Max): a2ap-dgx008:(gpu1:0%+gpu0:16%+gpu2:0%+gpu3:14%+gpu5:0%+gpu4:3%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:46%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:5%)
	GPU SM Utilization (Min): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx024:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: GPUs 1, 0, 3, 5, 4, 6, 7 have a percentage of 0 utilisation.
GPU application profile: Low
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

