========== 2-NODE TP16 OPTIMIZED ==========
Prepaid SU: 341.334 | 420s SU: 238.934 | Balance: 49348.765
N/A
Job ID: 96728.pbs111 | GPUs: 16 | Master: a2ap-dgx008.asp2p.nscc.sg:5000
============================================
[09:40:17] Launching optimized 2-node TP16 benchmark...
Warning: Permanently added 'a2ap-dgx014' (ED25519) to the list of known hosts.
 Data for JOB [26211,1] offset 0 Total slots allocated 4

 ========================   JOB MAP   ========================

 Data for node: a2ap-dgx008	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [26211,1] App: 0 Process rank: 0 Bound: N/A

 Data for node: a2ap-dgx014	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [26211,1] App: 0 Process rank: 1 Bound: N/A

 =============================================================
 Data for JOB [26211,1] offset 0 Total slots allocated 4

 ========================   JOB MAP   ========================

 Data for node: a2ap-dgx008	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [26211,1] App: 0 Process rank: 0 Bound: N/A

 Data for node: a2ap-dgx014	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [26211,1] App: 0 Process rank: 1 Bound: N/A

 =============================================================
[1,0]<stderr>:W1010 09:40:34.215000 3449647 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:34.215000 3449647 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:[2025-10-10 09:40:36] Using default HuggingFace chat template with detected content format: string
[1,1]<stderr>:W1010 09:40:39.171000 3173005 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:40:39.171000 3173005 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:40:55.776000 3450457 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:55.776000 3450457 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:40:57.051000 3450450 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:57.051000 3450450 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:40:57.664000 3450455 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:57.664000 3450455 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:40:58.355000 3450453 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:58.355000 3450453 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:40:58.388000 3450456 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:58.388000 3450456 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:40:58.399000 3450454 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:58.399000 3450454 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:40:58.403000 3450458 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:58.403000 3450458 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 09:40:58.405000 3450451 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:58.405000 3450451 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:[2025-10-10 09:40:58 TP0] MLA optimization is turned on. Use flashinfer backend.
[1,0]<stderr>:[2025-10-10 09:40:58 TP0] Chunked prefix cache is turned on.
[1,0]<stderr>:[2025-10-10 09:40:58 TP0] Init torch distributed begin.
[1,0]<stderr>:W1010 09:40:58.643000 3450452 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 09:40:58.643000 3450452 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:41:01.817000 3173653 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:41:01.817000 3173653 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:41:02.398000 3173652 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:41:02.398000 3173652 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:41:02.432000 3173650 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:41:02.432000 3173650 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:41:03.377000 3173654 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:41:03.377000 3173654 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:41:03.442000 3173657 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:41:03.442000 3173657 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:41:03.941000 3173651 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:41:03.941000 3173651 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:41:04.353000 3173656 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:41:04.353000 3173656 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 09:41:04.722000 3173655 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 09:41:04.722000 3173655 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 09:41:07 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:NCCL version 2.27.3+cuda12.9
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450457:3450457 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450457:3450457 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450453:3450453 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450453:3450453 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450455:3450455 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450455:3450455 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450456:3450456 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450456:3450456 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450451:3450451 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450451:3450451 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450450:3450450 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450450:3450450 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450454:3450454 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450454:3450454 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450452:3450452 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 09:41:14] a2ap-dgx008:3450452:3450452 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173650:3173650 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173650:3173650 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173655:3173655 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173655:3173655 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173651:3173651 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173651:3173651 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173652:3173652 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173652:3173652 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173654:3173654 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173654:3173654 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173656:3173656 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173656:3173656 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173657:3173657 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173657:3173657 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173653:3173653 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 09:41:15] a2ap-dgx014:3173653:3173653 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stderr>:[2025-10-10 09:41:18 TP0] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:41:18 TP15] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:41:18 TP14] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:41:18 TP13] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:41:18 TP2] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:41:18 TP11] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:41:18 TP12] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:41:18 TP10] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:41:18 TP3] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:41:18 TP4] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:41:18 TP5] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:41:18 TP1] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:41:18 TP7] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 09:41:18 TP6] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:41:18 TP9] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 09:41:18 TP8] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 09:41:18 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 09:41:20 TP0] Init torch distributed ends. mem usage=1.75 GB
[1,1]<stderr>:[2025-10-10 09:41:21 TP13] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:41:21 TP12] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:41:21 TP15] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:41:21 TP7] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:41:21 TP4] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:41:21 TP1] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:41:21 TP14] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:41:21 TP6] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:41:21 TP5] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:41:21 TP3] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:41:21 TP2] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:41:21 TP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:41:21 TP11] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:41:21 TP10] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:41:21 TP9] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 09:41:21 TP8] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 09:41:22 TP0] Load weight begin. avail mem=76.80 GB
[1,0]<stderr>:[2025-10-10 09:41:22 TP0] Detected fp8 checkpoint.
[1,0]<stderr>:[2025-10-10 09:41:23 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=36.24 GB, mem usage=40.55 GB.
[1,0]<stderr>:[2025-10-10 09:41:25 TP0] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:41:25 TP0] Memory pool end. avail mem=31.52 GB
[1,0]<stderr>:[2025-10-10 09:41:25 TP3] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:41:25 TP4] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:41:25 TP6] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:41:25 TP1] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:41:25 TP2] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:41:25 TP5] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:41:25 TP7] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:41:25 TP14] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:41:25 TP9] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:41:25 TP11] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:41:25 TP13] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:41:25 TP15] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:41:25 TP8] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:41:25 TP12] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 09:41:25 TP10] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 09:41:26 TP0] max_total_num_tokens=65536, chunked_prefill_size=1024, max_prefill_tokens=4096, max_running_requests=512, context_len=163840, available_gpu_mem=31.01 GB
[1,1]<stderr>:[2025-10-10 09:41:27] Starting dummy health check server at 127.0.0.1:30000
[1,0]<stdout>:#Input tokens: 626729
[1,0]<stdout>:#Output tokens: 388685
[1,0]<stdout>:#Input tokens: 4096
[1,0]<stdout>:#Output tokens: 256
[1,0]<stderr>:[2025-10-10 09:41:40] 
[1,0]<stderr>:Warmup...
[1,0]<stderr>:[2025-10-10 09:41:40 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 6, 
[1,0]<stderr>:[2025-10-10 09:41:40 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 8, token usage: 0.02, #running-req: 3, #queue-req: 8, 
[1,0]<stderr>:[2025-10-10 09:41:46 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 09:41:46 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 09:41:46 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4883.29it/s]
[1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4822.05it/s]
[1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 09:41:46 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 09:41:46 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 3532.54it/s]
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4241.73it/s]
[1,0]<stderr>:[2025-10-10 09:41:46 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:46 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4674.35it/s]
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5514.20it/s]
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4998.27it/s]
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4959.05it/s]
[1,0]<stderr>:[2025-10-10 09:41:46 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5040.13it/s]
[1,0]<stderr>:[2025-10-10 09:41:46 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4993.76it/s]
[1,0]<stderr>:[2025-10-10 09:41:46 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:46 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 3882.96it/s]
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 3432.50it/s][1,1]<stderr>:
[1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 3491.73it/s][1,1]<stderr>:
[1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 09:41:47 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:47 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 1909.63it/s]
[1,1]<stderr>:[2025-10-10 09:41:47 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 2117.23it/s]
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 2461.31it/s]
[1,1]<stderr>:[2025-10-10 09:41:47 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 09:41:47 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:47 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:47 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12868.65it/s]
[1,0]<stderr>:[2025-10-10 09:41:47 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 09:41:47 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 13137.06it/s]
[1,0]<stderr>:[2025-10-10 09:41:47 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 8113.49it/s]
[1,1]<stderr>:[2025-10-10 09:41:47 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 8417.30it/s]
[1,1]<stderr>:[2025-10-10 09:41:47 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12370.09it/s]
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12938.12it/s]
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12262.42it/s]
[1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 11948.81it/s]
[1,0]<stderr>:[2025-10-10 09:41:47 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:47 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 09:41:47 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:47 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 11377.89it/s]
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12361.80it/s][1,0]<stderr>:
[1,0]<stderr>:[2025-10-10 09:41:47 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:47 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 10381.21it/s][1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 12885.16it/s]
[1,0]<stderr>:[2025-10-10 09:41:47 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 09:41:47 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 09:41:47 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 6868.83it/s]
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 09:41:47 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 8008.57it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 09:41:47 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 7494.80it/s]
[1,1]<stderr>:[2025-10-10 09:41:47 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11674.01it/s]
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11406.42it/s]
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 12059.53it/s]
[1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11014.45it/s]
[1,0]<stderr>:[2025-10-10 09:41:47 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:47 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 09:41:47 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:47 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11952.50it/s][1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11596.54it/s]
[1,0]<stderr>:[2025-10-10 09:41:47 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:47 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 7219.96it/s]
[1,1]<stderr>:[2025-10-10 09:41:47 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 8336.69it/s]
[1,1]<stderr>:[2025-10-10 09:41:48 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 3441.67it/s]
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 3872.04it/s]
[1,1]<stderr>:[2025-10-10 09:41:48 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 3982.94it/s]
[1,1]<stderr>:[2025-10-10 09:41:48 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 09:41:48 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:48 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 18829.65it/s]
[1,0]<stderr>:[2025-10-10 09:41:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 09:41:48 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14662.19it/s][1,0]<stderr>:
[1,0]<stderr>:[2025-10-10 09:41:48 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 8239.27it/s]
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 8017.07it/s]
[1,1]<stderr>:[2025-10-10 09:41:48 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 7175.12it/s]
[1,1]<stderr>:[2025-10-10 09:41:48 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:48 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 18782.22it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 16233.40it/s]
[1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 15516.50it/s]
[1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 16035.57it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 09:41:48 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 6909.89it/s]
[1,0]<stderr>:[2025-10-10 09:41:48 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:48 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:48 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 12935.40it/s]
[1,1]<stderr>:[2025-10-10 09:41:48 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 09:41:48 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13709.68it/s]
[1,0]<stderr>:[2025-10-10 09:41:48 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 7266.28it/s]
[1,1]<stderr>:[2025-10-10 09:41:48 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 15932.78it/s]
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 15181.28it/s]
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 7415.75it/s]
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 7666.08it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 7495.68it/s]
[1,1]<stderr>:[2025-10-10 09:41:49 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 14599.99it/s]
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 12936.65it/s]
[1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 16196.18it/s]
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 14430.46it/s]
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 12986.72it/s]
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 14339.50it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 6640.76it/s]
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 1794.72it/s]
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 3014.63it/s]
[1,1]<stderr>:[2025-10-10 09:41:49 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:49 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 09:41:49 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:49 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6646.42it/s]
[1,1]<stderr>:[2025-10-10 09:41:49 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 5841.65it/s]
[1,1]<stderr>:[2025-10-10 09:41:49 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 8079.56it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 8648.05it/s]
[1,1]<stderr>:[2025-10-10 09:41:49 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 09:41:49 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6184.58it/s]
[1,1]<stderr>:[2025-10-10 09:41:49 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 8301.44it/s]
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 7356.81it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6936.32it/s][1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:41:50 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 09:41:50 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:50 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:50 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:50 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:50 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:50 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:50 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:50 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:50 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:50 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 09:41:50 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:50 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 09:41:50 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 8298.88it/s]
[1,1]<stderr>:[2025-10-10 09:41:50 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 09:41:50 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 7318.31it/s]
[1,1]<stderr>:[2025-10-10 09:41:50 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 20104.51it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 12284.25it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 5617.21it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 7981.55it/s]
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6292.44it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 9354.46it/s][1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 7173.58it/s][1,1]<stderr>:
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14681.44it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 12409.18it/s]
[1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13127.71it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14899.84it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13384.30it/s]
[1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 9798.34it/s][1,0]<stderr>:
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6757.51it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6535.73it/s]
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 7470.24it/s]
[1,1]<stderr>:[2025-10-10 09:41:51 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6079.25it/s]
[1,1]<stderr>:[2025-10-10 09:41:51 TP10] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 09:41:51 TP15] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 09:41:51 TP12] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 09:41:51 TP13] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 09:41:51 TP9] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 09:41:51 TP14] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 09:41:51 TP6] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 09:41:51 TP5] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 09:41:51 TP1] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 09:41:51 TP0] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 09:41:51 TP4] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 09:41:51 TP2] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 09:41:51 TP3] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 09:41:51 TP7] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 09:41:51 TP8] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 09:41:51 TP11] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 09:41:53 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 10, token usage: 0.03, #running-req: 8, #queue-req: 3, 
[1,0]<stderr>:[2025-10-10 09:41:53 TP0] Prefill batch. #new-seq: 4, #new-token: 1012, #cached-token: 10, token usage: 0.05, #running-req: 12, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:41:58] 
[1,0]<stderr>:Benchmark...
[1,0]<stderr>:[2025-10-10 09:41:58 TP0] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:41:58 TP0] Prefill batch. #new-seq: 3, #new-token: 241, #cached-token: 3, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:41:58 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 9, token usage: 0.01, #running-req: 4, #queue-req: 480, 
[1,0]<stderr>:[2025-10-10 09:41:58 TP0] Prefill batch. #new-seq: 10, #new-token: 1024, #cached-token: 10, token usage: 0.03, #running-req: 10, #queue-req: 605, 
[1,0]<stderr>:[2025-10-10 09:41:58 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 4, token usage: 0.04, #running-req: 19, #queue-req: 765, 
[1,0]<stderr>:[2025-10-10 09:41:58 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 923, 
[1,0]<stderr>:[2025-10-10 09:41:59 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.07, #running-req: 25, #queue-req: 1056, 
[1,0]<stderr>:[2025-10-10 09:41:59 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 3, token usage: 0.09, #running-req: 26, #queue-req: 1109, 
[1,0]<stderr>:[2025-10-10 09:41:59 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.11, #running-req: 29, #queue-req: 1108, 
[1,0]<stderr>:[2025-10-10 09:41:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.12, #running-req: 30, #queue-req: 1246, 
[1,0]<stderr>:[2025-10-10 09:41:59 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 3, token usage: 0.14, #running-req: 30, #queue-req: 1395, 
[1,0]<stderr>:[2025-10-10 09:41:59 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 8, token usage: 0.15, #running-req: 33, #queue-req: 1563, 
[1,0]<stderr>:[2025-10-10 09:41:59 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.17, #running-req: 38, #queue-req: 1698, 
[1,0]<stderr>:[2025-10-10 09:41:59 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 3, token usage: 0.18, #running-req: 41, #queue-req: 1832, 
[1,0]<stderr>:[2025-10-10 09:42:00 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.20, #running-req: 44, #queue-req: 1952, 
[1,0]<stderr>:[2025-10-10 09:42:00 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.21, #running-req: 47, #queue-req: 1951, 
[1,0]<stderr>:[2025-10-10 09:42:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.23, #running-req: 48, #queue-req: 1951, 
[1,0]<stderr>:[2025-10-10 09:42:00 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 9, token usage: 0.25, #running-req: 48, #queue-req: 1947, 
[1,0]<stderr>:[2025-10-10 09:42:00 TP0] Prefill batch. #new-seq: 8, #new-token: 1024, #cached-token: 11, token usage: 0.26, #running-req: 52, #queue-req: 1940, 
[1,0]<stderr>:[2025-10-10 09:42:00 TP0] Prefill batch. #new-seq: 10, #new-token: 1024, #cached-token: 16, token usage: 0.28, #running-req: 59, #queue-req: 1931, 
[1,0]<stderr>:[2025-10-10 09:42:00 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 14, token usage: 0.29, #running-req: 68, #queue-req: 1927, 
[1,0]<stderr>:[2025-10-10 09:42:00 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 10, token usage: 0.31, #running-req: 72, #queue-req: 1923, 
[1,0]<stderr>:[2025-10-10 09:42:00 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 3, token usage: 0.32, #running-req: 76, #queue-req: 1921, 
[1,0]<stderr>:[2025-10-10 09:42:01 TP0] Prefill batch. #new-seq: 3, #new-token: 925, #cached-token: 5, token usage: 0.34, #running-req: 78, #queue-req: 1919, 
[1,0]<stderr>:[2025-10-10 09:42:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.35, #running-req: 81, #queue-req: 1918, 
[1,0]<stderr>:[2025-10-10 09:42:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.37, #running-req: 81, #queue-req: 1918, 
[1,0]<stderr>:[2025-10-10 09:42:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.38, #running-req: 81, #queue-req: 1918, 
[1,0]<stderr>:[2025-10-10 09:42:01 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.40, #running-req: 81, #queue-req: 1917, 
[1,0]<stderr>:[2025-10-10 09:42:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.42, #running-req: 82, #queue-req: 1917, 
[1,0]<stderr>:[2025-10-10 09:42:01 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 13, token usage: 0.43, #running-req: 82, #queue-req: 1913, 
[1,0]<stderr>:[2025-10-10 09:42:01 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 9, token usage: 0.45, #running-req: 86, #queue-req: 1909, 
[1,0]<stderr>:[2025-10-10 09:42:02 TP0] Prefill batch. #new-seq: 9, #new-token: 1024, #cached-token: 11, token usage: 0.46, #running-req: 90, #queue-req: 1901, 
[1,0]<stderr>:[2025-10-10 09:42:02 TP0] Prefill batch. #new-seq: 8, #new-token: 1024, #cached-token: 19, token usage: 0.48, #running-req: 98, #queue-req: 1894, 
[1,0]<stderr>:[2025-10-10 09:42:02 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 11, token usage: 0.49, #running-req: 105, #queue-req: 1888, 
[1,0]<stderr>:[2025-10-10 09:42:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.51, #running-req: 111, #queue-req: 1888, 
[1,0]<stderr>:[2025-10-10 09:42:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.53, #running-req: 111, #queue-req: 1888, 
[1,0]<stderr>:[2025-10-10 09:42:02 TP0] Prefill batch. #new-seq: 10, #new-token: 1024, #cached-token: 31, token usage: 0.54, #running-req: 111, #queue-req: 1879, 
[1,0]<stderr>:[2025-10-10 09:42:02 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.56, #running-req: 120, #queue-req: 1876, 
[1,0]<stderr>:[2025-10-10 09:42:02 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 2, token usage: 0.57, #running-req: 123, #queue-req: 1874, 
[1,0]<stderr>:[2025-10-10 09:42:02 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 10, token usage: 0.59, #running-req: 125, #queue-req: 1870, 
[1,0]<stderr>:[2025-10-10 09:42:03 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 12, token usage: 0.60, #running-req: 129, #queue-req: 1864, 
[1,0]<stderr>:[2025-10-10 09:42:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.62, #running-req: 135, #queue-req: 1864, 
[1,0]<stderr>:[2025-10-10 09:42:03 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 3, token usage: 0.63, #running-req: 135, #queue-req: 1863, 
[1,0]<stderr>:[2025-10-10 09:42:03 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 13, token usage: 0.65, #running-req: 136, #queue-req: 1857, 
[1,0]<stderr>:[2025-10-10 09:42:03 TP0] Prefill batch. #new-seq: 2, #new-token: 731, #cached-token: 2, token usage: 0.67, #running-req: 142, #queue-req: 1856, 
[1,0]<stderr>:[2025-10-10 09:42:04 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 7, token usage: 0.58, #running-req: 139, #queue-req: 1851, 
[1,0]<stderr>:[2025-10-10 09:42:04 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.58, #running-req: 143, #queue-req: 1850, 
[1,0]<stderr>:[2025-10-10 09:42:04 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 7, token usage: 0.60, #running-req: 144, #queue-req: 1847, 
[1,0]<stderr>:[2025-10-10 09:42:04 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 14, token usage: 0.61, #running-req: 147, #queue-req: 1842, 
[1,0]<stderr>:[2025-10-10 09:42:04 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 4, token usage: 0.63, #running-req: 152, #queue-req: 1840, 
[1,0]<stderr>:[2025-10-10 09:42:04 TP0] Prefill batch. #new-seq: 1, #new-token: 333, #cached-token: 0, token usage: 0.64, #running-req: 154, #queue-req: 1840, 
[1,0]<stderr>:[2025-10-10 09:42:05 TP0] Prefill batch. #new-seq: 4, #new-token: 372, #cached-token: 11, token usage: 0.63, #running-req: 153, #queue-req: 1836, 
[1,0]<stderr>:[2025-10-10 09:42:05 TP0] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 1, token usage: 0.62, #running-req: 152, #queue-req: 1835, 
[1,0]<stderr>:[2025-10-10 09:42:05 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 8, token usage: 0.61, #running-req: 152, #queue-req: 1831, 
[1,0]<stderr>:[2025-10-10 09:42:06 TP0] Prefill batch. #new-seq: 5, #new-token: 775, #cached-token: 11, token usage: 0.61, #running-req: 155, #queue-req: 1827, 
[1,0]<stderr>:[2025-10-10 09:42:06 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 3, token usage: 0.63, #running-req: 155, #queue-req: 1826, 
[1,0]<stderr>:[2025-10-10 09:42:06 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 10, token usage: 0.60, #running-req: 151, #queue-req: 1824, 
[1,0]<stderr>:[2025-10-10 09:42:06 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.60, #running-req: 152, #queue-req: 1823, 
[1,0]<stderr>:[2025-10-10 09:42:06 TP0] Prefill batch. #new-seq: 2, #new-token: 164, #cached-token: 1, token usage: 0.62, #running-req: 153, #queue-req: 1822, 
[1,0]<stderr>:[2025-10-10 09:42:07 TP0] Prefill batch. #new-seq: 2, #new-token: 939, #cached-token: 6, token usage: 0.62, #running-req: 149, #queue-req: 1820, 
[1,0]<stderr>:[2025-10-10 09:42:07 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 5, token usage: 0.59, #running-req: 148, #queue-req: 1816, 
[1,0]<stderr>:[2025-10-10 09:42:07 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 4, token usage: 0.59, #running-req: 151, #queue-req: 1814, 
[1,0]<stderr>:[2025-10-10 09:42:07 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 3, token usage: 0.60, #running-req: 153, #queue-req: 1812, 
[1,0]<stderr>:[2025-10-10 09:42:07 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 0, token usage: 0.62, #running-req: 155, #queue-req: 1812, 
[1,0]<stderr>:[2025-10-10 09:42:08 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 11, token usage: 0.59, #running-req: 149, #queue-req: 1807, 
[1,0]<stderr>:[2025-10-10 09:42:08 TP0] Prefill batch. #new-seq: 6, #new-token: 872, #cached-token: 13, token usage: 0.60, #running-req: 153, #queue-req: 1802, 
[1,0]<stderr>:[2025-10-10 09:42:09 TP0] Prefill batch. #new-seq: 3, #new-token: 96, #cached-token: 5, token usage: 0.61, #running-req: 157, #queue-req: 1799, 
[1,0]<stderr>:[2025-10-10 09:42:09 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 4, token usage: 0.61, #running-req: 159, #queue-req: 1798, 
[1,0]<stderr>:[2025-10-10 09:42:10 TP0] Decode batch. #running-req: 160, #token: 40004, token usage: 0.61, cuda graph: False, gen throughput (token/s): 89.31, #queue-req: 1798, 
[1,0]<stderr>:[2025-10-10 09:42:10 TP0] Prefill batch. #new-seq: 3, #new-token: 754, #cached-token: 7, token usage: 0.61, #running-req: 159, #queue-req: 1795, 
[1,0]<stderr>:[2025-10-10 09:42:11 TP0] Prefill batch. #new-seq: 2, #new-token: 171, #cached-token: 7, token usage: 0.61, #running-req: 158, #queue-req: 1793, 
[1,0]<stderr>:[2025-10-10 09:42:11 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 11, token usage: 0.60, #running-req: 154, #queue-req: 1789, 
[1,0]<stderr>:[2025-10-10 09:42:11 TP0] Prefill batch. #new-seq: 2, #new-token: 230, #cached-token: 2, token usage: 0.62, #running-req: 157, #queue-req: 1788, 
[1,0]<stderr>:[2025-10-10 09:42:12 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 2, token usage: 0.62, #running-req: 155, #queue-req: 1787, 
[1,0]<stderr>:[2025-10-10 09:42:12 TP0] Prefill batch. #new-seq: 2, #new-token: 783, #cached-token: 3, token usage: 0.61, #running-req: 154, #queue-req: 1785, 
[1,0]<stderr>:[2025-10-10 09:42:13 TP0] Prefill batch. #new-seq: 2, #new-token: 72, #cached-token: 4, token usage: 0.63, #running-req: 155, #queue-req: 1783, 
[1,0]<stderr>:[2025-10-10 09:42:13 TP0] Prefill batch. #new-seq: 3, #new-token: 751, #cached-token: 5, token usage: 0.60, #running-req: 150, #queue-req: 1780, 
[1,0]<stderr>:[2025-10-10 09:42:13 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 7, token usage: 0.61, #running-req: 152, #queue-req: 1779, 
[1,0]<stderr>:[2025-10-10 09:42:13 TP0] Prefill batch. #new-seq: 2, #new-token: 612, #cached-token: 4, token usage: 0.60, #running-req: 152, #queue-req: 1777, 
[1,0]<stderr>:[2025-10-10 09:42:14 TP0] Prefill batch. #new-seq: 1, #new-token: 515, #cached-token: 6, token usage: 0.60, #running-req: 153, #queue-req: 1776, 
[1,0]<stderr>:[2025-10-10 09:42:14 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 8, token usage: 0.61, #running-req: 153, #queue-req: 1775, 
[1,0]<stderr>:[2025-10-10 09:42:14 TP0] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 4, token usage: 0.61, #running-req: 153, #queue-req: 1774, 
[1,0]<stderr>:[2025-10-10 09:42:14 TP0] Prefill batch. #new-seq: 4, #new-token: 842, #cached-token: 5, token usage: 0.60, #running-req: 152, #queue-req: 1770, 
[1,0]<stderr>:[2025-10-10 09:42:15 TP0] Prefill batch. #new-seq: 4, #new-token: 482, #cached-token: 8, token usage: 0.60, #running-req: 155, #queue-req: 1766, 
[1,0]<stderr>:[2025-10-10 09:42:15 TP0] Prefill batch. #new-seq: 2, #new-token: 311, #cached-token: 5, token usage: 0.59, #running-req: 158, #queue-req: 1764, 
[1,0]<stderr>:[2025-10-10 09:42:15 TP0] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 3, token usage: 0.59, #running-req: 159, #queue-req: 1763, 
[1,0]<stderr>:[2025-10-10 09:42:16 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.61, #running-req: 159, #queue-req: 1762, 
[1,0]<stderr>:[2025-10-10 09:42:17 TP0] Prefill batch. #new-seq: 2, #new-token: 18, #cached-token: 6, token usage: 0.61, #running-req: 159, #queue-req: 1760, 
[1,0]<stderr>:[2025-10-10 09:42:17 TP0] Prefill batch. #new-seq: 2, #new-token: 385, #cached-token: 5, token usage: 0.60, #running-req: 160, #queue-req: 1758, 
[1,0]<stderr>:[2025-10-10 09:42:17 TP0] Prefill batch. #new-seq: 2, #new-token: 251, #cached-token: 4, token usage: 0.60, #running-req: 161, #queue-req: 1756, 
[1,0]<stderr>:[2025-10-10 09:42:18 TP0] Prefill batch. #new-seq: 4, #new-token: 924, #cached-token: 9, token usage: 0.59, #running-req: 162, #queue-req: 1752, 
[1,0]<stderr>:[2025-10-10 09:42:18 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 5, token usage: 0.59, #running-req: 163, #queue-req: 1750, 
[1,0]<stderr>:[2025-10-10 09:42:19 TP0] Decode batch. #running-req: 163, #token: 39742, token usage: 0.61, cuda graph: False, gen throughput (token/s): 713.39, #queue-req: 1750, 
[1,0]<stderr>:[2025-10-10 09:42:19 TP0] Prefill batch. #new-seq: 2, #new-token: 507, #cached-token: 2, token usage: 0.61, #running-req: 164, #queue-req: 1749, 
[1,0]<stderr>:[2025-10-10 09:42:19 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 8, token usage: 0.59, #running-req: 161, #queue-req: 1745, 
[1,0]<stderr>:[2025-10-10 09:42:19 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.60, #running-req: 164, #queue-req: 1742, 
[1,0]<stderr>:[2025-10-10 09:42:19 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 0, token usage: 0.62, #running-req: 167, #queue-req: 1742, 
[1,0]<stderr>:[2025-10-10 09:42:20 TP0] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 2, token usage: 0.61, #running-req: 164, #queue-req: 1741, 
[1,0]<stderr>:[2025-10-10 09:42:21 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 7, token usage: 0.58, #running-req: 161, #queue-req: 1739, 
[1,0]<stderr>:[2025-10-10 09:42:21 TP0] Prefill batch. #new-seq: 2, #new-token: 849, #cached-token: 2, token usage: 0.60, #running-req: 162, #queue-req: 1738, 
[1,0]<stderr>:[2025-10-10 09:42:21 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.61, #running-req: 160, #queue-req: 1737, 
[1,0]<stderr>:[2025-10-10 09:42:22 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 4, token usage: 0.61, #running-req: 160, #queue-req: 1736, 
[1,0]<stderr>:[2025-10-10 09:42:22 TP0] Prefill batch. #new-seq: 3, #new-token: 160, #cached-token: 6, token usage: 0.61, #running-req: 158, #queue-req: 1733, 
[1,0]<stderr>:[2025-10-10 09:42:22 TP0] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 2, token usage: 0.61, #running-req: 160, #queue-req: 1732, 
[1,0]<stderr>:[2025-10-10 09:42:22 TP0] Prefill batch. #new-seq: 1, #new-token: 868, #cached-token: 3, token usage: 0.60, #running-req: 160, #queue-req: 1731, 
[1,0]<stderr>:[2025-10-10 09:42:23 TP0] Prefill batch. #new-seq: 4, #new-token: 888, #cached-token: 6, token usage: 0.59, #running-req: 156, #queue-req: 1727, 
[1,0]<stderr>:[2025-10-10 09:42:23 TP0] Prefill batch. #new-seq: 1, #new-token: 660, #cached-token: 4, token usage: 0.61, #running-req: 159, #queue-req: 1726, 
[1,0]<stderr>:[2025-10-10 09:42:24 TP0] Prefill batch. #new-seq: 4, #new-token: 574, #cached-token: 8, token usage: 0.61, #running-req: 157, #queue-req: 1722, 
[1,0]<stderr>:[2025-10-10 09:42:24 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.61, #running-req: 159, #queue-req: 1721, 
[1,0]<stderr>:[2025-10-10 09:42:25 TP0] Prefill batch. #new-seq: 2, #new-token: 324, #cached-token: 6, token usage: 0.63, #running-req: 159, #queue-req: 1719, 
[1,0]<stderr>:[2025-10-10 09:42:25 TP0] Prefill batch. #new-seq: 5, #new-token: 1008, #cached-token: 16, token usage: 0.60, #running-req: 158, #queue-req: 1714, 
[1,0]<stderr>:[2025-10-10 09:42:25 TP0] Decode batch. #running-req: 163, #token: 40635, token usage: 0.62, cuda graph: False, gen throughput (token/s): 925.43, #queue-req: 1714, 
[1,0]<stderr>:[2025-10-10 09:42:26 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 2, token usage: 0.62, #running-req: 162, #queue-req: 1713, 
[1,0]<stderr>:[2025-10-10 09:42:26 TP0] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 4, token usage: 0.63, #running-req: 162, #queue-req: 1712, 
[1,0]<stderr>:[2025-10-10 09:42:27 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 4, token usage: 0.62, #running-req: 160, #queue-req: 1709, 
[1,0]<stderr>:[2025-10-10 09:42:27 TP0] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 0, token usage: 0.64, #running-req: 162, #queue-req: 1709, 
[1,0]<stderr>:[2025-10-10 09:42:28 TP0] Prefill batch. #new-seq: 2, #new-token: 814, #cached-token: 9, token usage: 0.63, #running-req: 158, #queue-req: 1707, 
[1,0]<stderr>:[2025-10-10 09:42:28 TP0] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 2, token usage: 0.64, #running-req: 155, #queue-req: 1706, 
[1,0]<stderr>:[2025-10-10 09:42:28 TP0] Prefill batch. #new-seq: 2, #new-token: 346, #cached-token: 9, token usage: 0.65, #running-req: 155, #queue-req: 1704, 
[1,0]<stderr>:[2025-10-10 09:42:29 TP0] Prefill batch. #new-seq: 3, #new-token: 40, #cached-token: 10, token usage: 0.65, #running-req: 155, #queue-req: 1701, 
[1,0]<stderr>:[2025-10-10 09:42:29 TP0] Prefill batch. #new-seq: 2, #new-token: 506, #cached-token: 2, token usage: 0.65, #running-req: 153, #queue-req: 1699, 
[1,0]<stderr>:[2025-10-10 09:42:30 TP0] Prefill batch. #new-seq: 2, #new-token: 675, #cached-token: 7, token usage: 0.64, #running-req: 152, #queue-req: 1697, 
[1,0]<stderr>:[2025-10-10 09:42:30 TP0] Prefill batch. #new-seq: 1, #new-token: 224, #cached-token: 4, token usage: 0.66, #running-req: 153, #queue-req: 1696, 
[1,0]<stderr>:[2025-10-10 09:42:31 TP0] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.66, #running-req: 150, #queue-req: 1695, 
[1,0]<stderr>:[2025-10-10 09:42:31 TP0] Decode batch. #running-req: 151, #token: 44695, token usage: 0.68, cuda graph: False, gen throughput (token/s): 1047.97, #queue-req: 1695, 
[1,0]<stderr>:[2025-10-10 09:42:32 TP0] Prefill batch. #new-seq: 2, #new-token: 457, #cached-token: 6, token usage: 0.68, #running-req: 148, #queue-req: 1693, 
[1,0]<stderr>:[2025-10-10 09:42:34 TP0] Prefill batch. #new-seq: 2, #new-token: 614, #cached-token: 7, token usage: 0.70, #running-req: 146, #queue-req: 1691, 
[1,0]<stderr>:[2025-10-10 09:42:34 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.70, #running-req: 147, #queue-req: 1690, 
[1,0]<stderr>:[2025-10-10 09:42:35 TP0] Prefill batch. #new-seq: 4, #new-token: 938, #cached-token: 7, token usage: 0.70, #running-req: 146, #queue-req: 1686, 
[1,0]<stderr>:[2025-10-10 09:42:36 TP0] Prefill batch. #new-seq: 2, #new-token: 457, #cached-token: 6, token usage: 0.72, #running-req: 149, #queue-req: 1684, 
[1,0]<stderr>:[2025-10-10 09:42:36 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 4, token usage: 0.72, #running-req: 149, #queue-req: 1683, 
[1,0]<stderr>:[2025-10-10 09:42:36 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 1, token usage: 0.72, #running-req: 148, #queue-req: 1682, 
[1,0]<stderr>:[2025-10-10 09:42:37 TP0] Decode batch. #running-req: 147, #token: 47527, token usage: 0.73, cuda graph: False, gen throughput (token/s): 1093.34, #queue-req: 1682, 
[1,0]<stderr>:[2025-10-10 09:42:37 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 9, token usage: 0.70, #running-req: 144, #queue-req: 1679, 
[1,0]<stderr>:[2025-10-10 09:42:37 TP0] Prefill batch. #new-seq: 2, #new-token: 32, #cached-token: 3, token usage: 0.72, #running-req: 146, #queue-req: 1678, 
[1,0]<stderr>:[2025-10-10 09:42:38 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 7, token usage: 0.67, #running-req: 145, #queue-req: 1674, 
[1,0]<stderr>:[2025-10-10 09:42:38 TP0] Prefill batch. #new-seq: 9, #new-token: 673, #cached-token: 20, token usage: 0.68, #running-req: 148, #queue-req: 1666, 
[1,0]<stderr>:[2025-10-10 09:42:38 TP0] Prefill batch. #new-seq: 5, #new-token: 844, #cached-token: 11, token usage: 0.69, #running-req: 153, #queue-req: 1661, 
[1,0]<stderr>:[2025-10-10 09:42:39 TP0] Prefill batch. #new-seq: 2, #new-token: 683, #cached-token: 4, token usage: 0.69, #running-req: 156, #queue-req: 1659, 
[1,0]<stderr>:[2025-10-10 09:42:39 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.70, #running-req: 156, #queue-req: 1658, 
[1,0]<stderr>:[2025-10-10 09:42:39 TP0] Prefill batch. #new-seq: 4, #new-token: 705, #cached-token: 7, token usage: 0.67, #running-req: 154, #queue-req: 1654, 
[1,0]<stderr>:[2025-10-10 09:42:40 TP0] Prefill batch. #new-seq: 2, #new-token: 884, #cached-token: 6, token usage: 0.68, #running-req: 156, #queue-req: 1652, 
[1,0]<stderr>:[2025-10-10 09:42:40 TP0] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 3, token usage: 0.69, #running-req: 155, #queue-req: 1651, 
[1,0]<stderr>:[2025-10-10 09:42:40 TP0] Prefill batch. #new-seq: 2, #new-token: 633, #cached-token: 10, token usage: 0.69, #running-req: 154, #queue-req: 1649, 
[1,0]<stderr>:[2025-10-10 09:42:41 TP0] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 6, token usage: 0.69, #running-req: 154, #queue-req: 1648, 
[1,0]<stderr>:[2025-10-10 09:42:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 4, token usage: 0.71, #running-req: 150, #queue-req: 1647, 
[1,0]<stderr>:[2025-10-10 09:42:42 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 0, token usage: 0.72, #running-req: 150, #queue-req: 1647, 
[1,0]<stderr>:[2025-10-10 09:42:43 TP0] Prefill batch. #new-seq: 2, #new-token: 741, #cached-token: 5, token usage: 0.71, #running-req: 149, #queue-req: 1645, 
[1,0]<stderr>:[2025-10-10 09:42:43 TP0] Decode batch. #running-req: 150, #token: 47787, token usage: 0.73, cuda graph: False, gen throughput (token/s): 961.76, #queue-req: 1645, 
[1,0]<stderr>:[2025-10-10 09:42:44 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.73, #running-req: 148, #queue-req: 1644, 
[1,0]<stderr>:[2025-10-10 09:42:45 TP0] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 1, token usage: 0.75, #running-req: 146, #queue-req: 1643, 
[1,0]<stderr>:[2025-10-10 09:42:46 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.76, #running-req: 146, #queue-req: 1642, 
[1,0]<stderr>:[2025-10-10 09:42:46 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.74, #running-req: 145, #queue-req: 1641, 
[1,0]<stderr>:[2025-10-10 09:42:48 TP0] Decode batch. #running-req: 140, #token: 49304, token usage: 0.75, cuda graph: False, gen throughput (token/s): 1156.25, #queue-req: 1641, 
[1,0]<stderr>:[2025-10-10 09:42:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.74, #running-req: 138, #queue-req: 1640, 
[1,0]<stderr>:[2025-10-10 09:42:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.75, #running-req: 138, #queue-req: 1640, 
[1,0]<stderr>:[2025-10-10 09:42:49 TP0] Prefill batch. #new-seq: 4, #new-token: 463, #cached-token: 7, token usage: 0.77, #running-req: 138, #queue-req: 1637, 
[1,0]<stderr>:[2025-10-10 09:42:50 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.78, #running-req: 139, #queue-req: 1636, 
[1,0]<stderr>:[2025-10-10 09:42:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.79, #running-req: 132, #queue-req: 1635, 
[1,0]<stderr>:[2025-10-10 09:42:53 TP0] Prefill batch. #new-seq: 3, #new-token: 409, #cached-token: 4, token usage: 0.81, #running-req: 132, #queue-req: 1633, 
[1,0]<stderr>:[2025-10-10 09:42:53 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 1, token usage: 0.81, #running-req: 134, #queue-req: 1632, 
[1,0]<stderr>:[2025-10-10 09:42:54 TP0] Decode batch. #running-req: 135, #token: 54070, token usage: 0.83, cuda graph: False, gen throughput (token/s): 1014.15, #queue-req: 1632, 
[1,0]<stderr>:[2025-10-10 09:42:54 TP0] Prefill batch. #new-seq: 3, #new-token: 632, #cached-token: 14, token usage: 0.82, #running-req: 132, #queue-req: 1629, 
[1,0]<stderr>:[2025-10-10 09:42:55 TP0] Prefill batch. #new-seq: 1, #new-token: 728, #cached-token: 5, token usage: 0.82, #running-req: 129, #queue-req: 1628, 
[1,0]<stderr>:[2025-10-10 09:42:56 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 5, token usage: 0.80, #running-req: 126, #queue-req: 1625, 
[1,0]<stderr>:[2025-10-10 09:42:56 TP0] Prefill batch. #new-seq: 2, #new-token: 231, #cached-token: 3, token usage: 0.82, #running-req: 128, #queue-req: 1624, 
[1,0]<stderr>:[2025-10-10 09:42:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.81, #running-req: 125, #queue-req: 1623, 
[1,0]<stderr>:[2025-10-10 09:42:57 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 0, token usage: 0.83, #running-req: 125, #queue-req: 1623, 
[1,0]<stderr>:[2025-10-10 09:42:58 TP0] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 3, token usage: 0.83, #running-req: 125, #queue-req: 1622, 
[1,0]<stderr>:[2025-10-10 09:42:59 TP0] Prefill batch. #new-seq: 1, #new-token: 990, #cached-token: 3, token usage: 0.83, #running-req: 124, #queue-req: 1621, 
[1,0]<stderr>:[2025-10-10 09:42:59 TP0] Decode batch. #running-req: 125, #token: 55889, token usage: 0.85, cuda graph: False, gen throughput (token/s): 916.64, #queue-req: 1621, 
[1,0]<stderr>:[2025-10-10 09:43:00 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.86, #running-req: 121, #queue-req: 1620, 
[1,0]<stderr>:[2025-10-10 09:43:01 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.86, #running-req: 120, #queue-req: 1619, 
[1,0]<stderr>:[2025-10-10 09:43:02 TP0] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.85, #running-req: 120, #queue-req: 1618, 
[1,0]<stderr>:[2025-10-10 09:43:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.84, #running-req: 116, #queue-req: 1617, 
[1,0]<stderr>:[2025-10-10 09:43:04 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.84, #running-req: 116, #queue-req: 1616, 
[1,0]<stderr>:[2025-10-10 09:43:04 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.86, #running-req: 117, #queue-req: 1615, 
[1,0]<stderr>:[2025-10-10 09:43:04 TP0] Prefill batch. #new-seq: 1, #new-token: 351, #cached-token: 0, token usage: 0.87, #running-req: 118, #queue-req: 1615, 
[1,0]<stderr>:[2025-10-10 09:43:05 TP0] Decode batch. #running-req: 117, #token: 58434, token usage: 0.89, cuda graph: False, gen throughput (token/s): 861.31, #queue-req: 1615, 
[1,0]<stderr>:[2025-10-10 09:43:06 TP0] Prefill batch. #new-seq: 1, #new-token: 834, #cached-token: 1, token usage: 0.88, #running-req: 115, #queue-req: 1614, 
[1,0]<stderr>:[2025-10-10 09:43:06 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.88, #running-req: 113, #queue-req: 1613, 
[1,0]<stderr>:[2025-10-10 09:43:06 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 14, token usage: 0.83, #running-req: 110, #queue-req: 1606, 
[1,0]<stderr>:[2025-10-10 09:43:06 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 13, token usage: 0.83, #running-req: 116, #queue-req: 1602, 
[1,0]<stderr>:[2025-10-10 09:43:07 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.85, #running-req: 120, #queue-req: 1599, 
[1,0]<stderr>:[2025-10-10 09:43:07 TP0] Prefill batch. #new-seq: 3, #new-token: 400, #cached-token: 3, token usage: 0.86, #running-req: 123, #queue-req: 1597, 
[1,0]<stderr>:[2025-10-10 09:43:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.85, #running-req: 121, #queue-req: 1596, 
[1,0]<stderr>:[2025-10-10 09:43:07 TP0] Prefill batch. #new-seq: 2, #new-token: 315, #cached-token: 1, token usage: 0.87, #running-req: 121, #queue-req: 1595, 
[1,0]<stderr>:[2025-10-10 09:43:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.85, #running-req: 118, #queue-req: 1594, 
[1,0]<stderr>:[2025-10-10 09:43:08 TP0] Prefill batch. #new-seq: 4, #new-token: 998, #cached-token: 7, token usage: 0.86, #running-req: 118, #queue-req: 1591, 
[1,0]<stderr>:[2025-10-10 09:43:08 TP0] Prefill batch. #new-seq: 2, #new-token: 298, #cached-token: 6, token usage: 0.88, #running-req: 118, #queue-req: 1589, 
[1,0]<stderr>:[2025-10-10 09:43:09 TP0] Prefill batch. #new-seq: 3, #new-token: 576, #cached-token: 4, token usage: 0.87, #running-req: 118, #queue-req: 1586, 
[1,0]<stderr>:[2025-10-10 09:43:09 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.87, #running-req: 120, #queue-req: 1585, 
[1,0]<stderr>:[2025-10-10 09:43:09 TP0] Prefill batch. #new-seq: 5, #new-token: 587, #cached-token: 14, token usage: 0.86, #running-req: 119, #queue-req: 1580, 
[1,0]<stderr>:[2025-10-10 09:43:10 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 6, token usage: 0.85, #running-req: 121, #queue-req: 1576, 
[1,0]<stderr>:[2025-10-10 09:43:10 TP0] Prefill batch. #new-seq: 2, #new-token: 858, #cached-token: 3, token usage: 0.86, #running-req: 124, #queue-req: 1575, 
[1,0]<stderr>:[2025-10-10 09:43:10 TP0] Prefill batch. #new-seq: 2, #new-token: 299, #cached-token: 5, token usage: 0.88, #running-req: 124, #queue-req: 1573, 
[1,0]<stderr>:[2025-10-10 09:43:11 TP0] Prefill batch. #new-seq: 1, #new-token: 547, #cached-token: 1, token usage: 0.88, #running-req: 124, #queue-req: 1572, 
[1,0]<stderr>:[2025-10-10 09:43:11 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.88, #running-req: 123, #queue-req: 1571, 
[1,0]<stderr>:[2025-10-10 09:43:11 TP0] Prefill batch. #new-seq: 1, #new-token: 762, #cached-token: 3, token usage: 0.87, #running-req: 122, #queue-req: 1570, 
[1,0]<stderr>:[2025-10-10 09:43:12 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.87, #running-req: 119, #queue-req: 1569, 
[1,0]<stderr>:[2025-10-10 09:43:12 TP0] Decode batch. #running-req: 120, #token: 56952, token usage: 0.87, cuda graph: False, gen throughput (token/s): 672.07, #queue-req: 1569, 
[1,0]<stderr>:[2025-10-10 09:43:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.86, #running-req: 119, #queue-req: 1568, 
[1,0]<stderr>:[2025-10-10 09:43:12 TP0] Prefill batch. #new-seq: 2, #new-token: 59, #cached-token: 2, token usage: 0.87, #running-req: 119, #queue-req: 1567, 
[1,0]<stderr>:[2025-10-10 09:43:12 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 4, token usage: 0.88, #running-req: 120, #queue-req: 1566, 
[1,0]<stderr>:[2025-10-10 09:43:13 TP0] Prefill batch. #new-seq: 2, #new-token: 779, #cached-token: 3, token usage: 0.88, #running-req: 118, #queue-req: 1564, 
[1,0]<stderr>:[2025-10-10 09:43:14 TP0] Prefill batch. #new-seq: 3, #new-token: 284, #cached-token: 5, token usage: 0.89, #running-req: 119, #queue-req: 1561, 
[1,0]<stderr>:[2025-10-10 09:43:14 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.88, #running-req: 121, #queue-req: 1560, 
[1,0]<stderr>:[2025-10-10 09:43:14 TP0] Prefill batch. #new-seq: 1, #new-token: 837, #cached-token: 2, token usage: 0.88, #running-req: 121, #queue-req: 1559, 
[1,0]<stderr>:[2025-10-10 09:43:14 TP0] Prefill batch. #new-seq: 2, #new-token: 97, #cached-token: 11, token usage: 0.89, #running-req: 121, #queue-req: 1557, 
[1,0]<stderr>:[2025-10-10 09:43:18 TP0] Decode batch. #running-req: 115, #token: 57506, token usage: 0.88, cuda graph: False, gen throughput (token/s): 861.31, #queue-req: 1557, 
[1,0]<stderr>:[2025-10-10 09:43:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.88, #running-req: 114, #queue-req: 1556, 
[1,0]<stderr>:[2025-10-10 09:43:18 TP0] Prefill batch. #new-seq: 2, #new-token: 893, #cached-token: 1, token usage: 0.89, #running-req: 114, #queue-req: 1555, 
[1,0]<stderr>:[2025-10-10 09:43:18 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.91, #running-req: 114, #queue-req: 1554, 
[1,0]<stderr>:[2025-10-10 09:43:19 TP0] Prefill batch. #new-seq: 3, #new-token: 995, #cached-token: 4, token usage: 0.88, #running-req: 113, #queue-req: 1551, 
[1,0]<stderr>:[2025-10-10 09:43:19 TP0] Prefill batch. #new-seq: 6, #new-token: 452, #cached-token: 13, token usage: 0.87, #running-req: 111, #queue-req: 1545, 
[1,0]<stderr>:[2025-10-10 09:43:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.87, #running-req: 116, #queue-req: 1544, 
[1,0]<stderr>:[2025-10-10 09:43:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.88, #running-req: 116, #queue-req: 1544, 
[1,0]<stderr>:[2025-10-10 09:43:20 TP0] Prefill batch. #new-seq: 4, #new-token: 556, #cached-token: 4, token usage: 0.90, #running-req: 116, #queue-req: 1541, 
[1,0]<stderr>:[2025-10-10 09:43:20 TP0] Prefill batch. #new-seq: 2, #new-token: 15, #cached-token: 2, token usage: 0.91, #running-req: 118, #queue-req: 1539, 
[1,0]<stderr>:[2025-10-10 09:43:21 TP0] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 5, token usage: 0.91, #running-req: 118, #queue-req: 1538, 
[1,0]<stderr>:[2025-10-10 09:43:22 TP0] Prefill batch. #new-seq: 2, #new-token: 126, #cached-token: 3, token usage: 0.91, #running-req: 118, #queue-req: 1536, 
[1,0]<stderr>:[2025-10-10 09:43:23 TP0] Prefill batch. #new-seq: 6, #new-token: 588, #cached-token: 14, token usage: 0.88, #running-req: 116, #queue-req: 1530, 
[1,0]<stderr>:[2025-10-10 09:43:23 TP0] Prefill batch. #new-seq: 3, #new-token: 37, #cached-token: 5, token usage: 0.90, #running-req: 120, #queue-req: 1527, 
[1,0]<stderr>:[2025-10-10 09:43:24 TP0] Decode batch. #running-req: 122, #token: 58584, token usage: 0.89, cuda graph: False, gen throughput (token/s): 760.42, #queue-req: 1527, 
[1,0]<stderr>:[2025-10-10 09:43:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.85, #running-req: 121, #queue-req: 1526, 
[1,0]<stderr>:[2025-10-10 09:43:24 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 6, token usage: 0.86, #running-req: 121, #queue-req: 1523, 
[1,0]<stderr>:[2025-10-10 09:43:24 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 11, token usage: 0.88, #running-req: 124, #queue-req: 1517, 
[1,0]<stderr>:[2025-10-10 09:43:24 TP0] Prefill batch. #new-seq: 2, #new-token: 540, #cached-token: 2, token usage: 0.89, #running-req: 130, #queue-req: 1516, 
[1,0]<stderr>:[2025-10-10 09:43:26 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 5, token usage: 0.89, #running-req: 125, #queue-req: 1513, 
[1,0]<stderr>:[2025-10-10 09:43:26 TP0] Prefill batch. #new-seq: 5, #new-token: 892, #cached-token: 7, token usage: 0.90, #running-req: 127, #queue-req: 1509, 
[1,0]<stderr>:[2025-10-10 09:43:26 TP0] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 5, token usage: 0.91, #running-req: 129, #queue-req: 1508, 
[1,0]<stderr>:[2025-10-10 09:43:26 TP0] Prefill batch. #new-seq: 4, #new-token: 517, #cached-token: 10, token usage: 0.91, #running-req: 129, #queue-req: 1504, 
[1,0]<stderr>:[2025-10-10 09:43:27 TP0] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 3, token usage: 0.90, #running-req: 131, #queue-req: 1503, 
[1,0]<stderr>:[2025-10-10 09:43:27 TP0] Prefill batch. #new-seq: 4, #new-token: 658, #cached-token: 8, token usage: 0.89, #running-req: 130, #queue-req: 1499, 
[1,0]<stderr>:[2025-10-10 09:43:28 TP0] Prefill batch. #new-seq: 2, #new-token: 47, #cached-token: 3, token usage: 0.91, #running-req: 132, #queue-req: 1497, 
[1,0]<stderr>:[2025-10-10 09:43:28 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 4, token usage: 0.90, #running-req: 131, #queue-req: 1494, 
[1,0]<stderr>:[2025-10-10 09:43:28 TP0] Prefill batch. #new-seq: 2, #new-token: 221, #cached-token: 3, token usage: 0.91, #running-req: 133, #queue-req: 1493, 
[1,0]<stderr>:[2025-10-10 09:43:28 TP0] Prefill batch. #new-seq: 2, #new-token: 882, #cached-token: 8, token usage: 0.91, #running-req: 132, #queue-req: 1491, 
[1,0]<stderr>:[2025-10-10 09:43:29 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 1, token usage: 0.92, #running-req: 132, #queue-req: 1490, 
[1,0]<stderr>:[2025-10-10 09:43:30 TP0] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 2, token usage: 0.92, #running-req: 132, #queue-req: 1489, 
[1,0]<stderr>:[2025-10-10 09:43:30 TP0] Decode batch. #running-req: 133, #token: 59534, token usage: 0.91, cuda graph: False, gen throughput (token/s): 807.90, #queue-req: 1489, 
[1,0]<stderr>:[2025-10-10 09:43:30 TP0] Prefill batch. #new-seq: 3, #new-token: 43, #cached-token: 6, token usage: 0.91, #running-req: 132, #queue-req: 1486, 
[1,0]<stderr>:[2025-10-10 09:43:31 TP0] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 2, token usage: 0.91, #running-req: 132, #queue-req: 1485, 
[1,0]<stderr>:[2025-10-10 09:43:32 TP0] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 2, token usage: 0.92, #running-req: 132, #queue-req: 1484, 
[1,0]<stderr>:[2025-10-10 09:43:33 TP0] Prefill batch. #new-seq: 1, #new-token: 881, #cached-token: 1, token usage: 0.91, #running-req: 128, #queue-req: 1483, 
[1,0]<stderr>:[2025-10-10 09:43:33 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 9, token usage: 0.93, #running-req: 128, #queue-req: 1480, 
[1,0]<stderr>:[2025-10-10 09:43:33 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 0, token usage: 0.94, #running-req: 130, #queue-req: 1480, 
[1,0]<stderr>:[2025-10-10 09:43:34 TP0] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 1, token usage: 0.94, #running-req: 130, #queue-req: 1479, 
[1,0]<stderr>:[2025-10-10 09:43:35 TP0] Prefill batch. #new-seq: 5, #new-token: 161, #cached-token: 11, token usage: 0.94, #running-req: 130, #queue-req: 1474, 
[1,0]<stderr>:[2025-10-10 09:43:35 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.93, #running-req: 134, #queue-req: 1473, 
[1,0]<stderr>:[2025-10-10 09:43:35 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 1, token usage: 0.93, #running-req: 134, #queue-req: 1472, 
[1,0]<stderr>:[2025-10-10 09:43:36 TP0] Decode batch. #running-req: 135, #token: 62670, token usage: 0.96, cuda graph: False, gen throughput (token/s): 909.42, #queue-req: 1472, 
[1,0]<stderr>:[2025-10-10 09:43:37 TP0] Prefill batch. #new-seq: 5, #new-token: 589, #cached-token: 5, token usage: 0.94, #running-req: 134, #queue-req: 1467, 
[1,0]<stderr>:[2025-10-10 09:43:37 TP0] Prefill batch. #new-seq: 2, #new-token: 688, #cached-token: 10, token usage: 0.94, #running-req: 136, #queue-req: 1465, 
[1,0]<stderr>:[2025-10-10 09:43:38 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 14, token usage: 0.92, #running-req: 136, #queue-req: 1460, 
[1,0]<stderr>:[2025-10-10 09:43:38 TP0] Prefill batch. #new-seq: 5, #new-token: 819, #cached-token: 8, token usage: 0.93, #running-req: 140, #queue-req: 1456, 
[1,0]<stderr>:[2025-10-10 09:43:38 TP0] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 2, token usage: 0.95, #running-req: 144, #queue-req: 1455, 
[1,0]<stderr>:[2025-10-10 09:43:40 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 7, token usage: 0.93, #running-req: 136, #queue-req: 1451, 
[1,0]<stderr>:[2025-10-10 09:43:41 TP0] Prefill batch. #new-seq: 3, #new-token: 415, #cached-token: 4, token usage: 0.94, #running-req: 139, #queue-req: 1449, 
[1,0]<stderr>:[2025-10-10 09:43:41 TP0] Prefill batch. #new-seq: 1, #new-token: 720, #cached-token: 1, token usage: 0.94, #running-req: 139, #queue-req: 1448, 
[1,0]<stderr>:[2025-10-10 09:43:41 TP0] Decode batch. #running-req: 138, #token: 61798, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1012.45, #queue-req: 1448, 
[1,0]<stderr>:[2025-10-10 09:43:41 TP0] Prefill batch. #new-seq: 1, #new-token: 795, #cached-token: 2, token usage: 0.94, #running-req: 137, #queue-req: 1447, 
[1,0]<stderr>:[2025-10-10 09:43:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.93, #running-req: 136, #queue-req: 1446, 
[1,0]<stderr>:[2025-10-10 09:43:42 TP0] Prefill batch. #new-seq: 6, #new-token: 875, #cached-token: 11, token usage: 0.94, #running-req: 136, #queue-req: 1441, 
[1,0]<stderr>:[2025-10-10 09:43:42 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 1, token usage: 0.95, #running-req: 140, #queue-req: 1440, 
[1,0]<stderr>:[2025-10-10 09:43:43 TP0] Prefill batch. #new-seq: 2, #new-token: 611, #cached-token: 4, token usage: 0.95, #running-req: 140, #queue-req: 1438, 
[1,0]<stderr>:[2025-10-10 09:43:43 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.95, #running-req: 138, #queue-req: 1437, 
[1,0]<stderr>:[2025-10-10 09:43:44 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 1, token usage: 0.94, #running-req: 137, #queue-req: 1436, 
[1,0]<stderr>:[2025-10-10 09:43:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.93, #running-req: 134, #queue-req: 1435, 
[1,0]<stderr>:[2025-10-10 09:43:45 TP0] Prefill batch. #new-seq: 1, #new-token: 571, #cached-token: 0, token usage: 0.95, #running-req: 134, #queue-req: 1435, 
[1,0]<stderr>:[2025-10-10 09:43:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.93, #running-req: 127, #queue-req: 1434, 
[1,0]<stderr>:[2025-10-10 09:43:47 TP0] Prefill batch. #new-seq: 2, #new-token: 857, #cached-token: 1, token usage: 0.94, #running-req: 127, #queue-req: 1433, 
[1,0]<stderr>:[2025-10-10 09:43:47 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.95, #running-req: 124, #queue-req: 1432, 
[1,0]<stderr>:[2025-10-10 09:43:48 TP0] Decode batch. #running-req: 125, #token: 62978, token usage: 0.96, cuda graph: False, gen throughput (token/s): 837.78, #queue-req: 1432, 
[1,0]<stderr>:[2025-10-10 09:43:49 TP0] Prefill batch. #new-seq: 2, #new-token: 514, #cached-token: 7, token usage: 0.94, #running-req: 121, #queue-req: 1430, 
[1,0]<stderr>:[2025-10-10 09:43:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.88, #running-req: 116, #queue-req: 1429, 
[1,0]<stderr>:[2025-10-10 09:43:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.90, #running-req: 116, #queue-req: 1429, 
[1,0]<stderr>:[2025-10-10 09:43:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.91, #running-req: 116, #queue-req: 1429, 
[1,0]<stderr>:[2025-10-10 09:43:50 TP0] Prefill batch. #new-seq: 3, #new-token: 500, #cached-token: 2, token usage: 0.93, #running-req: 116, #queue-req: 1427, 
[1,0]<stderr>:[2025-10-10 09:43:50 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 17, token usage: 0.94, #running-req: 118, #queue-req: 1424, 
[1,0]<stderr>:[2025-10-10 09:43:50 TP0] Prefill batch. #new-seq: 2, #new-token: 85, #cached-token: 1, token usage: 0.95, #running-req: 120, #queue-req: 1423, 
[1,0]<stderr>:[2025-10-10 09:43:51 TP0] Prefill batch. #new-seq: 2, #new-token: 757, #cached-token: 6, token usage: 0.95, #running-req: 120, #queue-req: 1421, 
[1,0]<stderr>:[2025-10-10 09:43:51 TP0] Prefill batch. #new-seq: 2, #new-token: 310, #cached-token: 10, token usage: 0.95, #running-req: 120, #queue-req: 1419, 
[1,0]<stderr>:[2025-10-10 09:43:51 TP0] Prefill batch. #new-seq: 4, #new-token: 729, #cached-token: 8, token usage: 0.94, #running-req: 121, #queue-req: 1415, 
[1,0]<stderr>:[2025-10-10 09:43:52 TP0] Prefill batch. #new-seq: 2, #new-token: 245, #cached-token: 3, token usage: 0.95, #running-req: 123, #queue-req: 1413, 
[1,0]<stderr>:[2025-10-10 09:43:53 TP0] Prefill batch. #new-seq: 3, #new-token: 330, #cached-token: 5, token usage: 0.95, #running-req: 124, #queue-req: 1410, 
[1,0]<stderr>:[2025-10-10 09:43:53 TP0] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 8, token usage: 0.95, #running-req: 125, #queue-req: 1409, 
[1,0]<stderr>:[2025-10-10 09:43:54 TP0] Decode batch. #running-req: 125, #token: 63556, token usage: 0.97, cuda graph: False, gen throughput (token/s): 794.16, #queue-req: 1409, 
[1,0]<stderr>:[2025-10-10 09:43:56 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.95, #running-req: 120, #queue-req: 1408, 
[1,0]<stderr>:[2025-10-10 09:43:56 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 23, token usage: 0.94, #running-req: 119, #queue-req: 1404, 
[1,0]<stderr>:[2025-10-10 09:43:56 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 0, token usage: 0.96, #running-req: 122, #queue-req: 1404, 
[1,0]<stderr>:[2025-10-10 09:43:57 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.95, #running-req: 122, #queue-req: 1403, 
[1,0]<stderr>:[2025-10-10 09:43:57 TP0] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 2, token usage: 0.95, #running-req: 121, #queue-req: 1402, 
[1,0]<stderr>:[2025-10-10 09:43:57 TP0] Prefill batch. #new-seq: 3, #new-token: 842, #cached-token: 4, token usage: 0.94, #running-req: 120, #queue-req: 1399, 
[1,0]<stderr>:[2025-10-10 09:43:58 TP0] Prefill batch. #new-seq: 1, #new-token: 708, #cached-token: 5, token usage: 0.95, #running-req: 119, #queue-req: 1398, 
[1,0]<stderr>:[2025-10-10 09:43:58 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 10, token usage: 0.88, #running-req: 116, #queue-req: 1394, 
[1,0]<stderr>:[2025-10-10 09:43:58 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.90, #running-req: 119, #queue-req: 1393, 
[1,0]<stderr>:[2025-10-10 09:43:59 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 9, token usage: 0.91, #running-req: 120, #queue-req: 1389, 
[1,0]<stderr>:[2025-10-10 09:43:59 TP0] Prefill batch. #new-seq: 6, #new-token: 1002, #cached-token: 11, token usage: 0.93, #running-req: 124, #queue-req: 1384, 
[1,0]<stderr>:[2025-10-10 09:43:59 TP0] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 3, token usage: 0.94, #running-req: 127, #queue-req: 1383, 
[1,0]<stderr>:[2025-10-10 09:44:00 TP0] Prefill batch. #new-seq: 1, #new-token: 497, #cached-token: 2, token usage: 0.94, #running-req: 126, #queue-req: 1382, 
[1,0]<stderr>:[2025-10-10 09:44:00 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 8, token usage: 0.92, #running-req: 121, #queue-req: 1379, 
[1,0]<stderr>:[2025-10-10 09:44:00 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 9, token usage: 0.93, #running-req: 123, #queue-req: 1376, 
[1,0]<stderr>:[2025-10-10 09:44:00 TP0] Prefill batch. #new-seq: 1, #new-token: 752, #cached-token: 0, token usage: 0.94, #running-req: 126, #queue-req: 1376, 
[1,0]<stderr>:[2025-10-10 09:44:01 TP0] Decode batch. #running-req: 126, #token: 62049, token usage: 0.95, cuda graph: False, gen throughput (token/s): 737.71, #queue-req: 1376, 
[1,0]<stderr>:[2025-10-10 09:44:01 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.95, #running-req: 125, #queue-req: 1375, 
[1,0]<stderr>:[2025-10-10 09:44:01 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 16, token usage: 0.91, #running-req: 123, #queue-req: 1368, 
[1,0]<stderr>:[2025-10-10 09:44:01 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 5, token usage: 0.92, #running-req: 129, #queue-req: 1367, 
[1,0]<stderr>:[2025-10-10 09:44:02 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 3, token usage: 0.94, #running-req: 130, #queue-req: 1365, 
[1,0]<stderr>:[2025-10-10 09:44:02 TP0] Prefill batch. #new-seq: 2, #new-token: 266, #cached-token: 2, token usage: 0.95, #running-req: 132, #queue-req: 1364, 
[1,0]<stderr>:[2025-10-10 09:44:02 TP0] Prefill batch. #new-seq: 2, #new-token: 448, #cached-token: 7, token usage: 0.95, #running-req: 128, #queue-req: 1362, 
[1,0]<stderr>:[2025-10-10 09:44:02 TP0] Prefill batch. #new-seq: 3, #new-token: 270, #cached-token: 8, token usage: 0.94, #running-req: 129, #queue-req: 1359, 
[1,0]<stderr>:[2025-10-10 09:44:03 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 7, token usage: 0.94, #running-req: 130, #queue-req: 1357, 
[1,0]<stderr>:[2025-10-10 09:44:03 TP0] Prefill batch. #new-seq: 2, #new-token: 155, #cached-token: 2, token usage: 0.95, #running-req: 131, #queue-req: 1356, 
[1,0]<stderr>:[2025-10-10 09:44:03 TP0] Prefill batch. #new-seq: 1, #new-token: 910, #cached-token: 3, token usage: 0.94, #running-req: 131, #queue-req: 1355, 
[1,0]<stderr>:[2025-10-10 09:44:03 TP0] Prefill batch. #new-seq: 4, #new-token: 399, #cached-token: 7, token usage: 0.94, #running-req: 130, #queue-req: 1351, 
[1,0]<stderr>:[2025-10-10 09:44:04 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 20, token usage: 0.92, #running-req: 133, #queue-req: 1344, 
[1,0]<stderr>:[2025-10-10 09:44:04 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 8, token usage: 0.94, #running-req: 139, #queue-req: 1342, 
[1,0]<stderr>:[2025-10-10 09:44:04 TP0] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 0, token usage: 0.95, #running-req: 141, #queue-req: 1342, 
[1,0]<stderr>:[2025-10-10 09:44:05 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 7, token usage: 0.92, #running-req: 140, #queue-req: 1338, 
[1,0]<stderr>:[2025-10-10 09:44:05 TP0] Prefill batch. #new-seq: 4, #new-token: 421, #cached-token: 12, token usage: 0.93, #running-req: 143, #queue-req: 1335, 
[1,0]<stderr>:[2025-10-10 09:44:05 TP0] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 7, token usage: 0.94, #running-req: 144, #queue-req: 1334, 
[1,0]<stderr>:[2025-10-10 09:44:06 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.95, #running-req: 144, #queue-req: 1333, 
[1,0]<stderr>:[2025-10-10 09:44:06 TP0] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 5, token usage: 0.95, #running-req: 144, #queue-req: 1332, 
[1,0]<stderr>:[2025-10-10 09:44:06 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 2, token usage: 0.95, #running-req: 144, #queue-req: 1331, 
[1,0]<stderr>:[2025-10-10 09:44:06 TP0] Prefill batch. #new-seq: 2, #new-token: 21, #cached-token: 3, token usage: 0.95, #running-req: 144, #queue-req: 1329, 
[1,0]<stderr>:[2025-10-10 09:44:06 TP0] Prefill batch. #new-seq: 4, #new-token: 41, #cached-token: 11, token usage: 0.94, #running-req: 145, #queue-req: 1325, 
[1,0]<stderr>:[2025-10-10 09:44:07 TP0] Prefill batch. #new-seq: 1, #new-token: 429, #cached-token: 1, token usage: 0.95, #running-req: 148, #queue-req: 1324, 
[1,0]<stderr>:[2025-10-10 09:44:07 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 1, token usage: 0.95, #running-req: 148, #queue-req: 1323, 
[1,0]<stderr>:[2025-10-10 09:44:08 TP0] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 2, token usage: 0.95, #running-req: 148, #queue-req: 1322, 
[1,0]<stderr>:[2025-10-10 09:44:08 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.95, #running-req: 148, #queue-req: 1321, 
[1,0]<stderr>:[2025-10-10 09:44:08 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 4, token usage: 0.94, #running-req: 147, #queue-req: 1318, 
[1,0]<stderr>:[2025-10-10 09:44:08 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 0, token usage: 0.96, #running-req: 149, #queue-req: 1318, 
[1,0]<stderr>:[2025-10-10 09:44:09 TP0] Decode batch. #running-req: 150, #token: 62627, token usage: 0.96, cuda graph: False, gen throughput (token/s): 699.20, #queue-req: 1318, 
[1,0]<stderr>:[2025-10-10 09:44:09 TP0] Prefill batch. #new-seq: 3, #new-token: 870, #cached-token: 5, token usage: 0.92, #running-req: 145, #queue-req: 1315, 
[1,0]<stderr>:[2025-10-10 09:44:09 TP0] Prefill batch. #new-seq: 2, #new-token: 275, #cached-token: 5, token usage: 0.94, #running-req: 146, #queue-req: 1313, 
[1,0]<stderr>:[2025-10-10 09:44:10 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 6, token usage: 0.93, #running-req: 144, #queue-req: 1309, 
[1,0]<stderr>:[2025-10-10 09:44:10 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.93, #running-req: 147, #queue-req: 1308, 
[1,0]<stderr>:[2025-10-10 09:44:10 TP0] Prefill batch. #new-seq: 2, #new-token: 225, #cached-token: 1, token usage: 0.94, #running-req: 148, #queue-req: 1307, 
[1,0]<stderr>:[2025-10-10 09:44:10 TP0] Prefill batch. #new-seq: 4, #new-token: 683, #cached-token: 11, token usage: 0.92, #running-req: 142, #queue-req: 1303, 
[1,0]<stderr>:[2025-10-10 09:44:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 7, token usage: 0.91, #running-req: 142, #queue-req: 1301, 
[1,0]<stderr>:[2025-10-10 09:44:11 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 2, token usage: 0.93, #running-req: 143, #queue-req: 1299, 
[1,0]<stderr>:[2025-10-10 09:44:11 TP0] Prefill batch. #new-seq: 5, #new-token: 668, #cached-token: 8, token usage: 0.94, #running-req: 145, #queue-req: 1295, 
[1,0]<stderr>:[2025-10-10 09:44:11 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.95, #running-req: 148, #queue-req: 1294, 
[1,0]<stderr>:[2025-10-10 09:44:12 TP0] Prefill batch. #new-seq: 2, #new-token: 824, #cached-token: 4, token usage: 0.94, #running-req: 142, #queue-req: 1292, 
[1,0]<stderr>:[2025-10-10 09:44:13 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.93, #running-req: 141, #queue-req: 1291, 
[1,0]<stderr>:[2025-10-10 09:44:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 3, token usage: 0.92, #running-req: 141, #queue-req: 1290, 
[1,0]<stderr>:[2025-10-10 09:44:13 TP0] Prefill batch. #new-seq: 3, #new-token: 828, #cached-token: 4, token usage: 0.93, #running-req: 141, #queue-req: 1288, 
[1,0]<stderr>:[2025-10-10 09:44:13 TP0] Prefill batch. #new-seq: 2, #new-token: 30, #cached-token: 7, token usage: 0.95, #running-req: 143, #queue-req: 1286, 
[1,0]<stderr>:[2025-10-10 09:44:14 TP0] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 1, token usage: 0.95, #running-req: 144, #queue-req: 1285, 
[1,0]<stderr>:[2025-10-10 09:44:14 TP0] Prefill batch. #new-seq: 2, #new-token: 809, #cached-token: 9, token usage: 0.94, #running-req: 142, #queue-req: 1283, 
[1,0]<stderr>:[2025-10-10 09:44:15 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 3, token usage: 0.93, #running-req: 139, #queue-req: 1280, 
[1,0]<stderr>:[2025-10-10 09:44:15 TP0] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 0, token usage: 0.95, #running-req: 141, #queue-req: 1280, 
[1,0]<stderr>:[2025-10-10 09:44:15 TP0] Decode batch. #running-req: 141, #token: 62923, token usage: 0.96, cuda graph: False, gen throughput (token/s): 859.13, #queue-req: 1280, 
[1,0]<stderr>:[2025-10-10 09:44:16 TP0] Prefill batch. #new-seq: 4, #new-token: 749, #cached-token: 8, token usage: 0.93, #running-req: 135, #queue-req: 1276, 
[1,0]<stderr>:[2025-10-10 09:44:16 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.92, #running-req: 134, #queue-req: 1274, 
[1,0]<stderr>:[2025-10-10 09:44:17 TP0] Prefill batch. #new-seq: 5, #new-token: 777, #cached-token: 6, token usage: 0.94, #running-req: 135, #queue-req: 1270, 
[1,0]<stderr>:[2025-10-10 09:44:17 TP0] Prefill batch. #new-seq: 2, #new-token: 31, #cached-token: 5, token usage: 0.95, #running-req: 139, #queue-req: 1268, 
[1,0]<stderr>:[2025-10-10 09:44:20 TP0] Decode batch. #running-req: 123, #token: 58212, token usage: 0.89, cuda graph: False, gen throughput (token/s): 1060.58, #queue-req: 1268, 
[1,0]<stderr>:[2025-10-10 09:44:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 3, token usage: 0.84, #running-req: 117, #queue-req: 1267, 
[1,0]<stderr>:[2025-10-10 09:44:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.85, #running-req: 117, #queue-req: 1267, 
[1,0]<stderr>:[2025-10-10 09:44:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.87, #running-req: 117, #queue-req: 1267, 
[1,0]<stderr>:[2025-10-10 09:44:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.88, #running-req: 117, #queue-req: 1267, 
[1,0]<stderr>:[2025-10-10 09:44:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.90, #running-req: 117, #queue-req: 1267, 
[1,0]<stderr>:[2025-10-10 09:44:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 117, #queue-req: 1267, 
[1,0]<stderr>:[2025-10-10 09:44:22 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 7, token usage: 0.93, #running-req: 117, #queue-req: 1263, 
[1,0]<stderr>:[2025-10-10 09:44:22 TP0] Prefill batch. #new-seq: 5, #new-token: 627, #cached-token: 7, token usage: 0.95, #running-req: 121, #queue-req: 1259, 
[1,0]<stderr>:[2025-10-10 09:44:23 TP0] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 2, token usage: 0.96, #running-req: 122, #queue-req: 1258, 
[1,0]<stderr>:[2025-10-10 09:44:23 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 5, token usage: 0.96, #running-req: 121, #queue-req: 1257, 
[1,0]<stderr>:[2025-10-10 09:44:24 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.95, #running-req: 121, #queue-req: 1256, 
[1,0]<stderr>:[2025-10-10 09:44:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 112, #queue-req: 1255, 
[1,0]<stderr>:[2025-10-10 09:44:25 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.93, #running-req: 112, #queue-req: 1254, 
[1,0]<stderr>:[2025-10-10 09:44:26 TP0] Prefill batch. #new-seq: 2, #new-token: 474, #cached-token: 3, token usage: 0.95, #running-req: 113, #queue-req: 1253, 
[1,0]<stderr>:[2025-10-10 09:44:26 TP0] Prefill batch. #new-seq: 1, #new-token: 750, #cached-token: 5, token usage: 0.95, #running-req: 112, #queue-req: 1252, 
[1,0]<stderr>:[2025-10-10 09:44:27 TP0] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 1, token usage: 0.95, #running-req: 112, #queue-req: 1251, 
[1,0]<stderr>:[2025-10-10 09:44:27 TP0] Decode batch. #running-req: 111, #token: 62512, token usage: 0.95, cuda graph: False, gen throughput (token/s): 736.69, #queue-req: 1251, 
[1,0]<stderr>:[2025-10-10 09:44:28 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 14, token usage: 0.94, #running-req: 104, #queue-req: 1247, 
[1,0]<stderr>:[2025-10-10 09:44:28 TP0] Prefill batch. #new-seq: 4, #new-token: 385, #cached-token: 6, token usage: 0.93, #running-req: 107, #queue-req: 1244, 
[1,0]<stderr>:[2025-10-10 09:44:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 4, token usage: 0.92, #running-req: 102, #queue-req: 1243, 
[1,0]<stderr>:[2025-10-10 09:44:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.94, #running-req: 102, #queue-req: 1243, 
[1,0]<stderr>:[2025-10-10 09:44:32 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 0, token usage: 0.95, #running-req: 102, #queue-req: 1243, 
[1,0]<stderr>:[2025-10-10 09:44:33 TP0] Decode batch. #running-req: 102, #token: 62983, token usage: 0.96, cuda graph: False, gen throughput (token/s): 750.33, #queue-req: 1243, 
[1,0]<stderr>:[2025-10-10 09:44:33 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 1, token usage: 0.94, #running-req: 99, #queue-req: 1242, 
[1,0]<stderr>:[2025-10-10 09:44:34 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.93, #running-req: 98, #queue-req: 1240, 
[1,0]<stderr>:[2025-10-10 09:44:34 TP0] Prefill batch. #new-seq: 5, #new-token: 102, #cached-token: 5, token usage: 0.95, #running-req: 99, #queue-req: 1236, 
[1,0]<stderr>:[2025-10-10 09:44:34 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 12, token usage: 0.92, #running-req: 103, #queue-req: 1229, 
[1,0]<stderr>:[2025-10-10 09:44:34 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 9, token usage: 0.93, #running-req: 109, #queue-req: 1226, 
[1,0]<stderr>:[2025-10-10 09:44:34 TP0] Prefill batch. #new-seq: 2, #new-token: 425, #cached-token: 1, token usage: 0.94, #running-req: 112, #queue-req: 1225, 
[1,0]<stderr>:[2025-10-10 09:44:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.93, #running-req: 109, #queue-req: 1224, 
[1,0]<stderr>:[2025-10-10 09:44:36 TP0] Prefill batch. #new-seq: 1, #new-token: 874, #cached-token: 0, token usage: 0.95, #running-req: 109, #queue-req: 1224, 
[1,0]<stderr>:[2025-10-10 09:44:36 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 8, token usage: 0.93, #running-req: 105, #queue-req: 1219, 
[1,0]<stderr>:[2025-10-10 09:44:36 TP0] Prefill batch. #new-seq: 4, #new-token: 1007, #cached-token: 3, token usage: 0.94, #running-req: 109, #queue-req: 1216, 
[1,0]<stderr>:[2025-10-10 09:44:37 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.96, #running-req: 112, #queue-req: 1215, 
[1,0]<stderr>:[2025-10-10 09:44:37 TP0] Prefill batch. #new-seq: 3, #new-token: 383, #cached-token: 6, token usage: 0.95, #running-req: 112, #queue-req: 1212, 
[1,0]<stderr>:[2025-10-10 09:44:37 TP0] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 1, token usage: 0.95, #running-req: 113, #queue-req: 1211, 
[1,0]<stderr>:[2025-10-10 09:44:39 TP0] Decode batch. #running-req: 109, #token: 61851, token usage: 0.94, cuda graph: False, gen throughput (token/s): 719.30, #queue-req: 1211, 
[1,0]<stderr>:[2025-10-10 09:44:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 106, #queue-req: 1210, 
[1,0]<stderr>:[2025-10-10 09:44:39 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 3, token usage: 0.94, #running-req: 106, #queue-req: 1209, 
[1,0]<stderr>:[2025-10-10 09:44:39 TP0] Prefill batch. #new-seq: 2, #new-token: 24, #cached-token: 2, token usage: 0.95, #running-req: 107, #queue-req: 1208, 
[1,0]<stderr>:[2025-10-10 09:44:41 TP0] Prefill batch. #new-seq: 1, #new-token: 771, #cached-token: 3, token usage: 0.95, #running-req: 101, #queue-req: 1207, 
[1,0]<stderr>:[2025-10-10 09:44:44 TP0] Decode batch. #running-req: 97, #token: 62219, token usage: 0.95, cuda graph: False, gen throughput (token/s): 811.38, #queue-req: 1207, 
[1,0]<stderr>:[2025-10-10 09:44:44 TP0] Prefill batch. #new-seq: 2, #new-token: 795, #cached-token: 5, token usage: 0.95, #running-req: 95, #queue-req: 1205, 
[1,0]<stderr>:[2025-10-10 09:44:44 TP0] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 7, token usage: 0.96, #running-req: 96, #queue-req: 1204, 
[1,0]<stderr>:[2025-10-10 09:44:45 TP0] Prefill batch. #new-seq: 2, #new-token: 746, #cached-token: 8, token usage: 0.95, #running-req: 95, #queue-req: 1202, 
[1,0]<stderr>:[2025-10-10 09:44:45 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 1, token usage: 0.96, #running-req: 95, #queue-req: 1201, 
[1,0]<stderr>:[2025-10-10 09:44:45 TP0] Prefill batch. #new-seq: 2, #new-token: 320, #cached-token: 4, token usage: 0.96, #running-req: 95, #queue-req: 1199, 
[1,0]<stderr>:[2025-10-10 09:44:45 TP0] Prefill batch. #new-seq: 3, #new-token: 509, #cached-token: 13, token usage: 0.96, #running-req: 96, #queue-req: 1196, 
[1,0]<stderr>:[2025-10-10 09:44:46 TP0] Prefill batch. #new-seq: 2, #new-token: 564, #cached-token: 4, token usage: 0.96, #running-req: 98, #queue-req: 1194, 
[1,0]<stderr>:[2025-10-10 09:44:47 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 3, token usage: 0.96, #running-req: 95, #queue-req: 1193, 
[1,0]<stderr>:[2025-10-10 09:44:48 TP0] Prefill batch. #new-seq: 1, #new-token: 691, #cached-token: 1, token usage: 0.95, #running-req: 94, #queue-req: 1192, 
[1,0]<stderr>:[2025-10-10 09:44:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.94, #running-req: 90, #queue-req: 1191, 
[1,0]<stderr>:[2025-10-10 09:44:49 TP0] Prefill batch. #new-seq: 2, #new-token: 115, #cached-token: 5, token usage: 0.95, #running-req: 90, #queue-req: 1190, 
[1,0]<stderr>:[2025-10-10 09:44:50 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.96, #running-req: 91, #queue-req: 1189, 
[1,0]<stderr>:[2025-10-10 09:44:50 TP0] Decode batch. #running-req: 91, #token: 62987, token usage: 0.96, cuda graph: False, gen throughput (token/s): 641.36, #queue-req: 1189, 
[1,0]<stderr>:[2025-10-10 09:44:50 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 5, token usage: 0.92, #running-req: 89, #queue-req: 1185, 
[1,0]<stderr>:[2025-10-10 09:44:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.94, #running-req: 92, #queue-req: 1185, 
[1,0]<stderr>:[2025-10-10 09:44:50 TP0] Prefill batch. #new-seq: 2, #new-token: 648, #cached-token: 2, token usage: 0.95, #running-req: 92, #queue-req: 1184, 
[1,0]<stderr>:[2025-10-10 09:44:51 TP0] Prefill batch. #new-seq: 2, #new-token: 663, #cached-token: 3, token usage: 0.95, #running-req: 92, #queue-req: 1182, 
[1,0]<stderr>:[2025-10-10 09:44:51 TP0] Prefill batch. #new-seq: 2, #new-token: 28, #cached-token: 4, token usage: 0.95, #running-req: 92, #queue-req: 1180, 
[1,0]<stderr>:[2025-10-10 09:44:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.95, #running-req: 88, #queue-req: 1179, 
[1,0]<stderr>:[2025-10-10 09:44:53 TP0] Prefill batch. #new-seq: 3, #new-token: 486, #cached-token: 10, token usage: 0.96, #running-req: 88, #queue-req: 1177, 
[1,0]<stderr>:[2025-10-10 09:44:53 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.97, #running-req: 90, #queue-req: 1176, 
[1,0]<stderr>:[2025-10-10 09:44:54 TP0] Prefill batch. #new-seq: 2, #new-token: 134, #cached-token: 3, token usage: 0.96, #running-req: 90, #queue-req: 1174, 
[1,0]<stderr>:[2025-10-10 09:44:54 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.97, #running-req: 91, #queue-req: 1173, 
[1,0]<stderr>:[2025-10-10 09:44:55 TP0] Prefill batch. #new-seq: 4, #new-token: 137, #cached-token: 8, token usage: 0.96, #running-req: 91, #queue-req: 1169, 
[1,0]<stderr>:[2025-10-10 09:44:55 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.96, #running-req: 94, #queue-req: 1168, 
[1,0]<stderr>:[2025-10-10 09:44:56 TP0] Decode batch. #running-req: 95, #token: 63441, token usage: 0.97, cuda graph: False, gen throughput (token/s): 594.95, #queue-req: 1168, 
[1,0]<stderr>:[2025-10-10 09:44:56 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 10, token usage: 0.90, #running-req: 93, #queue-req: 1165, 
[1,0]<stderr>:[2025-10-10 09:44:56 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 3, token usage: 0.91, #running-req: 95, #queue-req: 1162, 
[1,0]<stderr>:[2025-10-10 09:44:57 TP0] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 0, token usage: 0.93, #running-req: 98, #queue-req: 1162, 
[1,0]<stderr>:[2025-10-10 09:44:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 90, #queue-req: 1161, 
[1,0]<stderr>:[2025-10-10 09:44:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.94, #running-req: 90, #queue-req: 1161, 
[1,0]<stderr>:[2025-10-10 09:44:59 TP0] Prefill batch. #new-seq: 2, #new-token: 383, #cached-token: 2, token usage: 0.96, #running-req: 90, #queue-req: 1160, 
[1,0]<stderr>:[2025-10-10 09:45:00 TP0] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 2, token usage: 0.96, #running-req: 90, #queue-req: 1159, 
[1,0]<stderr>:[2025-10-10 09:45:00 TP0] Prefill batch. #new-seq: 4, #new-token: 697, #cached-token: 13, token usage: 0.94, #running-req: 89, #queue-req: 1155, 
[1,0]<stderr>:[2025-10-10 09:45:01 TP0] Prefill batch. #new-seq: 2, #new-token: 971, #cached-token: 2, token usage: 0.95, #running-req: 92, #queue-req: 1153, 
[1,0]<stderr>:[2025-10-10 09:45:01 TP0] Decode batch. #running-req: 94, #token: 63789, token usage: 0.97, cuda graph: False, gen throughput (token/s): 658.81, #queue-req: 1153, 
[1,0]<stderr>:[2025-10-10 09:45:02 TP0] Prefill batch. #new-seq: 3, #new-token: 376, #cached-token: 5, token usage: 0.96, #running-req: 88, #queue-req: 1150, 
[1,0]<stderr>:[2025-10-10 09:45:02 TP0] Prefill batch. #new-seq: 2, #new-token: 618, #cached-token: 7, token usage: 0.96, #running-req: 90, #queue-req: 1148, 
[1,0]<stderr>:[2025-10-10 09:45:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 83, #queue-req: 1147, 
[1,0]<stderr>:[2025-10-10 09:45:05 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 6, token usage: 0.93, #running-req: 83, #queue-req: 1145, 
[1,0]<stderr>:[2025-10-10 09:45:06 TP0] Prefill batch. #new-seq: 3, #new-token: 515, #cached-token: 2, token usage: 0.95, #running-req: 85, #queue-req: 1143, 
[1,0]<stderr>:[2025-10-10 09:45:06 TP0] Prefill batch. #new-seq: 3, #new-token: 168, #cached-token: 3, token usage: 0.96, #running-req: 87, #queue-req: 1140, 
[1,0]<stderr>:[2025-10-10 09:45:06 TP0] Prefill batch. #new-seq: 2, #new-token: 618, #cached-token: 4, token usage: 0.94, #running-req: 88, #queue-req: 1138, 
[1,0]<stderr>:[2025-10-10 09:45:06 TP0] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 4, token usage: 0.95, #running-req: 88, #queue-req: 1137, 
[1,0]<stderr>:[2025-10-10 09:45:07 TP0] Decode batch. #running-req: 89, #token: 61308, token usage: 0.94, cuda graph: False, gen throughput (token/s): 643.90, #queue-req: 1137, 
[1,0]<stderr>:[2025-10-10 09:45:07 TP0] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 1, token usage: 0.94, #running-req: 88, #queue-req: 1136, 
[1,0]<stderr>:[2025-10-10 09:45:08 TP0] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 2, token usage: 0.94, #running-req: 86, #queue-req: 1135, 
[1,0]<stderr>:[2025-10-10 09:45:09 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.95, #running-req: 86, #queue-req: 1133, 
[1,0]<stderr>:[2025-10-10 09:45:09 TP0] Prefill batch. #new-seq: 3, #new-token: 235, #cached-token: 4, token usage: 0.96, #running-req: 87, #queue-req: 1131, 
[1,0]<stderr>:[2025-10-10 09:45:09 TP0] Prefill batch. #new-seq: 2, #new-token: 424, #cached-token: 4, token usage: 0.95, #running-req: 87, #queue-req: 1129, 
[1,0]<stderr>:[2025-10-10 09:45:10 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 5, token usage: 0.94, #running-req: 88, #queue-req: 1125, 
[1,0]<stderr>:[2025-10-10 09:45:10 TP0] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 0, token usage: 0.96, #running-req: 91, #queue-req: 1125, 
[1,0]<stderr>:[2025-10-10 09:45:11 TP0] Prefill batch. #new-seq: 2, #new-token: 380, #cached-token: 2, token usage: 0.96, #running-req: 89, #queue-req: 1123, 
[1,0]<stderr>:[2025-10-10 09:45:11 TP0] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 1, token usage: 0.95, #running-req: 90, #queue-req: 1122, 
[1,0]<stderr>:[2025-10-10 09:45:11 TP0] Prefill batch. #new-seq: 3, #new-token: 878, #cached-token: 5, token usage: 0.95, #running-req: 90, #queue-req: 1119, 
[1,0]<stderr>:[2025-10-10 09:45:12 TP0] Prefill batch. #new-seq: 2, #new-token: 827, #cached-token: 2, token usage: 0.95, #running-req: 91, #queue-req: 1117, 
[1,0]<stderr>:[2025-10-10 09:45:13 TP0] Decode batch. #running-req: 90, #token: 62948, token usage: 0.96, cuda graph: False, gen throughput (token/s): 612.29, #queue-req: 1117, 
[1,0]<stderr>:[2025-10-10 09:45:14 TP0] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 4, token usage: 0.96, #running-req: 88, #queue-req: 1116, 
[1,0]<stderr>:[2025-10-10 09:45:14 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 4, token usage: 0.96, #running-req: 88, #queue-req: 1115, 
[1,0]<stderr>:[2025-10-10 09:45:15 TP0] Prefill batch. #new-seq: 2, #new-token: 580, #cached-token: 5, token usage: 0.93, #running-req: 88, #queue-req: 1113, 
[1,0]<stderr>:[2025-10-10 09:45:15 TP0] Prefill batch. #new-seq: 1, #new-token: 986, #cached-token: 1, token usage: 0.94, #running-req: 88, #queue-req: 1112, 
[1,0]<stderr>:[2025-10-10 09:45:15 TP0] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 2, token usage: 0.95, #running-req: 88, #queue-req: 1111, 
[1,0]<stderr>:[2025-10-10 09:45:16 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 9, token usage: 0.92, #running-req: 87, #queue-req: 1108, 
[1,0]<stderr>:[2025-10-10 09:45:16 TP0] Prefill batch. #new-seq: 8, #new-token: 1024, #cached-token: 13, token usage: 0.88, #running-req: 89, #queue-req: 1101, 
[1,0]<stderr>:[2025-10-10 09:45:16 TP0] Prefill batch. #new-seq: 10, #new-token: 1024, #cached-token: 16, token usage: 0.90, #running-req: 96, #queue-req: 1092, 
[1,0]<stderr>:[2025-10-10 09:45:16 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 2, token usage: 0.91, #running-req: 105, #queue-req: 1090, 
[1,0]<stderr>:[2025-10-10 09:45:16 TP0] Prefill batch. #new-seq: 4, #new-token: 971, #cached-token: 18, token usage: 0.93, #running-req: 107, #queue-req: 1087, 
[1,0]<stderr>:[2025-10-10 09:45:16 TP0] Prefill batch. #new-seq: 4, #new-token: 629, #cached-token: 6, token usage: 0.94, #running-req: 110, #queue-req: 1083, 
[1,0]<stderr>:[2025-10-10 09:45:17 TP0] Prefill batch. #new-seq: 2, #new-token: 556, #cached-token: 8, token usage: 0.94, #running-req: 112, #queue-req: 1081, 
[1,0]<stderr>:[2025-10-10 09:45:17 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 13, token usage: 0.90, #running-req: 112, #queue-req: 1074, 
[1,0]<stderr>:[2025-10-10 09:45:17 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.90, #running-req: 118, #queue-req: 1073, 
[1,0]<stderr>:[2025-10-10 09:45:17 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 119, #queue-req: 1072, 
[1,0]<stderr>:[2025-10-10 09:45:17 TP0] Prefill batch. #new-seq: 3, #new-token: 982, #cached-token: 2, token usage: 0.93, #running-req: 120, #queue-req: 1070, 
[1,0]<stderr>:[2025-10-10 09:45:17 TP0] Prefill batch. #new-seq: 2, #new-token: 28, #cached-token: 6, token usage: 0.95, #running-req: 121, #queue-req: 1068, 
[1,0]<stderr>:[2025-10-10 09:45:18 TP0] Prefill batch. #new-seq: 2, #new-token: 491, #cached-token: 6, token usage: 0.95, #running-req: 121, #queue-req: 1066, 
[1,0]<stderr>:[2025-10-10 09:45:19 TP0] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 3, token usage: 0.94, #running-req: 120, #queue-req: 1065, 
[1,0]<stderr>:[2025-10-10 09:45:19 TP0] Prefill batch. #new-seq: 4, #new-token: 822, #cached-token: 11, token usage: 0.93, #running-req: 118, #queue-req: 1061, 
[1,0]<stderr>:[2025-10-10 09:45:19 TP0] Prefill batch. #new-seq: 3, #new-token: 865, #cached-token: 6, token usage: 0.94, #running-req: 121, #queue-req: 1058, 
[1,0]<stderr>:[2025-10-10 09:45:19 TP0] Prefill batch. #new-seq: 4, #new-token: 31, #cached-token: 5, token usage: 0.95, #running-req: 122, #queue-req: 1054, 
[1,0]<stderr>:[2025-10-10 09:45:20 TP0] Prefill batch. #new-seq: 2, #new-token: 457, #cached-token: 2, token usage: 0.93, #running-req: 125, #queue-req: 1052, 
[1,0]<stderr>:[2025-10-10 09:45:20 TP0] Decode batch. #running-req: 125, #token: 61139, token usage: 0.93, cuda graph: False, gen throughput (token/s): 580.89, #queue-req: 1052, 
[1,0]<stderr>:[2025-10-10 09:45:20 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 12, token usage: 0.93, #running-req: 125, #queue-req: 1050, 
[1,0]<stderr>:[2025-10-10 09:45:20 TP0] Prefill batch. #new-seq: 7, #new-token: 989, #cached-token: 13, token usage: 0.91, #running-req: 126, #queue-req: 1044, 
[1,0]<stderr>:[2025-10-10 09:45:21 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 10, token usage: 0.92, #running-req: 131, #queue-req: 1038, 
[1,0]<stderr>:[2025-10-10 09:45:21 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 6, token usage: 0.83, #running-req: 136, #queue-req: 1035, 
[1,0]<stderr>:[2025-10-10 09:45:21 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 11, token usage: 0.85, #running-req: 139, #queue-req: 1030, 
[1,0]<stderr>:[2025-10-10 09:45:21 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 3, token usage: 0.86, #running-req: 144, #queue-req: 1027, 
[1,0]<stderr>:[2025-10-10 09:45:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.88, #running-req: 147, #queue-req: 1027, 
[1,0]<stderr>:[2025-10-10 09:45:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.89, #running-req: 147, #queue-req: 1027, 
[1,0]<stderr>:[2025-10-10 09:45:21 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 147, #queue-req: 1026, 
[1,0]<stderr>:[2025-10-10 09:45:21 TP0] Prefill batch. #new-seq: 4, #new-token: 421, #cached-token: 11, token usage: 0.92, #running-req: 148, #queue-req: 1023, 
[1,0]<stderr>:[2025-10-10 09:45:22 TP0] Prefill batch. #new-seq: 3, #new-token: 925, #cached-token: 6, token usage: 0.92, #running-req: 146, #queue-req: 1020, 
[1,0]<stderr>:[2025-10-10 09:45:23 TP0] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 1, token usage: 0.93, #running-req: 146, #queue-req: 1019, 
[1,0]<stderr>:[2025-10-10 09:45:23 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.93, #running-req: 145, #queue-req: 1017, 
[1,0]<stderr>:[2025-10-10 09:45:23 TP0] Prefill batch. #new-seq: 2, #new-token: 268, #cached-token: 2, token usage: 0.94, #running-req: 146, #queue-req: 1016, 
[1,0]<stderr>:[2025-10-10 09:45:24 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.94, #running-req: 147, #queue-req: 1015, 
[1,0]<stderr>:[2025-10-10 09:45:24 TP0] Prefill batch. #new-seq: 3, #new-token: 511, #cached-token: 3, token usage: 0.93, #running-req: 146, #queue-req: 1012, 
[1,0]<stderr>:[2025-10-10 09:45:26 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.92, #running-req: 144, #queue-req: 1010, 
[1,0]<stderr>:[2025-10-10 09:45:26 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 0, token usage: 0.93, #running-req: 145, #queue-req: 1010, 
[1,0]<stderr>:[2025-10-10 09:45:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.91, #running-req: 139, #queue-req: 1009, 
[1,0]<stderr>:[2025-10-10 09:45:27 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.92, #running-req: 139, #queue-req: 1008, 
[1,0]<stderr>:[2025-10-10 09:45:27 TP0] Prefill batch. #new-seq: 3, #new-token: 239, #cached-token: 4, token usage: 0.94, #running-req: 140, #queue-req: 1006, 
[1,0]<stderr>:[2025-10-10 09:45:28 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 11, token usage: 0.91, #running-req: 138, #queue-req: 1002, 
[1,0]<stderr>:[2025-10-10 09:45:28 TP0] Prefill batch. #new-seq: 4, #new-token: 210, #cached-token: 4, token usage: 0.92, #running-req: 141, #queue-req: 999, 
[1,0]<stderr>:[2025-10-10 09:45:28 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 6, token usage: 0.92, #running-req: 141, #queue-req: 996, 
[1,0]<stderr>:[2025-10-10 09:45:29 TP0] Decode batch. #running-req: 141, #token: 60974, token usage: 0.93, cuda graph: False, gen throughput (token/s): 679.12, #queue-req: 996, 
[1,0]<stderr>:[2025-10-10 09:45:29 TP0] Prefill batch. #new-seq: 2, #new-token: 579, #cached-token: 1, token usage: 0.93, #running-req: 143, #queue-req: 995, 
[1,0]<stderr>:[2025-10-10 09:45:29 TP0] Prefill batch. #new-seq: 1, #new-token: 798, #cached-token: 2, token usage: 0.94, #running-req: 139, #queue-req: 994, 
[1,0]<stderr>:[2025-10-10 09:45:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.91, #running-req: 131, #queue-req: 993, 
[1,0]<stderr>:[2025-10-10 09:45:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 131, #queue-req: 993, 
[1,0]<stderr>:[2025-10-10 09:45:31 TP0] Prefill batch. #new-seq: 3, #new-token: 91, #cached-token: 3, token usage: 0.93, #running-req: 131, #queue-req: 991, 
[1,0]<stderr>:[2025-10-10 09:45:32 TP0] Prefill batch. #new-seq: 2, #new-token: 147, #cached-token: 5, token usage: 0.94, #running-req: 133, #queue-req: 989, 
[1,0]<stderr>:[2025-10-10 09:45:33 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 7, token usage: 0.92, #running-req: 133, #queue-req: 984, 
[1,0]<stderr>:[2025-10-10 09:45:33 TP0] Prefill batch. #new-seq: 2, #new-token: 358, #cached-token: 3, token usage: 0.94, #running-req: 137, #queue-req: 983, 
[1,0]<stderr>:[2025-10-10 09:45:33 TP0] Prefill batch. #new-seq: 2, #new-token: 749, #cached-token: 9, token usage: 0.94, #running-req: 138, #queue-req: 981, 
[1,0]<stderr>:[2025-10-10 09:45:34 TP0] Prefill batch. #new-seq: 2, #new-token: 31, #cached-token: 7, token usage: 0.94, #running-req: 137, #queue-req: 979, 
[1,0]<stderr>:[2025-10-10 09:45:34 TP0] Decode batch. #running-req: 139, #token: 62176, token usage: 0.95, cuda graph: False, gen throughput (token/s): 921.94, #queue-req: 979, 
[1,0]<stderr>:[2025-10-10 09:45:35 TP0] Prefill batch. #new-seq: 2, #new-token: 641, #cached-token: 4, token usage: 0.92, #running-req: 134, #queue-req: 977, 
[1,0]<stderr>:[2025-10-10 09:45:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 130, #queue-req: 976, 
[1,0]<stderr>:[2025-10-10 09:45:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.93, #running-req: 130, #queue-req: 976, 
[1,0]<stderr>:[2025-10-10 09:45:37 TP0] Prefill batch. #new-seq: 2, #new-token: 643, #cached-token: 2, token usage: 0.94, #running-req: 130, #queue-req: 975, 
[1,0]<stderr>:[2025-10-10 09:45:40 TP0] Decode batch. #running-req: 124, #token: 63162, token usage: 0.96, cuda graph: False, gen throughput (token/s): 1022.22, #queue-req: 975, 
[1,0]<stderr>:[2025-10-10 09:45:40 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 15, token usage: 0.93, #running-req: 122, #queue-req: 970, 
[1,0]<stderr>:[2025-10-10 09:45:41 TP0] Prefill batch. #new-seq: 7, #new-token: 945, #cached-token: 12, token usage: 0.93, #running-req: 126, #queue-req: 964, 
[1,0]<stderr>:[2025-10-10 09:45:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.92, #running-req: 127, #queue-req: 963, 
[1,0]<stderr>:[2025-10-10 09:45:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1008, #cached-token: 0, token usage: 0.93, #running-req: 127, #queue-req: 963, 
[1,0]<stderr>:[2025-10-10 09:45:43 TP0] Prefill batch. #new-seq: 3, #new-token: 969, #cached-token: 8, token usage: 0.92, #running-req: 120, #queue-req: 960, 
[1,0]<stderr>:[2025-10-10 09:45:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.93, #running-req: 121, #queue-req: 959, 
[1,0]<stderr>:[2025-10-10 09:45:43 TP0] Prefill batch. #new-seq: 3, #new-token: 356, #cached-token: 4, token usage: 0.95, #running-req: 121, #queue-req: 957, 
[1,0]<stderr>:[2025-10-10 09:45:43 TP0] Prefill batch. #new-seq: 4, #new-token: 615, #cached-token: 8, token usage: 0.93, #running-req: 122, #queue-req: 953, 
[1,0]<stderr>:[2025-10-10 09:45:44 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 5, token usage: 0.93, #running-req: 123, #queue-req: 949, 
[1,0]<stderr>:[2025-10-10 09:45:44 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 0, token usage: 0.95, #running-req: 126, #queue-req: 949, 
[1,0]<stderr>:[2025-10-10 09:45:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 125, #queue-req: 948, 
[1,0]<stderr>:[2025-10-10 09:45:44 TP0] Prefill batch. #new-seq: 3, #new-token: 902, #cached-token: 3, token usage: 0.93, #running-req: 125, #queue-req: 946, 
[1,0]<stderr>:[2025-10-10 09:45:45 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 2, token usage: 0.94, #running-req: 125, #queue-req: 945, 
[1,0]<stderr>:[2025-10-10 09:45:45 TP0] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 1, token usage: 0.95, #running-req: 125, #queue-req: 944, 
[1,0]<stderr>:[2025-10-10 09:45:46 TP0] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 1, token usage: 0.95, #running-req: 124, #queue-req: 943, 
[1,0]<stderr>:[2025-10-10 09:45:46 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 2, token usage: 0.95, #running-req: 124, #queue-req: 942, 
[1,0]<stderr>:[2025-10-10 09:45:46 TP0] Decode batch. #running-req: 125, #token: 61810, token usage: 0.94, cuda graph: False, gen throughput (token/s): 737.64, #queue-req: 942, 
[1,0]<stderr>:[2025-10-10 09:45:46 TP0] Prefill batch. #new-seq: 2, #new-token: 920, #cached-token: 2, token usage: 0.94, #running-req: 124, #queue-req: 940, 
[1,0]<stderr>:[2025-10-10 09:45:47 TP0] Prefill batch. #new-seq: 2, #new-token: 573, #cached-token: 5, token usage: 0.94, #running-req: 122, #queue-req: 938, 
[1,0]<stderr>:[2025-10-10 09:45:47 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.95, #running-req: 123, #queue-req: 937, 
[1,0]<stderr>:[2025-10-10 09:45:48 TP0] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 2, token usage: 0.95, #running-req: 123, #queue-req: 936, 
[1,0]<stderr>:[2025-10-10 09:45:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.94, #running-req: 117, #queue-req: 935, 
[1,0]<stderr>:[2025-10-10 09:45:49 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 0, token usage: 0.95, #running-req: 117, #queue-req: 935, 
[1,0]<stderr>:[2025-10-10 09:45:51 TP0] Prefill batch. #new-seq: 1, #new-token: 782, #cached-token: 1, token usage: 0.95, #running-req: 110, #queue-req: 934, 
[1,0]<stderr>:[2025-10-10 09:45:51 TP0] Prefill batch. #new-seq: 2, #new-token: 399, #cached-token: 3, token usage: 0.94, #running-req: 109, #queue-req: 932, 
[1,0]<stderr>:[2025-10-10 09:45:51 TP0] Prefill batch. #new-seq: 2, #new-token: 447, #cached-token: 2, token usage: 0.94, #running-req: 108, #queue-req: 930, 
[1,0]<stderr>:[2025-10-10 09:45:52 TP0] Prefill batch. #new-seq: 3, #new-token: 212, #cached-token: 6, token usage: 0.95, #running-req: 109, #queue-req: 927, 
[1,0]<stderr>:[2025-10-10 09:45:52 TP0] Decode batch. #running-req: 109, #token: 60324, token usage: 0.92, cuda graph: False, gen throughput (token/s): 831.78, #queue-req: 927, 
[1,0]<stderr>:[2025-10-10 09:45:52 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 13, token usage: 0.92, #running-req: 111, #queue-req: 925, 
[1,0]<stderr>:[2025-10-10 09:45:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.94, #running-req: 112, #queue-req: 925, 
[1,0]<stderr>:[2025-10-10 09:45:52 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 0, token usage: 0.95, #running-req: 112, #queue-req: 925, 
[1,0]<stderr>:[2025-10-10 09:45:53 TP0] Prefill batch. #new-seq: 2, #new-token: 424, #cached-token: 3, token usage: 0.95, #running-req: 112, #queue-req: 923, 
[1,0]<stderr>:[2025-10-10 09:45:54 TP0] Prefill batch. #new-seq: 2, #new-token: 38, #cached-token: 3, token usage: 0.95, #running-req: 110, #queue-req: 921, 
[1,0]<stderr>:[2025-10-10 09:45:54 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.95, #running-req: 111, #queue-req: 920, 
[1,0]<stderr>:[2025-10-10 09:45:55 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 1, token usage: 0.94, #running-req: 110, #queue-req: 919, 
[1,0]<stderr>:[2025-10-10 09:45:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.93, #running-req: 104, #queue-req: 918, 
[1,0]<stderr>:[2025-10-10 09:45:57 TP0] Prefill batch. #new-seq: 1, #new-token: 755, #cached-token: 0, token usage: 0.95, #running-req: 104, #queue-req: 918, 
[1,0]<stderr>:[2025-10-10 09:45:58 TP0] Decode batch. #running-req: 105, #token: 63058, token usage: 0.96, cuda graph: False, gen throughput (token/s): 753.17, #queue-req: 918, 
[1,0]<stderr>:[2025-10-10 09:45:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.90, #running-req: 98, #queue-req: 917, 
[1,0]<stderr>:[2025-10-10 09:45:59 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 98, #queue-req: 916, 
[1,0]<stderr>:[2025-10-10 09:45:59 TP0] Prefill batch. #new-seq: 4, #new-token: 952, #cached-token: 7, token usage: 0.93, #running-req: 99, #queue-req: 913, 
[1,0]<stderr>:[2025-10-10 09:46:03 TP0] Decode batch. #running-req: 94, #token: 58663, token usage: 0.90, cuda graph: False, gen throughput (token/s): 792.67, #queue-req: 913, 
[1,0]<stderr>:[2025-10-10 09:46:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.90, #running-req: 92, #queue-req: 912, 
[1,0]<stderr>:[2025-10-10 09:46:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.91, #running-req: 92, #queue-req: 912, 
[1,0]<stderr>:[2025-10-10 09:46:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.93, #running-req: 92, #queue-req: 912, 
[1,0]<stderr>:[2025-10-10 09:46:03 TP0] Prefill batch. #new-seq: 4, #new-token: 467, #cached-token: 4, token usage: 0.94, #running-req: 92, #queue-req: 909, 
[1,0]<stderr>:[2025-10-10 09:46:04 TP0] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 1, token usage: 0.95, #running-req: 95, #queue-req: 908, 
[1,0]<stderr>:[2025-10-10 09:46:05 TP0] Prefill batch. #new-seq: 3, #new-token: 694, #cached-token: 5, token usage: 0.94, #running-req: 95, #queue-req: 905, 
[1,0]<stderr>:[2025-10-10 09:46:05 TP0] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 2, token usage: 0.95, #running-req: 97, #queue-req: 904, 
[1,0]<stderr>:[2025-10-10 09:46:05 TP0] Prefill batch. #new-seq: 3, #new-token: 1021, #cached-token: 8, token usage: 0.94, #running-req: 97, #queue-req: 901, 
[1,0]<stderr>:[2025-10-10 09:46:06 TP0] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 1, token usage: 0.96, #running-req: 99, #queue-req: 900, 
[1,0]<stderr>:[2025-10-10 09:46:06 TP0] Prefill batch. #new-seq: 9, #new-token: 1024, #cached-token: 19, token usage: 0.90, #running-req: 98, #queue-req: 891, 
[1,0]<stderr>:[2025-10-10 09:46:06 TP0] Prefill batch. #new-seq: 5, #new-token: 821, #cached-token: 10, token usage: 0.92, #running-req: 106, #queue-req: 887, 
[1,0]<stderr>:[2025-10-10 09:46:06 TP0] Prefill batch. #new-seq: 2, #new-token: 698, #cached-token: 5, token usage: 0.93, #running-req: 110, #queue-req: 885, 
[1,0]<stderr>:[2025-10-10 09:46:07 TP0] Prefill batch. #new-seq: 2, #new-token: 698, #cached-token: 2, token usage: 0.94, #running-req: 111, #queue-req: 883, 
[1,0]<stderr>:[2025-10-10 09:46:07 TP0] Prefill batch. #new-seq: 2, #new-token: 1022, #cached-token: 2, token usage: 0.94, #running-req: 111, #queue-req: 881, 
[1,0]<stderr>:[2025-10-10 09:46:08 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.96, #running-req: 112, #queue-req: 880, 
[1,0]<stderr>:[2025-10-10 09:46:09 TP0] Decode batch. #running-req: 110, #token: 61451, token usage: 0.94, cuda graph: False, gen throughput (token/s): 658.27, #queue-req: 880, 
[1,0]<stderr>:[2025-10-10 09:46:09 TP0] Prefill batch. #new-seq: 3, #new-token: 228, #cached-token: 5, token usage: 0.94, #running-req: 109, #queue-req: 877, 
[1,0]<stderr>:[2025-10-10 09:46:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 108, #queue-req: 876, 
[1,0]<stderr>:[2025-10-10 09:46:10 TP0] Prefill batch. #new-seq: 4, #new-token: 588, #cached-token: 5, token usage: 0.93, #running-req: 108, #queue-req: 873, 
[1,0]<stderr>:[2025-10-10 09:46:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 3, token usage: 0.89, #running-req: 102, #queue-req: 872, 
[1,0]<stderr>:[2025-10-10 09:46:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.91, #running-req: 102, #queue-req: 872, 
[1,0]<stderr>:[2025-10-10 09:46:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 102, #queue-req: 872, 
[1,0]<stderr>:[2025-10-10 09:46:12 TP0] Prefill batch. #new-seq: 3, #new-token: 561, #cached-token: 6, token usage: 0.94, #running-req: 102, #queue-req: 870, 
[1,0]<stderr>:[2025-10-10 09:46:13 TP0] Prefill batch. #new-seq: 3, #new-token: 94, #cached-token: 6, token usage: 0.95, #running-req: 103, #queue-req: 867, 
[1,0]<stderr>:[2025-10-10 09:46:13 TP0] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 1, token usage: 0.95, #running-req: 105, #queue-req: 866, 
[1,0]<stderr>:[2025-10-10 09:46:14 TP0] Prefill batch. #new-seq: 2, #new-token: 56, #cached-token: 4, token usage: 0.95, #running-req: 105, #queue-req: 864, 
[1,0]<stderr>:[2025-10-10 09:46:14 TP0] Prefill batch. #new-seq: 2, #new-token: 665, #cached-token: 11, token usage: 0.95, #running-req: 106, #queue-req: 862, 
[1,0]<stderr>:[2025-10-10 09:46:15 TP0] Decode batch. #running-req: 107, #token: 63225, token usage: 0.96, cuda graph: False, gen throughput (token/s): 737.81, #queue-req: 862, 
[1,0]<stderr>:[2025-10-10 09:46:15 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.94, #running-req: 106, #queue-req: 858, 
[1,0]<stderr>:[2025-10-10 09:46:15 TP0] Prefill batch. #new-seq: 3, #new-token: 381, #cached-token: 6, token usage: 0.95, #running-req: 109, #queue-req: 856, 
[1,0]<stderr>:[2025-10-10 09:46:16 TP0] Prefill batch. #new-seq: 2, #new-token: 289, #cached-token: 2, token usage: 0.95, #running-req: 107, #queue-req: 854, 
[1,0]<stderr>:[2025-10-10 09:46:17 TP0] Prefill batch. #new-seq: 2, #new-token: 958, #cached-token: 2, token usage: 0.95, #running-req: 106, #queue-req: 852, 
[1,0]<stderr>:[2025-10-10 09:46:18 TP0] Prefill batch. #new-seq: 2, #new-token: 14, #cached-token: 5, token usage: 0.96, #running-req: 104, #queue-req: 850, 
[1,0]<stderr>:[2025-10-10 09:46:18 TP0] Prefill batch. #new-seq: 1, #new-token: 456, #cached-token: 1, token usage: 0.96, #running-req: 104, #queue-req: 849, 
[1,0]<stderr>:[2025-10-10 09:46:18 TP0] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 1, token usage: 0.95, #running-req: 103, #queue-req: 848, 
[1,0]<stderr>:[2025-10-10 09:46:19 TP0] Prefill batch. #new-seq: 2, #new-token: 814, #cached-token: 3, token usage: 0.95, #running-req: 102, #queue-req: 846, 
[1,0]<stderr>:[2025-10-10 09:46:20 TP0] Prefill batch. #new-seq: 1, #new-token: 674, #cached-token: 1, token usage: 0.95, #running-req: 98, #queue-req: 845, 
[1,0]<stderr>:[2025-10-10 09:46:20 TP0] Decode batch. #running-req: 98, #token: 62819, token usage: 0.96, cuda graph: False, gen throughput (token/s): 774.69, #queue-req: 845, 
[1,0]<stderr>:[2025-10-10 09:46:21 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 4, token usage: 0.94, #running-req: 98, #queue-req: 844, 
[1,0]<stderr>:[2025-10-10 09:46:21 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 3, token usage: 0.94, #running-req: 96, #queue-req: 841, 
[1,0]<stderr>:[2025-10-10 09:46:21 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 0, token usage: 0.95, #running-req: 98, #queue-req: 841, 
[1,0]<stderr>:[2025-10-10 09:46:22 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 7, token usage: 0.90, #running-req: 98, #queue-req: 839, 
[1,0]<stderr>:[2025-10-10 09:46:22 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 16, token usage: 0.91, #running-req: 99, #queue-req: 834, 
[1,0]<stderr>:[2025-10-10 09:46:22 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 7, token usage: 0.93, #running-req: 104, #queue-req: 829, 
[1,0]<stderr>:[2025-10-10 09:46:22 TP0] Prefill batch. #new-seq: 3, #new-token: 348, #cached-token: 5, token usage: 0.94, #running-req: 109, #queue-req: 827, 
[1,0]<stderr>:[2025-10-10 09:46:22 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.95, #running-req: 110, #queue-req: 826, 
[1,0]<stderr>:[2025-10-10 09:46:23 TP0] Prefill batch. #new-seq: 4, #new-token: 879, #cached-token: 10, token usage: 0.94, #running-req: 110, #queue-req: 822, 
[1,0]<stderr>:[2025-10-10 09:46:24 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.92, #running-req: 111, #queue-req: 820, 
[1,0]<stderr>:[2025-10-10 09:46:24 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 5, token usage: 0.94, #running-req: 112, #queue-req: 817, 
[1,0]<stderr>:[2025-10-10 09:46:24 TP0] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 0, token usage: 0.95, #running-req: 115, #queue-req: 817, 
[1,0]<stderr>:[2025-10-10 09:46:24 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 10, token usage: 0.90, #running-req: 114, #queue-req: 812, 
[1,0]<stderr>:[2025-10-10 09:46:24 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 5, token usage: 0.87, #running-req: 118, #queue-req: 810, 
[1,0]<stderr>:[2025-10-10 09:46:25 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.89, #running-req: 120, #queue-req: 809, 
[1,0]<stderr>:[2025-10-10 09:46:25 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 10, token usage: 0.90, #running-req: 122, #queue-req: 802, 
[1,0]<stderr>:[2025-10-10 09:46:25 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 4, token usage: 0.92, #running-req: 128, #queue-req: 800, 
[1,0]<stderr>:[2025-10-10 09:46:25 TP0] Prefill batch. #new-seq: 2, #new-token: 689, #cached-token: 9, token usage: 0.94, #running-req: 130, #queue-req: 799, 
[1,0]<stderr>:[2025-10-10 09:46:26 TP0] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 8, token usage: 0.94, #running-req: 126, #queue-req: 798, 
[1,0]<stderr>:[2025-10-10 09:46:26 TP0] Prefill batch. #new-seq: 2, #new-token: 488, #cached-token: 4, token usage: 0.95, #running-req: 125, #queue-req: 796, 
[1,0]<stderr>:[2025-10-10 09:46:26 TP0] Prefill batch. #new-seq: 2, #new-token: 156, #cached-token: 4, token usage: 0.94, #running-req: 126, #queue-req: 794, 
[1,0]<stderr>:[2025-10-10 09:46:27 TP0] Prefill batch. #new-seq: 5, #new-token: 672, #cached-token: 7, token usage: 0.93, #running-req: 125, #queue-req: 789, 
[1,0]<stderr>:[2025-10-10 09:46:27 TP0] Prefill batch. #new-seq: 4, #new-token: 488, #cached-token: 10, token usage: 0.93, #running-req: 128, #queue-req: 785, 
[1,0]<stderr>:[2025-10-10 09:46:27 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 7, token usage: 0.93, #running-req: 131, #queue-req: 782, 
[1,0]<stderr>:[2025-10-10 09:46:27 TP0] Prefill batch. #new-seq: 2, #new-token: 392, #cached-token: 1, token usage: 0.95, #running-req: 133, #queue-req: 781, 
[1,0]<stderr>:[2025-10-10 09:46:28 TP0] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.95, #running-req: 133, #queue-req: 780, 
[1,0]<stderr>:[2025-10-10 09:46:28 TP0] Decode batch. #running-req: 133, #token: 62309, token usage: 0.95, cuda graph: False, gen throughput (token/s): 617.00, #queue-req: 780, 
[1,0]<stderr>:[2025-10-10 09:46:28 TP0] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 1, token usage: 0.95, #running-req: 132, #queue-req: 779, 
[1,0]<stderr>:[2025-10-10 09:46:29 TP0] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 1, token usage: 0.94, #running-req: 130, #queue-req: 778, 
[1,0]<stderr>:[2025-10-10 09:46:30 TP0] Prefill batch. #new-seq: 5, #new-token: 922, #cached-token: 7, token usage: 0.93, #running-req: 129, #queue-req: 773, 
[1,0]<stderr>:[2025-10-10 09:46:30 TP0] Prefill batch. #new-seq: 2, #new-token: 877, #cached-token: 6, token usage: 0.93, #running-req: 130, #queue-req: 771, 
[1,0]<stderr>:[2025-10-10 09:46:30 TP0] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 4, token usage: 0.94, #running-req: 131, #queue-req: 770, 
[1,0]<stderr>:[2025-10-10 09:46:31 TP0] Prefill batch. #new-seq: 2, #new-token: 37, #cached-token: 4, token usage: 0.94, #running-req: 131, #queue-req: 768, 
[1,0]<stderr>:[2025-10-10 09:46:31 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 17, token usage: 0.94, #running-req: 132, #queue-req: 767, 
[1,0]<stderr>:[2025-10-10 09:46:31 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 11, token usage: 0.93, #running-req: 129, #queue-req: 764, 
[1,0]<stderr>:[2025-10-10 09:46:31 TP0] Prefill batch. #new-seq: 4, #new-token: 229, #cached-token: 5, token usage: 0.93, #running-req: 131, #queue-req: 761, 
[1,0]<stderr>:[2025-10-10 09:46:32 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.94, #running-req: 134, #queue-req: 760, 
[1,0]<stderr>:[2025-10-10 09:46:32 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.94, #running-req: 134, #queue-req: 759, 
[1,0]<stderr>:[2025-10-10 09:46:33 TP0] Prefill batch. #new-seq: 3, #new-token: 811, #cached-token: 8, token usage: 0.93, #running-req: 133, #queue-req: 756, 
[1,0]<stderr>:[2025-10-10 09:46:33 TP0] Prefill batch. #new-seq: 4, #new-token: 450, #cached-token: 5, token usage: 0.93, #running-req: 133, #queue-req: 752, 
[1,0]<stderr>:[2025-10-10 09:46:33 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 7, token usage: 0.90, #running-req: 135, #queue-req: 749, 
[1,0]<stderr>:[2025-10-10 09:46:33 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 9, token usage: 0.92, #running-req: 137, #queue-req: 748, 
[1,0]<stderr>:[2025-10-10 09:46:33 TP0] Prefill batch. #new-seq: 2, #new-token: 99, #cached-token: 1, token usage: 0.94, #running-req: 138, #queue-req: 747, 
[1,0]<stderr>:[2025-10-10 09:46:34 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.94, #running-req: 139, #queue-req: 746, 
[1,0]<stderr>:[2025-10-10 09:46:34 TP0] Prefill batch. #new-seq: 3, #new-token: 548, #cached-token: 6, token usage: 0.94, #running-req: 136, #queue-req: 743, 
[1,0]<stderr>:[2025-10-10 09:46:35 TP0] Decode batch. #running-req: 137, #token: 60754, token usage: 0.93, cuda graph: False, gen throughput (token/s): 783.07, #queue-req: 743, 
[1,0]<stderr>:[2025-10-10 09:46:35 TP0] Prefill batch. #new-seq: 5, #new-token: 914, #cached-token: 9, token usage: 0.92, #running-req: 134, #queue-req: 738, 
[1,0]<stderr>:[2025-10-10 09:46:35 TP0] Prefill batch. #new-seq: 4, #new-token: 402, #cached-token: 8, token usage: 0.94, #running-req: 138, #queue-req: 734, 
[1,0]<stderr>:[2025-10-10 09:46:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.93, #running-req: 129, #queue-req: 733, 
[1,0]<stderr>:[2025-10-10 09:46:39 TP0] Prefill batch. #new-seq: 4, #new-token: 448, #cached-token: 4, token usage: 0.93, #running-req: 129, #queue-req: 730, 
[1,0]<stderr>:[2025-10-10 09:46:39 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.94, #running-req: 130, #queue-req: 729, 
[1,0]<stderr>:[2025-10-10 09:46:40 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 3, token usage: 0.94, #running-req: 130, #queue-req: 728, 
[1,0]<stderr>:[2025-10-10 09:46:40 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 8, token usage: 0.92, #running-req: 128, #queue-req: 725, 
[1,0]<stderr>:[2025-10-10 09:46:41 TP0] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 0, token usage: 0.94, #running-req: 130, #queue-req: 725, 
[1,0]<stderr>:[2025-10-10 09:46:42 TP0] Decode batch. #running-req: 128, #token: 61259, token usage: 0.93, cuda graph: False, gen throughput (token/s): 793.85, #queue-req: 725, 
[1,0]<stderr>:[2025-10-10 09:46:42 TP0] Prefill batch. #new-seq: 2, #new-token: 950, #cached-token: 5, token usage: 0.93, #running-req: 127, #queue-req: 723, 
[1,0]<stderr>:[2025-10-10 09:46:42 TP0] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 1, token usage: 0.94, #running-req: 128, #queue-req: 722, 
[1,0]<stderr>:[2025-10-10 09:46:43 TP0] Prefill batch. #new-seq: 4, #new-token: 595, #cached-token: 7, token usage: 0.93, #running-req: 127, #queue-req: 718, 
[1,0]<stderr>:[2025-10-10 09:46:43 TP0] Prefill batch. #new-seq: 2, #new-token: 412, #cached-token: 10, token usage: 0.94, #running-req: 130, #queue-req: 716, 
[1,0]<stderr>:[2025-10-10 09:46:45 TP0] Prefill batch. #new-seq: 5, #new-token: 345, #cached-token: 12, token usage: 0.92, #running-req: 125, #queue-req: 711, 
[1,0]<stderr>:[2025-10-10 09:46:46 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 3, token usage: 0.93, #running-req: 128, #queue-req: 708, 
[1,0]<stderr>:[2025-10-10 09:46:46 TP0] Prefill batch. #new-seq: 3, #new-token: 204, #cached-token: 6, token usage: 0.94, #running-req: 130, #queue-req: 706, 
[1,0]<stderr>:[2025-10-10 09:46:46 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.94, #running-req: 132, #queue-req: 705, 
[1,0]<stderr>:[2025-10-10 09:46:47 TP0] Decode batch. #running-req: 131, #token: 60439, token usage: 0.92, cuda graph: False, gen throughput (token/s): 954.26, #queue-req: 705, 
[1,0]<stderr>:[2025-10-10 09:46:47 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.92, #running-req: 128, #queue-req: 703, 
[1,0]<stderr>:[2025-10-10 09:46:47 TP0] Prefill batch. #new-seq: 2, #new-token: 785, #cached-token: 2, token usage: 0.94, #running-req: 129, #queue-req: 702, 
[1,0]<stderr>:[2025-10-10 09:46:48 TP0] Prefill batch. #new-seq: 2, #new-token: 609, #cached-token: 3, token usage: 0.95, #running-req: 130, #queue-req: 700, 
[1,0]<stderr>:[2025-10-10 09:46:48 TP0] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 1, token usage: 0.95, #running-req: 130, #queue-req: 699, 
[1,0]<stderr>:[2025-10-10 09:46:48 TP0] Prefill batch. #new-seq: 2, #new-token: 94, #cached-token: 2, token usage: 0.94, #running-req: 130, #queue-req: 697, 
[1,0]<stderr>:[2025-10-10 09:46:48 TP0] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 1, token usage: 0.94, #running-req: 131, #queue-req: 696, 
[1,0]<stderr>:[2025-10-10 09:46:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 129, #queue-req: 695, 
[1,0]<stderr>:[2025-10-10 09:46:49 TP0] Prefill batch. #new-seq: 2, #new-token: 524, #cached-token: 1, token usage: 0.91, #running-req: 129, #queue-req: 694, 
[1,0]<stderr>:[2025-10-10 09:46:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.87, #running-req: 123, #queue-req: 693, 
[1,0]<stderr>:[2025-10-10 09:46:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.88, #running-req: 123, #queue-req: 693, 
[1,0]<stderr>:[2025-10-10 09:46:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.89, #running-req: 123, #queue-req: 693, 
[1,0]<stderr>:[2025-10-10 09:46:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.91, #running-req: 123, #queue-req: 693, 
[1,0]<stderr>:[2025-10-10 09:46:51 TP0] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 0, token usage: 0.92, #running-req: 123, #queue-req: 693, 
[1,0]<stderr>:[2025-10-10 09:46:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 120, #queue-req: 692, 
[1,0]<stderr>:[2025-10-10 09:46:51 TP0] Prefill batch. #new-seq: 3, #new-token: 815, #cached-token: 2, token usage: 0.93, #running-req: 120, #queue-req: 690, 
[1,0]<stderr>:[2025-10-10 09:46:53 TP0] Decode batch. #running-req: 120, #token: 58098, token usage: 0.89, cuda graph: False, gen throughput (token/s): 817.71, #queue-req: 690, 
[1,0]<stderr>:[2025-10-10 09:46:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.89, #running-req: 119, #queue-req: 689, 
[1,0]<stderr>:[2025-10-10 09:46:53 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 3, token usage: 0.90, #running-req: 119, #queue-req: 686, 
[1,0]<stderr>:[2025-10-10 09:46:53 TP0] Prefill batch. #new-seq: 2, #new-token: 693, #cached-token: 3, token usage: 0.92, #running-req: 122, #queue-req: 685, 
[1,0]<stderr>:[2025-10-10 09:46:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 120, #queue-req: 684, 
[1,0]<stderr>:[2025-10-10 09:46:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.93, #running-req: 120, #queue-req: 684, 
[1,0]<stderr>:[2025-10-10 09:46:54 TP0] Prefill batch. #new-seq: 3, #new-token: 252, #cached-token: 5, token usage: 0.95, #running-req: 120, #queue-req: 682, 
[1,0]<stderr>:[2025-10-10 09:46:54 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 1, token usage: 0.95, #running-req: 122, #queue-req: 681, 
[1,0]<stderr>:[2025-10-10 09:46:55 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.94, #running-req: 122, #queue-req: 680, 
[1,0]<stderr>:[2025-10-10 09:46:56 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 3, token usage: 0.94, #running-req: 119, #queue-req: 679, 
[1,0]<stderr>:[2025-10-10 09:46:56 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 11, token usage: 0.92, #running-req: 118, #queue-req: 673, 
[1,0]<stderr>:[2025-10-10 09:46:56 TP0] Prefill batch. #new-seq: 2, #new-token: 846, #cached-token: 2, token usage: 0.94, #running-req: 123, #queue-req: 672, 
[1,0]<stderr>:[2025-10-10 09:46:57 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 5, token usage: 0.93, #running-req: 122, #queue-req: 670, 
[1,0]<stderr>:[2025-10-10 09:46:57 TP0] Prefill batch. #new-seq: 2, #new-token: 451, #cached-token: 3, token usage: 0.94, #running-req: 123, #queue-req: 669, 
[1,0]<stderr>:[2025-10-10 09:46:58 TP0] Prefill batch. #new-seq: 2, #new-token: 461, #cached-token: 9, token usage: 0.94, #running-req: 121, #queue-req: 667, 
[1,0]<stderr>:[2025-10-10 09:46:58 TP0] Prefill batch. #new-seq: 1, #new-token: 349, #cached-token: 2, token usage: 0.95, #running-req: 122, #queue-req: 666, 
[1,0]<stderr>:[2025-10-10 09:46:58 TP0] Prefill batch. #new-seq: 4, #new-token: 429, #cached-token: 13, token usage: 0.94, #running-req: 121, #queue-req: 662, 
[1,0]<stderr>:[2025-10-10 09:46:59 TP0] Decode batch. #running-req: 122, #token: 61401, token usage: 0.94, cuda graph: False, gen throughput (token/s): 764.23, #queue-req: 662, 
[1,0]<stderr>:[2025-10-10 09:46:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.94, #running-req: 121, #queue-req: 661, 
[1,0]<stderr>:[2025-10-10 09:47:00 TP0] Prefill batch. #new-seq: 2, #new-token: 186, #cached-token: 3, token usage: 0.95, #running-req: 121, #queue-req: 660, 
[1,0]<stderr>:[2025-10-10 09:47:00 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.95, #running-req: 121, #queue-req: 659, 
[1,0]<stderr>:[2025-10-10 09:47:01 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 1, token usage: 0.94, #running-req: 119, #queue-req: 658, 
[1,0]<stderr>:[2025-10-10 09:47:02 TP0] Prefill batch. #new-seq: 4, #new-token: 498, #cached-token: 8, token usage: 0.94, #running-req: 118, #queue-req: 654, 
[1,0]<stderr>:[2025-10-10 09:47:03 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.94, #running-req: 119, #queue-req: 653, 
[1,0]<stderr>:[2025-10-10 09:47:03 TP0] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 1, token usage: 0.94, #running-req: 119, #queue-req: 652, 
[1,0]<stderr>:[2025-10-10 09:47:05 TP0] Decode batch. #running-req: 120, #token: 63941, token usage: 0.98, cuda graph: False, gen throughput (token/s): 908.45, #queue-req: 652, 
[1,0]<stderr>:[2025-10-10 09:47:06 TP0] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 2, token usage: 0.96, #running-req: 115, #queue-req: 651, 
[1,0]<stderr>:[2025-10-10 09:47:07 TP0] Prefill batch. #new-seq: 2, #new-token: 14, #cached-token: 2, token usage: 0.96, #running-req: 114, #queue-req: 649, 
[1,0]<stderr>:[2025-10-10 09:47:07 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.96, #running-req: 114, #queue-req: 648, 
[1,0]<stderr>:[2025-10-10 09:47:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 112, #queue-req: 647, 
[1,0]<stderr>:[2025-10-10 09:47:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.93, #running-req: 112, #queue-req: 647, 
[1,0]<stderr>:[2025-10-10 09:47:08 TP0] Prefill batch. #new-seq: 2, #new-token: 351, #cached-token: 1, token usage: 0.95, #running-req: 112, #queue-req: 646, 
[1,0]<stderr>:[2025-10-10 09:47:09 TP0] Prefill batch. #new-seq: 3, #new-token: 43, #cached-token: 5, token usage: 0.94, #running-req: 108, #queue-req: 643, 
[1,0]<stderr>:[2025-10-10 09:47:09 TP0] Prefill batch. #new-seq: 4, #new-token: 499, #cached-token: 7, token usage: 0.93, #running-req: 110, #queue-req: 639, 
[1,0]<stderr>:[2025-10-10 09:47:10 TP0] Prefill batch. #new-seq: 2, #new-token: 997, #cached-token: 2, token usage: 0.93, #running-req: 112, #queue-req: 637, 
[1,0]<stderr>:[2025-10-10 09:47:10 TP0] Prefill batch. #new-seq: 2, #new-token: 841, #cached-token: 4, token usage: 0.95, #running-req: 113, #queue-req: 635, 
[1,0]<stderr>:[2025-10-10 09:47:10 TP0] Decode batch. #running-req: 115, #token: 62814, token usage: 0.96, cuda graph: False, gen throughput (token/s): 800.26, #queue-req: 635, 
[1,0]<stderr>:[2025-10-10 09:47:11 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.96, #running-req: 114, #queue-req: 634, 
[1,0]<stderr>:[2025-10-10 09:47:11 TP0] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 3, token usage: 0.95, #running-req: 113, #queue-req: 633, 
[1,0]<stderr>:[2025-10-10 09:47:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 3, token usage: 0.91, #running-req: 107, #queue-req: 632, 
[1,0]<stderr>:[2025-10-10 09:47:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 107, #queue-req: 632, 
[1,0]<stderr>:[2025-10-10 09:47:13 TP0] Prefill batch. #new-seq: 2, #new-token: 922, #cached-token: 1, token usage: 0.94, #running-req: 107, #queue-req: 631, 
[1,0]<stderr>:[2025-10-10 09:47:13 TP0] Prefill batch. #new-seq: 2, #new-token: 238, #cached-token: 4, token usage: 0.95, #running-req: 108, #queue-req: 629, 
[1,0]<stderr>:[2025-10-10 09:47:15 TP0] Prefill batch. #new-seq: 2, #new-token: 104, #cached-token: 4, token usage: 0.96, #running-req: 105, #queue-req: 627, 
[1,0]<stderr>:[2025-10-10 09:47:16 TP0] Decode batch. #running-req: 107, #token: 62984, token usage: 0.96, cuda graph: False, gen throughput (token/s): 822.72, #queue-req: 627, 
[1,0]<stderr>:[2025-10-10 09:47:16 TP0] Prefill batch. #new-seq: 2, #new-token: 667, #cached-token: 5, token usage: 0.94, #running-req: 105, #queue-req: 625, 
[1,0]<stderr>:[2025-10-10 09:47:16 TP0] Prefill batch. #new-seq: 1, #new-token: 448, #cached-token: 1, token usage: 0.95, #running-req: 106, #queue-req: 624, 
[1,0]<stderr>:[2025-10-10 09:47:19 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 9, token usage: 0.90, #running-req: 99, #queue-req: 620, 
[1,0]<stderr>:[2025-10-10 09:47:19 TP0] Prefill batch. #new-seq: 9, #new-token: 1024, #cached-token: 14, token usage: 0.91, #running-req: 102, #queue-req: 612, 
[1,0]<stderr>:[2025-10-10 09:47:20 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 7, token usage: 0.93, #running-req: 110, #queue-req: 607, 
[1,0]<stderr>:[2025-10-10 09:47:20 TP0] Prefill batch. #new-seq: 3, #new-token: 225, #cached-token: 7, token usage: 0.95, #running-req: 115, #queue-req: 605, 
[1,0]<stderr>:[2025-10-10 09:47:20 TP0] Prefill batch. #new-seq: 2, #new-token: 433, #cached-token: 4, token usage: 0.95, #running-req: 117, #queue-req: 603, 
[1,0]<stderr>:[2025-10-10 09:47:20 TP0] Prefill batch. #new-seq: 3, #new-token: 98, #cached-token: 8, token usage: 0.95, #running-req: 118, #queue-req: 600, 
[1,0]<stderr>:[2025-10-10 09:47:21 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 5, token usage: 0.94, #running-req: 119, #queue-req: 597, 
[1,0]<stderr>:[2025-10-10 09:47:21 TP0] Prefill batch. #new-seq: 5, #new-token: 554, #cached-token: 11, token usage: 0.94, #running-req: 121, #queue-req: 593, 
[1,0]<stderr>:[2025-10-10 09:47:21 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.95, #running-req: 125, #queue-req: 592, 
[1,0]<stderr>:[2025-10-10 09:47:21 TP0] Prefill batch. #new-seq: 2, #new-token: 23, #cached-token: 2, token usage: 0.95, #running-req: 125, #queue-req: 590, 
[1,0]<stderr>:[2025-10-10 09:47:21 TP0] Prefill batch. #new-seq: 3, #new-token: 226, #cached-token: 7, token usage: 0.95, #running-req: 126, #queue-req: 587, 
[1,0]<stderr>:[2025-10-10 09:47:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.94, #running-req: 127, #queue-req: 586, 
[1,0]<stderr>:[2025-10-10 09:47:22 TP0] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 0, token usage: 0.95, #running-req: 127, #queue-req: 586, 
[1,0]<stderr>:[2025-10-10 09:47:23 TP0] Prefill batch. #new-seq: 3, #new-token: 470, #cached-token: 5, token usage: 0.94, #running-req: 126, #queue-req: 583, 
[1,0]<stderr>:[2025-10-10 09:47:23 TP0] Decode batch. #running-req: 126, #token: 62213, token usage: 0.95, cuda graph: False, gen throughput (token/s): 648.56, #queue-req: 583, 
[1,0]<stderr>:[2025-10-10 09:47:23 TP0] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 3, token usage: 0.95, #running-req: 126, #queue-req: 582, 
[1,0]<stderr>:[2025-10-10 09:47:23 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.95, #running-req: 126, #queue-req: 581, 
[1,0]<stderr>:[2025-10-10 09:47:24 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.93, #running-req: 123, #queue-req: 579, 
[1,0]<stderr>:[2025-10-10 09:47:24 TP0] Prefill batch. #new-seq: 2, #new-token: 772, #cached-token: 3, token usage: 0.94, #running-req: 124, #queue-req: 578, 
[1,0]<stderr>:[2025-10-10 09:47:24 TP0] Prefill batch. #new-seq: 2, #new-token: 418, #cached-token: 5, token usage: 0.95, #running-req: 124, #queue-req: 576, 
[1,0]<stderr>:[2025-10-10 09:47:25 TP0] Prefill batch. #new-seq: 1, #new-token: 861, #cached-token: 4, token usage: 0.94, #running-req: 124, #queue-req: 575, 
[1,0]<stderr>:[2025-10-10 09:47:25 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.95, #running-req: 124, #queue-req: 574, 
[1,0]<stderr>:[2025-10-10 09:47:26 TP0] Prefill batch. #new-seq: 3, #new-token: 329, #cached-token: 4, token usage: 0.94, #running-req: 123, #queue-req: 571, 
[1,0]<stderr>:[2025-10-10 09:47:26 TP0] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 2, token usage: 0.94, #running-req: 124, #queue-req: 570, 
[1,0]<stderr>:[2025-10-10 09:47:27 TP0] Prefill batch. #new-seq: 2, #new-token: 858, #cached-token: 5, token usage: 0.94, #running-req: 124, #queue-req: 568, 
[1,0]<stderr>:[2025-10-10 09:47:27 TP0] Prefill batch. #new-seq: 3, #new-token: 527, #cached-token: 7, token usage: 0.95, #running-req: 125, #queue-req: 565, 
[1,0]<stderr>:[2025-10-10 09:47:27 TP0] Prefill batch. #new-seq: 1, #new-token: 851, #cached-token: 1, token usage: 0.94, #running-req: 125, #queue-req: 564, 
[1,0]<stderr>:[2025-10-10 09:47:28 TP0] Prefill batch. #new-seq: 2, #new-token: 258, #cached-token: 2, token usage: 0.95, #running-req: 123, #queue-req: 562, 
[1,0]<stderr>:[2025-10-10 09:47:28 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.93, #running-req: 124, #queue-req: 560, 
[1,0]<stderr>:[2025-10-10 09:47:28 TP0] Prefill batch. #new-seq: 2, #new-token: 238, #cached-token: 2, token usage: 0.94, #running-req: 125, #queue-req: 559, 
[1,0]<stderr>:[2025-10-10 09:47:29 TP0] Decode batch. #running-req: 123, #token: 61237, token usage: 0.93, cuda graph: False, gen throughput (token/s): 780.09, #queue-req: 559, 
[1,0]<stderr>:[2025-10-10 09:47:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 116, #queue-req: 558, 
[1,0]<stderr>:[2025-10-10 09:47:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 116, #queue-req: 558, 
[1,0]<stderr>:[2025-10-10 09:47:31 TP0] Prefill batch. #new-seq: 6, #new-token: 978, #cached-token: 11, token usage: 0.94, #running-req: 116, #queue-req: 553, 
[1,0]<stderr>:[2025-10-10 09:47:31 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.95, #running-req: 120, #queue-req: 552, 
[1,0]<stderr>:[2025-10-10 09:47:33 TP0] Prefill batch. #new-seq: 10, #new-token: 937, #cached-token: 21, token usage: 0.90, #running-req: 118, #queue-req: 542, 
[1,0]<stderr>:[2025-10-10 09:47:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.92, #running-req: 127, #queue-req: 541, 
[1,0]<stderr>:[2025-10-10 09:47:33 TP0] Prefill batch. #new-seq: 3, #new-token: 384, #cached-token: 5, token usage: 0.93, #running-req: 127, #queue-req: 539, 
[1,0]<stderr>:[2025-10-10 09:47:33 TP0] Prefill batch. #new-seq: 2, #new-token: 509, #cached-token: 4, token usage: 0.94, #running-req: 129, #queue-req: 537, 
[1,0]<stderr>:[2025-10-10 09:47:35 TP0] Decode batch. #running-req: 129, #token: 60861, token usage: 0.93, cuda graph: False, gen throughput (token/s): 888.34, #queue-req: 537, 
[1,0]<stderr>:[2025-10-10 09:47:35 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 7, token usage: 0.93, #running-req: 128, #queue-req: 534, 
[1,0]<stderr>:[2025-10-10 09:47:35 TP0] Prefill batch. #new-seq: 2, #new-token: 273, #cached-token: 1, token usage: 0.94, #running-req: 130, #queue-req: 533, 
[1,0]<stderr>:[2025-10-10 09:47:36 TP0] Prefill batch. #new-seq: 3, #new-token: 114, #cached-token: 5, token usage: 0.93, #running-req: 128, #queue-req: 530, 
[1,0]<stderr>:[2025-10-10 09:47:36 TP0] Prefill batch. #new-seq: 2, #new-token: 507, #cached-token: 4, token usage: 0.93, #running-req: 130, #queue-req: 528, 
[1,0]<stderr>:[2025-10-10 09:47:36 TP0] Prefill batch. #new-seq: 5, #new-token: 602, #cached-token: 9, token usage: 0.94, #running-req: 130, #queue-req: 523, 
[1,0]<stderr>:[2025-10-10 09:47:37 TP0] Prefill batch. #new-seq: 7, #new-token: 755, #cached-token: 11, token usage: 0.93, #running-req: 134, #queue-req: 516, 
[1,0]<stderr>:[2025-10-10 09:47:37 TP0] Prefill batch. #new-seq: 3, #new-token: 46, #cached-token: 5, token usage: 0.94, #running-req: 136, #queue-req: 513, 
[1,0]<stderr>:[2025-10-10 09:47:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 135, #queue-req: 512, 
[1,0]<stderr>:[2025-10-10 09:47:38 TP0] Prefill batch. #new-seq: 3, #new-token: 1022, #cached-token: 3, token usage: 0.92, #running-req: 135, #queue-req: 510, 
[1,0]<stderr>:[2025-10-10 09:47:38 TP0] Prefill batch. #new-seq: 3, #new-token: 562, #cached-token: 4, token usage: 0.94, #running-req: 137, #queue-req: 507, 
[1,0]<stderr>:[2025-10-10 09:47:39 TP0] Prefill batch. #new-seq: 2, #new-token: 582, #cached-token: 4, token usage: 0.95, #running-req: 138, #queue-req: 505, 
[1,0]<stderr>:[2025-10-10 09:47:39 TP0] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 1, token usage: 0.95, #running-req: 139, #queue-req: 504, 
[1,0]<stderr>:[2025-10-10 09:47:39 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 2, token usage: 0.94, #running-req: 138, #queue-req: 503, 
[1,0]<stderr>:[2025-10-10 09:47:41 TP0] Decode batch. #running-req: 137, #token: 63423, token usage: 0.97, cuda graph: False, gen throughput (token/s): 905.58, #queue-req: 503, 
[1,0]<stderr>:[2025-10-10 09:47:42 TP0] Prefill batch. #new-seq: 4, #new-token: 840, #cached-token: 10, token usage: 0.92, #running-req: 130, #queue-req: 499, 
[1,0]<stderr>:[2025-10-10 09:47:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.94, #running-req: 131, #queue-req: 498, 
[1,0]<stderr>:[2025-10-10 09:47:42 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 0, token usage: 0.95, #running-req: 131, #queue-req: 498, 
[1,0]<stderr>:[2025-10-10 09:47:43 TP0] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.95, #running-req: 130, #queue-req: 497, 
[1,0]<stderr>:[2025-10-10 09:47:44 TP0] Prefill batch. #new-seq: 2, #new-token: 406, #cached-token: 3, token usage: 0.94, #running-req: 130, #queue-req: 495, 
[1,0]<stderr>:[2025-10-10 09:47:44 TP0] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 1, token usage: 0.95, #running-req: 131, #queue-req: 494, 
[1,0]<stderr>:[2025-10-10 09:47:46 TP0] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 2, token usage: 0.95, #running-req: 126, #queue-req: 493, 
[1,0]<stderr>:[2025-10-10 09:47:46 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.95, #running-req: 124, #queue-req: 492, 
[1,0]<stderr>:[2025-10-10 09:47:46 TP0] Decode batch. #running-req: 125, #token: 60511, token usage: 0.92, cuda graph: False, gen throughput (token/s): 933.63, #queue-req: 492, 
[1,0]<stderr>:[2025-10-10 09:47:46 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 13, token usage: 0.93, #running-req: 124, #queue-req: 486, 
[1,0]<stderr>:[2025-10-10 09:47:46 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 2, token usage: 0.94, #running-req: 129, #queue-req: 484, 
[1,0]<stderr>:[2025-10-10 09:47:47 TP0] Prefill batch. #new-seq: 4, #new-token: 146, #cached-token: 9, token usage: 0.95, #running-req: 131, #queue-req: 481, 
[1,0]<stderr>:[2025-10-10 09:47:47 TP0] Prefill batch. #new-seq: 2, #new-token: 51, #cached-token: 3, token usage: 0.95, #running-req: 131, #queue-req: 479, 
[1,0]<stderr>:[2025-10-10 09:47:48 TP0] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 2, token usage: 0.93, #running-req: 131, #queue-req: 478, 
[1,0]<stderr>:[2025-10-10 09:47:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 129, #queue-req: 477, 
[1,0]<stderr>:[2025-10-10 09:47:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.94, #running-req: 129, #queue-req: 477, 
[1,0]<stderr>:[2025-10-10 09:47:49 TP0] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 0, token usage: 0.95, #running-req: 129, #queue-req: 477, 
[1,0]<stderr>:[2025-10-10 09:47:49 TP0] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 2, token usage: 0.95, #running-req: 128, #queue-req: 476, 
[1,0]<stderr>:[2025-10-10 09:47:49 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 2, token usage: 0.95, #running-req: 128, #queue-req: 475, 
[1,0]<stderr>:[2025-10-10 09:47:51 TP0] Prefill batch. #new-seq: 3, #new-token: 448, #cached-token: 9, token usage: 0.94, #running-req: 127, #queue-req: 472, 
[1,0]<stderr>:[2025-10-10 09:47:51 TP0] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 1, token usage: 0.95, #running-req: 126, #queue-req: 471, 
[1,0]<stderr>:[2025-10-10 09:47:51 TP0] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 1, token usage: 0.96, #running-req: 126, #queue-req: 470, 
[1,0]<stderr>:[2025-10-10 09:47:51 TP0] Prefill batch. #new-seq: 7, #new-token: 652, #cached-token: 16, token usage: 0.90, #running-req: 124, #queue-req: 463, 
[1,0]<stderr>:[2025-10-10 09:47:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 130, #queue-req: 462, 
[1,0]<stderr>:[2025-10-10 09:47:52 TP0] Prefill batch. #new-seq: 2, #new-token: 477, #cached-token: 12, token usage: 0.93, #running-req: 130, #queue-req: 461, 
[1,0]<stderr>:[2025-10-10 09:47:52 TP0] Prefill batch. #new-seq: 2, #new-token: 301, #cached-token: 2, token usage: 0.94, #running-req: 131, #queue-req: 459, 
[1,0]<stderr>:[2025-10-10 09:47:53 TP0] Decode batch. #running-req: 133, #token: 62546, token usage: 0.95, cuda graph: False, gen throughput (token/s): 772.60, #queue-req: 459, 
[1,0]<stderr>:[2025-10-10 09:47:53 TP0] Prefill batch. #new-seq: 3, #new-token: 541, #cached-token: 4, token usage: 0.94, #running-req: 132, #queue-req: 456, 
[1,0]<stderr>:[2025-10-10 09:47:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 126, #queue-req: 455, 
[1,0]<stderr>:[2025-10-10 09:47:55 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 5, token usage: 0.93, #running-req: 126, #queue-req: 451, 
[1,0]<stderr>:[2025-10-10 09:47:55 TP0] Prefill batch. #new-seq: 5, #new-token: 474, #cached-token: 6, token usage: 0.94, #running-req: 130, #queue-req: 447, 
[1,0]<stderr>:[2025-10-10 09:47:58 TP0] Decode batch. #running-req: 127, #token: 62656, token usage: 0.96, cuda graph: False, gen throughput (token/s): 1024.90, #queue-req: 447, 
[1,0]<stderr>:[2025-10-10 09:47:58 TP0] Prefill batch. #new-seq: 2, #new-token: 141, #cached-token: 3, token usage: 0.94, #running-req: 123, #queue-req: 445, 
[1,0]<stderr>:[2025-10-10 09:48:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.93, #running-req: 118, #queue-req: 444, 
[1,0]<stderr>:[2025-10-10 09:48:00 TP0] Prefill batch. #new-seq: 1, #new-token: 840, #cached-token: 0, token usage: 0.95, #running-req: 118, #queue-req: 444, 
[1,0]<stderr>:[2025-10-10 09:48:01 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.93, #running-req: 117, #queue-req: 442, 
[1,0]<stderr>:[2025-10-10 09:48:01 TP0] Prefill batch. #new-seq: 12, #new-token: 1024, #cached-token: 20, token usage: 0.88, #running-req: 118, #queue-req: 431, 
[1,0]<stderr>:[2025-10-10 09:48:01 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 12, token usage: 0.90, #running-req: 129, #queue-req: 427, 
[1,0]<stderr>:[2025-10-10 09:48:01 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 10, token usage: 0.91, #running-req: 133, #queue-req: 421, 
[1,0]<stderr>:[2025-10-10 09:48:01 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 5, token usage: 0.93, #running-req: 139, #queue-req: 419, 
[1,0]<stderr>:[2025-10-10 09:48:01 TP0] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 0, token usage: 0.95, #running-req: 141, #queue-req: 419, 
[1,0]<stderr>:[2025-10-10 09:48:02 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 5, token usage: 0.93, #running-req: 140, #queue-req: 415, 
[1,0]<stderr>:[2025-10-10 09:48:02 TP0] Prefill batch. #new-seq: 2, #new-token: 287, #cached-token: 1, token usage: 0.95, #running-req: 143, #queue-req: 414, 
[1,0]<stderr>:[2025-10-10 09:48:02 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.95, #running-req: 142, #queue-req: 413, 
[1,0]<stderr>:[2025-10-10 09:48:02 TP0] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 5, token usage: 0.95, #running-req: 142, #queue-req: 412, 
[1,0]<stderr>:[2025-10-10 09:48:03 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 3, token usage: 0.93, #running-req: 140, #queue-req: 410, 
[1,0]<stderr>:[2025-10-10 09:48:03 TP0] Prefill batch. #new-seq: 4, #new-token: 83, #cached-token: 5, token usage: 0.94, #running-req: 141, #queue-req: 407, 
[1,0]<stderr>:[2025-10-10 09:48:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.86, #running-req: 139, #queue-req: 406, 
[1,0]<stderr>:[2025-10-10 09:48:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.87, #running-req: 139, #queue-req: 406, 
[1,0]<stderr>:[2025-10-10 09:48:04 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 13, token usage: 0.88, #running-req: 139, #queue-req: 402, 
[1,0]<stderr>:[2025-10-10 09:48:04 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.90, #running-req: 143, #queue-req: 401, 
[1,0]<stderr>:[2025-10-10 09:48:04 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 13, token usage: 0.91, #running-req: 144, #queue-req: 397, 
[1,0]<stderr>:[2025-10-10 09:48:04 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.93, #running-req: 148, #queue-req: 394, 
[1,0]<stderr>:[2025-10-10 09:48:04 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 0, token usage: 0.94, #running-req: 151, #queue-req: 394, 
[1,0]<stderr>:[2025-10-10 09:48:05 TP0] Prefill batch. #new-seq: 4, #new-token: 591, #cached-token: 5, token usage: 0.92, #running-req: 146, #queue-req: 390, 
[1,0]<stderr>:[2025-10-10 09:48:05 TP0] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 1, token usage: 0.93, #running-req: 147, #queue-req: 389, 
[1,0]<stderr>:[2025-10-10 09:48:05 TP0] Decode batch. #running-req: 147, #token: 61198, token usage: 0.93, cuda graph: False, gen throughput (token/s): 723.93, #queue-req: 389, 
[1,0]<stderr>:[2025-10-10 09:48:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 3, token usage: 0.92, #running-req: 145, #queue-req: 388, 
[1,0]<stderr>:[2025-10-10 09:48:06 TP0] Prefill batch. #new-seq: 3, #new-token: 762, #cached-token: 3, token usage: 0.92, #running-req: 145, #queue-req: 386, 
[1,0]<stderr>:[2025-10-10 09:48:06 TP0] Prefill batch. #new-seq: 2, #new-token: 766, #cached-token: 2, token usage: 0.94, #running-req: 145, #queue-req: 384, 
[1,0]<stderr>:[2025-10-10 09:48:06 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 9, token usage: 0.90, #running-req: 144, #queue-req: 381, 
[1,0]<stderr>:[2025-10-10 09:48:06 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 7, token usage: 0.91, #running-req: 146, #queue-req: 380, 
[1,0]<stderr>:[2025-10-10 09:48:06 TP0] Prefill batch. #new-seq: 5, #new-token: 768, #cached-token: 9, token usage: 0.93, #running-req: 147, #queue-req: 376, 
[1,0]<stderr>:[2025-10-10 09:48:07 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 10, token usage: 0.92, #running-req: 148, #queue-req: 373, 
[1,0]<stderr>:[2025-10-10 09:48:08 TP0] Prefill batch. #new-seq: 1, #new-token: 585, #cached-token: 0, token usage: 0.94, #running-req: 150, #queue-req: 373, 
[1,0]<stderr>:[2025-10-10 09:48:08 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.92, #running-req: 146, #queue-req: 371, 
[1,0]<stderr>:[2025-10-10 09:48:08 TP0] Prefill batch. #new-seq: 4, #new-token: 980, #cached-token: 5, token usage: 0.93, #running-req: 147, #queue-req: 368, 
[1,0]<stderr>:[2025-10-10 09:48:08 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.94, #running-req: 146, #queue-req: 367, 
[1,0]<stderr>:[2025-10-10 09:48:09 TP0] Prefill batch. #new-seq: 4, #new-token: 92, #cached-token: 9, token usage: 0.93, #running-req: 145, #queue-req: 363, 
[1,0]<stderr>:[2025-10-10 09:48:09 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 5, token usage: 0.91, #running-req: 146, #queue-req: 361, 
[1,0]<stderr>:[2025-10-10 09:48:09 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 6, token usage: 0.92, #running-req: 147, #queue-req: 357, 
[1,0]<stderr>:[2025-10-10 09:48:09 TP0] Prefill batch. #new-seq: 4, #new-token: 633, #cached-token: 5, token usage: 0.93, #running-req: 151, #queue-req: 354, 
[1,0]<stderr>:[2025-10-10 09:48:10 TP0] Prefill batch. #new-seq: 3, #new-token: 529, #cached-token: 7, token usage: 0.94, #running-req: 153, #queue-req: 351, 
[1,0]<stderr>:[2025-10-10 09:48:11 TP0] Prefill batch. #new-seq: 3, #new-token: 80, #cached-token: 6, token usage: 0.94, #running-req: 152, #queue-req: 348, 
[1,0]<stderr>:[2025-10-10 09:48:11 TP0] Prefill batch. #new-seq: 4, #new-token: 920, #cached-token: 8, token usage: 0.93, #running-req: 154, #queue-req: 344, 
[1,0]<stderr>:[2025-10-10 09:48:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 7, token usage: 0.93, #running-req: 155, #queue-req: 342, 
[1,0]<stderr>:[2025-10-10 09:48:11 TP0] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 0, token usage: 0.94, #running-req: 156, #queue-req: 342, 
[1,0]<stderr>:[2025-10-10 09:48:12 TP0] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 3, token usage: 0.94, #running-req: 155, #queue-req: 341, 
[1,0]<stderr>:[2025-10-10 09:48:12 TP0] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 2, token usage: 0.94, #running-req: 154, #queue-req: 340, 
[1,0]<stderr>:[2025-10-10 09:48:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.90, #running-req: 152, #queue-req: 339, 
[1,0]<stderr>:[2025-10-10 09:48:12 TP0] Decode batch. #running-req: 152, #token: 59814, token usage: 0.91, cuda graph: False, gen throughput (token/s): 842.46, #queue-req: 339, 
[1,0]<stderr>:[2025-10-10 09:48:12 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 152, #queue-req: 338, 
[1,0]<stderr>:[2025-10-10 09:48:12 TP0] Prefill batch. #new-seq: 5, #new-token: 955, #cached-token: 6, token usage: 0.93, #running-req: 153, #queue-req: 334, 
[1,0]<stderr>:[2025-10-10 09:48:13 TP0] Prefill batch. #new-seq: 1, #new-token: 444, #cached-token: 6, token usage: 0.95, #running-req: 154, #queue-req: 333, 
[1,0]<stderr>:[2025-10-10 09:48:13 TP0] Prefill batch. #new-seq: 2, #new-token: 45, #cached-token: 6, token usage: 0.94, #running-req: 153, #queue-req: 331, 
[1,0]<stderr>:[2025-10-10 09:48:13 TP0] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 3, token usage: 0.93, #running-req: 153, #queue-req: 330, 
[1,0]<stderr>:[2025-10-10 09:48:14 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.92, #running-req: 151, #queue-req: 328, 
[1,0]<stderr>:[2025-10-10 09:48:14 TP0] Prefill batch. #new-seq: 3, #new-token: 595, #cached-token: 3, token usage: 0.93, #running-req: 152, #queue-req: 326, 
[1,0]<stderr>:[2025-10-10 09:48:15 TP0] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 3, token usage: 0.94, #running-req: 153, #queue-req: 325, 
[1,0]<stderr>:[2025-10-10 09:48:15 TP0] Prefill batch. #new-seq: 5, #new-token: 314, #cached-token: 10, token usage: 0.92, #running-req: 151, #queue-req: 320, 
[1,0]<stderr>:[2025-10-10 09:48:15 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 5, token usage: 0.91, #running-req: 152, #queue-req: 318, 
[1,0]<stderr>:[2025-10-10 09:48:15 TP0] Prefill batch. #new-seq: 2, #new-token: 254, #cached-token: 2, token usage: 0.93, #running-req: 153, #queue-req: 317, 
[1,0]<stderr>:[2025-10-10 09:48:16 TP0] Prefill batch. #new-seq: 3, #new-token: 728, #cached-token: 7, token usage: 0.93, #running-req: 154, #queue-req: 314, 
[1,0]<stderr>:[2025-10-10 09:48:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.92, #running-req: 149, #queue-req: 313, 
[1,0]<stderr>:[2025-10-10 09:48:18 TP0] Prefill batch. #new-seq: 1, #new-token: 787, #cached-token: 0, token usage: 0.94, #running-req: 149, #queue-req: 313, 
[1,0]<stderr>:[2025-10-10 09:48:19 TP0] Prefill batch. #new-seq: 4, #new-token: 710, #cached-token: 5, token usage: 0.92, #running-req: 147, #queue-req: 309, 
[1,0]<stderr>:[2025-10-10 09:48:19 TP0] Prefill batch. #new-seq: 4, #new-token: 411, #cached-token: 9, token usage: 0.94, #running-req: 146, #queue-req: 305, 
[1,0]<stderr>:[2025-10-10 09:48:19 TP0] Decode batch. #running-req: 150, #token: 61711, token usage: 0.94, cuda graph: False, gen throughput (token/s): 892.28, #queue-req: 305, 
[1,0]<stderr>:[2025-10-10 09:48:20 TP0] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 5, token usage: 0.94, #running-req: 147, #queue-req: 304, 
[1,0]<stderr>:[2025-10-10 09:48:20 TP0] Prefill batch. #new-seq: 1, #new-token: 415, #cached-token: 1, token usage: 0.95, #running-req: 147, #queue-req: 303, 
[1,0]<stderr>:[2025-10-10 09:48:21 TP0] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 2, token usage: 0.94, #running-req: 143, #queue-req: 302, 
[1,0]<stderr>:[2025-10-10 09:48:22 TP0] Prefill batch. #new-seq: 1, #new-token: 760, #cached-token: 1, token usage: 0.94, #running-req: 143, #queue-req: 301, 
[1,0]<stderr>:[2025-10-10 09:48:23 TP0] Prefill batch. #new-seq: 2, #new-token: 263, #cached-token: 4, token usage: 0.94, #running-req: 139, #queue-req: 299, 
[1,0]<stderr>:[2025-10-10 09:48:23 TP0] Prefill batch. #new-seq: 2, #new-token: 503, #cached-token: 2, token usage: 0.95, #running-req: 140, #queue-req: 297, 
[1,0]<stderr>:[2025-10-10 09:48:23 TP0] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 2, token usage: 0.94, #running-req: 140, #queue-req: 296, 
[1,0]<stderr>:[2025-10-10 09:48:24 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.95, #running-req: 139, #queue-req: 295, 
[1,0]<stderr>:[2025-10-10 09:48:25 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 7, token usage: 0.93, #running-req: 138, #queue-req: 293, 
[1,0]<stderr>:[2025-10-10 09:48:25 TP0] Prefill batch. #new-seq: 2, #new-token: 81, #cached-token: 2, token usage: 0.95, #running-req: 139, #queue-req: 292, 
[1,0]<stderr>:[2025-10-10 09:48:25 TP0] Decode batch. #running-req: 140, #token: 59709, token usage: 0.91, cuda graph: False, gen throughput (token/s): 963.16, #queue-req: 292, 
[1,0]<stderr>:[2025-10-10 09:48:25 TP0] Prefill batch. #new-seq: 7, #new-token: 1024, #cached-token: 16, token usage: 0.91, #running-req: 139, #queue-req: 285, 
[1,0]<stderr>:[2025-10-10 09:48:25 TP0] Prefill batch. #new-seq: 4, #new-token: 612, #cached-token: 5, token usage: 0.92, #running-req: 145, #queue-req: 282, 
[1,0]<stderr>:[2025-10-10 09:48:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 4, token usage: 0.92, #running-req: 141, #queue-req: 281, 
[1,0]<stderr>:[2025-10-10 09:48:27 TP0] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 0, token usage: 0.92, #running-req: 141, #queue-req: 281, 
[1,0]<stderr>:[2025-10-10 09:48:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.91, #running-req: 134, #queue-req: 280, 
[1,0]<stderr>:[2025-10-10 09:48:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.89, #running-req: 134, #queue-req: 280, 
[1,0]<stderr>:[2025-10-10 09:48:28 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 9, token usage: 0.90, #running-req: 134, #queue-req: 278, 
[1,0]<stderr>:[2025-10-10 09:48:28 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 3, token usage: 0.92, #running-req: 136, #queue-req: 276, 
[1,0]<stderr>:[2025-10-10 09:48:28 TP0] Prefill batch. #new-seq: 4, #new-token: 460, #cached-token: 7, token usage: 0.94, #running-req: 138, #queue-req: 273, 
[1,0]<stderr>:[2025-10-10 09:48:30 TP0] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 1, token usage: 0.94, #running-req: 138, #queue-req: 272, 
[1,0]<stderr>:[2025-10-10 09:48:30 TP0] Prefill batch. #new-seq: 2, #new-token: 12, #cached-token: 5, token usage: 0.95, #running-req: 135, #queue-req: 270, 
[1,0]<stderr>:[2025-10-10 09:48:31 TP0] Decode batch. #running-req: 135, #token: 59787, token usage: 0.91, cuda graph: False, gen throughput (token/s): 989.05, #queue-req: 270, 
[1,0]<stderr>:[2025-10-10 09:48:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.90, #running-req: 129, #queue-req: 269, 
[1,0]<stderr>:[2025-10-10 09:48:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 129, #queue-req: 269, 
[1,0]<stderr>:[2025-10-10 09:48:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.93, #running-req: 129, #queue-req: 269, 
[1,0]<stderr>:[2025-10-10 09:48:32 TP0] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 0, token usage: 0.95, #running-req: 129, #queue-req: 269, 
[1,0]<stderr>:[2025-10-10 09:48:34 TP0] Prefill batch. #new-seq: 5, #new-token: 145, #cached-token: 6, token usage: 0.94, #running-req: 124, #queue-req: 264, 
[1,0]<stderr>:[2025-10-10 09:48:35 TP0] Prefill batch. #new-seq: 7, #new-token: 932, #cached-token: 15, token usage: 0.93, #running-req: 128, #queue-req: 257, 
[1,0]<stderr>:[2025-10-10 09:48:36 TP0] Decode batch. #running-req: 132, #token: 61875, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1020.71, #queue-req: 257, 
[1,0]<stderr>:[2025-10-10 09:48:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.91, #running-req: 129, #queue-req: 256, 
[1,0]<stderr>:[2025-10-10 09:48:36 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 8, token usage: 0.93, #running-req: 129, #queue-req: 255, 
[1,0]<stderr>:[2025-10-10 09:48:37 TP0] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 0, token usage: 0.94, #running-req: 130, #queue-req: 255, 
[1,0]<stderr>:[2025-10-10 09:48:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 120, #queue-req: 254, 
[1,0]<stderr>:[2025-10-10 09:48:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 120, #queue-req: 254, 
[1,0]<stderr>:[2025-10-10 09:48:39 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 2, token usage: 0.94, #running-req: 120, #queue-req: 253, 
[1,0]<stderr>:[2025-10-10 09:48:40 TP0] Prefill batch. #new-seq: 4, #new-token: 321, #cached-token: 6, token usage: 0.95, #running-req: 121, #queue-req: 250, 
[1,0]<stderr>:[2025-10-10 09:48:40 TP0] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 1, token usage: 0.96, #running-req: 121, #queue-req: 249, 
[1,0]<stderr>:[2025-10-10 09:48:41 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 10, token usage: 0.93, #running-req: 118, #queue-req: 244, 
[1,0]<stderr>:[2025-10-10 09:48:41 TP0] Prefill batch. #new-seq: 5, #new-token: 821, #cached-token: 10, token usage: 0.94, #running-req: 122, #queue-req: 240, 
[1,0]<stderr>:[2025-10-10 09:48:41 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.96, #running-req: 126, #queue-req: 239, 
[1,0]<stderr>:[2025-10-10 09:48:41 TP0] Decode batch. #running-req: 126, #token: 62328, token usage: 0.95, cuda graph: False, gen throughput (token/s): 902.79, #queue-req: 239, 
[1,0]<stderr>:[2025-10-10 09:48:42 TP0] Prefill batch. #new-seq: 3, #new-token: 195, #cached-token: 4, token usage: 0.95, #running-req: 125, #queue-req: 236, 
[1,0]<stderr>:[2025-10-10 09:48:42 TP0] Prefill batch. #new-seq: 2, #new-token: 899, #cached-token: 6, token usage: 0.95, #running-req: 127, #queue-req: 234, 
[1,0]<stderr>:[2025-10-10 09:48:42 TP0] Prefill batch. #new-seq: 2, #new-token: 841, #cached-token: 2, token usage: 0.95, #running-req: 126, #queue-req: 232, 
[1,0]<stderr>:[2025-10-10 09:48:42 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 2, token usage: 0.95, #running-req: 126, #queue-req: 231, 
[1,0]<stderr>:[2025-10-10 09:48:43 TP0] Prefill batch. #new-seq: 2, #new-token: 351, #cached-token: 3, token usage: 0.95, #running-req: 123, #queue-req: 229, 
[1,0]<stderr>:[2025-10-10 09:48:43 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 9, token usage: 0.93, #running-req: 123, #queue-req: 225, 
[1,0]<stderr>:[2025-10-10 09:48:43 TP0] Prefill batch. #new-seq: 3, #new-token: 932, #cached-token: 2, token usage: 0.94, #running-req: 126, #queue-req: 223, 
[1,0]<stderr>:[2025-10-10 09:48:44 TP0] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 3, token usage: 0.95, #running-req: 127, #queue-req: 222, 
[1,0]<stderr>:[2025-10-10 09:48:45 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.93, #running-req: 124, #queue-req: 221, 
[1,0]<stderr>:[2025-10-10 09:48:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.89, #running-req: 120, #queue-req: 220, 
[1,0]<stderr>:[2025-10-10 09:48:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.90, #running-req: 120, #queue-req: 220, 
[1,0]<stderr>:[2025-10-10 09:48:45 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 4, token usage: 0.92, #running-req: 120, #queue-req: 218, 
[1,0]<stderr>:[2025-10-10 09:48:46 TP0] Prefill batch. #new-seq: 6, #new-token: 824, #cached-token: 12, token usage: 0.94, #running-req: 122, #queue-req: 213, 
[1,0]<stderr>:[2025-10-10 09:48:46 TP0] Prefill batch. #new-seq: 1, #new-token: 820, #cached-token: 2, token usage: 0.95, #running-req: 127, #queue-req: 212, 
[1,0]<stderr>:[2025-10-10 09:48:46 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.96, #running-req: 127, #queue-req: 211, 
[1,0]<stderr>:[2025-10-10 09:48:47 TP0] Prefill batch. #new-seq: 1, #new-token: 601, #cached-token: 1, token usage: 0.95, #running-req: 126, #queue-req: 210, 
[1,0]<stderr>:[2025-10-10 09:48:47 TP0] Prefill batch. #new-seq: 5, #new-token: 749, #cached-token: 22, token usage: 0.93, #running-req: 124, #queue-req: 205, 
[1,0]<stderr>:[2025-10-10 09:48:47 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 6, token usage: 0.93, #running-req: 127, #queue-req: 203, 
[1,0]<stderr>:[2025-10-10 09:48:47 TP0] Prefill batch. #new-seq: 7, #new-token: 728, #cached-token: 21, token usage: 0.93, #running-req: 128, #queue-req: 197, 
[1,0]<stderr>:[2025-10-10 09:48:47 TP0] Prefill batch. #new-seq: 2, #new-token: 134, #cached-token: 5, token usage: 0.94, #running-req: 133, #queue-req: 195, 
[1,0]<stderr>:[2025-10-10 09:48:48 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 6, token usage: 0.88, #running-req: 133, #queue-req: 193, 
[1,0]<stderr>:[2025-10-10 09:48:48 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 5, token usage: 0.90, #running-req: 134, #queue-req: 191, 
[1,0]<stderr>:[2025-10-10 09:48:48 TP0] Prefill batch. #new-seq: 6, #new-token: 1024, #cached-token: 13, token usage: 0.91, #running-req: 136, #queue-req: 186, 
[1,0]<stderr>:[2025-10-10 09:48:48 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 8, token usage: 0.93, #running-req: 141, #queue-req: 182, 
[1,0]<stderr>:[2025-10-10 09:48:48 TP0] Prefill batch. #new-seq: 3, #new-token: 934, #cached-token: 2, token usage: 0.94, #running-req: 145, #queue-req: 180, 
[1,0]<stderr>:[2025-10-10 09:48:49 TP0] Prefill batch. #new-seq: 2, #new-token: 496, #cached-token: 7, token usage: 0.95, #running-req: 145, #queue-req: 178, 
[1,0]<stderr>:[2025-10-10 09:48:49 TP0] Prefill batch. #new-seq: 2, #new-token: 44, #cached-token: 7, token usage: 0.95, #running-req: 144, #queue-req: 176, 
[1,0]<stderr>:[2025-10-10 09:48:49 TP0] Decode batch. #running-req: 144, #token: 62016, token usage: 0.95, cuda graph: False, gen throughput (token/s): 687.68, #queue-req: 176, 
[1,0]<stderr>:[2025-10-10 09:48:49 TP0] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.95, #running-req: 145, #queue-req: 175, 
[1,0]<stderr>:[2025-10-10 09:48:50 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 5, token usage: 0.93, #running-req: 141, #queue-req: 173, 
[1,0]<stderr>:[2025-10-10 09:48:50 TP0] Prefill batch. #new-seq: 2, #new-token: 1021, #cached-token: 1, token usage: 0.94, #running-req: 142, #queue-req: 172, 
[1,0]<stderr>:[2025-10-10 09:48:50 TP0] Prefill batch. #new-seq: 5, #new-token: 1024, #cached-token: 14, token usage: 0.93, #running-req: 140, #queue-req: 167, 
[1,0]<stderr>:[2025-10-10 09:48:50 TP0] Prefill batch. #new-seq: 3, #new-token: 393, #cached-token: 4, token usage: 0.95, #running-req: 144, #queue-req: 165, 
[1,0]<stderr>:[2025-10-10 09:48:51 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.95, #running-req: 143, #queue-req: 164, 
[1,0]<stderr>:[2025-10-10 09:48:51 TP0] Prefill batch. #new-seq: 2, #new-token: 610, #cached-token: 4, token usage: 0.95, #running-req: 143, #queue-req: 162, 
[1,0]<stderr>:[2025-10-10 09:48:51 TP0] Prefill batch. #new-seq: 2, #new-token: 13, #cached-token: 2, token usage: 0.95, #running-req: 143, #queue-req: 160, 
[1,0]<stderr>:[2025-10-10 09:48:52 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 11, token usage: 0.93, #running-req: 143, #queue-req: 156, 
[1,0]<stderr>:[2025-10-10 09:48:52 TP0] Prefill batch. #new-seq: 3, #new-token: 444, #cached-token: 6, token usage: 0.94, #running-req: 146, #queue-req: 154, 
[1,0]<stderr>:[2025-10-10 09:48:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 3, token usage: 0.94, #running-req: 146, #queue-req: 153, 
[1,0]<stderr>:[2025-10-10 09:48:52 TP0] Prefill batch. #new-seq: 2, #new-token: 710, #cached-token: 5, token usage: 0.95, #running-req: 146, #queue-req: 152, 
[1,0]<stderr>:[2025-10-10 09:48:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.90, #running-req: 137, #queue-req: 151, 
[1,0]<stderr>:[2025-10-10 09:48:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 137, #queue-req: 151, 
[1,0]<stderr>:[2025-10-10 09:48:54 TP0] Prefill batch. #new-seq: 2, #new-token: 721, #cached-token: 2, token usage: 0.93, #running-req: 137, #queue-req: 150, 
[1,0]<stderr>:[2025-10-10 09:48:54 TP0] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 4, token usage: 0.95, #running-req: 137, #queue-req: 149, 
[1,0]<stderr>:[2025-10-10 09:48:54 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 5, token usage: 0.93, #running-req: 137, #queue-req: 146, 
[1,0]<stderr>:[2025-10-10 09:48:54 TP0] Prefill batch. #new-seq: 4, #new-token: 703, #cached-token: 5, token usage: 0.94, #running-req: 139, #queue-req: 143, 
[1,0]<stderr>:[2025-10-10 09:48:55 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 4, token usage: 0.93, #running-req: 140, #queue-req: 141, 
[1,0]<stderr>:[2025-10-10 09:48:55 TP0] Prefill batch. #new-seq: 4, #new-token: 920, #cached-token: 11, token usage: 0.93, #running-req: 141, #queue-req: 138, 
[1,0]<stderr>:[2025-10-10 09:48:55 TP0] Prefill batch. #new-seq: 1, #new-token: 638, #cached-token: 2, token usage: 0.95, #running-req: 140, #queue-req: 137, 
[1,0]<stderr>:[2025-10-10 09:48:56 TP0] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 1, token usage: 0.95, #running-req: 139, #queue-req: 136, 
[1,0]<stderr>:[2025-10-10 09:48:56 TP0] Prefill batch. #new-seq: 2, #new-token: 25, #cached-token: 2, token usage: 0.95, #running-req: 138, #queue-req: 134, 
[1,0]<stderr>:[2025-10-10 09:48:56 TP0] Prefill batch. #new-seq: 1, #new-token: 602, #cached-token: 1, token usage: 0.94, #running-req: 139, #queue-req: 133, 
[1,0]<stderr>:[2025-10-10 09:48:56 TP0] Decode batch. #running-req: 139, #token: 62182, token usage: 0.95, cuda graph: False, gen throughput (token/s): 774.29, #queue-req: 133, 
[1,0]<stderr>:[2025-10-10 09:48:57 TP0] Prefill batch. #new-seq: 3, #new-token: 303, #cached-token: 5, token usage: 0.94, #running-req: 139, #queue-req: 130, 
[1,0]<stderr>:[2025-10-10 09:48:57 TP0] Prefill batch. #new-seq: 1, #new-token: 727, #cached-token: 2, token usage: 0.95, #running-req: 141, #queue-req: 129, 
[1,0]<stderr>:[2025-10-10 09:48:57 TP0] Prefill batch. #new-seq: 2, #new-token: 870, #cached-token: 8, token usage: 0.94, #running-req: 137, #queue-req: 127, 
[1,0]<stderr>:[2025-10-10 09:48:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 8, token usage: 0.93, #running-req: 134, #queue-req: 126, 
[1,0]<stderr>:[2025-10-10 09:48:58 TP0] Prefill batch. #new-seq: 4, #new-token: 410, #cached-token: 16, token usage: 0.94, #running-req: 134, #queue-req: 123, 
[1,0]<stderr>:[2025-10-10 09:48:58 TP0] Prefill batch. #new-seq: 2, #new-token: 792, #cached-token: 11, token usage: 0.94, #running-req: 137, #queue-req: 121, 
[1,0]<stderr>:[2025-10-10 09:48:59 TP0] Prefill batch. #new-seq: 2, #new-token: 593, #cached-token: 10, token usage: 0.94, #running-req: 137, #queue-req: 119, 
[1,0]<stderr>:[2025-10-10 09:48:59 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5, token usage: 0.95, #running-req: 138, #queue-req: 118, 
[1,0]<stderr>:[2025-10-10 09:48:59 TP0] Prefill batch. #new-seq: 2, #new-token: 874, #cached-token: 9, token usage: 0.94, #running-req: 138, #queue-req: 116, 
[1,0]<stderr>:[2025-10-10 09:49:00 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 8, token usage: 0.92, #running-req: 137, #queue-req: 114, 
[1,0]<stderr>:[2025-10-10 09:49:00 TP0] Prefill batch. #new-seq: 4, #new-token: 968, #cached-token: 12, token usage: 0.92, #running-req: 138, #queue-req: 111, 
[1,0]<stderr>:[2025-10-10 09:49:00 TP0] Prefill batch. #new-seq: 2, #new-token: 780, #cached-token: 8, token usage: 0.92, #running-req: 138, #queue-req: 109, 
[1,0]<stderr>:[2025-10-10 09:49:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 3, token usage: 0.93, #running-req: 139, #queue-req: 108, 
[1,0]<stderr>:[2025-10-10 09:49:01 TP0] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 0, token usage: 0.94, #running-req: 139, #queue-req: 108, 
[1,0]<stderr>:[2025-10-10 09:49:01 TP0] Prefill batch. #new-seq: 4, #new-token: 83, #cached-token: 13, token usage: 0.94, #running-req: 138, #queue-req: 104, 
[1,0]<stderr>:[2025-10-10 09:49:01 TP0] Prefill batch. #new-seq: 2, #new-token: 556, #cached-token: 6, token usage: 0.94, #running-req: 141, #queue-req: 102, 
[1,0]<stderr>:[2025-10-10 09:49:02 TP0] Prefill batch. #new-seq: 4, #new-token: 112, #cached-token: 12, token usage: 0.93, #running-req: 140, #queue-req: 98, 
[1,0]<stderr>:[2025-10-10 09:49:02 TP0] Prefill batch. #new-seq: 3, #new-token: 1024, #cached-token: 9, token usage: 0.93, #running-req: 143, #queue-req: 95, 
[1,0]<stderr>:[2025-10-10 09:49:02 TP0] Prefill batch. #new-seq: 6, #new-token: 337, #cached-token: 15, token usage: 0.93, #running-req: 145, #queue-req: 90, 
[1,0]<stderr>:[2025-10-10 09:49:02 TP0] Prefill batch. #new-seq: 5, #new-token: 57, #cached-token: 15, token usage: 0.94, #running-req: 149, #queue-req: 85, 
[1,0]<stderr>:[2025-10-10 09:49:02 TP0] Prefill batch. #new-seq: 2, #new-token: 466, #cached-token: 5, token usage: 0.92, #running-req: 152, #queue-req: 83, 
[1,0]<stderr>:[2025-10-10 09:49:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.89, #running-req: 151, #queue-req: 82, 
[1,0]<stderr>:[2025-10-10 09:49:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.91, #running-req: 151, #queue-req: 82, 
[1,0]<stderr>:[2025-10-10 09:49:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 151, #queue-req: 82, 
[1,0]<stderr>:[2025-10-10 09:49:04 TP0] Prefill batch. #new-seq: 3, #new-token: 89, #cached-token: 4, token usage: 0.94, #running-req: 151, #queue-req: 80, 
[1,0]<stderr>:[2025-10-10 09:49:04 TP0] Decode batch. #running-req: 154, #token: 61515, token usage: 0.94, cuda graph: False, gen throughput (token/s): 736.83, #queue-req: 80, 
[1,0]<stderr>:[2025-10-10 09:49:04 TP0] Prefill batch. #new-seq: 4, #new-token: 404, #cached-token: 8, token usage: 0.94, #running-req: 153, #queue-req: 76, 
[1,0]<stderr>:[2025-10-10 09:49:04 TP0] Prefill batch. #new-seq: 2, #new-token: 287, #cached-token: 4, token usage: 0.95, #running-req: 155, #queue-req: 74, 
[1,0]<stderr>:[2025-10-10 09:49:05 TP0] Prefill batch. #new-seq: 1, #new-token: 866, #cached-token: 3, token usage: 0.94, #running-req: 153, #queue-req: 73, 
[1,0]<stderr>:[2025-10-10 09:49:06 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.95, #running-req: 152, #queue-req: 72, 
[1,0]<stderr>:[2025-10-10 09:49:06 TP0] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 2, token usage: 0.94, #running-req: 152, #queue-req: 71, 
[1,0]<stderr>:[2025-10-10 09:49:09 TP0] Decode batch. #running-req: 138, #token: 60951, token usage: 0.93, cuda graph: False, gen throughput (token/s): 1101.78, #queue-req: 71, 
[1,0]<stderr>:[2025-10-10 09:49:14 TP0] Decode batch. #running-req: 119, #token: 61362, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1121.96, #queue-req: 71, 
[1,0]<stderr>:[2025-10-10 09:49:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.93, #running-req: 115, #queue-req: 70, 
[1,0]<stderr>:[2025-10-10 09:49:16 TP0] Prefill batch. #new-seq: 1, #new-token: 536, #cached-token: 0, token usage: 0.95, #running-req: 115, #queue-req: 70, 
[1,0]<stderr>:[2025-10-10 09:49:16 TP0] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 2, token usage: 0.96, #running-req: 115, #queue-req: 69, 
[1,0]<stderr>:[2025-10-10 09:49:16 TP0] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 4, token usage: 0.96, #running-req: 115, #queue-req: 67, 
[1,0]<stderr>:[2025-10-10 09:49:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.94, #running-req: 112, #queue-req: 66, 
[1,0]<stderr>:[2025-10-10 09:49:18 TP0] Prefill batch. #new-seq: 2, #new-token: 305, #cached-token: 2, token usage: 0.95, #running-req: 112, #queue-req: 65, 
[1,0]<stderr>:[2025-10-10 09:49:19 TP0] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 1, token usage: 0.96, #running-req: 112, #queue-req: 64, 
[1,0]<stderr>:[2025-10-10 09:49:19 TP0] Decode batch. #running-req: 113, #token: 63322, token usage: 0.97, cuda graph: False, gen throughput (token/s): 843.66, #queue-req: 64, 
[1,0]<stderr>:[2025-10-10 09:49:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 2, token usage: 0.94, #running-req: 110, #queue-req: 63, 
[1,0]<stderr>:[2025-10-10 09:49:20 TP0] Prefill batch. #new-seq: 2, #new-token: 355, #cached-token: 1, token usage: 0.95, #running-req: 110, #queue-req: 62, 
[1,0]<stderr>:[2025-10-10 09:49:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.91, #running-req: 96, #queue-req: 61, 
[1,0]<stderr>:[2025-10-10 09:49:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.91, #running-req: 96, #queue-req: 61, 
[1,0]<stderr>:[2025-10-10 09:49:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 96, #queue-req: 61, 
[1,0]<stderr>:[2025-10-10 09:49:22 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.94, #running-req: 96, #queue-req: 60, 
[1,0]<stderr>:[2025-10-10 09:49:22 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 1, token usage: 0.95, #running-req: 97, #queue-req: 59, 
[1,0]<stderr>:[2025-10-10 09:49:22 TP0] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 0, token usage: 0.97, #running-req: 98, #queue-req: 59, 
[1,0]<stderr>:[2025-10-10 09:49:23 TP0] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 1, token usage: 0.96, #running-req: 96, #queue-req: 58, 
[1,0]<stderr>:[2025-10-10 09:49:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.95, #running-req: 93, #queue-req: 57, 
[1,0]<stderr>:[2025-10-10 09:49:23 TP0] Prefill batch. #new-seq: 3, #new-token: 773, #cached-token: 2, token usage: 0.95, #running-req: 93, #queue-req: 55, 
[1,0]<stderr>:[2025-10-10 09:49:24 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 1, token usage: 0.96, #running-req: 94, #queue-req: 54, 
[1,0]<stderr>:[2025-10-10 09:49:24 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.91, #running-req: 94, #queue-req: 50, 
[1,0]<stderr>:[2025-10-10 09:49:24 TP0] Prefill batch. #new-seq: 2, #new-token: 510, #cached-token: 1, token usage: 0.93, #running-req: 97, #queue-req: 49, 
[1,0]<stderr>:[2025-10-10 09:49:25 TP0] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 4, token usage: 0.94, #running-req: 98, #queue-req: 48, 
[1,0]<stderr>:[2025-10-10 09:49:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.90, #running-req: 96, #queue-req: 47, 
[1,0]<stderr>:[2025-10-10 09:49:26 TP0] Decode batch. #running-req: 96, #token: 60318, token usage: 0.92, cuda graph: False, gen throughput (token/s): 639.85, #queue-req: 47, 
[1,0]<stderr>:[2025-10-10 09:49:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.92, #running-req: 96, #queue-req: 47, 
[1,0]<stderr>:[2025-10-10 09:49:26 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 3, token usage: 0.94, #running-req: 96, #queue-req: 44, 
[1,0]<stderr>:[2025-10-10 09:49:26 TP0] Prefill batch. #new-seq: 2, #new-token: 846, #cached-token: 2, token usage: 0.95, #running-req: 99, #queue-req: 43, 
[1,0]<stderr>:[2025-10-10 09:49:26 TP0] Prefill batch. #new-seq: 1, #new-token: 452, #cached-token: 2, token usage: 0.96, #running-req: 97, #queue-req: 42, 
[1,0]<stderr>:[2025-10-10 09:49:27 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 8, token usage: 0.90, #running-req: 96, #queue-req: 38, 
[1,0]<stderr>:[2025-10-10 09:49:27 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.92, #running-req: 99, #queue-req: 35, 
[1,0]<stderr>:[2025-10-10 09:49:27 TP0] Prefill batch. #new-seq: 6, #new-token: 531, #cached-token: 5, token usage: 0.93, #running-req: 102, #queue-req: 30, 
[1,0]<stderr>:[2025-10-10 09:49:27 TP0] Prefill batch. #new-seq: 4, #new-token: 1024, #cached-token: 4, token usage: 0.94, #running-req: 106, #queue-req: 26, 
[1,0]<stderr>:[2025-10-10 09:49:27 TP0] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 0, token usage: 0.94, #running-req: 109, #queue-req: 26, 
[1,0]<stderr>:[2025-10-10 09:49:28 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.94, #running-req: 109, #queue-req: 25, 
[1,0]<stderr>:[2025-10-10 09:49:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.92, #running-req: 102, #queue-req: 24, 
[1,0]<stderr>:[2025-10-10 09:49:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.94, #running-req: 102, #queue-req: 24, 
[1,0]<stderr>:[2025-10-10 09:49:30 TP0] Prefill batch. #new-seq: 2, #new-token: 424, #cached-token: 1, token usage: 0.95, #running-req: 102, #queue-req: 23, 
[1,0]<stderr>:[2025-10-10 09:49:30 TP0] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 1, token usage: 0.96, #running-req: 101, #queue-req: 22, 
[1,0]<stderr>:[2025-10-10 09:49:30 TP0] Prefill batch. #new-seq: 4, #new-token: 147, #cached-token: 4, token usage: 0.96, #running-req: 101, #queue-req: 18, 
[1,0]<stderr>:[2025-10-10 09:49:31 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 1, token usage: 0.95, #running-req: 103, #queue-req: 17, 
[1,0]<stderr>:[2025-10-10 09:49:31 TP0] Prefill batch. #new-seq: 2, #new-token: 755, #cached-token: 4, token usage: 0.94, #running-req: 103, #queue-req: 15, 
[1,0]<stderr>:[2025-10-10 09:49:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 1, token usage: 0.94, #running-req: 101, #queue-req: 14, 
[1,0]<stderr>:[2025-10-10 09:49:31 TP0] Prefill batch. #new-seq: 2, #new-token: 887, #cached-token: 1, token usage: 0.95, #running-req: 101, #queue-req: 13, 
[1,0]<stderr>:[2025-10-10 09:49:32 TP0] Prefill batch. #new-seq: 4, #new-token: 35, #cached-token: 4, token usage: 0.94, #running-req: 98, #queue-req: 9, 
[1,0]<stderr>:[2025-10-10 09:49:32 TP0] Decode batch. #running-req: 98, #token: 60811, token usage: 0.93, cuda graph: False, gen throughput (token/s): 599.66, #queue-req: 9, 
[1,0]<stderr>:[2025-10-10 09:49:33 TP0] Prefill batch. #new-seq: 5, #new-token: 866, #cached-token: 5, token usage: 0.93, #running-req: 100, #queue-req: 4, 
[1,0]<stderr>:[2025-10-10 09:49:33 TP0] Prefill batch. #new-seq: 4, #new-token: 866, #cached-token: 4, token usage: 0.93, #running-req: 104, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:49:37 TP0] Decode batch. #running-req: 86, #token: 53230, token usage: 0.81, cuda graph: False, gen throughput (token/s): 808.31, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:49:42 TP0] Decode batch. #running-req: 75, #token: 50830, token usage: 0.78, cuda graph: False, gen throughput (token/s): 702.21, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:49:46 TP0] Decode batch. #running-req: 63, #token: 44577, token usage: 0.68, cuda graph: False, gen throughput (token/s): 602.68, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:49:51 TP0] Decode batch. #running-req: 55, #token: 40463, token usage: 0.62, cuda graph: False, gen throughput (token/s): 524.93, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:49:55 TP0] Decode batch. #running-req: 46, #token: 37865, token usage: 0.58, cuda graph: False, gen throughput (token/s): 441.31, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:00 TP0] Decode batch. #running-req: 34, #token: 25195, token usage: 0.38, cuda graph: False, gen throughput (token/s): 351.23, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:05 TP0] Decode batch. #running-req: 32, #token: 25274, token usage: 0.39, cuda graph: False, gen throughput (token/s): 287.56, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:09 TP0] Decode batch. #running-req: 29, #token: 25046, token usage: 0.38, cuda graph: False, gen throughput (token/s): 243.62, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:14 TP0] Decode batch. #running-req: 27, #token: 23303, token usage: 0.36, cuda graph: False, gen throughput (token/s): 233.98, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:19 TP0] Decode batch. #running-req: 24, #token: 23222, token usage: 0.35, cuda graph: False, gen throughput (token/s): 215.35, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:23 TP0] Decode batch. #running-req: 19, #token: 19642, token usage: 0.30, cuda graph: False, gen throughput (token/s): 184.04, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:28 TP0] Decode batch. #running-req: 17, #token: 16447, token usage: 0.25, cuda graph: False, gen throughput (token/s): 161.34, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:32 TP0] Decode batch. #running-req: 12, #token: 10737, token usage: 0.16, cuda graph: False, gen throughput (token/s): 134.61, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:37 TP0] Decode batch. #running-req: 9, #token: 6765, token usage: 0.10, cuda graph: False, gen throughput (token/s): 102.76, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:41 TP0] Decode batch. #running-req: 8, #token: 7084, token usage: 0.11, cuda graph: False, gen throughput (token/s): 71.18, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:46 TP0] Decode batch. #running-req: 6, #token: 5998, token usage: 0.09, cuda graph: False, gen throughput (token/s): 64.89, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:50 TP0] Decode batch. #running-req: 6, #token: 6238, token usage: 0.10, cuda graph: False, gen throughput (token/s): 54.20, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:50:55 TP0] Decode batch. #running-req: 4, #token: 3357, token usage: 0.05, cuda graph: False, gen throughput (token/s): 43.57, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 09:51:02 TP0] Decode batch. #running-req: 1, #token: 1000, token usage: 0.02, cuda graph: False, gen throughput (token/s): 11.46, #queue-req: 0, 
[1,0]<stdout>:
[1,0]<stdout>:====== Offline Throughput Benchmark Result =======
[1,0]<stdout>:Backend:                                 engine    
[1,0]<stdout>:Successful requests:                     2000      
[1,0]<stdout>:Benchmark duration (s):                  545.82    
[1,0]<stdout>:Total input tokens:                      626729    
[1,0]<stdout>:Total generated tokens:                  388685    
[1,0]<stdout>:Last generation throughput (tok/s):      11.46     
[1,0]<stdout>:Request throughput (req/s):              3.66      
[1,0]<stdout>:Input token throughput (tok/s):          1148.24   
[1,0]<stdout>:Output token throughput (tok/s):         712.12    
[1,0]<stdout>:Total token throughput (tok/s):          1860.36   
[1,0]<stdout>:==================================================
[1,1]<stderr>:[rank14]:[W1010 09:51:04.978874759 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:57268, remote=[a2ap-dgx008.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank9]:[W1010 09:51:04.978869962 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:57256, remote=[a2ap-dgx008.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank9]:[W1010 09:51:04.986290898 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 9] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stderr>:[rank14]:[W1010 09:51:04.986302596 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 14] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stderr>:[2025-10-10 09:51:04 TP8] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:535] Read error [10.104.4.82]:54180: Connection reset by peer
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:51:04] Received sigquit from a child process. It usually means the child failed.
[1,1]<stderr>:[2025-10-10 09:51:04 TP10] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.82]:9636
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:51:04 TP11] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.82]:21396
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:51:04] Received sigquit from a child process. It usually means the child failed.
[1,1]<stderr>:[2025-10-10 09:51:04 TP9] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:535] Read error [10.104.4.82]:4521: Connection reset by peer
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:51:04 TP12] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.82]:60803
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:51:04 TP14] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    [1,1]<stderr>:recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.82]:58766
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:51:04 TP15] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.82]:4529
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:51:04 TP13] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.82]:39345
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 09:51:04] Received sigquit from a child process. It usually means the child failed.
[1,1]<stderr>:bash: line 4: 3173005 Killed                  '/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/bin/python3' -m sglang.bench_offline_throughput --model-path '/home/users/industry/ai-hpc/apacsc34/scratch/model/DeepSeek-R1' --dataset-path '/home/users/industry/ai-hpc/apacsc34/scratch/ShareGPT_V3_unfiltered_cleaned_split.json' --num-prompts 2000 --load-format dummy --seed 2025 --dtype bfloat16 --tp 16 --nnodes 2 --trust-remote-code --dist-init-addr ${DIST_INIT_ADDR}:5000 --node-rank ${OMPI_COMM_WORLD_RANK} --max-running-requests 512 --max-total-tokens 65536 --chunked-prefill-size 1024 --max-prefill-tokens 4096 --schedule-policy lpm --attention-backend flashinfer --disable-cuda-graph
[1,1]<stderr>:
[1,1]<stderr>:real	10m46.851s
[1,1]<stderr>:user	0m23.664s
[1,1]<stderr>:sys	0m8.238s
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[26211,1],1]
  Exit code:    137
--------------------------------------------------------------------------

real	10m51.608s
user	0m0.056s
sys	0m0.147s
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-10 09:51:23.920162:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 96728.pbs111
	Project: 50000128
	Exit Status: 137
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 02:27:58
	Memory: Requested(3760gb), Used(25689284kb)
	Vmem Used: 21419370652kb
	Walltime: Requested(00:40:00), Used(00:11:03)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx008:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx014:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 11.29mins
	GPU Power Consumed: 401.62W
	GPU Max GPU Memory Used: 786.78GB
	Memory Throughput Rate (Average): a2ap-dgx008:(gpu1:3%+gpu0:3%+gpu2:3%+gpu3:3%+gpu5:3%+gpu4:3%+gpu6:3%+gpu7:3%)+a2ap-dgx014:(gpu1:3%+gpu0:3%+gpu2:3%+gpu3:3%+gpu5:3%+gpu4:3%+gpu6:3%+gpu7:3%)
	Memory Throughput Rate (Max): a2ap-dgx008:(gpu1:13%+gpu0:13%+gpu2:10%+gpu3:12%+gpu5:9%+gpu4:12%+gpu6:12%+gpu7:12%)+a2ap-dgx014:(gpu1:28%+gpu0:11%+gpu2:12%+gpu3:11%+gpu5:8%+gpu4:11%+gpu6:11%+gpu7:8%)
	Memory Throughput Rate (Min): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx014:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx008:(gpu1:68%+gpu0:82%+gpu2:83%+gpu3:63%+gpu5:79%+gpu4:81%+gpu6:82%+gpu7:70%)+a2ap-dgx014:(gpu1:78%+gpu0:84%+gpu2:85%+gpu3:68%+gpu5:82%+gpu4:84%+gpu6:83%+gpu7:71%)
	GPU SM Utilization (Max): a2ap-dgx008:(gpu1:100%+gpu0:100%+gpu2:100%+gpu3:100%+gpu5:100%+gpu4:100%+gpu6:100%+gpu7:100%)+a2ap-dgx014:(gpu1:100%+gpu0:100%+gpu2:100%+gpu3:100%+gpu5:100%+gpu4:100%+gpu6:100%+gpu7:100%)
	GPU SM Utilization (Min): a2ap-dgx008:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx014:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: None
GPU application profile: High
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

