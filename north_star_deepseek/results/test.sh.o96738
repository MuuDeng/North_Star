========== 2-NODE TP16 FAST ==========
Prepaid SU: 682.666 | 720s SU: 409.600 | Balance: 48630.259
N/A
Job ID: 96738.pbs111 | GPUs: 16 | Master: a2ap-dgx021.asp2p.nscc.sg:5000
============================================
[10:15:16] Launching fast 2-node TP16 benchmark...
Warning: Permanently added 'a2ap-dgx023' (ED25519) to the list of known hosts.
 Data for JOB [31332,1] offset 0 Total slots allocated 4

 ========================   JOB MAP   ========================

 Data for node: a2ap-dgx021	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [31332,1] App: 0 Process rank: 0 Bound: N/A

 Data for node: a2ap-dgx023	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [31332,1] App: 0 Process rank: 1 Bound: N/A

 =============================================================
 Data for JOB [31332,1] offset 0 Total slots allocated 4

 ========================   JOB MAP   ========================

 Data for node: a2ap-dgx021	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [31332,1] App: 0 Process rank: 0 Bound: N/A

 Data for node: a2ap-dgx023	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [31332,1] App: 0 Process rank: 1 Bound: N/A

 =============================================================
[1,0]<stderr>:W1010 10:15:47.014000 3024233 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:15:47.014000 3024233 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 10:15:48.040000 2024219 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 10:15:48.040000 2024219 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:[2025-10-10 10:15:50] Using default HuggingFace chat template with detected content format: string
[1,0]<stderr>:W1010 10:16:10.185000 3025245 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:16:10.185000 3025245 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 10:16:10.327000 2025248 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 10:16:10.327000 2025248 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 10:16:10.641000 3025244 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:16:10.641000 3025244 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 10:16:11.139000 3025248 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:16:11.139000 3025248 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 10:16:11.193000 3025250 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:16:11.193000 3025250 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 10:16:11.227000 3025252 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:16:11.227000 3025252 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 10:16:11.234000 3025251 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:16:11.234000 3025251 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 10:16:11.280000 2025253 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 10:16:11.280000 2025253 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 10:16:11.317000 3025249 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:16:11.317000 3025249 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 10:16:11.338000 3025246 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:16:11.338000 3025246 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 10:16:11.403000 3025247 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 10:16:11.403000 3025247 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 10:16:11.918000 2025250 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 10:16:11.918000 2025250 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 10:16:12.090000 2025252 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 10:16:12.090000 2025252 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 10:16:12.111000 2025254 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 10:16:12.111000 2025254 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 10:16:12.126000 2025247 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 10:16:12.126000 2025247 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 10:16:12.127000 2025249 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 10:16:12.127000 2025249 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 10:16:12.246000 2025251 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 10:16:12.246000 2025251 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:[2025-10-10 10:16:12 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[1,0]<stderr>:[2025-10-10 10:16:12 TP0] Chunked prefix cache is turned on.
[1,0]<stderr>:[2025-10-10 10:16:12 TP0] Init torch distributed begin.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 10:16:15 TP0] sglang is using nccl==2.27.3
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:NCCL version 2.27.3+cuda12.9
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025244:3025244 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025244:3025244 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025245:3025245 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025245:3025245 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025246:3025246 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025246:3025246 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025249:3025249 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025249:3025249 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025247:3025247 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025247:3025247 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025250:3025250 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025250:3025250 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025248:3025248 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025248:3025248 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025251:3025251 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 10:16:21] a2ap-dgx021:3025251:3025251 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025254:2025254 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025254:2025254 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025252:2025252 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025249:2025249 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025252:2025252 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025249:2025249 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025248:2025248 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025248:2025248 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025253:2025253 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025253:2025253 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025250:2025250 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025250:2025250 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025251:2025251 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025251:2025251 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025247:2025247 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 10:16:22] a2ap-dgx023:2025247:2025247 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stderr>:[2025-10-10 10:16:24 TP0] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 10:16:24 TP1] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 10:16:24 TP2] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 10:16:24 TP3] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 10:16:24 TP5] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 10:16:24 TP4] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 10:16:24 TP14] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 10:16:24 TP15] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 10:16:24 TP13] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 10:16:24 TP12] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 10:16:24 TP11] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 10:16:24 TP10] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 10:16:24 TP6] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 10:16:24 TP9] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 10:16:24 TP7] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 10:16:24 TP8] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 10:16:24 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 10:16:26 TP0] Init torch distributed ends. mem usage=1.75 GB
[1,1]<stderr>:[2025-10-10 10:16:27 TP8] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 10:16:27 TP9] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 10:16:27 TP12] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 10:16:27 TP14] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 10:16:27 TP11] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 10:16:27 TP13] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 10:16:27 TP1] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 10:16:27 TP6] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 10:16:27 TP4] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 10:16:27 TP3] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 10:16:27 TP5] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 10:16:27 TP7] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 10:16:27 TP2] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 10:16:27 TP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 10:16:27 TP15] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 10:16:27 TP10] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 10:16:28 TP0] Load weight begin. avail mem=76.80 GB
[1,0]<stderr>:[2025-10-10 10:16:28 TP0] Detected fp8 checkpoint.
[1,0]<stderr>:[2025-10-10 10:16:29 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=36.24 GB, mem usage=40.55 GB.
[1,1]<stderr>:[2025-10-10 10:16:29 TP15] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 10:16:29 TP8] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 10:16:29 TP10] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 10:16:29 TP11] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 10:16:29 TP14] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 10:16:29 TP9] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 10:16:29 TP3] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 10:16:29 TP5] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 10:16:29 TP1] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 10:16:29 TP6] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 10:16:29 TP7] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 10:16:29 TP2] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 10:16:29 TP0] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 10:16:29 TP0] Memory pool end. avail mem=31.52 GB
[1,0]<stderr>:[2025-10-10 10:16:29 TP4] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 10:16:29 TP12] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 10:16:29 TP13] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 10:16:30 TP0] max_total_num_tokens=65536, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=512, context_len=163840, available_gpu_mem=31.43 GB
[1,1]<stderr>:[2025-10-10 10:16:30] Starting dummy health check server at 127.0.0.1:30000
[1,0]<stdout>:#Input tokens: 626729
[1,0]<stdout>:#Output tokens: 388685
[1,0]<stdout>:#Input tokens: 4096
[1,0]<stdout>:#Output tokens: 256
[1,0]<stderr>:[2025-10-10 10:16:44] 
[1,0]<stderr>:Warmup...
[1,0]<stderr>:[2025-10-10 10:16:44 TP0] Prefill batch. #new-seq: 16, #new-token: 4112, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,1]<stderr>:[2025-10-10 10:16:48 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:48 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:48 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:48 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:48 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:48 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:48 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:48 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 10:16:48 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:48 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:48 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:48 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 10:16:48 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:48 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:48 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:48 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:48 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 1916.48it/s][1,0]<stderr>:
[1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 3023.81it/s]100%|██████████| 33/33 [00:00<00:00, 1925.12it/s]
[1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 1749.15it/s]
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 1671.50it/s][1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 2083.70it/s]
[1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 3893.56it/s]
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4771.18it/s]
[1,0]<stderr>:[2025-10-10 10:16:49 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5219.75it/s]
[1,1]<stderr>:[2025-10-10 10:16:49 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:49 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:49 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:49 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:49 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:49 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:49 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 10:16:49 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:49 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5322.11it/s]
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4590.78it/s]
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4410.70it/s][1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4687.17it/s][1,0]<stderr>:
[1,0]<stderr>:[2025-10-10 10:16:49 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:49 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4212.30it/s][1,0]<stderr>:
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4732.20it/s]
[1,0]<stderr>:[2025-10-10 10:16:49 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:49 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:49 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 10:16:49 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5162.70it/s][1,0]<stderr>:
[1,0]<stderr>:[2025-10-10 10:16:49 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 5992.25it/s]
[1,0]<stderr>:[2025-10-10 10:16:50 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 13122.11it/s]
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 6350.41it/s]100%|██████████| 44/44 [00:00<00:00, 11005.39it/s]
[1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 7840.82it/s][1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12312.32it/s]
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 10:16:50 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 10906.53it/s][1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 13076.55it/s]
[1,1]<stderr>:[2025-10-10 10:16:50 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 10:16:50 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12791.06it/s]
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12131.83it/s]
[1,0]<stderr>:[2025-10-10 10:16:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 10:16:50 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12398.35it/s]
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 11403.20it/s]  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 10:16:50 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 11889.54it/s]
[1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12455.25it/s]
[1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 11164.51it/s]
[1,0]<stderr>:[2025-10-10 10:16:50 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:50 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:50 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:50 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12985.46it/s]
[1,0]<stderr>:[2025-10-10 10:16:50 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 5235.03it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 5287.26it/s]
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 6595.41it/s]
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 7276.36it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 10820.42it/s]
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11071.77it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11445.55it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11815.89it/s]
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 12816.54it/s]
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 10:16:50 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 10637.73it/s]
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 10957.72it/s]
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11911.77it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 10:16:50 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11879.00it/s]
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 10:16:50 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 10:16:50 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11782.70it/s]
[1,0]<stderr>:[2025-10-10 10:16:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 10:16:50 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11687.95it/s]
[1,0]<stderr>:[2025-10-10 10:16:50 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:50 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:50 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:50 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:50 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:50 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 14407.76it/s]
[1,0]<stderr>:[2025-10-10 10:16:50 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 3819.51it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6970.18it/s][1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 5538.41it/s][1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 15880.00it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13228.63it/s]
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 15584.97it/s]
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 12039.62it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14758.93it/s]
[1,1]<stderr>:[2025-10-10 10:16:51 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:51 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13940.35it/s][1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 10:16:51 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 10:16:51 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 17011.12it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 10:16:51 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13386.97it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13791.38it/s][1,0]<stderr>:
[1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13347.03it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:51 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13908.57it/s]
[1,1]<stderr>:[2025-10-10 10:16:51 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 16233.40it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13606.83it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 5932.80it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 14227.02it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 6619.86it/s]
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13875.50it/s]
[1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 12798.49it/s][1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13108.48it/s]
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 12146.40it/s]
[1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13094.41it/s]
[1,1]<stderr>:[2025-10-10 10:16:51 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 10:16:51 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13842.59it/s][1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 10:16:51 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 10:16:51 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 11473.56it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13376.29it/s]
[1,0]<stderr>:[2025-10-10 10:16:51 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 10:16:51 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13427.14it/s]
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13741.96it/s]
[1,0]<stderr>:[2025-10-10 10:16:52 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 10:16:52 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 14530.45it/s]
[1,1]<stderr>:[2025-10-10 10:16:52 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 14466.23it/s]
[1,0]<stderr>:[2025-10-10 10:16:52 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 14673.42it/s]
[1,0]<stderr>:[2025-10-10 10:16:52 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 5828.96it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6109.69it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 17833.87it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13788.55it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 11015.90it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 18340.77it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 16508.95it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13584.79it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 11574.48it/s][1,1]<stderr>:
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14475.60it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 12645.35it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13617.87it/s]
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 12635.82it/s][1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:
[1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14503.75it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 15842.51it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13740.55it/s]
[1,1]<stderr>:[2025-10-10 10:16:52 TP8] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 10:16:52 TP13] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 10:16:52 TP12] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 10:16:52 TP4] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 10:16:52 TP1] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 10:16:52 TP7] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 10:16:52 TP6] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 10:16:52 TP14] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 10:16:52 TP11] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 10:16:52 TP9] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 10:16:52 TP0] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 10:16:52 TP10] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 10:16:52 TP15] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 10:16:52 TP2] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 10:16:52 TP5] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 10:16:52 TP3] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 10:16:57] 
[1,0]<stderr>:Benchmark...
[1,0]<stderr>:[2025-10-10 10:16:57 TP0] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 10:16:57 TP0] Prefill batch. #new-seq: 3, #new-token: 241, #cached-token: 3, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 10:16:57 TP0] Prefill batch. #new-seq: 27, #new-token: 8192, #cached-token: 32, token usage: 0.01, #running-req: 4, #queue-req: 667, 
[1,0]<stderr>:[2025-10-10 10:16:58 TP0] Prefill batch. #new-seq: 23, #new-token: 8192, #cached-token: 28, token usage: 0.14, #running-req: 30, #queue-req: 1086, 
[1,0]<stderr>:[2025-10-10 10:16:58 TP0] Prefill batch. #new-seq: 30, #new-token: 8192, #cached-token: 50, token usage: 0.26, #running-req: 52, #queue-req: 1247, 
[1,0]<stderr>:[2025-10-10 10:16:58 TP0] Prefill batch. #new-seq: 31, #new-token: 8192, #cached-token: 63, token usage: 0.39, #running-req: 81, #queue-req: 1446, 
[1,0]<stderr>:[2025-10-10 10:16:58 TP0] Prefill batch. #new-seq: 25, #new-token: 8192, #cached-token: 59, token usage: 0.51, #running-req: 111, #queue-req: 1780, 
[1,0]<stderr>:[2025-10-10 10:16:59 TP0] Prefill batch. #new-seq: 8, #new-token: 2350, #cached-token: 16, token usage: 0.64, #running-req: 135, #queue-req: 1857, 
[1,0]<stderr>:[2025-10-10 10:17:00 TP0] Prefill batch. #new-seq: 14, #new-token: 3874, #cached-token: 29, token usage: 0.57, #running-req: 138, #queue-req: 1843, 
[1,0]<stderr>:[2025-10-10 10:17:00 TP0] Prefill batch. #new-seq: 3, #new-token: 1925, #cached-token: 7, token usage: 0.62, #running-req: 151, #queue-req: 1840, 
[1,0]<stderr>:[2025-10-10 10:17:00 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.64, #running-req: 153, #queue-req: 1839, 
[1,0]<stderr>:[2025-10-10 10:17:01 TP0] Prefill batch. #new-seq: 3, #new-token: 363, #cached-token: 7, token usage: 0.63, #running-req: 151, #queue-req: 1836, 
[1,0]<stderr>:[2025-10-10 10:17:02 TP0] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 1, token usage: 0.62, #running-req: 152, #queue-req: 1835, 
[1,0]<stderr>:[2025-10-10 10:17:02 TP0] Prefill batch. #new-seq: 4, #new-token: 1070, #cached-token: 8, token usage: 0.61, #running-req: 152, #queue-req: 1831, 
[1,0]<stderr>:[2025-10-10 10:17:02 TP0] Prefill batch. #new-seq: 4, #new-token: 729, #cached-token: 11, token usage: 0.62, #running-req: 151, #queue-req: 1827, 
[1,0]<stderr>:[2025-10-10 10:17:03 TP0] Prefill batch. #new-seq: 3, #new-token: 1148, #cached-token: 13, token usage: 0.60, #running-req: 150, #queue-req: 1824, 
[1,0]<stderr>:[2025-10-10 10:17:03 TP0] Prefill batch. #new-seq: 2, #new-token: 1116, #cached-token: 3, token usage: 0.61, #running-req: 149, #queue-req: 1822, 
[1,0]<stderr>:[2025-10-10 10:17:03 TP0] Prefill batch. #new-seq: 2, #new-token: 939, #cached-token: 6, token usage: 0.61, #running-req: 149, #queue-req: 1820, 
[1,0]<stderr>:[2025-10-10 10:17:04 TP0] Prefill batch. #new-seq: 7, #new-token: 2966, #cached-token: 11, token usage: 0.58, #running-req: 149, #queue-req: 1813, 
[1,0]<stderr>:[2025-10-10 10:17:04 TP0] Prefill batch. #new-seq: 6, #new-token: 1482, #cached-token: 12, token usage: 0.60, #running-req: 150, #queue-req: 1807, 
[1,0]<stderr>:[2025-10-10 10:17:04 TP0] Prefill batch. #new-seq: 4, #new-token: 352, #cached-token: 11, token usage: 0.61, #running-req: 154, #queue-req: 1803, 
[1,0]<stderr>:[2025-10-10 10:17:04 TP0] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.61, #running-req: 157, #queue-req: 1802, 
[1,0]<stderr>:[2025-10-10 10:17:05 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 1, token usage: 0.61, #running-req: 157, #queue-req: 1801, 
[1,0]<stderr>:[2025-10-10 10:17:05 TP0] Prefill batch. #new-seq: 3, #new-token: 101, #cached-token: 8, token usage: 0.61, #running-req: 157, #queue-req: 1798, 
[1,0]<stderr>:[2025-10-10 10:17:05 TP0] Decode batch. #running-req: 157, #token: 39830, token usage: 0.61, cuda graph: False, gen throughput (token/s): 109.52, #queue-req: 1798, 
[1,0]<stderr>:[2025-10-10 10:17:06 TP0] Prefill batch. #new-seq: 3, #new-token: 754, #cached-token: 7, token usage: 0.61, #running-req: 158, #queue-req: 1795, 
[1,0]<stderr>:[2025-10-10 10:17:06 TP0] Prefill batch. #new-seq: 2, #new-token: 171, #cached-token: 7, token usage: 0.61, #running-req: 157, #queue-req: 1793, 
[1,0]<stderr>:[2025-10-10 10:17:07 TP0] Prefill batch. #new-seq: 4, #new-token: 1237, #cached-token: 11, token usage: 0.60, #running-req: 154, #queue-req: 1789, 
[1,0]<stderr>:[2025-10-10 10:17:07 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.62, #running-req: 157, #queue-req: 1788, 
[1,0]<stderr>:[2025-10-10 10:17:07 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 2, token usage: 0.61, #running-req: 156, #queue-req: 1787, 
[1,0]<stderr>:[2025-10-10 10:17:08 TP0] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 1, token usage: 0.62, #running-req: 155, #queue-req: 1786, 
[1,0]<stderr>:[2025-10-10 10:17:08 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.62, #running-req: 155, #queue-req: 1785, 
[1,0]<stderr>:[2025-10-10 10:17:08 TP0] Prefill batch. #new-seq: 2, #new-token: 72, #cached-token: 4, token usage: 0.62, #running-req: 155, #queue-req: 1783, 
[1,0]<stderr>:[2025-10-10 10:17:09 TP0] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 2, token usage: 0.61, #running-req: 155, #queue-req: 1782, 
[1,0]<stderr>:[2025-10-10 10:17:09 TP0] Prefill batch. #new-seq: 3, #new-token: 768, #cached-token: 10, token usage: 0.60, #running-req: 150, #queue-req: 1779, 
[1,0]<stderr>:[2025-10-10 10:17:10 TP0] Prefill batch. #new-seq: 4, #new-token: 1349, #cached-token: 18, token usage: 0.59, #running-req: 151, #queue-req: 1775, 
[1,0]<stderr>:[2025-10-10 10:17:10 TP0] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 4, token usage: 0.61, #running-req: 153, #queue-req: 1774, 
[1,0]<stderr>:[2025-10-10 10:17:10 TP0] Prefill batch. #new-seq: 2, #new-token: 189, #cached-token: 3, token usage: 0.61, #running-req: 153, #queue-req: 1772, 
[1,0]<stderr>:[2025-10-10 10:17:10 TP0] Prefill batch. #new-seq: 6, #new-token: 1135, #cached-token: 10, token usage: 0.59, #running-req: 153, #queue-req: 1766, 
[1,0]<stderr>:[2025-10-10 10:17:11 TP0] Prefill batch. #new-seq: 3, #new-token: 1302, #cached-token: 8, token usage: 0.58, #running-req: 157, #queue-req: 1763, 
[1,0]<stderr>:[2025-10-10 10:17:11 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.61, #running-req: 159, #queue-req: 1762, 
[1,0]<stderr>:[2025-10-10 10:17:11 TP0] Prefill batch. #new-seq: 2, #new-token: 18, #cached-token: 6, token usage: 0.61, #running-req: 159, #queue-req: 1760, 
[1,0]<stderr>:[2025-10-10 10:17:12 TP0] Prefill batch. #new-seq: 4, #new-token: 636, #cached-token: 9, token usage: 0.59, #running-req: 159, #queue-req: 1756, 
[1,0]<stderr>:[2025-10-10 10:17:12 TP0] Prefill batch. #new-seq: 3, #new-token: 904, #cached-token: 8, token usage: 0.59, #running-req: 162, #queue-req: 1753, 
[1,0]<stderr>:[2025-10-10 10:17:13 TP0] Prefill batch. #new-seq: 2, #new-token: 450, #cached-token: 3, token usage: 0.60, #running-req: 162, #queue-req: 1751, 
[1,0]<stderr>:[2025-10-10 10:17:13 TP0] Prefill batch. #new-seq: 2, #new-token: 1101, #cached-token: 5, token usage: 0.60, #running-req: 163, #queue-req: 1749, 
[1,0]<stderr>:[2025-10-10 10:17:13 TP0] Decode batch. #running-req: 163, #token: 40351, token usage: 0.62, cuda graph: False, gen throughput (token/s): 837.24, #queue-req: 1749, 
[1,0]<stderr>:[2025-10-10 10:17:13 TP0] Prefill batch. #new-seq: 6, #new-token: 1826, #cached-token: 11, token usage: 0.58, #running-req: 163, #queue-req: 1743, 
[1,0]<stderr>:[2025-10-10 10:17:14 TP0] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.61, #running-req: 167, #queue-req: 1742, 
[1,0]<stderr>:[2025-10-10 10:17:14 TP0] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 2, token usage: 0.61, #running-req: 166, #queue-req: 1741, 
[1,0]<stderr>:[2025-10-10 10:17:15 TP0] Prefill batch. #new-seq: 2, #new-token: 1481, #cached-token: 7, token usage: 0.58, #running-req: 161, #queue-req: 1739, 
[1,0]<stderr>:[2025-10-10 10:17:15 TP0] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 2, token usage: 0.61, #running-req: 160, #queue-req: 1738, 
[1,0]<stderr>:[2025-10-10 10:17:16 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.62, #running-req: 160, #queue-req: 1737, 
[1,0]<stderr>:[2025-10-10 10:17:16 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 4, token usage: 0.61, #running-req: 160, #queue-req: 1736, 
[1,0]<stderr>:[2025-10-10 10:17:16 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.61, #running-req: 159, #queue-req: 1735, 
[1,0]<stderr>:[2025-10-10 10:17:17 TP0] Prefill batch. #new-seq: 3, #new-token: 201, #cached-token: 6, token usage: 0.61, #running-req: 158, #queue-req: 1732, 
[1,0]<stderr>:[2025-10-10 10:17:17 TP0] Prefill batch. #new-seq: 4, #new-token: 1656, #cached-token: 8, token usage: 0.58, #running-req: 158, #queue-req: 1728, 
[1,0]<stderr>:[2025-10-10 10:17:17 TP0] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 1, token usage: 0.60, #running-req: 158, #queue-req: 1727, 
[1,0]<stderr>:[2025-10-10 10:17:18 TP0] Prefill batch. #new-seq: 5, #new-token: 1234, #cached-token: 12, token usage: 0.60, #running-req: 158, #queue-req: 1722, 
[1,0]<stderr>:[2025-10-10 10:17:18 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.61, #running-req: 160, #queue-req: 1721, 
[1,0]<stderr>:[2025-10-10 10:17:19 TP0] Prefill batch. #new-seq: 2, #new-token: 324, #cached-token: 6, token usage: 0.62, #running-req: 159, #queue-req: 1719, 
[1,0]<stderr>:[2025-10-10 10:17:20 TP0] Prefill batch. #new-seq: 5, #new-token: 1008, #cached-token: 16, token usage: 0.60, #running-req: 158, #queue-req: 1714, 
[1,0]<stderr>:[2025-10-10 10:17:20 TP0] Decode batch. #running-req: 158, #token: 40458, token usage: 0.62, cuda graph: False, gen throughput (token/s): 959.82, #queue-req: 1714, 
[1,0]<stderr>:[2025-10-10 10:17:20 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 2, token usage: 0.62, #running-req: 162, #queue-req: 1713, 
[1,0]<stderr>:[2025-10-10 10:17:20 TP0] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 4, token usage: 0.63, #running-req: 162, #queue-req: 1712, 
[1,0]<stderr>:[2025-10-10 10:17:22 TP0] Prefill batch. #new-seq: 3, #new-token: 1179, #cached-token: 4, token usage: 0.62, #running-req: 160, #queue-req: 1709, 
[1,0]<stderr>:[2025-10-10 10:17:22 TP0] Prefill batch. #new-seq: 3, #new-token: 1471, #cached-token: 11, token usage: 0.63, #running-req: 156, #queue-req: 1706, 
[1,0]<stderr>:[2025-10-10 10:17:23 TP0] Prefill batch. #new-seq: 2, #new-token: 346, #cached-token: 9, token usage: 0.66, #running-req: 155, #queue-req: 1704, 
[1,0]<stderr>:[2025-10-10 10:17:23 TP0] Prefill batch. #new-seq: 3, #new-token: 40, #cached-token: 10, token usage: 0.65, #running-req: 154, #queue-req: 1701, 
[1,0]<stderr>:[2025-10-10 10:17:23 TP0] Prefill batch. #new-seq: 2, #new-token: 506, #cached-token: 2, token usage: 0.65, #running-req: 152, #queue-req: 1699, 
[1,0]<stderr>:[2025-10-10 10:17:24 TP0] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 1, token usage: 0.65, #running-req: 153, #queue-req: 1698, 
[1,0]<stderr>:[2025-10-10 10:17:24 TP0] Prefill batch. #new-seq: 2, #new-token: 779, #cached-token: 10, token usage: 0.65, #running-req: 152, #queue-req: 1696, 
[1,0]<stderr>:[2025-10-10 10:17:25 TP0] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.66, #running-req: 150, #queue-req: 1695, 
[1,0]<stderr>:[2025-10-10 10:17:26 TP0] Decode batch. #running-req: 151, #token: 44680, token usage: 0.68, cuda graph: False, gen throughput (token/s): 1001.04, #queue-req: 1695, 
[1,0]<stderr>:[2025-10-10 10:17:27 TP0] Prefill batch. #new-seq: 2, #new-token: 457, #cached-token: 6, token usage: 0.68, #running-req: 149, #queue-req: 1693, 
[1,0]<stderr>:[2025-10-10 10:17:28 TP0] Prefill batch. #new-seq: 2, #new-token: 614, #cached-token: 7, token usage: 0.70, #running-req: 147, #queue-req: 1691, 
[1,0]<stderr>:[2025-10-10 10:17:29 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.71, #running-req: 147, #queue-req: 1690, 
[1,0]<stderr>:[2025-10-10 10:17:30 TP0] Prefill batch. #new-seq: 4, #new-token: 938, #cached-token: 7, token usage: 0.70, #running-req: 146, #queue-req: 1686, 
[1,0]<stderr>:[2025-10-10 10:17:30 TP0] Prefill batch. #new-seq: 2, #new-token: 457, #cached-token: 6, token usage: 0.72, #running-req: 149, #queue-req: 1684, 
[1,0]<stderr>:[2025-10-10 10:17:31 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 4, token usage: 0.72, #running-req: 149, #queue-req: 1683, 
[1,0]<stderr>:[2025-10-10 10:17:31 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 1, token usage: 0.72, #running-req: 148, #queue-req: 1682, 
[1,0]<stderr>:[2025-10-10 10:17:32 TP0] Decode batch. #running-req: 147, #token: 46995, token usage: 0.72, cuda graph: False, gen throughput (token/s): 1052.76, #queue-req: 1682, 
[1,0]<stderr>:[2025-10-10 10:17:32 TP0] Prefill batch. #new-seq: 3, #new-token: 1048, #cached-token: 9, token usage: 0.70, #running-req: 146, #queue-req: 1679, 
[1,0]<stderr>:[2025-10-10 10:17:32 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.72, #running-req: 146, #queue-req: 1678, 
[1,0]<stderr>:[2025-10-10 10:17:33 TP0] Prefill batch. #new-seq: 11, #new-token: 1674, #cached-token: 24, token usage: 0.67, #running-req: 146, #queue-req: 1667, 
[1,0]<stderr>:[2025-10-10 10:17:33 TP0] Prefill batch. #new-seq: 6, #new-token: 867, #cached-token: 14, token usage: 0.69, #running-req: 152, #queue-req: 1661, 
[1,0]<stderr>:[2025-10-10 10:17:34 TP0] Prefill batch. #new-seq: 2, #new-token: 683, #cached-token: 4, token usage: 0.69, #running-req: 156, #queue-req: 1659, 
[1,0]<stderr>:[2025-10-10 10:17:34 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.69, #running-req: 155, #queue-req: 1658, 
[1,0]<stderr>:[2025-10-10 10:17:34 TP0] Prefill batch. #new-seq: 4, #new-token: 705, #cached-token: 7, token usage: 0.67, #running-req: 154, #queue-req: 1654, 
[1,0]<stderr>:[2025-10-10 10:17:35 TP0] Prefill batch. #new-seq: 2, #new-token: 884, #cached-token: 6, token usage: 0.68, #running-req: 156, #queue-req: 1652, 
[1,0]<stderr>:[2025-10-10 10:17:35 TP0] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 3, token usage: 0.69, #running-req: 155, #queue-req: 1651, 
[1,0]<stderr>:[2025-10-10 10:17:35 TP0] Prefill batch. #new-seq: 2, #new-token: 633, #cached-token: 10, token usage: 0.69, #running-req: 154, #queue-req: 1649, 
[1,0]<stderr>:[2025-10-10 10:17:36 TP0] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 6, token usage: 0.69, #running-req: 154, #queue-req: 1648, 
[1,0]<stderr>:[2025-10-10 10:17:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1132, #cached-token: 4, token usage: 0.70, #running-req: 151, #queue-req: 1647, 
[1,0]<stderr>:[2025-10-10 10:17:38 TP0] Prefill batch. #new-seq: 2, #new-token: 741, #cached-token: 5, token usage: 0.71, #running-req: 149, #queue-req: 1645, 
[1,0]<stderr>:[2025-10-10 10:17:38 TP0] Decode batch. #running-req: 150, #token: 47783, token usage: 0.73, cuda graph: False, gen throughput (token/s): 937.25, #queue-req: 1645, 
[1,0]<stderr>:[2025-10-10 10:17:39 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.73, #running-req: 148, #queue-req: 1644, 
[1,0]<stderr>:[2025-10-10 10:17:40 TP0] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 1, token usage: 0.75, #running-req: 146, #queue-req: 1643, 
[1,0]<stderr>:[2025-10-10 10:17:41 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.76, #running-req: 146, #queue-req: 1642, 
[1,0]<stderr>:[2025-10-10 10:17:41 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.75, #running-req: 146, #queue-req: 1641, 
[1,0]<stderr>:[2025-10-10 10:17:43 TP0] Decode batch. #running-req: 140, #token: 49302, token usage: 0.75, cuda graph: False, gen throughput (token/s): 1130.39, #queue-req: 1641, 
[1,0]<stderr>:[2025-10-10 10:17:44 TP0] Prefill batch. #new-seq: 4, #new-token: 2511, #cached-token: 8, token usage: 0.74, #running-req: 138, #queue-req: 1637, 
[1,0]<stderr>:[2025-10-10 10:17:45 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.78, #running-req: 140, #queue-req: 1636, 
[1,0]<stderr>:[2025-10-10 10:17:48 TP0] Prefill batch. #new-seq: 3, #new-token: 1433, #cached-token: 6, token usage: 0.79, #running-req: 132, #queue-req: 1633, 
[1,0]<stderr>:[2025-10-10 10:17:48 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 1, token usage: 0.81, #running-req: 134, #queue-req: 1632, 
[1,0]<stderr>:[2025-10-10 10:17:48 TP0] Decode batch. #running-req: 135, #token: 54069, token usage: 0.83, cuda graph: False, gen throughput (token/s): 1093.57, #queue-req: 1632, 
[1,0]<stderr>:[2025-10-10 10:17:49 TP0] Prefill batch. #new-seq: 3, #new-token: 632, #cached-token: 14, token usage: 0.82, #running-req: 130, #queue-req: 1629, 
[1,0]<stderr>:[2025-10-10 10:17:50 TP0] Prefill batch. #new-seq: 1, #new-token: 728, #cached-token: 5, token usage: 0.82, #running-req: 130, #queue-req: 1628, 
[1,0]<stderr>:[2025-10-10 10:17:51 TP0] Prefill batch. #new-seq: 4, #new-token: 1255, #cached-token: 8, token usage: 0.81, #running-req: 126, #queue-req: 1624, 
[1,0]<stderr>:[2025-10-10 10:17:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 2, token usage: 0.81, #running-req: 127, #queue-req: 1623, 
[1,0]<stderr>:[2025-10-10 10:17:52 TP0] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 3, token usage: 0.83, #running-req: 126, #queue-req: 1622, 
[1,0]<stderr>:[2025-10-10 10:17:53 TP0] Prefill batch. #new-seq: 1, #new-token: 990, #cached-token: 3, token usage: 0.83, #running-req: 124, #queue-req: 1621, 
[1,0]<stderr>:[2025-10-10 10:17:54 TP0] Decode batch. #running-req: 124, #token: 55894, token usage: 0.85, cuda graph: False, gen throughput (token/s): 935.76, #queue-req: 1621, 
[1,0]<stderr>:[2025-10-10 10:17:55 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.85, #running-req: 122, #queue-req: 1620, 
[1,0]<stderr>:[2025-10-10 10:17:55 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.86, #running-req: 122, #queue-req: 1619, 
[1,0]<stderr>:[2025-10-10 10:17:56 TP0] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.86, #running-req: 122, #queue-req: 1618, 
[1,0]<stderr>:[2025-10-10 10:17:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1940, #cached-token: 1, token usage: 0.84, #running-req: 116, #queue-req: 1617, 
[1,0]<stderr>:[2025-10-10 10:17:58 TP0] Prefill batch. #new-seq: 2, #new-token: 1483, #cached-token: 6, token usage: 0.86, #running-req: 115, #queue-req: 1615, 
[1,0]<stderr>:[2025-10-10 10:17:59 TP0] Decode batch. #running-req: 117, #token: 58450, token usage: 0.89, cuda graph: False, gen throughput (token/s): 912.66, #queue-req: 1615, 
[1,0]<stderr>:[2025-10-10 10:18:00 TP0] Prefill batch. #new-seq: 1, #new-token: 834, #cached-token: 1, token usage: 0.88, #running-req: 115, #queue-req: 1614, 
[1,0]<stderr>:[2025-10-10 10:18:00 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.88, #running-req: 113, #queue-req: 1613, 
[1,0]<stderr>:[2025-10-10 10:18:00 TP0] Prefill batch. #new-seq: 6, #new-token: 950, #cached-token: 12, token usage: 0.86, #running-req: 111, #queue-req: 1607, 
[1,0]<stderr>:[2025-10-10 10:18:00 TP0] Prefill batch. #new-seq: 3, #new-token: 730, #cached-token: 9, token usage: 0.87, #running-req: 116, #queue-req: 1604, 
[1,0]<stderr>:[2025-10-10 10:18:01 TP0] Prefill batch. #new-seq: 3, #new-token: 1085, #cached-token: 8, token usage: 0.87, #running-req: 117, #queue-req: 1601, 
[1,0]<stderr>:[2025-10-10 10:18:01 TP0] Prefill batch. #new-seq: 4, #new-token: 707, #cached-token: 5, token usage: 0.86, #running-req: 118, #queue-req: 1597, 
[1,0]<stderr>:[2025-10-10 10:18:01 TP0] Prefill batch. #new-seq: 2, #new-token: 1339, #cached-token: 3, token usage: 0.86, #running-req: 120, #queue-req: 1595, 
[1,0]<stderr>:[2025-10-10 10:18:02 TP0] Prefill batch. #new-seq: 3, #new-token: 1263, #cached-token: 7, token usage: 0.85, #running-req: 117, #queue-req: 1592, 
[1,0]<stderr>:[2025-10-10 10:18:02 TP0] Prefill batch. #new-seq: 3, #new-token: 1057, #cached-token: 8, token usage: 0.87, #running-req: 117, #queue-req: 1589, 
[1,0]<stderr>:[2025-10-10 10:18:03 TP0] Prefill batch. #new-seq: 3, #new-token: 576, #cached-token: 4, token usage: 0.88, #running-req: 118, #queue-req: 1586, 
[1,0]<stderr>:[2025-10-10 10:18:03 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.87, #running-req: 120, #queue-req: 1585, 
[1,0]<stderr>:[2025-10-10 10:18:03 TP0] Prefill batch. #new-seq: 5, #new-token: 587, #cached-token: 14, token usage: 0.86, #running-req: 120, #queue-req: 1580, 
[1,0]<stderr>:[2025-10-10 10:18:04 TP0] Prefill batch. #new-seq: 3, #new-token: 1020, #cached-token: 5, token usage: 0.86, #running-req: 122, #queue-req: 1577, 
[1,0]<stderr>:[2025-10-10 10:18:04 TP0] Prefill batch. #new-seq: 2, #new-token: 862, #cached-token: 4, token usage: 0.87, #running-req: 124, #queue-req: 1575, 
[1,0]<stderr>:[2025-10-10 10:18:04 TP0] Prefill batch. #new-seq: 2, #new-token: 299, #cached-token: 5, token usage: 0.88, #running-req: 124, #queue-req: 1573, 
[1,0]<stderr>:[2025-10-10 10:18:04 TP0] Prefill batch. #new-seq: 1, #new-token: 547, #cached-token: 1, token usage: 0.88, #running-req: 124, #queue-req: 1572, 
[1,0]<stderr>:[2025-10-10 10:18:05 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.88, #running-req: 123, #queue-req: 1571, 
[1,0]<stderr>:[2025-10-10 10:18:05 TP0] Prefill batch. #new-seq: 2, #new-token: 772, #cached-token: 6, token usage: 0.86, #running-req: 121, #queue-req: 1569, 
[1,0]<stderr>:[2025-10-10 10:18:06 TP0] Decode batch. #running-req: 120, #token: 56977, token usage: 0.87, cuda graph: False, gen throughput (token/s): 725.43, #queue-req: 1569, 
[1,0]<stderr>:[2025-10-10 10:18:06 TP0] Prefill batch. #new-seq: 2, #new-token: 1083, #cached-token: 3, token usage: 0.86, #running-req: 118, #queue-req: 1567, 
[1,0]<stderr>:[2025-10-10 10:18:06 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 4, token usage: 0.88, #running-req: 119, #queue-req: 1566, 
[1,0]<stderr>:[2025-10-10 10:18:07 TP0] Prefill batch. #new-seq: 4, #new-token: 1058, #cached-token: 7, token usage: 0.87, #running-req: 118, #queue-req: 1562, 
[1,0]<stderr>:[2025-10-10 10:18:07 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.89, #running-req: 121, #queue-req: 1561, 
[1,0]<stderr>:[2025-10-10 10:18:07 TP0] Prefill batch. #new-seq: 4, #new-token: 956, #cached-token: 14, token usage: 0.87, #running-req: 119, #queue-req: 1557, 
[1,0]<stderr>:[2025-10-10 10:18:11 TP0] Decode batch. #running-req: 115, #token: 57528, token usage: 0.88, cuda graph: False, gen throughput (token/s): 960.20, #queue-req: 1557, 
[1,0]<stderr>:[2025-10-10 10:18:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1917, #cached-token: 3, token usage: 0.88, #running-req: 114, #queue-req: 1555, 
[1,0]<stderr>:[2025-10-10 10:18:11 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.91, #running-req: 114, #queue-req: 1554, 
[1,0]<stderr>:[2025-10-10 10:18:11 TP0] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 2, token usage: 0.91, #running-req: 114, #queue-req: 1553, 
[1,0]<stderr>:[2025-10-10 10:18:12 TP0] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 1, token usage: 0.91, #running-req: 114, #queue-req: 1552, 
[1,0]<stderr>:[2025-10-10 10:18:12 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.90, #running-req: 113, #queue-req: 1551, 
[1,0]<stderr>:[2025-10-10 10:18:12 TP0] Prefill batch. #new-seq: 5, #new-token: 392, #cached-token: 11, token usage: 0.89, #running-req: 112, #queue-req: 1546, 
[1,0]<stderr>:[2025-10-10 10:18:12 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 2, token usage: 0.88, #running-req: 116, #queue-req: 1545, 
[1,0]<stderr>:[2025-10-10 10:18:13 TP0] Prefill batch. #new-seq: 2, #new-token: 2581, #cached-token: 4, token usage: 0.87, #running-req: 116, #queue-req: 1543, 
[1,0]<stderr>:[2025-10-10 10:18:13 TP0] Prefill batch. #new-seq: 3, #new-token: 31, #cached-token: 3, token usage: 0.91, #running-req: 116, #queue-req: 1540, 
[1,0]<stderr>:[2025-10-10 10:18:14 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.91, #running-req: 118, #queue-req: 1539, 
[1,0]<stderr>:[2025-10-10 10:18:14 TP0] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 5, token usage: 0.91, #running-req: 118, #queue-req: 1538, 
[1,0]<stderr>:[2025-10-10 10:18:15 TP0] Prefill batch. #new-seq: 2, #new-token: 126, #cached-token: 3, token usage: 0.91, #running-req: 118, #queue-req: 1536, 
[1,0]<stderr>:[2025-10-10 10:18:16 TP0] Prefill batch. #new-seq: 6, #new-token: 588, #cached-token: 14, token usage: 0.89, #running-req: 116, #queue-req: 1530, 
[1,0]<stderr>:[2025-10-10 10:18:16 TP0] Prefill batch. #new-seq: 3, #new-token: 37, #cached-token: 5, token usage: 0.90, #running-req: 120, #queue-req: 1527, 
[1,0]<stderr>:[2025-10-10 10:18:17 TP0] Decode batch. #running-req: 122, #token: 58596, token usage: 0.89, cuda graph: False, gen throughput (token/s): 763.70, #queue-req: 1527, 
[1,0]<stderr>:[2025-10-10 10:18:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1534, #cached-token: 1, token usage: 0.89, #running-req: 121, #queue-req: 1526, 
[1,0]<stderr>:[2025-10-10 10:18:17 TP0] Prefill batch. #new-seq: 9, #new-token: 1658, #cached-token: 17, token usage: 0.87, #running-req: 119, #queue-req: 1517, 
[1,0]<stderr>:[2025-10-10 10:18:18 TP0] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 2, token usage: 0.90, #running-req: 127, #queue-req: 1516, 
[1,0]<stderr>:[2025-10-10 10:18:18 TP0] Prefill batch. #new-seq: 3, #new-token: 1025, #cached-token: 5, token usage: 0.89, #running-req: 125, #queue-req: 1513, 
[1,0]<stderr>:[2025-10-10 10:18:19 TP0] Prefill batch. #new-seq: 7, #new-token: 1692, #cached-token: 16, token usage: 0.89, #running-req: 126, #queue-req: 1506, 
[1,0]<stderr>:[2025-10-10 10:18:19 TP0] Prefill batch. #new-seq: 2, #new-token: 286, #cached-token: 2, token usage: 0.91, #running-req: 130, #queue-req: 1504, 
[1,0]<stderr>:[2025-10-10 10:18:20 TP0] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 3, token usage: 0.90, #running-req: 131, #queue-req: 1503, 
[1,0]<stderr>:[2025-10-10 10:18:20 TP0] Prefill batch. #new-seq: 3, #new-token: 629, #cached-token: 7, token usage: 0.90, #running-req: 131, #queue-req: 1500, 
[1,0]<stderr>:[2025-10-10 10:18:20 TP0] Prefill batch. #new-seq: 2, #new-token: 49, #cached-token: 2, token usage: 0.91, #running-req: 133, #queue-req: 1498, 
[1,0]<stderr>:[2025-10-10 10:18:20 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.91, #running-req: 134, #queue-req: 1497, 
[1,0]<stderr>:[2025-10-10 10:18:21 TP0] Prefill batch. #new-seq: 2, #new-token: 726, #cached-token: 3, token usage: 0.91, #running-req: 133, #queue-req: 1495, 
[1,0]<stderr>:[2025-10-10 10:18:21 TP0] Prefill batch. #new-seq: 1, #new-token: 486, #cached-token: 1, token usage: 0.91, #running-req: 133, #queue-req: 1494, 
[1,0]<stderr>:[2025-10-10 10:18:21 TP0] Prefill batch. #new-seq: 2, #new-token: 94, #cached-token: 5, token usage: 0.90, #running-req: 131, #queue-req: 1492, 
[1,0]<stderr>:[2025-10-10 10:18:22 TP0] Prefill batch. #new-seq: 2, #new-token: 867, #cached-token: 7, token usage: 0.91, #running-req: 131, #queue-req: 1490, 
[1,0]<stderr>:[2025-10-10 10:18:23 TP0] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 2, token usage: 0.92, #running-req: 132, #queue-req: 1489, 
[1,0]<stderr>:[2025-10-10 10:18:23 TP0] Decode batch. #running-req: 133, #token: 59531, token usage: 0.91, cuda graph: False, gen throughput (token/s): 802.55, #queue-req: 1489, 
[1,0]<stderr>:[2025-10-10 10:18:23 TP0] Prefill batch. #new-seq: 3, #new-token: 43, #cached-token: 6, token usage: 0.91, #running-req: 132, #queue-req: 1486, 
[1,0]<stderr>:[2025-10-10 10:18:24 TP0] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 2, token usage: 0.91, #running-req: 133, #queue-req: 1485, 
[1,0]<stderr>:[2025-10-10 10:18:25 TP0] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 2, token usage: 0.92, #running-req: 132, #queue-req: 1484, 
[1,0]<stderr>:[2025-10-10 10:18:25 TP0] Prefill batch. #new-seq: 1, #new-token: 881, #cached-token: 1, token usage: 0.91, #running-req: 131, #queue-req: 1483, 
[1,0]<stderr>:[2025-10-10 10:18:26 TP0] Prefill batch. #new-seq: 3, #new-token: 1050, #cached-token: 9, token usage: 0.92, #running-req: 129, #queue-req: 1480, 
[1,0]<stderr>:[2025-10-10 10:18:27 TP0] Prefill batch. #new-seq: 6, #new-token: 226, #cached-token: 12, token usage: 0.93, #running-req: 129, #queue-req: 1474, 
[1,0]<stderr>:[2025-10-10 10:18:27 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.93, #running-req: 134, #queue-req: 1473, 
[1,0]<stderr>:[2025-10-10 10:18:29 TP0] Decode batch. #running-req: 134, #token: 61941, token usage: 0.95, cuda graph: False, gen throughput (token/s): 951.01, #queue-req: 1473, 
[1,0]<stderr>:[2025-10-10 10:18:30 TP0] Prefill batch. #new-seq: 6, #new-token: 1356, #cached-token: 6, token usage: 0.93, #running-req: 132, #queue-req: 1467, 
[1,0]<stderr>:[2025-10-10 10:18:30 TP0] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 3, token usage: 0.95, #running-req: 136, #queue-req: 1466, 
[1,0]<stderr>:[2025-10-10 10:18:31 TP0] Prefill batch. #new-seq: 8, #new-token: 1405, #cached-token: 25, token usage: 0.92, #running-req: 136, #queue-req: 1458, 
[1,0]<stderr>:[2025-10-10 10:18:31 TP0] Prefill batch. #new-seq: 2, #new-token: 548, #cached-token: 4, token usage: 0.94, #running-req: 141, #queue-req: 1456, 
[1,0]<stderr>:[2025-10-10 10:18:31 TP0] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 2, token usage: 0.95, #running-req: 142, #queue-req: 1455, 
[1,0]<stderr>:[2025-10-10 10:18:33 TP0] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 2, token usage: 0.95, #running-req: 137, #queue-req: 1454, 
[1,0]<stderr>:[2025-10-10 10:18:33 TP0] Prefill batch. #new-seq: 3, #new-token: 458, #cached-token: 5, token usage: 0.94, #running-req: 136, #queue-req: 1451, 
[1,0]<stderr>:[2025-10-10 10:18:34 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.95, #running-req: 137, #queue-req: 1450, 
[1,0]<stderr>:[2025-10-10 10:18:34 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 2, token usage: 0.96, #running-req: 137, #queue-req: 1449, 
[1,0]<stderr>:[2025-10-10 10:18:34 TP0] Prefill batch. #new-seq: 1, #new-token: 720, #cached-token: 1, token usage: 0.94, #running-req: 137, #queue-req: 1448, 
[1,0]<stderr>:[2025-10-10 10:18:35 TP0] Decode batch. #running-req: 137, #token: 62472, token usage: 0.95, cuda graph: False, gen throughput (token/s): 963.05, #queue-req: 1448, 
[1,0]<stderr>:[2025-10-10 10:18:35 TP0] Prefill batch. #new-seq: 1, #new-token: 795, #cached-token: 2, token usage: 0.94, #running-req: 137, #queue-req: 1447, 
[1,0]<stderr>:[2025-10-10 10:18:35 TP0] Prefill batch. #new-seq: 4, #new-token: 1487, #cached-token: 10, token usage: 0.93, #running-req: 134, #queue-req: 1443, 
[1,0]<stderr>:[2025-10-10 10:18:36 TP0] Prefill batch. #new-seq: 4, #new-token: 1012, #cached-token: 5, token usage: 0.94, #running-req: 137, #queue-req: 1439, 
[1,0]<stderr>:[2025-10-10 10:18:36 TP0] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 2, token usage: 0.96, #running-req: 139, #queue-req: 1438, 
[1,0]<stderr>:[2025-10-10 10:18:36 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.95, #running-req: 138, #queue-req: 1437, 
[1,0]<stderr>:[2025-10-10 10:18:37 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 1, token usage: 0.94, #running-req: 136, #queue-req: 1436, 
[1,0]<stderr>:[2025-10-10 10:18:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1595, #cached-token: 2, token usage: 0.94, #running-req: 134, #queue-req: 1435, 
[1,0]<stderr>:[2025-10-10 10:18:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1292, #cached-token: 2, token usage: 0.93, #running-req: 129, #queue-req: 1434, 
[1,0]<stderr>:[2025-10-10 10:18:39 TP0] Prefill batch. #new-seq: 2, #new-token: 598, #cached-token: 2, token usage: 0.94, #running-req: 124, #queue-req: 1432, 
[1,0]<stderr>:[2025-10-10 10:18:40 TP0] Decode batch. #running-req: 124, #token: 62792, token usage: 0.96, cuda graph: False, gen throughput (token/s): 940.95, #queue-req: 1432, 
[1,0]<stderr>:[2025-10-10 10:18:41 TP0] Prefill batch. #new-seq: 2, #new-token: 514, #cached-token: 7, token usage: 0.94, #running-req: 122, #queue-req: 1430, 
[1,0]<stderr>:[2025-10-10 10:18:42 TP0] Prefill batch. #new-seq: 2, #new-token: 3428, #cached-token: 3, token usage: 0.89, #running-req: 117, #queue-req: 1428, 
[1,0]<stderr>:[2025-10-10 10:18:42 TP0] Prefill batch. #new-seq: 4, #new-token: 1238, #cached-token: 18, token usage: 0.94, #running-req: 116, #queue-req: 1424, 
[1,0]<stderr>:[2025-10-10 10:18:42 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.95, #running-req: 119, #queue-req: 1423, 
[1,0]<stderr>:[2025-10-10 10:18:43 TP0] Prefill batch. #new-seq: 2, #new-token: 757, #cached-token: 6, token usage: 0.95, #running-req: 119, #queue-req: 1421, 
[1,0]<stderr>:[2025-10-10 10:18:43 TP0] Prefill batch. #new-seq: 2, #new-token: 310, #cached-token: 10, token usage: 0.95, #running-req: 120, #queue-req: 1419, 
[1,0]<stderr>:[2025-10-10 10:18:44 TP0] Prefill batch. #new-seq: 5, #new-token: 755, #cached-token: 10, token usage: 0.94, #running-req: 121, #queue-req: 1414, 
[1,0]<stderr>:[2025-10-10 10:18:44 TP0] Prefill batch. #new-seq: 4, #new-token: 549, #cached-token: 6, token usage: 0.94, #running-req: 123, #queue-req: 1410, 
[1,0]<stderr>:[2025-10-10 10:18:45 TP0] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 8, token usage: 0.95, #running-req: 126, #queue-req: 1409, 
[1,0]<stderr>:[2025-10-10 10:18:46 TP0] Decode batch. #running-req: 126, #token: 63544, token usage: 0.97, cuda graph: False, gen throughput (token/s): 891.54, #queue-req: 1409, 
[1,0]<stderr>:[2025-10-10 10:18:47 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.95, #running-req: 120, #queue-req: 1408, 
[1,0]<stderr>:[2025-10-10 10:18:48 TP0] Prefill batch. #new-seq: 3, #new-token: 411, #cached-token: 19, token usage: 0.95, #running-req: 120, #queue-req: 1405, 
[1,0]<stderr>:[2025-10-10 10:18:48 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 4, token usage: 0.95, #running-req: 122, #queue-req: 1404, 
[1,0]<stderr>:[2025-10-10 10:18:48 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.95, #running-req: 120, #queue-req: 1403, 
[1,0]<stderr>:[2025-10-10 10:18:49 TP0] Prefill batch. #new-seq: 3, #new-token: 1292, #cached-token: 5, token usage: 0.93, #running-req: 118, #queue-req: 1400, 
[1,0]<stderr>:[2025-10-10 10:18:49 TP0] Prefill batch. #new-seq: 2, #new-token: 1064, #cached-token: 7, token usage: 0.95, #running-req: 118, #queue-req: 1398, 
[1,0]<stderr>:[2025-10-10 10:18:50 TP0] Prefill batch. #new-seq: 3, #new-token: 950, #cached-token: 8, token usage: 0.93, #running-req: 119, #queue-req: 1395, 
[1,0]<stderr>:[2025-10-10 10:18:50 TP0] Prefill batch. #new-seq: 10, #new-token: 3012, #cached-token: 23, token usage: 0.90, #running-req: 117, #queue-req: 1385, 
[1,0]<stderr>:[2025-10-10 10:18:50 TP0] Prefill batch. #new-seq: 2, #new-token: 722, #cached-token: 6, token usage: 0.93, #running-req: 126, #queue-req: 1383, 
[1,0]<stderr>:[2025-10-10 10:18:51 TP0] Prefill batch. #new-seq: 1, #new-token: 497, #cached-token: 2, token usage: 0.94, #running-req: 125, #queue-req: 1382, 
[1,0]<stderr>:[2025-10-10 10:18:51 TP0] Prefill batch. #new-seq: 4, #new-token: 1264, #cached-token: 10, token usage: 0.93, #running-req: 124, #queue-req: 1378, 
[1,0]<stderr>:[2025-10-10 10:18:51 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 1, token usage: 0.94, #running-req: 126, #queue-req: 1377, 
[1,0]<stderr>:[2025-10-10 10:18:52 TP0] Decode batch. #running-req: 126, #token: 62038, token usage: 0.95, cuda graph: False, gen throughput (token/s): 851.34, #queue-req: 1377, 
[1,0]<stderr>:[2025-10-10 10:18:52 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 6, token usage: 0.95, #running-req: 126, #queue-req: 1376, 
[1,0]<stderr>:[2025-10-10 10:18:52 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.95, #running-req: 126, #queue-req: 1375, 
[1,0]<stderr>:[2025-10-10 10:18:52 TP0] Prefill batch. #new-seq: 5, #new-token: 686, #cached-token: 9, token usage: 0.94, #running-req: 125, #queue-req: 1370, 
[1,0]<stderr>:[2025-10-10 10:18:52 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 1, token usage: 0.94, #running-req: 128, #queue-req: 1369, 
[1,0]<stderr>:[2025-10-10 10:18:53 TP0] Prefill batch. #new-seq: 1, #new-token: 885, #cached-token: 6, token usage: 0.93, #running-req: 127, #queue-req: 1368, 
[1,0]<stderr>:[2025-10-10 10:18:53 TP0] Prefill batch. #new-seq: 4, #new-token: 1670, #cached-token: 10, token usage: 0.93, #running-req: 126, #queue-req: 1364, 
[1,0]<stderr>:[2025-10-10 10:18:53 TP0] Prefill batch. #new-seq: 2, #new-token: 449, #cached-token: 6, token usage: 0.95, #running-req: 128, #queue-req: 1362, 
[1,0]<stderr>:[2025-10-10 10:18:53 TP0] Prefill batch. #new-seq: 4, #new-token: 1048, #cached-token: 14, token usage: 0.94, #running-req: 128, #queue-req: 1358, 
[1,0]<stderr>:[2025-10-10 10:18:54 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 1, token usage: 0.95, #running-req: 131, #queue-req: 1357, 
[1,0]<stderr>:[2025-10-10 10:18:54 TP0] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 2, token usage: 0.94, #running-req: 131, #queue-req: 1356, 
[1,0]<stderr>:[2025-10-10 10:18:54 TP0] Prefill batch. #new-seq: 1, #new-token: 910, #cached-token: 3, token usage: 0.94, #running-req: 131, #queue-req: 1355, 
[1,0]<stderr>:[2025-10-10 10:18:54 TP0] Prefill batch. #new-seq: 4, #new-token: 399, #cached-token: 7, token usage: 0.94, #running-req: 130, #queue-req: 1351, 
[1,0]<stderr>:[2025-10-10 10:18:55 TP0] Prefill batch. #new-seq: 8, #new-token: 1890, #cached-token: 27, token usage: 0.92, #running-req: 133, #queue-req: 1343, 
[1,0]<stderr>:[2025-10-10 10:18:55 TP0] Prefill batch. #new-seq: 3, #new-token: 1317, #cached-token: 3, token usage: 0.94, #running-req: 140, #queue-req: 1340, 
[1,0]<stderr>:[2025-10-10 10:18:56 TP0] Prefill batch. #new-seq: 5, #new-token: 494, #cached-token: 17, token usage: 0.93, #running-req: 139, #queue-req: 1335, 
[1,0]<stderr>:[2025-10-10 10:18:56 TP0] Prefill batch. #new-seq: 2, #new-token: 142, #cached-token: 10, token usage: 0.94, #running-req: 143, #queue-req: 1333, 
[1,0]<stderr>:[2025-10-10 10:18:57 TP0] Prefill batch. #new-seq: 3, #new-token: 838, #cached-token: 8, token usage: 0.93, #running-req: 144, #queue-req: 1330, 
[1,0]<stderr>:[2025-10-10 10:18:57 TP0] Prefill batch. #new-seq: 2, #new-token: 18, #cached-token: 6, token usage: 0.95, #running-req: 145, #queue-req: 1328, 
[1,0]<stderr>:[2025-10-10 10:18:57 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.95, #running-req: 146, #queue-req: 1327, 
[1,0]<stderr>:[2025-10-10 10:18:58 TP0] Prefill batch. #new-seq: 3, #new-token: 456, #cached-token: 4, token usage: 0.95, #running-req: 146, #queue-req: 1324, 
[1,0]<stderr>:[2025-10-10 10:18:58 TP0] Prefill batch. #new-seq: 2, #new-token: 437, #cached-token: 3, token usage: 0.95, #running-req: 148, #queue-req: 1322, 
[1,0]<stderr>:[2025-10-10 10:18:58 TP0] Prefill batch. #new-seq: 5, #new-token: 2022, #cached-token: 7, token usage: 0.92, #running-req: 146, #queue-req: 1317, 
[1,0]<stderr>:[2025-10-10 10:18:59 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.95, #running-req: 148, #queue-req: 1316, 
[1,0]<stderr>:[2025-10-10 10:18:59 TP0] Decode batch. #running-req: 148, #token: 62477, token usage: 0.95, cuda graph: False, gen throughput (token/s): 759.39, #queue-req: 1316, 
[1,0]<stderr>:[2025-10-10 10:18:59 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.94, #running-req: 146, #queue-req: 1315, 
[1,0]<stderr>:[2025-10-10 10:18:59 TP0] Prefill batch. #new-seq: 2, #new-token: 275, #cached-token: 5, token usage: 0.94, #running-req: 146, #queue-req: 1313, 
[1,0]<stderr>:[2025-10-10 10:19:00 TP0] Prefill batch. #new-seq: 4, #new-token: 1371, #cached-token: 6, token usage: 0.93, #running-req: 147, #queue-req: 1309, 
[1,0]<stderr>:[2025-10-10 10:19:00 TP0] Prefill batch. #new-seq: 1, #new-token: 893, #cached-token: 1, token usage: 0.94, #running-req: 144, #queue-req: 1308, 
[1,0]<stderr>:[2025-10-10 10:19:00 TP0] Prefill batch. #new-seq: 5, #new-token: 692, #cached-token: 12, token usage: 0.91, #running-req: 140, #queue-req: 1303, 
[1,0]<stderr>:[2025-10-10 10:19:01 TP0] Prefill batch. #new-seq: 3, #new-token: 1422, #cached-token: 8, token usage: 0.91, #running-req: 142, #queue-req: 1300, 
[1,0]<stderr>:[2025-10-10 10:19:01 TP0] Prefill batch. #new-seq: 5, #new-token: 1294, #cached-token: 9, token usage: 0.93, #running-req: 144, #queue-req: 1295, 
[1,0]<stderr>:[2025-10-10 10:19:01 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.95, #running-req: 148, #queue-req: 1294, 
[1,0]<stderr>:[2025-10-10 10:19:02 TP0] Prefill batch. #new-seq: 2, #new-token: 826, #cached-token: 2, token usage: 0.94, #running-req: 145, #queue-req: 1292, 
[1,0]<stderr>:[2025-10-10 10:19:02 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.95, #running-req: 145, #queue-req: 1291, 
[1,0]<stderr>:[2025-10-10 10:19:03 TP0] Prefill batch. #new-seq: 3, #new-token: 1852, #cached-token: 7, token usage: 0.92, #running-req: 139, #queue-req: 1288, 
[1,0]<stderr>:[2025-10-10 10:19:04 TP0] Prefill batch. #new-seq: 3, #new-token: 273, #cached-token: 8, token usage: 0.95, #running-req: 141, #queue-req: 1285, 
[1,0]<stderr>:[2025-10-10 10:19:04 TP0] Prefill batch. #new-seq: 2, #new-token: 809, #cached-token: 9, token usage: 0.94, #running-req: 141, #queue-req: 1283, 
[1,0]<stderr>:[2025-10-10 10:19:04 TP0] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 1, token usage: 0.94, #running-req: 141, #queue-req: 1282, 
[1,0]<stderr>:[2025-10-10 10:19:05 TP0] Prefill batch. #new-seq: 1, #new-token: 695, #cached-token: 1, token usage: 0.94, #running-req: 141, #queue-req: 1281, 
[1,0]<stderr>:[2025-10-10 10:19:05 TP0] Decode batch. #running-req: 142, #token: 62398, token usage: 0.95, cuda graph: False, gen throughput (token/s): 892.81, #queue-req: 1281, 
[1,0]<stderr>:[2025-10-10 10:19:06 TP0] Prefill batch. #new-seq: 4, #new-token: 830, #cached-token: 6, token usage: 0.93, #running-req: 135, #queue-req: 1277, 
[1,0]<stderr>:[2025-10-10 10:19:06 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 3, token usage: 0.93, #running-req: 136, #queue-req: 1276, 
[1,0]<stderr>:[2025-10-10 10:19:06 TP0] Prefill batch. #new-seq: 2, #new-token: 1456, #cached-token: 4, token usage: 0.92, #running-req: 135, #queue-req: 1274, 
[1,0]<stderr>:[2025-10-10 10:19:07 TP0] Prefill batch. #new-seq: 6, #new-token: 376, #cached-token: 11, token usage: 0.94, #running-req: 135, #queue-req: 1268, 
[1,0]<stderr>:[2025-10-10 10:19:10 TP0] Decode batch. #running-req: 124, #token: 57687, token usage: 0.88, cuda graph: False, gen throughput (token/s): 1061.99, #queue-req: 1268, 
[1,0]<stderr>:[2025-10-10 10:19:11 TP0] Prefill batch. #new-seq: 4, #new-token: 7110, #cached-token: 9, token usage: 0.84, #running-req: 118, #queue-req: 1264, 
[1,0]<stderr>:[2025-10-10 10:19:11 TP0] Prefill batch. #new-seq: 2, #new-token: 291, #cached-token: 3, token usage: 0.95, #running-req: 121, #queue-req: 1262, 
[1,0]<stderr>:[2025-10-10 10:19:12 TP0] Prefill batch. #new-seq: 3, #new-token: 396, #cached-token: 3, token usage: 0.96, #running-req: 122, #queue-req: 1259, 
[1,0]<stderr>:[2025-10-10 10:19:12 TP0] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 2, token usage: 0.96, #running-req: 123, #queue-req: 1258, 
[1,0]<stderr>:[2025-10-10 10:19:13 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 5, token usage: 0.95, #running-req: 121, #queue-req: 1257, 
[1,0]<stderr>:[2025-10-10 10:19:13 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.93, #running-req: 119, #queue-req: 1256, 
[1,0]<stderr>:[2025-10-10 10:19:15 TP0] Prefill batch. #new-seq: 2, #new-token: 2321, #cached-token: 2, token usage: 0.92, #running-req: 111, #queue-req: 1254, 
[1,0]<stderr>:[2025-10-10 10:19:15 TP0] Prefill batch. #new-seq: 2, #new-token: 951, #cached-token: 8, token usage: 0.94, #running-req: 111, #queue-req: 1252, 
[1,0]<stderr>:[2025-10-10 10:19:16 TP0] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 1, token usage: 0.94, #running-req: 111, #queue-req: 1251, 
[1,0]<stderr>:[2025-10-10 10:19:16 TP0] Decode batch. #running-req: 111, #token: 62144, token usage: 0.95, cuda graph: False, gen throughput (token/s): 807.46, #queue-req: 1251, 
[1,0]<stderr>:[2025-10-10 10:19:17 TP0] Prefill batch. #new-seq: 4, #new-token: 1331, #cached-token: 14, token usage: 0.94, #running-req: 107, #queue-req: 1247, 
[1,0]<stderr>:[2025-10-10 10:19:18 TP0] Prefill batch. #new-seq: 3, #new-token: 78, #cached-token: 6, token usage: 0.94, #running-req: 108, #queue-req: 1244, 
[1,0]<stderr>:[2025-10-10 10:19:20 TP0] Prefill batch. #new-seq: 1, #new-token: 2247, #cached-token: 4, token usage: 0.92, #running-req: 103, #queue-req: 1243, 
[1,0]<stderr>:[2025-10-10 10:19:21 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 1, token usage: 0.96, #running-req: 103, #queue-req: 1242, 
[1,0]<stderr>:[2025-10-10 10:19:21 TP0] Decode batch. #running-req: 103, #token: 63014, token usage: 0.96, cuda graph: False, gen throughput (token/s): 840.21, #queue-req: 1242, 
[1,0]<stderr>:[2025-10-10 10:19:22 TP0] Prefill batch. #new-seq: 5, #new-token: 1106, #cached-token: 8, token usage: 0.94, #running-req: 100, #queue-req: 1237, 
[1,0]<stderr>:[2025-10-10 10:19:22 TP0] Prefill batch. #new-seq: 4, #new-token: 183, #cached-token: 6, token usage: 0.95, #running-req: 103, #queue-req: 1233, 
[1,0]<stderr>:[2025-10-10 10:19:23 TP0] Prefill batch. #new-seq: 7, #new-token: 1917, #cached-token: 16, token usage: 0.91, #running-req: 106, #queue-req: 1226, 
[1,0]<stderr>:[2025-10-10 10:19:23 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.94, #running-req: 111, #queue-req: 1225, 
[1,0]<stderr>:[2025-10-10 10:19:24 TP0] Prefill batch. #new-seq: 3, #new-token: 2672, #cached-token: 7, token usage: 0.92, #running-req: 110, #queue-req: 1222, 
[1,0]<stderr>:[2025-10-10 10:19:24 TP0] Prefill batch. #new-seq: 2, #new-token: 176, #cached-token: 2, token usage: 0.95, #running-req: 108, #queue-req: 1220, 
[1,0]<stderr>:[2025-10-10 10:19:25 TP0] Prefill batch. #new-seq: 6, #new-token: 1093, #cached-token: 8, token usage: 0.93, #running-req: 107, #queue-req: 1214, 
[1,0]<stderr>:[2025-10-10 10:19:25 TP0] Prefill batch. #new-seq: 3, #new-token: 844, #cached-token: 5, token usage: 0.94, #running-req: 111, #queue-req: 1211, 
[1,0]<stderr>:[2025-10-10 10:19:27 TP0] Decode batch. #running-req: 109, #token: 61845, token usage: 0.94, cuda graph: False, gen throughput (token/s): 791.50, #queue-req: 1211, 
[1,0]<stderr>:[2025-10-10 10:19:28 TP0] Prefill batch. #new-seq: 1, #new-token: 2044, #cached-token: 1, token usage: 0.93, #running-req: 102, #queue-req: 1210, 
[1,0]<stderr>:[2025-10-10 10:19:28 TP0] Prefill batch. #new-seq: 2, #new-token: 28, #cached-token: 5, token usage: 0.95, #running-req: 102, #queue-req: 1208, 
[1,0]<stderr>:[2025-10-10 10:19:29 TP0] Prefill batch. #new-seq: 1, #new-token: 771, #cached-token: 3, token usage: 0.95, #running-req: 101, #queue-req: 1207, 
[1,0]<stderr>:[2025-10-10 10:19:32 TP0] Decode batch. #running-req: 97, #token: 63332, token usage: 0.97, cuda graph: False, gen throughput (token/s): 823.55, #queue-req: 1207, 
[1,0]<stderr>:[2025-10-10 10:19:32 TP0] Prefill batch. #new-seq: 3, #new-token: 1047, #cached-token: 12, token usage: 0.94, #running-req: 94, #queue-req: 1204, 
[1,0]<stderr>:[2025-10-10 10:19:32 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.96, #running-req: 96, #queue-req: 1203, 
[1,0]<stderr>:[2025-10-10 10:19:33 TP0] Prefill batch. #new-seq: 2, #new-token: 1089, #cached-token: 6, token usage: 0.95, #running-req: 96, #queue-req: 1201, 
[1,0]<stderr>:[2025-10-10 10:19:33 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.96, #running-req: 95, #queue-req: 1200, 
[1,0]<stderr>:[2025-10-10 10:19:34 TP0] Prefill batch. #new-seq: 5, #new-token: 1040, #cached-token: 16, token usage: 0.95, #running-req: 94, #queue-req: 1195, 
[1,0]<stderr>:[2025-10-10 10:19:34 TP0] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.96, #running-req: 98, #queue-req: 1194, 
[1,0]<stderr>:[2025-10-10 10:19:35 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 3, token usage: 0.96, #running-req: 96, #queue-req: 1193, 
[1,0]<stderr>:[2025-10-10 10:19:36 TP0] Prefill batch. #new-seq: 1, #new-token: 691, #cached-token: 1, token usage: 0.95, #running-req: 94, #queue-req: 1192, 
[1,0]<stderr>:[2025-10-10 10:19:37 TP0] Prefill batch. #new-seq: 2, #new-token: 1139, #cached-token: 6, token usage: 0.94, #running-req: 90, #queue-req: 1190, 
[1,0]<stderr>:[2025-10-10 10:19:37 TP0] Decode batch. #running-req: 90, #token: 62736, token usage: 0.96, cuda graph: False, gen throughput (token/s): 674.23, #queue-req: 1190, 
[1,0]<stderr>:[2025-10-10 10:19:38 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.96, #running-req: 91, #queue-req: 1189, 
[1,0]<stderr>:[2025-10-10 10:19:38 TP0] Prefill batch. #new-seq: 3, #new-token: 933, #cached-token: 4, token usage: 0.93, #running-req: 90, #queue-req: 1186, 
[1,0]<stderr>:[2025-10-10 10:19:38 TP0] Prefill batch. #new-seq: 3, #new-token: 2414, #cached-token: 5, token usage: 0.93, #running-req: 91, #queue-req: 1183, 
[1,0]<stderr>:[2025-10-10 10:19:38 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.96, #running-req: 93, #queue-req: 1182, 
[1,0]<stderr>:[2025-10-10 10:19:39 TP0] Prefill batch. #new-seq: 2, #new-token: 28, #cached-token: 4, token usage: 0.95, #running-req: 93, #queue-req: 1180, 
[1,0]<stderr>:[2025-10-10 10:19:41 TP0] Prefill batch. #new-seq: 2, #new-token: 1479, #cached-token: 3, token usage: 0.94, #running-req: 89, #queue-req: 1178, 
[1,0]<stderr>:[2025-10-10 10:19:41 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 8, token usage: 0.97, #running-req: 90, #queue-req: 1177, 
[1,0]<stderr>:[2025-10-10 10:19:41 TP0] Prefill batch. #new-seq: 2, #new-token: 12, #cached-token: 5, token usage: 0.96, #running-req: 89, #queue-req: 1175, 
[1,0]<stderr>:[2025-10-10 10:19:42 TP0] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 1, token usage: 0.96, #running-req: 90, #queue-req: 1174, 
[1,0]<stderr>:[2025-10-10 10:19:42 TP0] Prefill batch. #new-seq: 4, #new-token: 101, #cached-token: 6, token usage: 0.96, #running-req: 90, #queue-req: 1170, 
[1,0]<stderr>:[2025-10-10 10:19:43 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 4, token usage: 0.96, #running-req: 93, #queue-req: 1169, 
[1,0]<stderr>:[2025-10-10 10:19:43 TP0] Decode batch. #running-req: 94, #token: 63399, token usage: 0.97, cuda graph: False, gen throughput (token/s): 632.07, #queue-req: 1169, 
[1,0]<stderr>:[2025-10-10 10:19:44 TP0] Prefill batch. #new-seq: 7, #new-token: 2204, #cached-token: 14, token usage: 0.90, #running-req: 91, #queue-req: 1162, 
[1,0]<stderr>:[2025-10-10 10:19:46 TP0] Prefill batch. #new-seq: 2, #new-token: 2431, #cached-token: 3, token usage: 0.93, #running-req: 92, #queue-req: 1160, 
[1,0]<stderr>:[2025-10-10 10:19:46 TP0] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 2, token usage: 0.96, #running-req: 92, #queue-req: 1159, 
[1,0]<stderr>:[2025-10-10 10:19:46 TP0] Prefill batch. #new-seq: 2, #new-token: 46, #cached-token: 4, token usage: 0.96, #running-req: 92, #queue-req: 1157, 
[1,0]<stderr>:[2025-10-10 10:19:47 TP0] Prefill batch. #new-seq: 2, #new-token: 651, #cached-token: 9, token usage: 0.94, #running-req: 91, #queue-req: 1155, 
[1,0]<stderr>:[2025-10-10 10:19:47 TP0] Prefill batch. #new-seq: 2, #new-token: 971, #cached-token: 2, token usage: 0.95, #running-req: 92, #queue-req: 1153, 
[1,0]<stderr>:[2025-10-10 10:19:48 TP0] Decode batch. #running-req: 93, #token: 63831, token usage: 0.97, cuda graph: False, gen throughput (token/s): 730.70, #queue-req: 1153, 
[1,0]<stderr>:[2025-10-10 10:19:49 TP0] Prefill batch. #new-seq: 3, #new-token: 376, #cached-token: 5, token usage: 0.96, #running-req: 89, #queue-req: 1150, 
[1,0]<stderr>:[2025-10-10 10:19:49 TP0] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 6, token usage: 0.96, #running-req: 91, #queue-req: 1149, 
[1,0]<stderr>:[2025-10-10 10:19:49 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.96, #running-req: 91, #queue-req: 1148, 
[1,0]<stderr>:[2025-10-10 10:19:52 TP0] Prefill batch. #new-seq: 4, #new-token: 2472, #cached-token: 8, token usage: 0.91, #running-req: 83, #queue-req: 1144, 
[1,0]<stderr>:[2025-10-10 10:19:52 TP0] Prefill batch. #new-seq: 2, #new-token: 103, #cached-token: 2, token usage: 0.95, #running-req: 86, #queue-req: 1142, 
[1,0]<stderr>:[2025-10-10 10:19:53 TP0] Prefill batch. #new-seq: 4, #new-token: 775, #cached-token: 5, token usage: 0.94, #running-req: 87, #queue-req: 1138, 
[1,0]<stderr>:[2025-10-10 10:19:53 TP0] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 4, token usage: 0.95, #running-req: 90, #queue-req: 1137, 
[1,0]<stderr>:[2025-10-10 10:19:53 TP0] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 1, token usage: 0.95, #running-req: 90, #queue-req: 1136, 
[1,0]<stderr>:[2025-10-10 10:19:54 TP0] Decode batch. #running-req: 91, #token: 63268, token usage: 0.97, cuda graph: False, gen throughput (token/s): 658.24, #queue-req: 1136, 
[1,0]<stderr>:[2025-10-10 10:19:55 TP0] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 2, token usage: 0.94, #running-req: 86, #queue-req: 1135, 
[1,0]<stderr>:[2025-10-10 10:19:55 TP0] Prefill batch. #new-seq: 3, #new-token: 1253, #cached-token: 3, token usage: 0.95, #running-req: 86, #queue-req: 1132, 
[1,0]<stderr>:[2025-10-10 10:19:55 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.96, #running-req: 88, #queue-req: 1131, 
[1,0]<stderr>:[2025-10-10 10:19:56 TP0] Prefill batch. #new-seq: 2, #new-token: 424, #cached-token: 4, token usage: 0.96, #running-req: 88, #queue-req: 1129, 
[1,0]<stderr>:[2025-10-10 10:19:56 TP0] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 1, token usage: 0.95, #running-req: 88, #queue-req: 1128, 
[1,0]<stderr>:[2025-10-10 10:19:57 TP0] Prefill batch. #new-seq: 2, #new-token: 327, #cached-token: 2, token usage: 0.96, #running-req: 88, #queue-req: 1126, 
[1,0]<stderr>:[2025-10-10 10:19:57 TP0] Prefill batch. #new-seq: 3, #new-token: 739, #cached-token: 3, token usage: 0.94, #running-req: 88, #queue-req: 1123, 
[1,0]<stderr>:[2025-10-10 10:19:58 TP0] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 1, token usage: 0.95, #running-req: 90, #queue-req: 1122, 
[1,0]<stderr>:[2025-10-10 10:19:58 TP0] Prefill batch. #new-seq: 4, #new-token: 1075, #cached-token: 6, token usage: 0.94, #running-req: 90, #queue-req: 1118, 
[1,0]<stderr>:[2025-10-10 10:19:58 TP0] Prefill batch. #new-seq: 1, #new-token: 630, #cached-token: 1, token usage: 0.95, #running-req: 91, #queue-req: 1117, 
[1,0]<stderr>:[2025-10-10 10:20:00 TP0] Decode batch. #running-req: 89, #token: 62958, token usage: 0.96, cuda graph: False, gen throughput (token/s): 615.57, #queue-req: 1117, 
[1,0]<stderr>:[2025-10-10 10:20:00 TP0] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 4, token usage: 0.96, #running-req: 88, #queue-req: 1116, 
[1,0]<stderr>:[2025-10-10 10:20:01 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 4, token usage: 0.96, #running-req: 88, #queue-req: 1115, 
[1,0]<stderr>:[2025-10-10 10:20:01 TP0] Prefill batch. #new-seq: 2, #new-token: 580, #cached-token: 5, token usage: 0.93, #running-req: 88, #queue-req: 1113, 
[1,0]<stderr>:[2025-10-10 10:20:02 TP0] Prefill batch. #new-seq: 1, #new-token: 986, #cached-token: 1, token usage: 0.94, #running-req: 89, #queue-req: 1112, 
[1,0]<stderr>:[2025-10-10 10:20:02 TP0] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 2, token usage: 0.95, #running-req: 89, #queue-req: 1111, 
[1,0]<stderr>:[2025-10-10 10:20:02 TP0] Prefill batch. #new-seq: 8, #new-token: 1964, #cached-token: 18, token usage: 0.91, #running-req: 88, #queue-req: 1103, 
[1,0]<stderr>:[2025-10-10 10:20:03 TP0] Prefill batch. #new-seq: 12, #new-token: 1627, #cached-token: 22, token usage: 0.90, #running-req: 94, #queue-req: 1091, 
[1,0]<stderr>:[2025-10-10 10:20:03 TP0] Prefill batch. #new-seq: 7, #new-token: 2044, #cached-token: 23, token usage: 0.91, #running-req: 104, #queue-req: 1084, 
[1,0]<stderr>:[2025-10-10 10:20:03 TP0] Prefill batch. #new-seq: 10, #new-token: 1762, #cached-token: 23, token usage: 0.92, #running-req: 110, #queue-req: 1074, 
[1,0]<stderr>:[2025-10-10 10:20:04 TP0] Prefill batch. #new-seq: 3, #new-token: 2308, #cached-token: 3, token usage: 0.92, #running-req: 118, #queue-req: 1071, 
[1,0]<stderr>:[2025-10-10 10:20:04 TP0] Prefill batch. #new-seq: 2, #new-token: 622, #cached-token: 2, token usage: 0.94, #running-req: 118, #queue-req: 1069, 
[1,0]<stderr>:[2025-10-10 10:20:04 TP0] Prefill batch. #new-seq: 3, #new-token: 497, #cached-token: 11, token usage: 0.94, #running-req: 119, #queue-req: 1066, 
[1,0]<stderr>:[2025-10-10 10:20:05 TP0] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 3, token usage: 0.94, #running-req: 121, #queue-req: 1065, 
[1,0]<stderr>:[2025-10-10 10:20:05 TP0] Prefill batch. #new-seq: 3, #new-token: 713, #cached-token: 8, token usage: 0.93, #running-req: 119, #queue-req: 1062, 
[1,0]<stderr>:[2025-10-10 10:20:06 TP0] Prefill batch. #new-seq: 3, #new-token: 399, #cached-token: 7, token usage: 0.94, #running-req: 118, #queue-req: 1059, 
[1,0]<stderr>:[2025-10-10 10:20:06 TP0] Prefill batch. #new-seq: 6, #new-token: 658, #cached-token: 8, token usage: 0.93, #running-req: 120, #queue-req: 1053, 
[1,0]<stderr>:[2025-10-10 10:20:06 TP0] Decode batch. #running-req: 126, #token: 61260, token usage: 0.93, cuda graph: False, gen throughput (token/s): 630.12, #queue-req: 1053, 
[1,0]<stderr>:[2025-10-10 10:20:06 TP0] Prefill batch. #new-seq: 2, #new-token: 1234, #cached-token: 11, token usage: 0.92, #running-req: 125, #queue-req: 1051, 
[1,0]<stderr>:[2025-10-10 10:20:06 TP0] Prefill batch. #new-seq: 20, #new-token: 3973, #cached-token: 41, token usage: 0.84, #running-req: 124, #queue-req: 1031, 
[1,0]<stderr>:[2025-10-10 10:20:07 TP0] Prefill batch. #new-seq: 3, #new-token: 929, #cached-token: 3, token usage: 0.90, #running-req: 143, #queue-req: 1028, 
[1,0]<stderr>:[2025-10-10 10:20:07 TP0] Prefill batch. #new-seq: 5, #new-token: 3871, #cached-token: 13, token usage: 0.87, #running-req: 144, #queue-req: 1023, 
[1,0]<stderr>:[2025-10-10 10:20:08 TP0] Prefill batch. #new-seq: 3, #new-token: 925, #cached-token: 6, token usage: 0.92, #running-req: 146, #queue-req: 1020, 
[1,0]<stderr>:[2025-10-10 10:20:08 TP0] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 1, token usage: 0.93, #running-req: 147, #queue-req: 1019, 
[1,0]<stderr>:[2025-10-10 10:20:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 1, token usage: 0.93, #running-req: 145, #queue-req: 1018, 
[1,0]<stderr>:[2025-10-10 10:20:09 TP0] Prefill batch. #new-seq: 5, #new-token: 745, #cached-token: 8, token usage: 0.93, #running-req: 143, #queue-req: 1013, 
[1,0]<stderr>:[2025-10-10 10:20:10 TP0] Prefill batch. #new-seq: 3, #new-token: 1117, #cached-token: 5, token usage: 0.92, #running-req: 144, #queue-req: 1010, 
[1,0]<stderr>:[2025-10-10 10:20:11 TP0] Prefill batch. #new-seq: 5, #new-token: 2912, #cached-token: 14, token usage: 0.89, #running-req: 139, #queue-req: 1005, 
[1,0]<stderr>:[2025-10-10 10:20:12 TP0] Prefill batch. #new-seq: 4, #new-token: 444, #cached-token: 7, token usage: 0.91, #running-req: 137, #queue-req: 1001, 
[1,0]<stderr>:[2025-10-10 10:20:12 TP0] Prefill batch. #new-seq: 4, #new-token: 958, #cached-token: 8, token usage: 0.91, #running-req: 138, #queue-req: 997, 
[1,0]<stderr>:[2025-10-10 10:20:12 TP0] Decode batch. #running-req: 138, #token: 60698, token usage: 0.93, cuda graph: False, gen throughput (token/s): 961.41, #queue-req: 997, 
[1,0]<stderr>:[2025-10-10 10:20:13 TP0] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 1, token usage: 0.93, #running-req: 141, #queue-req: 996, 
[1,0]<stderr>:[2025-10-10 10:20:13 TP0] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 1, token usage: 0.93, #running-req: 139, #queue-req: 995, 
[1,0]<stderr>:[2025-10-10 10:20:14 TP0] Prefill batch. #new-seq: 1, #new-token: 798, #cached-token: 2, token usage: 0.93, #running-req: 136, #queue-req: 994, 
[1,0]<stderr>:[2025-10-10 10:20:15 TP0] Prefill batch. #new-seq: 3, #new-token: 2139, #cached-token: 5, token usage: 0.90, #running-req: 130, #queue-req: 991, 
[1,0]<stderr>:[2025-10-10 10:20:15 TP0] Prefill batch. #new-seq: 2, #new-token: 147, #cached-token: 5, token usage: 0.94, #running-req: 132, #queue-req: 989, 
[1,0]<stderr>:[2025-10-10 10:20:16 TP0] Prefill batch. #new-seq: 6, #new-token: 1382, #cached-token: 10, token usage: 0.92, #running-req: 133, #queue-req: 983, 
[1,0]<stderr>:[2025-10-10 10:20:17 TP0] Prefill batch. #new-seq: 3, #new-token: 774, #cached-token: 12, token usage: 0.93, #running-req: 137, #queue-req: 980, 
[1,0]<stderr>:[2025-10-10 10:20:17 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.94, #running-req: 139, #queue-req: 979, 
[1,0]<stderr>:[2025-10-10 10:20:17 TP0] Prefill batch. #new-seq: 2, #new-token: 641, #cached-token: 4, token usage: 0.94, #running-req: 139, #queue-req: 977, 
[1,0]<stderr>:[2025-10-10 10:20:18 TP0] Decode batch. #running-req: 139, #token: 62603, token usage: 0.96, cuda graph: False, gen throughput (token/s): 952.21, #queue-req: 977, 
[1,0]<stderr>:[2025-10-10 10:20:22 TP0] Decode batch. #running-req: 122, #token: 61458, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1176.31, #queue-req: 977, 
[1,0]<stderr>:[2025-10-10 10:20:22 TP0] Prefill batch. #new-seq: 1, #new-token: 2428, #cached-token: 1, token usage: 0.92, #running-req: 121, #queue-req: 976, 
[1,0]<stderr>:[2025-10-10 10:20:23 TP0] Prefill batch. #new-seq: 7, #new-token: 1617, #cached-token: 18, token usage: 0.93, #running-req: 120, #queue-req: 969, 
[1,0]<stderr>:[2025-10-10 10:20:23 TP0] Prefill batch. #new-seq: 5, #new-token: 615, #cached-token: 11, token usage: 0.94, #running-req: 126, #queue-req: 964, 
[1,0]<stderr>:[2025-10-10 10:20:24 TP0] Prefill batch. #new-seq: 1, #new-token: 2032, #cached-token: 2, token usage: 0.92, #running-req: 126, #queue-req: 963, 
[1,0]<stderr>:[2025-10-10 10:20:25 TP0] Prefill batch. #new-seq: 3, #new-token: 969, #cached-token: 8, token usage: 0.93, #running-req: 124, #queue-req: 960, 
[1,0]<stderr>:[2025-10-10 10:20:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1101, #cached-token: 1, token usage: 0.94, #running-req: 125, #queue-req: 959, 
[1,0]<stderr>:[2025-10-10 10:20:25 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.96, #running-req: 124, #queue-req: 958, 
[1,0]<stderr>:[2025-10-10 10:20:26 TP0] Prefill batch. #new-seq: 2, #new-token: 284, #cached-token: 3, token usage: 0.94, #running-req: 121, #queue-req: 956, 
[1,0]<stderr>:[2025-10-10 10:20:26 TP0] Prefill batch. #new-seq: 4, #new-token: 1069, #cached-token: 8, token usage: 0.93, #running-req: 122, #queue-req: 952, 
[1,0]<stderr>:[2025-10-10 10:20:26 TP0] Prefill batch. #new-seq: 4, #new-token: 1993, #cached-token: 4, token usage: 0.92, #running-req: 124, #queue-req: 948, 
[1,0]<stderr>:[2025-10-10 10:20:27 TP0] Prefill batch. #new-seq: 3, #new-token: 1271, #cached-token: 5, token usage: 0.93, #running-req: 124, #queue-req: 945, 
[1,0]<stderr>:[2025-10-10 10:20:27 TP0] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 1, token usage: 0.95, #running-req: 126, #queue-req: 944, 
[1,0]<stderr>:[2025-10-10 10:20:28 TP0] Prefill batch. #new-seq: 2, #new-token: 556, #cached-token: 3, token usage: 0.95, #running-req: 124, #queue-req: 942, 
[1,0]<stderr>:[2025-10-10 10:20:28 TP0] Decode batch. #running-req: 124, #token: 62507, token usage: 0.95, cuda graph: False, gen throughput (token/s): 834.42, #queue-req: 942, 
[1,0]<stderr>:[2025-10-10 10:20:28 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 1, token usage: 0.95, #running-req: 123, #queue-req: 941, 
[1,0]<stderr>:[2025-10-10 10:20:29 TP0] Prefill batch. #new-seq: 3, #new-token: 725, #cached-token: 6, token usage: 0.94, #running-req: 121, #queue-req: 938, 
[1,0]<stderr>:[2025-10-10 10:20:29 TP0] Prefill batch. #new-seq: 2, #new-token: 339, #cached-token: 3, token usage: 0.95, #running-req: 123, #queue-req: 936, 
[1,0]<stderr>:[2025-10-10 10:20:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1117, #cached-token: 1, token usage: 0.94, #running-req: 117, #queue-req: 935, 
[1,0]<stderr>:[2025-10-10 10:20:32 TP0] Prefill batch. #new-seq: 1, #new-token: 782, #cached-token: 1, token usage: 0.95, #running-req: 112, #queue-req: 934, 
[1,0]<stderr>:[2025-10-10 10:20:32 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.95, #running-req: 112, #queue-req: 933, 
[1,0]<stderr>:[2025-10-10 10:20:33 TP0] Prefill batch. #new-seq: 2, #new-token: 48, #cached-token: 2, token usage: 0.94, #running-req: 111, #queue-req: 931, 
[1,0]<stderr>:[2025-10-10 10:20:33 TP0] Prefill batch. #new-seq: 4, #new-token: 635, #cached-token: 7, token usage: 0.94, #running-req: 109, #queue-req: 927, 
[1,0]<stderr>:[2025-10-10 10:20:34 TP0] Decode batch. #running-req: 113, #token: 60144, token usage: 0.92, cuda graph: False, gen throughput (token/s): 861.86, #queue-req: 927, 
[1,0]<stderr>:[2025-10-10 10:20:34 TP0] Prefill batch. #new-seq: 3, #new-token: 2395, #cached-token: 14, token usage: 0.92, #running-req: 112, #queue-req: 924, 
[1,0]<stderr>:[2025-10-10 10:20:34 TP0] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 2, token usage: 0.96, #running-req: 113, #queue-req: 923, 
[1,0]<stderr>:[2025-10-10 10:20:35 TP0] Prefill batch. #new-seq: 2, #new-token: 38, #cached-token: 3, token usage: 0.95, #running-req: 110, #queue-req: 921, 
[1,0]<stderr>:[2025-10-10 10:20:36 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.95, #running-req: 111, #queue-req: 920, 
[1,0]<stderr>:[2025-10-10 10:20:36 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 1, token usage: 0.95, #running-req: 111, #queue-req: 919, 
[1,0]<stderr>:[2025-10-10 10:20:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1779, #cached-token: 1, token usage: 0.93, #running-req: 106, #queue-req: 918, 
[1,0]<stderr>:[2025-10-10 10:20:39 TP0] Decode batch. #running-req: 106, #token: 62572, token usage: 0.95, cuda graph: False, gen throughput (token/s): 839.39, #queue-req: 918, 
[1,0]<stderr>:[2025-10-10 10:20:40 TP0] Prefill batch. #new-seq: 5, #new-token: 3000, #cached-token: 9, token usage: 0.89, #running-req: 101, #queue-req: 913, 
[1,0]<stderr>:[2025-10-10 10:20:44 TP0] Decode batch. #running-req: 93, #token: 60310, token usage: 0.92, cuda graph: False, gen throughput (token/s): 849.27, #queue-req: 913, 
[1,0]<stderr>:[2025-10-10 10:20:44 TP0] Prefill batch. #new-seq: 4, #new-token: 3539, #cached-token: 5, token usage: 0.90, #running-req: 92, #queue-req: 909, 
[1,0]<stderr>:[2025-10-10 10:20:45 TP0] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 1, token usage: 0.95, #running-req: 95, #queue-req: 908, 
[1,0]<stderr>:[2025-10-10 10:20:45 TP0] Prefill batch. #new-seq: 4, #new-token: 1151, #cached-token: 7, token usage: 0.94, #running-req: 94, #queue-req: 904, 
[1,0]<stderr>:[2025-10-10 10:20:46 TP0] Prefill batch. #new-seq: 3, #new-token: 1021, #cached-token: 8, token usage: 0.94, #running-req: 97, #queue-req: 901, 
[1,0]<stderr>:[2025-10-10 10:20:46 TP0] Prefill batch. #new-seq: 3, #new-token: 335, #cached-token: 3, token usage: 0.95, #running-req: 98, #queue-req: 898, 
[1,0]<stderr>:[2025-10-10 10:20:47 TP0] Prefill batch. #new-seq: 2, #new-token: 372, #cached-token: 4, token usage: 0.95, #running-req: 100, #queue-req: 896, 
[1,0]<stderr>:[2025-10-10 10:20:47 TP0] Prefill batch. #new-seq: 6, #new-token: 683, #cached-token: 16, token usage: 0.94, #running-req: 101, #queue-req: 890, 
[1,0]<stderr>:[2025-10-10 10:20:47 TP0] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 2, token usage: 0.95, #running-req: 105, #queue-req: 889, 
[1,0]<stderr>:[2025-10-10 10:20:48 TP0] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 3, token usage: 0.95, #running-req: 105, #queue-req: 888, 
[1,0]<stderr>:[2025-10-10 10:20:49 TP0] Prefill batch. #new-seq: 2, #new-token: 289, #cached-token: 4, token usage: 0.94, #running-req: 102, #queue-req: 886, 
[1,0]<stderr>:[2025-10-10 10:20:49 TP0] Decode batch. #running-req: 102, #token: 61460, token usage: 0.94, cuda graph: False, gen throughput (token/s): 692.11, #queue-req: 886, 
[1,0]<stderr>:[2025-10-10 10:20:50 TP0] Prefill batch. #new-seq: 3, #new-token: 1112, #cached-token: 5, token usage: 0.94, #running-req: 102, #queue-req: 883, 
[1,0]<stderr>:[2025-10-10 10:20:50 TP0] Prefill batch. #new-seq: 6, #new-token: 1258, #cached-token: 10, token usage: 0.91, #running-req: 102, #queue-req: 877, 
[1,0]<stderr>:[2025-10-10 10:20:50 TP0] Prefill batch. #new-seq: 3, #new-token: 1111, #cached-token: 5, token usage: 0.93, #running-req: 107, #queue-req: 874, 
[1,0]<stderr>:[2025-10-10 10:20:51 TP0] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 1, token usage: 0.94, #running-req: 109, #queue-req: 873, 
[1,0]<stderr>:[2025-10-10 10:20:53 TP0] Prefill batch. #new-seq: 3, #new-token: 3633, #cached-token: 9, token usage: 0.89, #running-req: 101, #queue-req: 870, 
[1,0]<stderr>:[2025-10-10 10:20:53 TP0] Prefill batch. #new-seq: 3, #new-token: 94, #cached-token: 6, token usage: 0.95, #running-req: 103, #queue-req: 867, 
[1,0]<stderr>:[2025-10-10 10:20:54 TP0] Prefill batch. #new-seq: 2, #new-token: 56, #cached-token: 4, token usage: 0.94, #running-req: 104, #queue-req: 865, 
[1,0]<stderr>:[2025-10-10 10:20:55 TP0] Decode batch. #running-req: 106, #token: 61891, token usage: 0.94, cuda graph: False, gen throughput (token/s): 756.48, #queue-req: 865, 
[1,0]<stderr>:[2025-10-10 10:20:55 TP0] Prefill batch. #new-seq: 2, #new-token: 289, #cached-token: 3, token usage: 0.95, #running-req: 105, #queue-req: 863, 
[1,0]<stderr>:[2025-10-10 10:20:55 TP0] Prefill batch. #new-seq: 4, #new-token: 1288, #cached-token: 12, token usage: 0.94, #running-req: 104, #queue-req: 859, 
[1,0]<stderr>:[2025-10-10 10:20:56 TP0] Prefill batch. #new-seq: 3, #new-token: 541, #cached-token: 7, token usage: 0.95, #running-req: 106, #queue-req: 856, 
[1,0]<stderr>:[2025-10-10 10:20:57 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.96, #running-req: 108, #queue-req: 855, 
[1,0]<stderr>:[2025-10-10 10:20:57 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 1, token usage: 0.95, #running-req: 108, #queue-req: 854, 
[1,0]<stderr>:[2025-10-10 10:20:58 TP0] Prefill batch. #new-seq: 3, #new-token: 966, #cached-token: 5, token usage: 0.94, #running-req: 103, #queue-req: 851, 
[1,0]<stderr>:[2025-10-10 10:20:59 TP0] Prefill batch. #new-seq: 2, #new-token: 461, #cached-token: 4, token usage: 0.96, #running-req: 104, #queue-req: 849, 
[1,0]<stderr>:[2025-10-10 10:20:59 TP0] Prefill batch. #new-seq: 3, #new-token: 889, #cached-token: 4, token usage: 0.94, #running-req: 102, #queue-req: 846, 
[1,0]<stderr>:[2025-10-10 10:21:00 TP0] Prefill batch. #new-seq: 1, #new-token: 674, #cached-token: 1, token usage: 0.95, #running-req: 101, #queue-req: 845, 
[1,0]<stderr>:[2025-10-10 10:21:01 TP0] Decode batch. #running-req: 101, #token: 62665, token usage: 0.96, cuda graph: False, gen throughput (token/s): 742.66, #queue-req: 845, 
[1,0]<stderr>:[2025-10-10 10:21:01 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 4, token usage: 0.95, #running-req: 97, #queue-req: 844, 
[1,0]<stderr>:[2025-10-10 10:21:02 TP0] Prefill batch. #new-seq: 2, #new-token: 820, #cached-token: 3, token usage: 0.95, #running-req: 97, #queue-req: 842, 
[1,0]<stderr>:[2025-10-10 10:21:02 TP0] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 1, token usage: 0.95, #running-req: 98, #queue-req: 841, 
[1,0]<stderr>:[2025-10-10 10:21:03 TP0] Prefill batch. #new-seq: 6, #new-token: 1291, #cached-token: 21, token usage: 0.90, #running-req: 96, #queue-req: 835, 
[1,0]<stderr>:[2025-10-10 10:21:03 TP0] Prefill batch. #new-seq: 11, #new-token: 2693, #cached-token: 21, token usage: 0.89, #running-req: 100, #queue-req: 824, 
[1,0]<stderr>:[2025-10-10 10:21:04 TP0] Prefill batch. #new-seq: 11, #new-token: 3412, #cached-token: 23, token usage: 0.89, #running-req: 110, #queue-req: 813, 
[1,0]<stderr>:[2025-10-10 10:21:04 TP0] Prefill batch. #new-seq: 2, #new-token: 838, #cached-token: 3, token usage: 0.94, #running-req: 120, #queue-req: 811, 
[1,0]<stderr>:[2025-10-10 10:21:04 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 3, token usage: 0.95, #running-req: 121, #queue-req: 810, 
[1,0]<stderr>:[2025-10-10 10:21:04 TP0] Prefill batch. #new-seq: 2, #new-token: 665, #cached-token: 2, token usage: 0.94, #running-req: 120, #queue-req: 808, 
[1,0]<stderr>:[2025-10-10 10:21:04 TP0] Prefill batch. #new-seq: 7, #new-token: 1304, #cached-token: 11, token usage: 0.91, #running-req: 119, #queue-req: 801, 
[1,0]<stderr>:[2025-10-10 10:21:05 TP0] Prefill batch. #new-seq: 2, #new-token: 1429, #cached-token: 14, token usage: 0.92, #running-req: 125, #queue-req: 799, 
[1,0]<stderr>:[2025-10-10 10:21:05 TP0] Prefill batch. #new-seq: 3, #new-token: 876, #cached-token: 12, token usage: 0.93, #running-req: 126, #queue-req: 796, 
[1,0]<stderr>:[2025-10-10 10:21:05 TP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.94, #running-req: 126, #queue-req: 792, 
[1,0]<stderr>:[2025-10-10 10:21:06 TP0] Prefill batch. #new-seq: 4, #new-token: 502, #cached-token: 6, token usage: 0.94, #running-req: 129, #queue-req: 788, 
[1,0]<stderr>:[2025-10-10 10:21:06 TP0] Prefill batch. #new-seq: 3, #new-token: 302, #cached-token: 8, token usage: 0.93, #running-req: 131, #queue-req: 785, 
[1,0]<stderr>:[2025-10-10 10:21:06 TP0] Prefill batch. #new-seq: 2, #new-token: 823, #cached-token: 4, token usage: 0.94, #running-req: 133, #queue-req: 783, 
[1,0]<stderr>:[2025-10-10 10:21:07 TP0] Decode batch. #running-req: 134, #token: 61148, token usage: 0.93, cuda graph: False, gen throughput (token/s): 713.40, #queue-req: 783, 
[1,0]<stderr>:[2025-10-10 10:21:07 TP0] Prefill batch. #new-seq: 4, #new-token: 1136, #cached-token: 6, token usage: 0.93, #running-req: 133, #queue-req: 779, 
[1,0]<stderr>:[2025-10-10 10:21:09 TP0] Prefill batch. #new-seq: 2, #new-token: 631, #cached-token: 2, token usage: 0.93, #running-req: 130, #queue-req: 777, 
[1,0]<stderr>:[2025-10-10 10:21:09 TP0] Prefill batch. #new-seq: 4, #new-token: 900, #cached-token: 6, token usage: 0.92, #running-req: 129, #queue-req: 773, 
[1,0]<stderr>:[2025-10-10 10:21:09 TP0] Prefill batch. #new-seq: 1, #new-token: 640, #cached-token: 4, token usage: 0.93, #running-req: 131, #queue-req: 772, 
[1,0]<stderr>:[2025-10-10 10:21:10 TP0] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 2, token usage: 0.93, #running-req: 129, #queue-req: 771, 
[1,0]<stderr>:[2025-10-10 10:21:10 TP0] Prefill batch. #new-seq: 3, #new-token: 182, #cached-token: 8, token usage: 0.94, #running-req: 129, #queue-req: 768, 
[1,0]<stderr>:[2025-10-10 10:21:10 TP0] Prefill batch. #new-seq: 3, #new-token: 846, #cached-token: 24, token usage: 0.93, #running-req: 131, #queue-req: 765, 
[1,0]<stderr>:[2025-10-10 10:21:10 TP0] Prefill batch. #new-seq: 5, #new-token: 794, #cached-token: 10, token usage: 0.92, #running-req: 131, #queue-req: 760, 
[1,0]<stderr>:[2025-10-10 10:21:11 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.94, #running-req: 135, #queue-req: 759, 
[1,0]<stderr>:[2025-10-10 10:21:11 TP0] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 2, token usage: 0.93, #running-req: 133, #queue-req: 758, 
[1,0]<stderr>:[2025-10-10 10:21:12 TP0] Prefill batch. #new-seq: 2, #new-token: 195, #cached-token: 6, token usage: 0.94, #running-req: 132, #queue-req: 756, 
[1,0]<stderr>:[2025-10-10 10:21:12 TP0] Prefill batch. #new-seq: 2, #new-token: 116, #cached-token: 3, token usage: 0.94, #running-req: 133, #queue-req: 754, 
[1,0]<stderr>:[2025-10-10 10:21:12 TP0] Prefill batch. #new-seq: 2, #new-token: 334, #cached-token: 2, token usage: 0.94, #running-req: 134, #queue-req: 752, 
[1,0]<stderr>:[2025-10-10 10:21:12 TP0] Prefill batch. #new-seq: 5, #new-token: 2147, #cached-token: 17, token usage: 0.90, #running-req: 134, #queue-req: 747, 
[1,0]<stderr>:[2025-10-10 10:21:13 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.94, #running-req: 138, #queue-req: 746, 
[1,0]<stderr>:[2025-10-10 10:21:13 TP0] Decode batch. #running-req: 139, #token: 62408, token usage: 0.95, cuda graph: False, gen throughput (token/s): 860.40, #queue-req: 746, 
[1,0]<stderr>:[2025-10-10 10:21:14 TP0] Prefill batch. #new-seq: 7, #new-token: 1387, #cached-token: 12, token usage: 0.92, #running-req: 136, #queue-req: 739, 
[1,0]<stderr>:[2025-10-10 10:21:14 TP0] Prefill batch. #new-seq: 3, #new-token: 417, #cached-token: 6, token usage: 0.94, #running-req: 136, #queue-req: 736, 
[1,0]<stderr>:[2025-10-10 10:21:14 TP0] Prefill batch. #new-seq: 2, #new-token: 61, #cached-token: 4, token usage: 0.94, #running-req: 138, #queue-req: 734, 
[1,0]<stderr>:[2025-10-10 10:21:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1156, #cached-token: 1, token usage: 0.93, #running-req: 130, #queue-req: 733, 
[1,0]<stderr>:[2025-10-10 10:21:17 TP0] Prefill batch. #new-seq: 3, #new-token: 316, #cached-token: 4, token usage: 0.94, #running-req: 127, #queue-req: 730, 
[1,0]<stderr>:[2025-10-10 10:21:17 TP0] Prefill batch. #new-seq: 2, #new-token: 60, #cached-token: 5, token usage: 0.93, #running-req: 129, #queue-req: 728, 
[1,0]<stderr>:[2025-10-10 10:21:18 TP0] Prefill batch. #new-seq: 2, #new-token: 732, #cached-token: 4, token usage: 0.93, #running-req: 129, #queue-req: 726, 
[1,0]<stderr>:[2025-10-10 10:21:18 TP0] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 4, token usage: 0.94, #running-req: 129, #queue-req: 725, 
[1,0]<stderr>:[2025-10-10 10:21:19 TP0] Decode batch. #running-req: 130, #token: 62252, token usage: 0.95, cuda graph: False, gen throughput (token/s): 984.82, #queue-req: 725, 
[1,0]<stderr>:[2025-10-10 10:21:19 TP0] Prefill batch. #new-seq: 3, #new-token: 1460, #cached-token: 6, token usage: 0.92, #running-req: 128, #queue-req: 722, 
[1,0]<stderr>:[2025-10-10 10:21:21 TP0] Prefill batch. #new-seq: 4, #new-token: 595, #cached-token: 7, token usage: 0.94, #running-req: 125, #queue-req: 718, 
[1,0]<stderr>:[2025-10-10 10:21:22 TP0] Prefill batch. #new-seq: 2, #new-token: 413, #cached-token: 9, token usage: 0.95, #running-req: 127, #queue-req: 716, 
[1,0]<stderr>:[2025-10-10 10:21:22 TP0] Prefill batch. #new-seq: 5, #new-token: 345, #cached-token: 12, token usage: 0.92, #running-req: 125, #queue-req: 711, 
[1,0]<stderr>:[2025-10-10 10:21:23 TP0] Prefill batch. #new-seq: 5, #new-token: 1228, #cached-token: 9, token usage: 0.93, #running-req: 129, #queue-req: 706, 
[1,0]<stderr>:[2025-10-10 10:21:24 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.94, #running-req: 132, #queue-req: 705, 
[1,0]<stderr>:[2025-10-10 10:21:24 TP0] Decode batch. #running-req: 132, #token: 61506, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1026.57, #queue-req: 705, 
[1,0]<stderr>:[2025-10-10 10:21:24 TP0] Prefill batch. #new-seq: 1, #new-token: 833, #cached-token: 1, token usage: 0.94, #running-req: 132, #queue-req: 704, 
[1,0]<stderr>:[2025-10-10 10:21:24 TP0] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 1, token usage: 0.95, #running-req: 131, #queue-req: 703, 
[1,0]<stderr>:[2025-10-10 10:21:24 TP0] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 2, token usage: 0.94, #running-req: 130, #queue-req: 702, 
[1,0]<stderr>:[2025-10-10 10:21:25 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 1, token usage: 0.95, #running-req: 130, #queue-req: 701, 
[1,0]<stderr>:[2025-10-10 10:21:25 TP0] Prefill batch. #new-seq: 2, #new-token: 664, #cached-token: 3, token usage: 0.94, #running-req: 130, #queue-req: 699, 
[1,0]<stderr>:[2025-10-10 10:21:25 TP0] Prefill batch. #new-seq: 2, #new-token: 94, #cached-token: 2, token usage: 0.94, #running-req: 130, #queue-req: 697, 
[1,0]<stderr>:[2025-10-10 10:21:25 TP0] Prefill batch. #new-seq: 3, #new-token: 1836, #cached-token: 4, token usage: 0.90, #running-req: 129, #queue-req: 694, 
[1,0]<stderr>:[2025-10-10 10:21:27 TP0] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 1, token usage: 0.86, #running-req: 123, #queue-req: 693, 
[1,0]<stderr>:[2025-10-10 10:21:28 TP0] Prefill batch. #new-seq: 2, #new-token: 1831, #cached-token: 2, token usage: 0.92, #running-req: 120, #queue-req: 691, 
[1,0]<stderr>:[2025-10-10 10:21:28 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.95, #running-req: 121, #queue-req: 690, 
[1,0]<stderr>:[2025-10-10 10:21:30 TP0] Decode batch. #running-req: 120, #token: 63051, token usage: 0.96, cuda graph: False, gen throughput (token/s): 884.38, #queue-req: 690, 
[1,0]<stderr>:[2025-10-10 10:21:30 TP0] Prefill batch. #new-seq: 4, #new-token: 2286, #cached-token: 5, token usage: 0.89, #running-req: 119, #queue-req: 686, 
[1,0]<stderr>:[2025-10-10 10:21:30 TP0] Prefill batch. #new-seq: 1, #new-token: 454, #cached-token: 3, token usage: 0.92, #running-req: 121, #queue-req: 685, 
[1,0]<stderr>:[2025-10-10 10:21:30 TP0] Prefill batch. #new-seq: 1, #new-token: 2073, #cached-token: 1, token usage: 0.92, #running-req: 121, #queue-req: 684, 
[1,0]<stderr>:[2025-10-10 10:21:31 TP0] Prefill batch. #new-seq: 4, #new-token: 289, #cached-token: 9, token usage: 0.93, #running-req: 119, #queue-req: 680, 
[1,0]<stderr>:[2025-10-10 10:21:32 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 3, token usage: 0.94, #running-req: 120, #queue-req: 679, 
[1,0]<stderr>:[2025-10-10 10:21:32 TP0] Prefill batch. #new-seq: 6, #new-token: 1228, #cached-token: 11, token usage: 0.93, #running-req: 119, #queue-req: 673, 
[1,0]<stderr>:[2025-10-10 10:21:33 TP0] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 3, token usage: 0.94, #running-req: 123, #queue-req: 672, 
[1,0]<stderr>:[2025-10-10 10:21:34 TP0] Prefill batch. #new-seq: 2, #new-token: 1232, #cached-token: 5, token usage: 0.94, #running-req: 120, #queue-req: 670, 
[1,0]<stderr>:[2025-10-10 10:21:34 TP0] Prefill batch. #new-seq: 2, #new-token: 321, #cached-token: 11, token usage: 0.94, #running-req: 119, #queue-req: 668, 
[1,0]<stderr>:[2025-10-10 10:21:35 TP0] Prefill batch. #new-seq: 3, #new-token: 740, #cached-token: 6, token usage: 0.94, #running-req: 119, #queue-req: 665, 
[1,0]<stderr>:[2025-10-10 10:21:35 TP0] Decode batch. #running-req: 122, #token: 62122, token usage: 0.95, cuda graph: False, gen throughput (token/s): 847.71, #queue-req: 665, 
[1,0]<stderr>:[2025-10-10 10:21:35 TP0] Prefill batch. #new-seq: 3, #new-token: 421, #cached-token: 10, token usage: 0.94, #running-req: 121, #queue-req: 662, 
[1,0]<stderr>:[2025-10-10 10:21:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1200, #cached-token: 1, token usage: 0.94, #running-req: 120, #queue-req: 661, 
[1,0]<stderr>:[2025-10-10 10:21:37 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.95, #running-req: 119, #queue-req: 660, 
[1,0]<stderr>:[2025-10-10 10:21:37 TP0] Prefill batch. #new-seq: 2, #new-token: 127, #cached-token: 2, token usage: 0.94, #running-req: 118, #queue-req: 658, 
[1,0]<stderr>:[2025-10-10 10:21:38 TP0] Prefill batch. #new-seq: 3, #new-token: 133, #cached-token: 5, token usage: 0.95, #running-req: 119, #queue-req: 655, 
[1,0]<stderr>:[2025-10-10 10:21:39 TP0] Prefill batch. #new-seq: 2, #new-token: 397, #cached-token: 5, token usage: 0.94, #running-req: 121, #queue-req: 653, 
[1,0]<stderr>:[2025-10-10 10:21:39 TP0] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 1, token usage: 0.94, #running-req: 120, #queue-req: 652, 
[1,0]<stderr>:[2025-10-10 10:21:41 TP0] Decode batch. #running-req: 120, #token: 63898, token usage: 0.98, cuda graph: False, gen throughput (token/s): 893.20, #queue-req: 652, 
[1,0]<stderr>:[2025-10-10 10:21:43 TP0] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 2, token usage: 0.95, #running-req: 113, #queue-req: 651, 
[1,0]<stderr>:[2025-10-10 10:21:43 TP0] Prefill batch. #new-seq: 2, #new-token: 14, #cached-token: 2, token usage: 0.96, #running-req: 112, #queue-req: 649, 
[1,0]<stderr>:[2025-10-10 10:21:44 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.96, #running-req: 113, #queue-req: 648, 
[1,0]<stderr>:[2025-10-10 10:21:45 TP0] Prefill batch. #new-seq: 5, #new-token: 2442, #cached-token: 7, token usage: 0.89, #running-req: 109, #queue-req: 643, 
[1,0]<stderr>:[2025-10-10 10:21:45 TP0] Prefill batch. #new-seq: 4, #new-token: 499, #cached-token: 7, token usage: 0.93, #running-req: 111, #queue-req: 639, 
[1,0]<stderr>:[2025-10-10 10:21:45 TP0] Prefill batch. #new-seq: 2, #new-token: 997, #cached-token: 2, token usage: 0.94, #running-req: 114, #queue-req: 637, 
[1,0]<stderr>:[2025-10-10 10:21:46 TP0] Decode batch. #running-req: 115, #token: 62180, token usage: 0.95, cuda graph: False, gen throughput (token/s): 857.00, #queue-req: 637, 
[1,0]<stderr>:[2025-10-10 10:21:46 TP0] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 2, token usage: 0.95, #running-req: 114, #queue-req: 636, 
[1,0]<stderr>:[2025-10-10 10:21:46 TP0] Prefill batch. #new-seq: 2, #new-token: 74, #cached-token: 5, token usage: 0.96, #running-req: 113, #queue-req: 634, 
[1,0]<stderr>:[2025-10-10 10:21:47 TP0] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 3, token usage: 0.95, #running-req: 113, #queue-req: 633, 
[1,0]<stderr>:[2025-10-10 10:21:48 TP0] Prefill batch. #new-seq: 1, #new-token: 2959, #cached-token: 3, token usage: 0.91, #running-req: 107, #queue-req: 632, 
[1,0]<stderr>:[2025-10-10 10:21:49 TP0] Prefill batch. #new-seq: 2, #new-token: 247, #cached-token: 2, token usage: 0.95, #running-req: 107, #queue-req: 630, 
[1,0]<stderr>:[2025-10-10 10:21:49 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.96, #running-req: 108, #queue-req: 629, 
[1,0]<stderr>:[2025-10-10 10:21:51 TP0] Decode batch. #running-req: 106, #token: 62924, token usage: 0.96, cuda graph: False, gen throughput (token/s): 817.88, #queue-req: 629, 
[1,0]<stderr>:[2025-10-10 10:21:52 TP0] Prefill batch. #new-seq: 3, #new-token: 298, #cached-token: 6, token usage: 0.94, #running-req: 104, #queue-req: 626, 
[1,0]<stderr>:[2025-10-10 10:21:55 TP0] Prefill batch. #new-seq: 2, #new-token: 921, #cached-token: 4, token usage: 0.94, #running-req: 100, #queue-req: 624, 
[1,0]<stderr>:[2025-10-10 10:21:55 TP0] Prefill batch. #new-seq: 2, #new-token: 863, #cached-token: 5, token usage: 0.95, #running-req: 101, #queue-req: 622, 
[1,0]<stderr>:[2025-10-10 10:21:55 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 2, token usage: 0.95, #running-req: 101, #queue-req: 621, 
[1,0]<stderr>:[2025-10-10 10:21:56 TP0] Prefill batch. #new-seq: 12, #new-token: 2041, #cached-token: 20, token usage: 0.91, #running-req: 100, #queue-req: 609, 
[1,0]<stderr>:[2025-10-10 10:21:56 TP0] Prefill batch. #new-seq: 5, #new-token: 379, #cached-token: 11, token usage: 0.93, #running-req: 111, #queue-req: 604, 
[1,0]<stderr>:[2025-10-10 10:21:56 TP0] Prefill batch. #new-seq: 6, #new-token: 1111, #cached-token: 15, token usage: 0.93, #running-req: 115, #queue-req: 598, 
[1,0]<stderr>:[2025-10-10 10:21:56 TP0] Prefill batch. #new-seq: 5, #new-token: 979, #cached-token: 12, token usage: 0.93, #running-req: 119, #queue-req: 593, 
[1,0]<stderr>:[2025-10-10 10:21:57 TP0] Prefill batch. #new-seq: 3, #new-token: 416, #cached-token: 3, token usage: 0.94, #running-req: 123, #queue-req: 590, 
[1,0]<stderr>:[2025-10-10 10:21:57 TP0] Decode batch. #running-req: 126, #token: 61208, token usage: 0.93, cuda graph: False, gen throughput (token/s): 751.33, #queue-req: 590, 
[1,0]<stderr>:[2025-10-10 10:21:57 TP0] Prefill batch. #new-seq: 3, #new-token: 226, #cached-token: 7, token usage: 0.94, #running-req: 124, #queue-req: 587, 
[1,0]<stderr>:[2025-10-10 10:21:57 TP0] Prefill batch. #new-seq: 3, #new-token: 1837, #cached-token: 3, token usage: 0.93, #running-req: 125, #queue-req: 584, 
[1,0]<stderr>:[2025-10-10 10:21:58 TP0] Prefill batch. #new-seq: 3, #new-token: 493, #cached-token: 8, token usage: 0.94, #running-req: 127, #queue-req: 581, 
[1,0]<stderr>:[2025-10-10 10:21:59 TP0] Prefill batch. #new-seq: 1, #new-token: 872, #cached-token: 6, token usage: 0.94, #running-req: 125, #queue-req: 580, 
[1,0]<stderr>:[2025-10-10 10:21:59 TP0] Prefill batch. #new-seq: 4, #new-token: 1334, #cached-token: 12, token usage: 0.93, #running-req: 123, #queue-req: 576, 
[1,0]<stderr>:[2025-10-10 10:22:00 TP0] Prefill batch. #new-seq: 2, #new-token: 872, #cached-token: 7, token usage: 0.94, #running-req: 125, #queue-req: 574, 
[1,0]<stderr>:[2025-10-10 10:22:00 TP0] Prefill batch. #new-seq: 2, #new-token: 116, #cached-token: 3, token usage: 0.95, #running-req: 125, #queue-req: 572, 
[1,0]<stderr>:[2025-10-10 10:22:01 TP0] Prefill batch. #new-seq: 2, #new-token: 400, #cached-token: 3, token usage: 0.95, #running-req: 124, #queue-req: 570, 
[1,0]<stderr>:[2025-10-10 10:22:01 TP0] Prefill batch. #new-seq: 2, #new-token: 858, #cached-token: 5, token usage: 0.94, #running-req: 124, #queue-req: 568, 
[1,0]<stderr>:[2025-10-10 10:22:01 TP0] Prefill batch. #new-seq: 4, #new-token: 1378, #cached-token: 8, token usage: 0.93, #running-req: 122, #queue-req: 564, 
[1,0]<stderr>:[2025-10-10 10:22:02 TP0] Prefill batch. #new-seq: 2, #new-token: 258, #cached-token: 2, token usage: 0.95, #running-req: 125, #queue-req: 562, 
[1,0]<stderr>:[2025-10-10 10:22:02 TP0] Prefill batch. #new-seq: 3, #new-token: 1262, #cached-token: 6, token usage: 0.93, #running-req: 125, #queue-req: 559, 
[1,0]<stderr>:[2025-10-10 10:22:03 TP0] Decode batch. #running-req: 124, #token: 61958, token usage: 0.95, cuda graph: False, gen throughput (token/s): 848.98, #queue-req: 559, 
[1,0]<stderr>:[2025-10-10 10:22:05 TP0] Prefill batch. #new-seq: 1, #new-token: 2196, #cached-token: 1, token usage: 0.93, #running-req: 119, #queue-req: 558, 
[1,0]<stderr>:[2025-10-10 10:22:05 TP0] Prefill batch. #new-seq: 2, #new-token: 17, #cached-token: 5, token usage: 0.95, #running-req: 117, #queue-req: 556, 
[1,0]<stderr>:[2025-10-10 10:22:05 TP0] Prefill batch. #new-seq: 3, #new-token: 813, #cached-token: 6, token usage: 0.94, #running-req: 117, #queue-req: 553, 
[1,0]<stderr>:[2025-10-10 10:22:06 TP0] Prefill batch. #new-seq: 5, #new-token: 140, #cached-token: 8, token usage: 0.93, #running-req: 119, #queue-req: 548, 
[1,0]<stderr>:[2025-10-10 10:22:07 TP0] Prefill batch. #new-seq: 6, #new-token: 828, #cached-token: 15, token usage: 0.93, #running-req: 123, #queue-req: 542, 
[1,0]<stderr>:[2025-10-10 10:22:07 TP0] Prefill batch. #new-seq: 2, #new-token: 1376, #cached-token: 5, token usage: 0.93, #running-req: 128, #queue-req: 540, 
[1,0]<stderr>:[2025-10-10 10:22:07 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.95, #running-req: 129, #queue-req: 539, 
[1,0]<stderr>:[2025-10-10 10:22:08 TP0] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 1, token usage: 0.95, #running-req: 129, #queue-req: 538, 
[1,0]<stderr>:[2025-10-10 10:22:08 TP0] Prefill batch. #new-seq: 3, #new-token: 729, #cached-token: 7, token usage: 0.93, #running-req: 127, #queue-req: 535, 
[1,0]<stderr>:[2025-10-10 10:22:08 TP0] Decode batch. #running-req: 127, #token: 61545, token usage: 0.94, cuda graph: False, gen throughput (token/s): 923.49, #queue-req: 535, 
[1,0]<stderr>:[2025-10-10 10:22:09 TP0] Prefill batch. #new-seq: 2, #new-token: 602, #cached-token: 4, token usage: 0.94, #running-req: 129, #queue-req: 533, 
[1,0]<stderr>:[2025-10-10 10:22:10 TP0] Prefill batch. #new-seq: 2, #new-token: 89, #cached-token: 4, token usage: 0.94, #running-req: 129, #queue-req: 531, 
[1,0]<stderr>:[2025-10-10 10:22:10 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.95, #running-req: 130, #queue-req: 530, 
[1,0]<stderr>:[2025-10-10 10:22:10 TP0] Prefill batch. #new-seq: 3, #new-token: 558, #cached-token: 7, token usage: 0.93, #running-req: 129, #queue-req: 527, 
[1,0]<stderr>:[2025-10-10 10:22:11 TP0] Prefill batch. #new-seq: 7, #new-token: 928, #cached-token: 9, token usage: 0.93, #running-req: 131, #queue-req: 520, 
[1,0]<stderr>:[2025-10-10 10:22:11 TP0] Prefill batch. #new-seq: 7, #new-token: 426, #cached-token: 11, token usage: 0.93, #running-req: 136, #queue-req: 513, 
[1,0]<stderr>:[2025-10-10 10:22:12 TP0] Prefill batch. #new-seq: 3, #new-token: 2046, #cached-token: 4, token usage: 0.91, #running-req: 139, #queue-req: 510, 
[1,0]<stderr>:[2025-10-10 10:22:12 TP0] Prefill batch. #new-seq: 4, #new-token: 810, #cached-token: 7, token usage: 0.94, #running-req: 138, #queue-req: 506, 
[1,0]<stderr>:[2025-10-10 10:22:12 TP0] Prefill batch. #new-seq: 2, #new-token: 501, #cached-token: 2, token usage: 0.94, #running-req: 139, #queue-req: 504, 
[1,0]<stderr>:[2025-10-10 10:22:13 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 2, token usage: 0.94, #running-req: 140, #queue-req: 503, 
[1,0]<stderr>:[2025-10-10 10:22:14 TP0] Decode batch. #running-req: 138, #token: 63125, token usage: 0.96, cuda graph: False, gen throughput (token/s): 944.52, #queue-req: 503, 
[1,0]<stderr>:[2025-10-10 10:22:16 TP0] Prefill batch. #new-seq: 4, #new-token: 840, #cached-token: 10, token usage: 0.93, #running-req: 132, #queue-req: 499, 
[1,0]<stderr>:[2025-10-10 10:22:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1051, #cached-token: 1, token usage: 0.93, #running-req: 130, #queue-req: 498, 
[1,0]<stderr>:[2025-10-10 10:22:17 TP0] Prefill batch. #new-seq: 2, #new-token: 189, #cached-token: 4, token usage: 0.94, #running-req: 129, #queue-req: 496, 
[1,0]<stderr>:[2025-10-10 10:22:17 TP0] Prefill batch. #new-seq: 2, #new-token: 780, #cached-token: 2, token usage: 0.94, #running-req: 130, #queue-req: 494, 
[1,0]<stderr>:[2025-10-10 10:22:19 TP0] Decode batch. #running-req: 126, #token: 62478, token usage: 0.95, cuda graph: False, gen throughput (token/s): 1061.46, #queue-req: 494, 
[1,0]<stderr>:[2025-10-10 10:22:19 TP0] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 2, token usage: 0.95, #running-req: 125, #queue-req: 493, 
[1,0]<stderr>:[2025-10-10 10:22:19 TP0] Prefill batch. #new-seq: 7, #new-token: 1310, #cached-token: 14, token usage: 0.92, #running-req: 124, #queue-req: 486, 
[1,0]<stderr>:[2025-10-10 10:22:20 TP0] Prefill batch. #new-seq: 2, #new-token: 997, #cached-token: 2, token usage: 0.94, #running-req: 129, #queue-req: 484, 
[1,0]<stderr>:[2025-10-10 10:22:21 TP0] Prefill batch. #new-seq: 6, #new-token: 831, #cached-token: 14, token usage: 0.91, #running-req: 127, #queue-req: 478, 
[1,0]<stderr>:[2025-10-10 10:22:21 TP0] Prefill batch. #new-seq: 1, #new-token: 2404, #cached-token: 1, token usage: 0.92, #running-req: 131, #queue-req: 477, 
[1,0]<stderr>:[2025-10-10 10:22:22 TP0] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 2, token usage: 0.95, #running-req: 129, #queue-req: 476, 
[1,0]<stderr>:[2025-10-10 10:22:22 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 2, token usage: 0.95, #running-req: 129, #queue-req: 475, 
[1,0]<stderr>:[2025-10-10 10:22:23 TP0] Prefill batch. #new-seq: 3, #new-token: 448, #cached-token: 9, token usage: 0.94, #running-req: 127, #queue-req: 472, 
[1,0]<stderr>:[2025-10-10 10:22:23 TP0] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 1, token usage: 0.95, #running-req: 127, #queue-req: 471, 
[1,0]<stderr>:[2025-10-10 10:22:24 TP0] Prefill batch. #new-seq: 8, #new-token: 837, #cached-token: 17, token usage: 0.91, #running-req: 124, #queue-req: 463, 
[1,0]<stderr>:[2025-10-10 10:22:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1428, #cached-token: 1, token usage: 0.92, #running-req: 131, #queue-req: 462, 
[1,0]<stderr>:[2025-10-10 10:22:25 TP0] Prefill batch. #new-seq: 2, #new-token: 88, #cached-token: 13, token usage: 0.95, #running-req: 131, #queue-req: 460, 
[1,0]<stderr>:[2025-10-10 10:22:25 TP0] Decode batch. #running-req: 131, #token: 61707, token usage: 0.94, cuda graph: False, gen throughput (token/s): 887.10, #queue-req: 460, 
[1,0]<stderr>:[2025-10-10 10:22:25 TP0] Prefill batch. #new-seq: 2, #new-token: 805, #cached-token: 2, token usage: 0.94, #running-req: 132, #queue-req: 458, 
[1,0]<stderr>:[2025-10-10 10:22:26 TP0] Prefill batch. #new-seq: 2, #new-token: 22, #cached-token: 3, token usage: 0.95, #running-req: 133, #queue-req: 456, 
[1,0]<stderr>:[2025-10-10 10:22:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1958, #cached-token: 1, token usage: 0.93, #running-req: 127, #queue-req: 455, 
[1,0]<stderr>:[2025-10-10 10:22:28 TP0] Prefill batch. #new-seq: 4, #new-token: 274, #cached-token: 5, token usage: 0.95, #running-req: 125, #queue-req: 451, 
[1,0]<stderr>:[2025-10-10 10:22:29 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.95, #running-req: 128, #queue-req: 450, 
[1,0]<stderr>:[2025-10-10 10:22:29 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.96, #running-req: 128, #queue-req: 449, 
[1,0]<stderr>:[2025-10-10 10:22:29 TP0] Prefill batch. #new-seq: 2, #new-token: 269, #cached-token: 3, token usage: 0.95, #running-req: 128, #queue-req: 447, 
[1,0]<stderr>:[2025-10-10 10:22:30 TP0] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 2, token usage: 0.95, #running-req: 127, #queue-req: 446, 
[1,0]<stderr>:[2025-10-10 10:22:30 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.95, #running-req: 127, #queue-req: 445, 
[1,0]<stderr>:[2025-10-10 10:22:31 TP0] Decode batch. #running-req: 127, #token: 62286, token usage: 0.95, cuda graph: False, gen throughput (token/s): 908.25, #queue-req: 445, 
[1,0]<stderr>:[2025-10-10 10:22:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1864, #cached-token: 1, token usage: 0.93, #running-req: 118, #queue-req: 444, 
[1,0]<stderr>:[2025-10-10 10:22:34 TP0] Prefill batch. #new-seq: 6, #new-token: 1230, #cached-token: 14, token usage: 0.93, #running-req: 117, #queue-req: 438, 
[1,0]<stderr>:[2025-10-10 10:22:34 TP0] Prefill batch. #new-seq: 13, #new-token: 2075, #cached-token: 24, token usage: 0.87, #running-req: 120, #queue-req: 425, 
[1,0]<stderr>:[2025-10-10 10:22:35 TP0] Prefill batch. #new-seq: 12, #new-token: 3556, #cached-token: 22, token usage: 0.88, #running-req: 130, #queue-req: 413, 
[1,0]<stderr>:[2025-10-10 10:22:35 TP0] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 5, token usage: 0.94, #running-req: 140, #queue-req: 412, 
[1,0]<stderr>:[2025-10-10 10:22:36 TP0] Prefill batch. #new-seq: 11, #new-token: 5218, #cached-token: 24, token usage: 0.84, #running-req: 134, #queue-req: 401, 
[1,0]<stderr>:[2025-10-10 10:22:36 TP0] Prefill batch. #new-seq: 7, #new-token: 2065, #cached-token: 17, token usage: 0.91, #running-req: 143, #queue-req: 394, 
[1,0]<stderr>:[2025-10-10 10:22:36 TP0] Decode batch. #running-req: 143, #token: 61342, token usage: 0.94, cuda graph: False, gen throughput (token/s): 900.58, #queue-req: 394, 
[1,0]<stderr>:[2025-10-10 10:22:37 TP0] Prefill batch. #new-seq: 4, #new-token: 591, #cached-token: 5, token usage: 0.93, #running-req: 144, #queue-req: 390, 
[1,0]<stderr>:[2025-10-10 10:22:37 TP0] Prefill batch. #new-seq: 6, #new-token: 2608, #cached-token: 9, token usage: 0.88, #running-req: 146, #queue-req: 384, 
[1,0]<stderr>:[2025-10-10 10:22:37 TP0] Prefill batch. #new-seq: 5, #new-token: 2145, #cached-token: 19, token usage: 0.91, #running-req: 147, #queue-req: 379, 
[1,0]<stderr>:[2025-10-10 10:22:38 TP0] Prefill batch. #new-seq: 2, #new-token: 18, #cached-token: 2, token usage: 0.94, #running-req: 151, #queue-req: 377, 
[1,0]<stderr>:[2025-10-10 10:22:38 TP0] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 4, token usage: 0.93, #running-req: 150, #queue-req: 376, 
[1,0]<stderr>:[2025-10-10 10:22:39 TP0] Prefill batch. #new-seq: 2, #new-token: 1017, #cached-token: 9, token usage: 0.93, #running-req: 147, #queue-req: 374, 
[1,0]<stderr>:[2025-10-10 10:22:39 TP0] Prefill batch. #new-seq: 2, #new-token: 1260, #cached-token: 2, token usage: 0.92, #running-req: 146, #queue-req: 372, 
[1,0]<stderr>:[2025-10-10 10:22:39 TP0] Prefill batch. #new-seq: 2, #new-token: 699, #cached-token: 3, token usage: 0.93, #running-req: 144, #queue-req: 370, 
[1,0]<stderr>:[2025-10-10 10:22:40 TP0] Prefill batch. #new-seq: 4, #new-token: 705, #cached-token: 7, token usage: 0.93, #running-req: 144, #queue-req: 366, 
=>> PBS: job killed: walltime 445 exceeded limit 420
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-10 10:22:59.665989:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 96738.pbs111
	Project: 50000128
	Exit Status: -29
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 01:34:03
	Memory: Requested(3760gb), Used(26123852kb)
	Vmem Used: 21430071356kb
	Walltime: Requested(00:07:00), Used(00:07:40)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx021:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx023:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 7.79mins
	GPU Power Consumed: 376.4W
	GPU Max GPU Memory Used: 804.78GB
	Memory Throughput Rate (Average): a2ap-dgx021:(gpu1:4%+gpu0:4%+gpu2:4%+gpu3:4%+gpu5:4%+gpu4:4%+gpu6:4%+gpu7:4%)+a2ap-dgx023:(gpu1:4%+gpu0:4%+gpu2:4%+gpu3:5%+gpu5:5%+gpu4:5%+gpu6:5%+gpu7:5%)
	Memory Throughput Rate (Max): a2ap-dgx021:(gpu1:17%+gpu0:41%+gpu2:23%+gpu3:41%+gpu5:40%+gpu4:44%+gpu6:40%+gpu7:46%)+a2ap-dgx023:(gpu1:15%+gpu0:17%+gpu2:14%+gpu3:21%+gpu5:22%+gpu4:18%+gpu6:22%+gpu7:21%)
	Memory Throughput Rate (Min): a2ap-dgx021:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx023:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx021:(gpu1:81%+gpu0:71%+gpu2:79%+gpu3:50%+gpu5:80%+gpu4:79%+gpu6:72%+gpu7:80%)+a2ap-dgx023:(gpu1:80%+gpu0:82%+gpu2:82%+gpu3:78%+gpu5:82%+gpu4:83%+gpu6:80%+gpu7:73%)
	GPU SM Utilization (Max): a2ap-dgx021:(gpu1:100%+gpu0:100%+gpu2:100%+gpu3:100%+gpu5:100%+gpu4:100%+gpu6:100%+gpu7:100%)+a2ap-dgx023:(gpu1:100%+gpu0:100%+gpu2:100%+gpu3:100%+gpu5:100%+gpu4:100%+gpu6:100%+gpu7:100%)
	GPU SM Utilization (Min): a2ap-dgx021:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx023:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: None
GPU application profile: High
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

