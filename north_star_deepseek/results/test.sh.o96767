========== 2-NODE TP16 FAST ==========
Prepaid SU: 682.666 | 720s SU: 409.600 | Balance: 48391.326
N/A
Job ID: 96767.pbs111 | GPUs: 16 | Master: a2ap-dgx021.asp2p.nscc.sg:5000
============================================
[17:17:53] Launching fast 2-node TP16 benchmark...
 Data for JOB [6252,1] offset 0 Total slots allocated 4

 ========================   JOB MAP   ========================

 Data for node: a2ap-dgx021	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [6252,1] App: 0 Process rank: 0 Bound: N/A

 Data for node: a2ap-dgx023	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [6252,1] App: 0 Process rank: 1 Bound: N/A

 =============================================================
 Data for JOB [6252,1] offset 0 Total slots allocated 4

 ========================   JOB MAP   ========================

 Data for node: a2ap-dgx021	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [6252,1] App: 0 Process rank: 0 Bound: N/A

 Data for node: a2ap-dgx023	Num slots: 2	Max slots: 0	Num procs: 1
 	Process OMPI jobid: [6252,1] App: 0 Process rank: 1 Bound: N/A

 =============================================================
[1,0]<stderr>:W1010 17:18:23.516000 3819358 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:23.516000 3819358 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 17:18:24.255000 2812685 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 17:18:24.255000 2812685 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:[2025-10-10 17:18:26] Using default HuggingFace chat template with detected content format: string
[1,1]<stderr>:W1010 17:18:44.707000 2814045 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 17:18:44.707000 2814045 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 17:18:45.418000 3820555 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:45.418000 3820555 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 17:18:46.760000 3820554 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:46.760000 3820554 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 17:18:47.470000 3820557 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:47.470000 3820557 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 17:18:47.517000 3820553 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:47.517000 3820553 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 17:18:47.606000 3820556 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:47.606000 3820556 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 17:18:47.682000 3820559 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:47.682000 3820559 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 17:18:47.682000 3820552 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:47.682000 3820552 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 17:18:47.767000 3820560 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:47.767000 3820560 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:W1010 17:18:47.850000 3820558 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,0]<stderr>:W1010 17:18:47.850000 3820558 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 17:18:47.912000 2814047 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 17:18:47.912000 2814047 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 17:18:48.138000 2814048 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 17:18:48.138000 2814048 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 17:18:48.482000 2814044 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 17:18:48.482000 2814044 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 17:18:48.668000 2814049 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 17:18:48.668000 2814049 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 17:18:48.728000 2814043 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 17:18:48.728000 2814043 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 17:18:48.805000 2814042 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 17:18:48.805000 2814042 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,1]<stderr>:W1010 17:18:49.056000 2814046 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1,1]<stderr>:W1010 17:18:49.056000 2814046 /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1,0]<stderr>:[2025-10-10 17:18:49 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[1,0]<stderr>:[2025-10-10 17:18:49 TP0] Chunked prefix cache is turned on.
[1,0]<stderr>:[2025-10-10 17:18:49 TP0] Init torch distributed begin.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 17:18:53 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:NCCL version 2.27.3+cuda12.9
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814049:2814049 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814049:2814049 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814048:2814048 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814048:2814048 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814042:2814042 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814042:2814042 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814047:2814047 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814047:2814047 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814045:2814045 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814045:2814045 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814046:2814046 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814046:2814046 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814043:2814043 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814043:2814043 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814044:2814044 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-10 17:18:58] a2ap-dgx023:2814044:2814044 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820559:3820559 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820559:3820559 [7] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820555:3820555 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820555:3820555 [3] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820556:3820556 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820556:3820556 [4] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820557:3820557 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820557:3820557 [5] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820554:3820554 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820554:3820554 [2] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820558:3820558 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820558:3820558 [6] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820553:3820553 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820553:3820553 [1] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820552:3820552 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [1]mlx5_1:1/IB and [2]mlx5_2:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stdout>:
[1,0]<stdout>:[2025-10-10 17:18:58] a2ap-dgx021:3820552:3820552 [0] transport/net_ib.cc:587 NCCL WARN NET/IB : Attempted to merge incompatible devices: [7]mlx5_7:1/IB and [8]mlx5_8:1/RoCE. Try selecting NICs of only one link type using NCCL_IB_HCA
[1,0]<stderr>:[2025-10-10 17:18:59 TP0] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 17:18:59 TP1] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 17:18:59 TP2] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 17:18:59 TP15] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 17:18:59 TP4] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 17:18:59 TP14] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 17:18:59 TP5] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 17:18:59 TP13] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 17:18:59 TP12] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 17:18:59 TP10] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 17:18:59 TP6] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 17:18:59 TP7] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 17:18:59 TP9] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stderr>:[2025-10-10 17:18:59 TP3] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 17:18:59 TP8] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stderr>:[2025-10-10 17:18:59 TP11] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 17:18:59 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stderr>:[2025-10-10 17:19:02 TP0] Init torch distributed ends. mem usage=1.75 GB
[1,0]<stderr>:[2025-10-10 17:19:03 TP3] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 17:19:03 TP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 17:19:03 TP5] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 17:19:03 TP7] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 17:19:03 TP1] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 17:19:03 TP2] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 17:19:03 TP4] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 17:19:03 TP6] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 17:19:03 TP15] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 17:19:03 TP13] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 17:19:03 TP9] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 17:19:03 TP12] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 17:19:03 TP11] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 17:19:03 TP10] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 17:19:03 TP14] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stderr>:[2025-10-10 17:19:03 TP8] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stderr>:[2025-10-10 17:19:04 TP0] Load weight begin. avail mem=76.80 GB
[1,0]<stderr>:[2025-10-10 17:19:04 TP0] Detected fp8 checkpoint.
[1,0]<stderr>:[2025-10-10 17:19:05 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=36.24 GB, mem usage=40.55 GB.
[1,1]<stderr>:[2025-10-10 17:19:05 TP12] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 17:19:05 TP14] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 17:19:05 TP10] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 17:19:05 TP13] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 17:19:05 TP8] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 17:19:05 TP11] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 17:19:05 TP9] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 17:19:05 TP6] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,1]<stderr>:[2025-10-10 17:19:05 TP15] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 17:19:05 TP3] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 17:19:05 TP4] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 17:19:05 TP7] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 17:19:05 TP2] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 17:19:05 TP5] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 17:19:05 TP0] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 17:19:05 TP0] Memory pool end. avail mem=31.52 GB
[1,0]<stderr>:[2025-10-10 17:19:05 TP1] KV Cache is allocated. #tokens: 65536, KV size: 4.29 GB
[1,0]<stderr>:[2025-10-10 17:19:06 TP0] max_total_num_tokens=65536, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=512, context_len=163840, available_gpu_mem=31.43 GB
[1,1]<stderr>:[2025-10-10 17:19:06] Starting dummy health check server at 127.0.0.1:30000
[1,0]<stdout>:#Input tokens: 626729
[1,0]<stdout>:#Output tokens: 388685
[1,0]<stdout>:#Input tokens: 4096
[1,0]<stdout>:#Output tokens: 256
[1,0]<stderr>:[2025-10-10 17:19:20] 
[1,0]<stderr>:Warmup...
[1,0]<stderr>:[2025-10-10 17:19:20 TP0] Prefill batch. #new-seq: 16, #new-token: 4112, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:19:24 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 17:19:24 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 17:19:24 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 2008.53it/s]
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 2151.73it/s][1,1]<stderr>:
[1,0]<stderr>:[2025-10-10 17:19:24 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 17:19:24 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4812.16it/s]
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5114.82it/s]
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5013.48it/s][1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4529.78it/s]
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4954.26it/s][1,1]<stderr>:
[1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5153.09it/s]
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5357.95it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,1]<stderr>:
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4338.39it/s][1,0]<stderr>:
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 4561.28it/s][1,0]<stderr>:
[1,1]<stderr>:[2025-10-10 17:19:24 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 17:19:24 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:24 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5351.74it/s]
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5147.53it/s]
[1,1]<stderr>:[2025-10-10 17:19:24 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5717.14it/s][1,0]<stderr>:
[1,1]<stderr>:[2025-10-10 17:19:24 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5106.32it/s]
[1,0]<stderr>:[2025-10-10 17:19:24 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 17:19:24 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:24 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/33 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 33/33 [00:00<00:00, 5113.12it/s][1,0]<stderr>:
[1,0]<stderr>:[2025-10-10 17:19:24 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 6829.60it/s]
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 17:19:25 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 7019.49it/s]
[1,1]<stderr>:[2025-10-10 17:19:25 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 11590.84it/s]
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 11441.37it/s]
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 10045.69it/s]
[1,1]<stderr>:[2025-10-10 17:19:25 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 10112.29it/s]
[1,1]<stderr>:[2025-10-10 17:19:25 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 9640.57it/s]
[1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 10958.34it/s]
[1,1]<stderr>:[2025-10-10 17:19:25 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:25 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:25 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 17:19:25 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:25 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12753.05it/s]
[1,1]<stderr>:[2025-10-10 17:19:25 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 13464.86it/s]
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12390.02it/s]
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 11866.60it/s]
[1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12507.58it/s]
[1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 12297.55it/s][1,0]<stderr>:
[1,0]<stderr>:[2025-10-10 17:19:25 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:25 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 17:19:25 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 17:19:25 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 13334.49it/s]
[1,0]<stderr>:[2025-10-10 17:19:25 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:25 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:25 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/44 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 44/44 [00:00<00:00, 13248.34it/s]
[1,0]<stderr>:[2025-10-10 17:19:25 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 5901.06it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 5554.11it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 9650.95it/s]
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 9141.90it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s]100%|██████████| 35/35 [00:00<00:00, 9242.63it/s][1,1]<stderr>:
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 9396.44it/s]
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 10438.04it/s]
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 10643.90it/s]
[1,1]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:[2025-10-10 17:19:26 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11089.34it/s]
[1,1]<stderr>:[2025-10-10 17:19:26 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:26 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 17:19:26 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:26 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:26 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:26 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:26 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:26 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:26 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 12309.29it/s]
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11640.68it/s]
[1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 10274.40it/s]
[1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11364.04it/s]
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 9784.10it/s]
[1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 11201.88it/s]
[1,0]<stderr>:[2025-10-10 17:19:26 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:26 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 17:19:26 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:26 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:26 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:26 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:26 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/35 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 35/35 [00:00<00:00, 12115.26it/s]
[1,0]<stderr>:[2025-10-10 17:19:26 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 5676.61it/s][1,0]<stderr>:
[1,0]<stderr>:[2025-10-10 17:19:26 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 8351.03it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 15760.65it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 18636.17it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14441.33it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 17:19:26 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 17:19:26 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 16356.05it/s]
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14435.12it/s]
[1,1]<stderr>:[2025-10-10 17:19:26 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:26 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 17:19:26 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 12226.06it/s]
[1,1]<stderr>:[2025-10-10 17:19:26 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 17:19:26 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14324.20it/s]
[1,1]<stderr>:[2025-10-10 17:19:26 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:26 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14863.54it/s]
[1,0]<stderr>:[2025-10-10 17:19:26 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 18108.17it/s]
[1,0]<stderr>:[2025-10-10 17:19:26 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 17711.50it/s][1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 15617.61it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14155.00it/s]
[1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 12980.44it/s]
[1,0]<stderr>:[2025-10-10 17:19:26 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 17:19:26 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:26 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:26 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:26 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 17563.17it/s][1,0]<stderr>:
[1,0]<stderr>:[2025-10-10 17:19:26 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 7816.54it/s]
[1,0]<stderr>:[2025-10-10 17:19:27 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 6450.29it/s]
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 14186.42it/s]
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 14428.91it/s]
[1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 12672.81it/s]
[1,1]<stderr>:[2025-10-10 17:19:27 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:27 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 17:19:27 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:[2025-10-10 17:19:27 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stderr>:[2025-10-10 17:19:27 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 11626.62it/s]
[1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13211.71it/s]
[1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 12925.44it/s]
[1,1]<stderr>:[2025-10-10 17:19:27 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:27 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:27 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13628.93it/s]
[1,1]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13927.34it/s][1,1]<stderr>:
[1,0]<stderr>:[2025-10-10 17:19:27 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stderr>:[2025-10-10 17:19:27 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 15961.20it/s]
[1,0]<stderr>:[2025-10-10 17:19:27 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 12761.98it/s]
[1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13663.62it/s]
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 12663.24it/s]
[1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13140.56it/s]
[1,0]<stderr>:[2025-10-10 17:19:27 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stderr>:[2025-10-10 17:19:27 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:27 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:27 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:[2025-10-10 17:19:27 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/32 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 32/32 [00:00<00:00, 13462.16it/s]
[1,0]<stderr>:[2025-10-10 17:19:27 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6117.49it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 6220.12it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 17247.20it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 17260.51it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14989.69it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 11430.57it/s]
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 10593.35it/s]
[1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 11229.73it/s][1,1]<stderr>:
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14172.94it/s]
[1,1]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,1]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14101.46it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 17895.70it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13662.23it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 18620.66it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 13150.86it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 11924.11it/s]
[1,0]<stderr>:  0%|          | 0/16 [00:00<?, ?it/s][1,0]<stderr>:100%|██████████| 16/16 [00:00<00:00, 14469.35it/s]
[1,0]<stderr>:[2025-10-10 17:19:27 TP6] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 17:19:27 TP1] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 17:19:27 TP14] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 17:19:27 TP13] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 17:19:27 TP8] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 17:19:27 TP11] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 17:19:27 TP15] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 17:19:27 TP10] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 17:19:27 TP12] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stderr>:[2025-10-10 17:19:27 TP9] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 17:19:27 TP5] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 17:19:27 TP7] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 17:19:27 TP0] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 17:19:27 TP2] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 17:19:27 TP4] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 17:19:28 TP3] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stderr>:[2025-10-10 17:19:32] 
[1,0]<stderr>:Benchmark...
[1,0]<stderr>:[2025-10-10 17:19:32 TP0] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:19:32 TP0] Prefill batch. #new-seq: 3, #new-token: 241, #cached-token: 3, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:19:32 TP0] Prefill batch. #new-seq: 27, #new-token: 8192, #cached-token: 32, token usage: 0.01, #running-req: 4, #queue-req: 648, 
[1,0]<stderr>:[2025-10-10 17:19:33 TP0] Prefill batch. #new-seq: 23, #new-token: 8192, #cached-token: 28, token usage: 0.14, #running-req: 30, #queue-req: 1086, 
[1,0]<stderr>:[2025-10-10 17:19:33 TP0] Prefill batch. #new-seq: 30, #new-token: 8192, #cached-token: 50, token usage: 0.26, #running-req: 52, #queue-req: 1297, 
[1,0]<stderr>:[2025-10-10 17:19:33 TP0] Prefill batch. #new-seq: 31, #new-token: 8192, #cached-token: 63, token usage: 0.39, #running-req: 81, #queue-req: 1515, 
[1,0]<stderr>:[2025-10-10 17:19:34 TP0] Prefill batch. #new-seq: 25, #new-token: 8192, #cached-token: 59, token usage: 0.51, #running-req: 111, #queue-req: 1864, 
[1,0]<stderr>:[2025-10-10 17:19:34 TP0] Prefill batch. #new-seq: 8, #new-token: 2350, #cached-token: 16, token usage: 0.64, #running-req: 135, #queue-req: 1857, 
[1,0]<stderr>:[2025-10-10 17:19:35 TP0] Prefill batch. #new-seq: 14, #new-token: 3874, #cached-token: 29, token usage: 0.57, #running-req: 138, #queue-req: 1843, 
[1,0]<stderr>:[2025-10-10 17:19:35 TP0] Prefill batch. #new-seq: 3, #new-token: 1925, #cached-token: 7, token usage: 0.62, #running-req: 151, #queue-req: 1840, 
[1,0]<stderr>:[2025-10-10 17:19:35 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.64, #running-req: 153, #queue-req: 1839, 
[1,0]<stderr>:[2025-10-10 17:19:36 TP0] Prefill batch. #new-seq: 3, #new-token: 363, #cached-token: 7, token usage: 0.63, #running-req: 151, #queue-req: 1836, 
[1,0]<stderr>:[2025-10-10 17:19:37 TP0] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 1, token usage: 0.62, #running-req: 152, #queue-req: 1835, 
[1,0]<stderr>:[2025-10-10 17:19:37 TP0] Prefill batch. #new-seq: 4, #new-token: 1070, #cached-token: 8, token usage: 0.61, #running-req: 152, #queue-req: 1831, 
[1,0]<stderr>:[2025-10-10 17:19:37 TP0] Prefill batch. #new-seq: 4, #new-token: 729, #cached-token: 11, token usage: 0.62, #running-req: 151, #queue-req: 1827, 
[1,0]<stderr>:[2025-10-10 17:19:38 TP0] Prefill batch. #new-seq: 3, #new-token: 1148, #cached-token: 13, token usage: 0.60, #running-req: 150, #queue-req: 1824, 
[1,0]<stderr>:[2025-10-10 17:19:38 TP0] Prefill batch. #new-seq: 2, #new-token: 1116, #cached-token: 3, token usage: 0.61, #running-req: 149, #queue-req: 1822, 
[1,0]<stderr>:[2025-10-10 17:19:38 TP0] Prefill batch. #new-seq: 2, #new-token: 939, #cached-token: 6, token usage: 0.61, #running-req: 149, #queue-req: 1820, 
[1,0]<stderr>:[2025-10-10 17:19:39 TP0] Prefill batch. #new-seq: 7, #new-token: 2966, #cached-token: 11, token usage: 0.58, #running-req: 149, #queue-req: 1813, 
[1,0]<stderr>:[2025-10-10 17:19:39 TP0] Prefill batch. #new-seq: 6, #new-token: 1482, #cached-token: 12, token usage: 0.60, #running-req: 150, #queue-req: 1807, 
[1,0]<stderr>:[2025-10-10 17:19:39 TP0] Prefill batch. #new-seq: 4, #new-token: 352, #cached-token: 11, token usage: 0.61, #running-req: 154, #queue-req: 1803, 
[1,0]<stderr>:[2025-10-10 17:19:40 TP0] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.61, #running-req: 157, #queue-req: 1802, 
[1,0]<stderr>:[2025-10-10 17:19:40 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 1, token usage: 0.61, #running-req: 157, #queue-req: 1801, 
[1,0]<stderr>:[2025-10-10 17:19:40 TP0] Prefill batch. #new-seq: 3, #new-token: 101, #cached-token: 8, token usage: 0.61, #running-req: 157, #queue-req: 1798, 
[1,0]<stderr>:[2025-10-10 17:19:40 TP0] Decode batch. #running-req: 157, #token: 39830, token usage: 0.61, cuda graph: False, gen throughput (token/s): 112.04, #queue-req: 1798, 
[1,0]<stderr>:[2025-10-10 17:19:41 TP0] Prefill batch. #new-seq: 3, #new-token: 754, #cached-token: 7, token usage: 0.61, #running-req: 158, #queue-req: 1795, 
[1,0]<stderr>:[2025-10-10 17:19:41 TP0] Prefill batch. #new-seq: 2, #new-token: 171, #cached-token: 7, token usage: 0.61, #running-req: 157, #queue-req: 1793, 
[1,0]<stderr>:[2025-10-10 17:19:42 TP0] Prefill batch. #new-seq: 4, #new-token: 1237, #cached-token: 11, token usage: 0.60, #running-req: 154, #queue-req: 1789, 
[1,0]<stderr>:[2025-10-10 17:19:42 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.62, #running-req: 157, #queue-req: 1788, 
[1,0]<stderr>:[2025-10-10 17:19:42 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 2, token usage: 0.61, #running-req: 156, #queue-req: 1787, 
[1,0]<stderr>:[2025-10-10 17:19:43 TP0] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 1, token usage: 0.62, #running-req: 155, #queue-req: 1786, 
[1,0]<stderr>:[2025-10-10 17:19:43 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.62, #running-req: 155, #queue-req: 1785, 
[1,0]<stderr>:[2025-10-10 17:19:43 TP0] Prefill batch. #new-seq: 2, #new-token: 72, #cached-token: 4, token usage: 0.62, #running-req: 155, #queue-req: 1783, 
[1,0]<stderr>:[2025-10-10 17:19:44 TP0] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 2, token usage: 0.61, #running-req: 155, #queue-req: 1782, 
[1,0]<stderr>:[2025-10-10 17:19:44 TP0] Prefill batch. #new-seq: 3, #new-token: 768, #cached-token: 10, token usage: 0.60, #running-req: 150, #queue-req: 1779, 
[1,0]<stderr>:[2025-10-10 17:19:44 TP0] Prefill batch. #new-seq: 4, #new-token: 1349, #cached-token: 18, token usage: 0.59, #running-req: 151, #queue-req: 1775, 
[1,0]<stderr>:[2025-10-10 17:19:45 TP0] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 4, token usage: 0.61, #running-req: 153, #queue-req: 1774, 
[1,0]<stderr>:[2025-10-10 17:19:45 TP0] Prefill batch. #new-seq: 2, #new-token: 189, #cached-token: 3, token usage: 0.61, #running-req: 153, #queue-req: 1772, 
[1,0]<stderr>:[2025-10-10 17:19:45 TP0] Prefill batch. #new-seq: 6, #new-token: 1135, #cached-token: 10, token usage: 0.59, #running-req: 153, #queue-req: 1766, 
[1,0]<stderr>:[2025-10-10 17:19:45 TP0] Prefill batch. #new-seq: 3, #new-token: 1302, #cached-token: 8, token usage: 0.58, #running-req: 157, #queue-req: 1763, 
[1,0]<stderr>:[2025-10-10 17:19:46 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.61, #running-req: 159, #queue-req: 1762, 
[1,0]<stderr>:[2025-10-10 17:19:46 TP0] Prefill batch. #new-seq: 2, #new-token: 18, #cached-token: 6, token usage: 0.61, #running-req: 159, #queue-req: 1760, 
[1,0]<stderr>:[2025-10-10 17:19:47 TP0] Prefill batch. #new-seq: 4, #new-token: 636, #cached-token: 9, token usage: 0.59, #running-req: 159, #queue-req: 1756, 
[1,0]<stderr>:[2025-10-10 17:19:47 TP0] Prefill batch. #new-seq: 3, #new-token: 904, #cached-token: 8, token usage: 0.59, #running-req: 162, #queue-req: 1753, 
[1,0]<stderr>:[2025-10-10 17:19:47 TP0] Prefill batch. #new-seq: 2, #new-token: 450, #cached-token: 3, token usage: 0.60, #running-req: 162, #queue-req: 1751, 
[1,0]<stderr>:[2025-10-10 17:19:48 TP0] Prefill batch. #new-seq: 2, #new-token: 1101, #cached-token: 5, token usage: 0.60, #running-req: 163, #queue-req: 1749, 
[1,0]<stderr>:[2025-10-10 17:19:48 TP0] Decode batch. #running-req: 163, #token: 40351, token usage: 0.62, cuda graph: False, gen throughput (token/s): 860.74, #queue-req: 1749, 
[1,0]<stderr>:[2025-10-10 17:19:48 TP0] Prefill batch. #new-seq: 6, #new-token: 1826, #cached-token: 11, token usage: 0.58, #running-req: 163, #queue-req: 1743, 
[1,0]<stderr>:[2025-10-10 17:19:49 TP0] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.61, #running-req: 167, #queue-req: 1742, 
[1,0]<stderr>:[2025-10-10 17:19:49 TP0] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 2, token usage: 0.61, #running-req: 166, #queue-req: 1741, 
[1,0]<stderr>:[2025-10-10 17:19:50 TP0] Prefill batch. #new-seq: 2, #new-token: 1481, #cached-token: 7, token usage: 0.58, #running-req: 161, #queue-req: 1739, 
[1,0]<stderr>:[2025-10-10 17:19:50 TP0] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 2, token usage: 0.61, #running-req: 160, #queue-req: 1738, 
[1,0]<stderr>:[2025-10-10 17:19:50 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.62, #running-req: 160, #queue-req: 1737, 
[1,0]<stderr>:[2025-10-10 17:19:51 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 4, token usage: 0.61, #running-req: 160, #queue-req: 1736, 
[1,0]<stderr>:[2025-10-10 17:19:51 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.61, #running-req: 159, #queue-req: 1735, 
[1,0]<stderr>:[2025-10-10 17:19:51 TP0] Prefill batch. #new-seq: 3, #new-token: 201, #cached-token: 6, token usage: 0.61, #running-req: 158, #queue-req: 1732, 
[1,0]<stderr>:[2025-10-10 17:19:52 TP0] Prefill batch. #new-seq: 4, #new-token: 1656, #cached-token: 8, token usage: 0.58, #running-req: 158, #queue-req: 1728, 
[1,0]<stderr>:[2025-10-10 17:19:52 TP0] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 1, token usage: 0.60, #running-req: 158, #queue-req: 1727, 
[1,0]<stderr>:[2025-10-10 17:19:53 TP0] Prefill batch. #new-seq: 5, #new-token: 1234, #cached-token: 12, token usage: 0.60, #running-req: 158, #queue-req: 1722, 
[1,0]<stderr>:[2025-10-10 17:19:53 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.61, #running-req: 160, #queue-req: 1721, 
[1,0]<stderr>:[2025-10-10 17:19:54 TP0] Prefill batch. #new-seq: 2, #new-token: 324, #cached-token: 6, token usage: 0.62, #running-req: 159, #queue-req: 1719, 
[1,0]<stderr>:[2025-10-10 17:19:54 TP0] Prefill batch. #new-seq: 5, #new-token: 1008, #cached-token: 16, token usage: 0.60, #running-req: 158, #queue-req: 1714, 
[1,0]<stderr>:[2025-10-10 17:19:54 TP0] Decode batch. #running-req: 158, #token: 40458, token usage: 0.62, cuda graph: False, gen throughput (token/s): 965.21, #queue-req: 1714, 
[1,0]<stderr>:[2025-10-10 17:19:55 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 2, token usage: 0.62, #running-req: 162, #queue-req: 1713, 
[1,0]<stderr>:[2025-10-10 17:19:55 TP0] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 4, token usage: 0.63, #running-req: 162, #queue-req: 1712, 
[1,0]<stderr>:[2025-10-10 17:19:56 TP0] Prefill batch. #new-seq: 3, #new-token: 1179, #cached-token: 4, token usage: 0.62, #running-req: 160, #queue-req: 1709, 
[1,0]<stderr>:[2025-10-10 17:19:57 TP0] Prefill batch. #new-seq: 3, #new-token: 1471, #cached-token: 11, token usage: 0.63, #running-req: 156, #queue-req: 1706, 
[1,0]<stderr>:[2025-10-10 17:19:57 TP0] Prefill batch. #new-seq: 2, #new-token: 346, #cached-token: 9, token usage: 0.66, #running-req: 155, #queue-req: 1704, 
[1,0]<stderr>:[2025-10-10 17:19:58 TP0] Prefill batch. #new-seq: 3, #new-token: 40, #cached-token: 10, token usage: 0.65, #running-req: 154, #queue-req: 1701, 
[1,0]<stderr>:[2025-10-10 17:19:58 TP0] Prefill batch. #new-seq: 2, #new-token: 506, #cached-token: 2, token usage: 0.65, #running-req: 152, #queue-req: 1699, 
[1,0]<stderr>:[2025-10-10 17:19:58 TP0] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 1, token usage: 0.65, #running-req: 153, #queue-req: 1698, 
[1,0]<stderr>:[2025-10-10 17:19:59 TP0] Prefill batch. #new-seq: 2, #new-token: 779, #cached-token: 10, token usage: 0.65, #running-req: 152, #queue-req: 1696, 
[1,0]<stderr>:[2025-10-10 17:20:00 TP0] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.66, #running-req: 150, #queue-req: 1695, 
[1,0]<stderr>:[2025-10-10 17:20:01 TP0] Decode batch. #running-req: 151, #token: 44680, token usage: 0.68, cuda graph: False, gen throughput (token/s): 1023.06, #queue-req: 1695, 
[1,0]<stderr>:[2025-10-10 17:20:01 TP0] Prefill batch. #new-seq: 2, #new-token: 457, #cached-token: 6, token usage: 0.68, #running-req: 149, #queue-req: 1693, 
[1,0]<stderr>:[2025-10-10 17:20:03 TP0] Prefill batch. #new-seq: 2, #new-token: 614, #cached-token: 7, token usage: 0.70, #running-req: 147, #queue-req: 1691, 
[1,0]<stderr>:[2025-10-10 17:20:04 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.71, #running-req: 147, #queue-req: 1690, 
[1,0]<stderr>:[2025-10-10 17:20:05 TP0] Prefill batch. #new-seq: 4, #new-token: 938, #cached-token: 7, token usage: 0.70, #running-req: 146, #queue-req: 1686, 
[1,0]<stderr>:[2025-10-10 17:20:05 TP0] Prefill batch. #new-seq: 2, #new-token: 457, #cached-token: 6, token usage: 0.72, #running-req: 149, #queue-req: 1684, 
[1,0]<stderr>:[2025-10-10 17:20:06 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 4, token usage: 0.72, #running-req: 149, #queue-req: 1683, 
[1,0]<stderr>:[2025-10-10 17:20:06 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 1, token usage: 0.72, #running-req: 148, #queue-req: 1682, 
[1,0]<stderr>:[2025-10-10 17:20:06 TP0] Decode batch. #running-req: 147, #token: 46995, token usage: 0.72, cuda graph: False, gen throughput (token/s): 1037.53, #queue-req: 1682, 
[1,0]<stderr>:[2025-10-10 17:20:06 TP0] Prefill batch. #new-seq: 3, #new-token: 1048, #cached-token: 9, token usage: 0.70, #running-req: 146, #queue-req: 1679, 
[1,0]<stderr>:[2025-10-10 17:20:07 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.72, #running-req: 146, #queue-req: 1678, 
[1,0]<stderr>:[2025-10-10 17:20:07 TP0] Prefill batch. #new-seq: 11, #new-token: 1674, #cached-token: 24, token usage: 0.67, #running-req: 146, #queue-req: 1667, 
[1,0]<stderr>:[2025-10-10 17:20:08 TP0] Prefill batch. #new-seq: 6, #new-token: 867, #cached-token: 14, token usage: 0.69, #running-req: 152, #queue-req: 1661, 
[1,0]<stderr>:[2025-10-10 17:20:08 TP0] Prefill batch. #new-seq: 2, #new-token: 683, #cached-token: 4, token usage: 0.69, #running-req: 156, #queue-req: 1659, 
[1,0]<stderr>:[2025-10-10 17:20:09 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.69, #running-req: 155, #queue-req: 1658, 
[1,0]<stderr>:[2025-10-10 17:20:09 TP0] Prefill batch. #new-seq: 4, #new-token: 705, #cached-token: 7, token usage: 0.67, #running-req: 154, #queue-req: 1654, 
[1,0]<stderr>:[2025-10-10 17:20:09 TP0] Prefill batch. #new-seq: 2, #new-token: 884, #cached-token: 6, token usage: 0.68, #running-req: 156, #queue-req: 1652, 
[1,0]<stderr>:[2025-10-10 17:20:09 TP0] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 3, token usage: 0.69, #running-req: 155, #queue-req: 1651, 
[1,0]<stderr>:[2025-10-10 17:20:10 TP0] Prefill batch. #new-seq: 2, #new-token: 633, #cached-token: 10, token usage: 0.69, #running-req: 154, #queue-req: 1649, 
[1,0]<stderr>:[2025-10-10 17:20:10 TP0] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 6, token usage: 0.69, #running-req: 154, #queue-req: 1648, 
[1,0]<stderr>:[2025-10-10 17:20:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1132, #cached-token: 4, token usage: 0.70, #running-req: 151, #queue-req: 1647, 
[1,0]<stderr>:[2025-10-10 17:20:12 TP0] Prefill batch. #new-seq: 2, #new-token: 741, #cached-token: 5, token usage: 0.71, #running-req: 149, #queue-req: 1645, 
[1,0]<stderr>:[2025-10-10 17:20:12 TP0] Decode batch. #running-req: 150, #token: 47783, token usage: 0.73, cuda graph: False, gen throughput (token/s): 993.77, #queue-req: 1645, 
[1,0]<stderr>:[2025-10-10 17:20:13 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.73, #running-req: 148, #queue-req: 1644, 
[1,0]<stderr>:[2025-10-10 17:20:15 TP0] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 1, token usage: 0.75, #running-req: 146, #queue-req: 1643, 
[1,0]<stderr>:[2025-10-10 17:20:15 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.76, #running-req: 146, #queue-req: 1642, 
[1,0]<stderr>:[2025-10-10 17:20:15 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.75, #running-req: 146, #queue-req: 1641, 
[1,0]<stderr>:[2025-10-10 17:20:18 TP0] Decode batch. #running-req: 140, #token: 49302, token usage: 0.75, cuda graph: False, gen throughput (token/s): 1156.03, #queue-req: 1641, 
[1,0]<stderr>:[2025-10-10 17:20:18 TP0] Prefill batch. #new-seq: 4, #new-token: 2511, #cached-token: 8, token usage: 0.74, #running-req: 138, #queue-req: 1637, 
[1,0]<stderr>:[2025-10-10 17:20:19 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.78, #running-req: 140, #queue-req: 1636, 
[1,0]<stderr>:[2025-10-10 17:20:22 TP0] Prefill batch. #new-seq: 3, #new-token: 1433, #cached-token: 6, token usage: 0.79, #running-req: 132, #queue-req: 1633, 
[1,0]<stderr>:[2025-10-10 17:20:22 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 1, token usage: 0.81, #running-req: 134, #queue-req: 1632, 
[1,0]<stderr>:[2025-10-10 17:20:23 TP0] Decode batch. #running-req: 135, #token: 54069, token usage: 0.83, cuda graph: False, gen throughput (token/s): 1075.52, #queue-req: 1632, 
[1,0]<stderr>:[2025-10-10 17:20:23 TP0] Prefill batch. #new-seq: 3, #new-token: 632, #cached-token: 14, token usage: 0.82, #running-req: 130, #queue-req: 1629, 
[1,0]<stderr>:[2025-10-10 17:20:24 TP0] Prefill batch. #new-seq: 1, #new-token: 728, #cached-token: 5, token usage: 0.82, #running-req: 130, #queue-req: 1628, 
[1,0]<stderr>:[2025-10-10 17:20:25 TP0] Prefill batch. #new-seq: 4, #new-token: 1255, #cached-token: 8, token usage: 0.81, #running-req: 126, #queue-req: 1624, 
[1,0]<stderr>:[2025-10-10 17:20:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 2, token usage: 0.81, #running-req: 127, #queue-req: 1623, 
[1,0]<stderr>:[2025-10-10 17:20:26 TP0] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 3, token usage: 0.83, #running-req: 126, #queue-req: 1622, 
[1,0]<stderr>:[2025-10-10 17:20:27 TP0] Prefill batch. #new-seq: 1, #new-token: 990, #cached-token: 3, token usage: 0.83, #running-req: 124, #queue-req: 1621, 
[1,0]<stderr>:[2025-10-10 17:20:28 TP0] Decode batch. #running-req: 124, #token: 55894, token usage: 0.85, cuda graph: False, gen throughput (token/s): 973.06, #queue-req: 1621, 
[1,0]<stderr>:[2025-10-10 17:20:29 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.85, #running-req: 122, #queue-req: 1620, 
[1,0]<stderr>:[2025-10-10 17:20:29 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.86, #running-req: 122, #queue-req: 1619, 
[1,0]<stderr>:[2025-10-10 17:20:30 TP0] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.86, #running-req: 122, #queue-req: 1618, 
[1,0]<stderr>:[2025-10-10 17:20:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1940, #cached-token: 1, token usage: 0.84, #running-req: 116, #queue-req: 1617, 
[1,0]<stderr>:[2025-10-10 17:20:32 TP0] Prefill batch. #new-seq: 2, #new-token: 1483, #cached-token: 6, token usage: 0.86, #running-req: 115, #queue-req: 1615, 
[1,0]<stderr>:[2025-10-10 17:20:33 TP0] Decode batch. #running-req: 117, #token: 58450, token usage: 0.89, cuda graph: False, gen throughput (token/s): 932.60, #queue-req: 1615, 
[1,0]<stderr>:[2025-10-10 17:20:34 TP0] Prefill batch. #new-seq: 1, #new-token: 834, #cached-token: 1, token usage: 0.88, #running-req: 115, #queue-req: 1614, 
[1,0]<stderr>:[2025-10-10 17:20:34 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.88, #running-req: 113, #queue-req: 1613, 
[1,0]<stderr>:[2025-10-10 17:20:34 TP0] Prefill batch. #new-seq: 6, #new-token: 950, #cached-token: 12, token usage: 0.86, #running-req: 111, #queue-req: 1607, 
[1,0]<stderr>:[2025-10-10 17:20:34 TP0] Prefill batch. #new-seq: 3, #new-token: 730, #cached-token: 9, token usage: 0.87, #running-req: 116, #queue-req: 1604, 
[1,0]<stderr>:[2025-10-10 17:20:35 TP0] Prefill batch. #new-seq: 3, #new-token: 1085, #cached-token: 8, token usage: 0.87, #running-req: 117, #queue-req: 1601, 
[1,0]<stderr>:[2025-10-10 17:20:35 TP0] Prefill batch. #new-seq: 4, #new-token: 707, #cached-token: 5, token usage: 0.86, #running-req: 118, #queue-req: 1597, 
[1,0]<stderr>:[2025-10-10 17:20:35 TP0] Prefill batch. #new-seq: 2, #new-token: 1339, #cached-token: 3, token usage: 0.86, #running-req: 120, #queue-req: 1595, 
[1,0]<stderr>:[2025-10-10 17:20:36 TP0] Prefill batch. #new-seq: 3, #new-token: 1263, #cached-token: 7, token usage: 0.85, #running-req: 117, #queue-req: 1592, 
[1,0]<stderr>:[2025-10-10 17:20:37 TP0] Prefill batch. #new-seq: 3, #new-token: 1057, #cached-token: 8, token usage: 0.87, #running-req: 117, #queue-req: 1589, 
[1,0]<stderr>:[2025-10-10 17:20:37 TP0] Prefill batch. #new-seq: 3, #new-token: 576, #cached-token: 4, token usage: 0.88, #running-req: 118, #queue-req: 1586, 
[1,0]<stderr>:[2025-10-10 17:20:37 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.87, #running-req: 120, #queue-req: 1585, 
[1,0]<stderr>:[2025-10-10 17:20:37 TP0] Prefill batch. #new-seq: 5, #new-token: 587, #cached-token: 14, token usage: 0.86, #running-req: 120, #queue-req: 1580, 
[1,0]<stderr>:[2025-10-10 17:20:38 TP0] Prefill batch. #new-seq: 3, #new-token: 1020, #cached-token: 5, token usage: 0.86, #running-req: 122, #queue-req: 1577, 
[1,0]<stderr>:[2025-10-10 17:20:38 TP0] Prefill batch. #new-seq: 2, #new-token: 862, #cached-token: 4, token usage: 0.87, #running-req: 124, #queue-req: 1575, 
[1,0]<stderr>:[2025-10-10 17:20:38 TP0] Prefill batch. #new-seq: 2, #new-token: 299, #cached-token: 5, token usage: 0.88, #running-req: 124, #queue-req: 1573, 
[1,0]<stderr>:[2025-10-10 17:20:39 TP0] Prefill batch. #new-seq: 1, #new-token: 547, #cached-token: 1, token usage: 0.88, #running-req: 124, #queue-req: 1572, 
[1,0]<stderr>:[2025-10-10 17:20:39 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.88, #running-req: 123, #queue-req: 1571, 
[1,0]<stderr>:[2025-10-10 17:20:40 TP0] Prefill batch. #new-seq: 2, #new-token: 772, #cached-token: 6, token usage: 0.86, #running-req: 121, #queue-req: 1569, 
[1,0]<stderr>:[2025-10-10 17:20:40 TP0] Decode batch. #running-req: 120, #token: 56977, token usage: 0.87, cuda graph: False, gen throughput (token/s): 697.10, #queue-req: 1569, 
[1,0]<stderr>:[2025-10-10 17:20:40 TP0] Prefill batch. #new-seq: 2, #new-token: 1083, #cached-token: 3, token usage: 0.86, #running-req: 118, #queue-req: 1567, 
[1,0]<stderr>:[2025-10-10 17:20:41 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 4, token usage: 0.88, #running-req: 119, #queue-req: 1566, 
[1,0]<stderr>:[2025-10-10 17:20:41 TP0] Prefill batch. #new-seq: 4, #new-token: 1058, #cached-token: 7, token usage: 0.87, #running-req: 118, #queue-req: 1562, 
[1,0]<stderr>:[2025-10-10 17:20:42 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.89, #running-req: 121, #queue-req: 1561, 
[1,0]<stderr>:[2025-10-10 17:20:42 TP0] Prefill batch. #new-seq: 4, #new-token: 956, #cached-token: 14, token usage: 0.87, #running-req: 119, #queue-req: 1557, 
[1,0]<stderr>:[2025-10-10 17:20:45 TP0] Decode batch. #running-req: 115, #token: 57528, token usage: 0.88, cuda graph: False, gen throughput (token/s): 917.78, #queue-req: 1557, 
[1,0]<stderr>:[2025-10-10 17:20:45 TP0] Prefill batch. #new-seq: 2, #new-token: 1917, #cached-token: 3, token usage: 0.88, #running-req: 114, #queue-req: 1555, 
[1,0]<stderr>:[2025-10-10 17:20:45 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.91, #running-req: 114, #queue-req: 1554, 
[1,0]<stderr>:[2025-10-10 17:20:46 TP0] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 2, token usage: 0.91, #running-req: 114, #queue-req: 1553, 
[1,0]<stderr>:[2025-10-10 17:20:46 TP0] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 1, token usage: 0.91, #running-req: 114, #queue-req: 1552, 
[1,0]<stderr>:[2025-10-10 17:20:46 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.90, #running-req: 113, #queue-req: 1551, 
[1,0]<stderr>:[2025-10-10 17:20:47 TP0] Prefill batch. #new-seq: 5, #new-token: 392, #cached-token: 11, token usage: 0.89, #running-req: 112, #queue-req: 1546, 
[1,0]<stderr>:[2025-10-10 17:20:47 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 2, token usage: 0.88, #running-req: 116, #queue-req: 1545, 
[1,0]<stderr>:[2025-10-10 17:20:48 TP0] Prefill batch. #new-seq: 2, #new-token: 2581, #cached-token: 4, token usage: 0.87, #running-req: 116, #queue-req: 1543, 
[1,0]<stderr>:[2025-10-10 17:20:48 TP0] Prefill batch. #new-seq: 3, #new-token: 31, #cached-token: 3, token usage: 0.91, #running-req: 116, #queue-req: 1540, 
[1,0]<stderr>:[2025-10-10 17:20:48 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.91, #running-req: 118, #queue-req: 1539, 
[1,0]<stderr>:[2025-10-10 17:20:49 TP0] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 5, token usage: 0.91, #running-req: 118, #queue-req: 1538, 
[1,0]<stderr>:[2025-10-10 17:20:50 TP0] Prefill batch. #new-seq: 2, #new-token: 126, #cached-token: 3, token usage: 0.91, #running-req: 118, #queue-req: 1536, 
[1,0]<stderr>:[2025-10-10 17:20:51 TP0] Prefill batch. #new-seq: 6, #new-token: 588, #cached-token: 14, token usage: 0.89, #running-req: 116, #queue-req: 1530, 
[1,0]<stderr>:[2025-10-10 17:20:51 TP0] Prefill batch. #new-seq: 3, #new-token: 37, #cached-token: 5, token usage: 0.90, #running-req: 120, #queue-req: 1527, 
[1,0]<stderr>:[2025-10-10 17:20:52 TP0] Decode batch. #running-req: 122, #token: 58596, token usage: 0.89, cuda graph: False, gen throughput (token/s): 739.31, #queue-req: 1527, 
[1,0]<stderr>:[2025-10-10 17:20:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1534, #cached-token: 1, token usage: 0.89, #running-req: 121, #queue-req: 1526, 
[1,0]<stderr>:[2025-10-10 17:20:52 TP0] Prefill batch. #new-seq: 9, #new-token: 1658, #cached-token: 17, token usage: 0.87, #running-req: 119, #queue-req: 1517, 
[1,0]<stderr>:[2025-10-10 17:20:52 TP0] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 2, token usage: 0.90, #running-req: 127, #queue-req: 1516, 
[1,0]<stderr>:[2025-10-10 17:20:53 TP0] Prefill batch. #new-seq: 3, #new-token: 1025, #cached-token: 5, token usage: 0.89, #running-req: 125, #queue-req: 1513, 
[1,0]<stderr>:[2025-10-10 17:20:54 TP0] Prefill batch. #new-seq: 7, #new-token: 1692, #cached-token: 16, token usage: 0.89, #running-req: 126, #queue-req: 1506, 
[1,0]<stderr>:[2025-10-10 17:20:54 TP0] Prefill batch. #new-seq: 2, #new-token: 286, #cached-token: 2, token usage: 0.91, #running-req: 130, #queue-req: 1504, 
[1,0]<stderr>:[2025-10-10 17:20:54 TP0] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 3, token usage: 0.90, #running-req: 131, #queue-req: 1503, 
[1,0]<stderr>:[2025-10-10 17:20:55 TP0] Prefill batch. #new-seq: 3, #new-token: 629, #cached-token: 7, token usage: 0.90, #running-req: 131, #queue-req: 1500, 
[1,0]<stderr>:[2025-10-10 17:20:55 TP0] Prefill batch. #new-seq: 2, #new-token: 49, #cached-token: 2, token usage: 0.91, #running-req: 133, #queue-req: 1498, 
[1,0]<stderr>:[2025-10-10 17:20:55 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.91, #running-req: 134, #queue-req: 1497, 
[1,0]<stderr>:[2025-10-10 17:20:56 TP0] Prefill batch. #new-seq: 2, #new-token: 726, #cached-token: 3, token usage: 0.91, #running-req: 133, #queue-req: 1495, 
[1,0]<stderr>:[2025-10-10 17:20:56 TP0] Prefill batch. #new-seq: 1, #new-token: 486, #cached-token: 1, token usage: 0.91, #running-req: 133, #queue-req: 1494, 
[1,0]<stderr>:[2025-10-10 17:20:56 TP0] Prefill batch. #new-seq: 2, #new-token: 94, #cached-token: 5, token usage: 0.90, #running-req: 131, #queue-req: 1492, 
[1,0]<stderr>:[2025-10-10 17:20:57 TP0] Prefill batch. #new-seq: 2, #new-token: 867, #cached-token: 7, token usage: 0.91, #running-req: 131, #queue-req: 1490, 
[1,0]<stderr>:[2025-10-10 17:20:57 TP0] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 2, token usage: 0.92, #running-req: 132, #queue-req: 1489, 
[1,0]<stderr>:[2025-10-10 17:20:58 TP0] Decode batch. #running-req: 133, #token: 59531, token usage: 0.91, cuda graph: False, gen throughput (token/s): 812.35, #queue-req: 1489, 
[1,0]<stderr>:[2025-10-10 17:20:58 TP0] Prefill batch. #new-seq: 3, #new-token: 43, #cached-token: 6, token usage: 0.91, #running-req: 132, #queue-req: 1486, 
[1,0]<stderr>:[2025-10-10 17:20:59 TP0] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 2, token usage: 0.91, #running-req: 133, #queue-req: 1485, 
[1,0]<stderr>:[2025-10-10 17:20:59 TP0] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 2, token usage: 0.92, #running-req: 132, #queue-req: 1484, 
[1,0]<stderr>:[2025-10-10 17:21:00 TP0] Prefill batch. #new-seq: 1, #new-token: 881, #cached-token: 1, token usage: 0.91, #running-req: 131, #queue-req: 1483, 
[1,0]<stderr>:[2025-10-10 17:21:00 TP0] Prefill batch. #new-seq: 3, #new-token: 1050, #cached-token: 9, token usage: 0.92, #running-req: 129, #queue-req: 1480, 
[1,0]<stderr>:[2025-10-10 17:21:01 TP0] Prefill batch. #new-seq: 6, #new-token: 226, #cached-token: 12, token usage: 0.93, #running-req: 129, #queue-req: 1474, 
[1,0]<stderr>:[2025-10-10 17:21:02 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.93, #running-req: 134, #queue-req: 1473, 
[1,0]<stderr>:[2025-10-10 17:21:03 TP0] Decode batch. #running-req: 134, #token: 61941, token usage: 0.95, cuda graph: False, gen throughput (token/s): 1006.39, #queue-req: 1473, 
[1,0]<stderr>:[2025-10-10 17:21:04 TP0] Prefill batch. #new-seq: 6, #new-token: 1356, #cached-token: 6, token usage: 0.93, #running-req: 132, #queue-req: 1467, 
[1,0]<stderr>:[2025-10-10 17:21:04 TP0] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 3, token usage: 0.95, #running-req: 136, #queue-req: 1466, 
[1,0]<stderr>:[2025-10-10 17:21:05 TP0] Prefill batch. #new-seq: 8, #new-token: 1405, #cached-token: 25, token usage: 0.92, #running-req: 136, #queue-req: 1458, 
[1,0]<stderr>:[2025-10-10 17:21:05 TP0] Prefill batch. #new-seq: 2, #new-token: 548, #cached-token: 4, token usage: 0.94, #running-req: 141, #queue-req: 1456, 
[1,0]<stderr>:[2025-10-10 17:21:06 TP0] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 2, token usage: 0.95, #running-req: 142, #queue-req: 1455, 
[1,0]<stderr>:[2025-10-10 17:21:07 TP0] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 2, token usage: 0.95, #running-req: 137, #queue-req: 1454, 
[1,0]<stderr>:[2025-10-10 17:21:08 TP0] Prefill batch. #new-seq: 3, #new-token: 458, #cached-token: 5, token usage: 0.94, #running-req: 136, #queue-req: 1451, 
[1,0]<stderr>:[2025-10-10 17:21:08 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.95, #running-req: 137, #queue-req: 1450, 
[1,0]<stderr>:[2025-10-10 17:21:08 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 2, token usage: 0.96, #running-req: 137, #queue-req: 1449, 
[1,0]<stderr>:[2025-10-10 17:21:09 TP0] Prefill batch. #new-seq: 1, #new-token: 720, #cached-token: 1, token usage: 0.94, #running-req: 137, #queue-req: 1448, 
[1,0]<stderr>:[2025-10-10 17:21:09 TP0] Decode batch. #running-req: 137, #token: 62472, token usage: 0.95, cuda graph: False, gen throughput (token/s): 1003.36, #queue-req: 1448, 
[1,0]<stderr>:[2025-10-10 17:21:09 TP0] Prefill batch. #new-seq: 1, #new-token: 795, #cached-token: 2, token usage: 0.94, #running-req: 137, #queue-req: 1447, 
[1,0]<stderr>:[2025-10-10 17:21:09 TP0] Prefill batch. #new-seq: 4, #new-token: 1487, #cached-token: 10, token usage: 0.93, #running-req: 134, #queue-req: 1443, 
[1,0]<stderr>:[2025-10-10 17:21:10 TP0] Prefill batch. #new-seq: 4, #new-token: 1012, #cached-token: 5, token usage: 0.94, #running-req: 137, #queue-req: 1439, 
[1,0]<stderr>:[2025-10-10 17:21:10 TP0] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 2, token usage: 0.96, #running-req: 139, #queue-req: 1438, 
[1,0]<stderr>:[2025-10-10 17:21:10 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.95, #running-req: 138, #queue-req: 1437, 
[1,0]<stderr>:[2025-10-10 17:21:12 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 1, token usage: 0.94, #running-req: 136, #queue-req: 1436, 
[1,0]<stderr>:[2025-10-10 17:21:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1595, #cached-token: 2, token usage: 0.94, #running-req: 134, #queue-req: 1435, 
[1,0]<stderr>:[2025-10-10 17:21:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1292, #cached-token: 2, token usage: 0.93, #running-req: 129, #queue-req: 1434, 
[1,0]<stderr>:[2025-10-10 17:21:14 TP0] Prefill batch. #new-seq: 2, #new-token: 598, #cached-token: 2, token usage: 0.94, #running-req: 124, #queue-req: 1432, 
[1,0]<stderr>:[2025-10-10 17:21:14 TP0] Decode batch. #running-req: 124, #token: 62792, token usage: 0.96, cuda graph: False, gen throughput (token/s): 938.38, #queue-req: 1432, 
[1,0]<stderr>:[2025-10-10 17:21:15 TP0] Prefill batch. #new-seq: 2, #new-token: 514, #cached-token: 7, token usage: 0.94, #running-req: 122, #queue-req: 1430, 
[1,0]<stderr>:[2025-10-10 17:21:16 TP0] Prefill batch. #new-seq: 2, #new-token: 3428, #cached-token: 3, token usage: 0.89, #running-req: 117, #queue-req: 1428, 
[1,0]<stderr>:[2025-10-10 17:21:16 TP0] Prefill batch. #new-seq: 4, #new-token: 1238, #cached-token: 18, token usage: 0.94, #running-req: 116, #queue-req: 1424, 
[1,0]<stderr>:[2025-10-10 17:21:16 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.95, #running-req: 119, #queue-req: 1423, 
[1,0]<stderr>:[2025-10-10 17:21:17 TP0] Prefill batch. #new-seq: 2, #new-token: 757, #cached-token: 6, token usage: 0.95, #running-req: 119, #queue-req: 1421, 
[1,0]<stderr>:[2025-10-10 17:21:17 TP0] Prefill batch. #new-seq: 2, #new-token: 310, #cached-token: 10, token usage: 0.95, #running-req: 120, #queue-req: 1419, 
[1,0]<stderr>:[2025-10-10 17:21:18 TP0] Prefill batch. #new-seq: 5, #new-token: 755, #cached-token: 10, token usage: 0.94, #running-req: 121, #queue-req: 1414, 
[1,0]<stderr>:[2025-10-10 17:21:18 TP0] Prefill batch. #new-seq: 4, #new-token: 549, #cached-token: 6, token usage: 0.94, #running-req: 123, #queue-req: 1410, 
[1,0]<stderr>:[2025-10-10 17:21:19 TP0] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 8, token usage: 0.95, #running-req: 126, #queue-req: 1409, 
[1,0]<stderr>:[2025-10-10 17:21:20 TP0] Decode batch. #running-req: 126, #token: 63544, token usage: 0.97, cuda graph: False, gen throughput (token/s): 898.23, #queue-req: 1409, 
[1,0]<stderr>:[2025-10-10 17:21:21 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.95, #running-req: 120, #queue-req: 1408, 
[1,0]<stderr>:[2025-10-10 17:21:22 TP0] Prefill batch. #new-seq: 3, #new-token: 411, #cached-token: 19, token usage: 0.95, #running-req: 120, #queue-req: 1405, 
[1,0]<stderr>:[2025-10-10 17:21:22 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 4, token usage: 0.95, #running-req: 122, #queue-req: 1404, 
[1,0]<stderr>:[2025-10-10 17:21:22 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.95, #running-req: 120, #queue-req: 1403, 
[1,0]<stderr>:[2025-10-10 17:21:23 TP0] Prefill batch. #new-seq: 3, #new-token: 1292, #cached-token: 5, token usage: 0.93, #running-req: 118, #queue-req: 1400, 
[1,0]<stderr>:[2025-10-10 17:21:23 TP0] Prefill batch. #new-seq: 2, #new-token: 1064, #cached-token: 7, token usage: 0.95, #running-req: 118, #queue-req: 1398, 
[1,0]<stderr>:[2025-10-10 17:21:24 TP0] Prefill batch. #new-seq: 3, #new-token: 950, #cached-token: 8, token usage: 0.93, #running-req: 119, #queue-req: 1395, 
[1,0]<stderr>:[2025-10-10 17:21:24 TP0] Prefill batch. #new-seq: 10, #new-token: 3012, #cached-token: 23, token usage: 0.90, #running-req: 117, #queue-req: 1385, 
[1,0]<stderr>:[2025-10-10 17:21:25 TP0] Prefill batch. #new-seq: 2, #new-token: 722, #cached-token: 6, token usage: 0.93, #running-req: 126, #queue-req: 1383, 
[1,0]<stderr>:[2025-10-10 17:21:25 TP0] Prefill batch. #new-seq: 1, #new-token: 497, #cached-token: 2, token usage: 0.94, #running-req: 125, #queue-req: 1382, 
[1,0]<stderr>:[2025-10-10 17:21:25 TP0] Prefill batch. #new-seq: 4, #new-token: 1264, #cached-token: 10, token usage: 0.93, #running-req: 124, #queue-req: 1378, 
[1,0]<stderr>:[2025-10-10 17:21:26 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 1, token usage: 0.94, #running-req: 126, #queue-req: 1377, 
[1,0]<stderr>:[2025-10-10 17:21:26 TP0] Decode batch. #running-req: 126, #token: 62038, token usage: 0.95, cuda graph: False, gen throughput (token/s): 838.83, #queue-req: 1377, 
[1,0]<stderr>:[2025-10-10 17:21:26 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 6, token usage: 0.95, #running-req: 126, #queue-req: 1376, 
[1,0]<stderr>:[2025-10-10 17:21:26 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.95, #running-req: 126, #queue-req: 1375, 
[1,0]<stderr>:[2025-10-10 17:21:26 TP0] Prefill batch. #new-seq: 5, #new-token: 686, #cached-token: 9, token usage: 0.94, #running-req: 125, #queue-req: 1370, 
[1,0]<stderr>:[2025-10-10 17:21:27 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 1, token usage: 0.94, #running-req: 128, #queue-req: 1369, 
[1,0]<stderr>:[2025-10-10 17:21:27 TP0] Prefill batch. #new-seq: 1, #new-token: 885, #cached-token: 6, token usage: 0.93, #running-req: 127, #queue-req: 1368, 
[1,0]<stderr>:[2025-10-10 17:21:27 TP0] Prefill batch. #new-seq: 4, #new-token: 1670, #cached-token: 10, token usage: 0.93, #running-req: 126, #queue-req: 1364, 
[1,0]<stderr>:[2025-10-10 17:21:27 TP0] Prefill batch. #new-seq: 2, #new-token: 449, #cached-token: 6, token usage: 0.95, #running-req: 128, #queue-req: 1362, 
[1,0]<stderr>:[2025-10-10 17:21:28 TP0] Prefill batch. #new-seq: 4, #new-token: 1048, #cached-token: 14, token usage: 0.94, #running-req: 128, #queue-req: 1358, 
[1,0]<stderr>:[2025-10-10 17:21:28 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 1, token usage: 0.95, #running-req: 131, #queue-req: 1357, 
[1,0]<stderr>:[2025-10-10 17:21:28 TP0] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 2, token usage: 0.94, #running-req: 131, #queue-req: 1356, 
[1,0]<stderr>:[2025-10-10 17:21:28 TP0] Prefill batch. #new-seq: 1, #new-token: 910, #cached-token: 3, token usage: 0.94, #running-req: 131, #queue-req: 1355, 
[1,0]<stderr>:[2025-10-10 17:21:29 TP0] Prefill batch. #new-seq: 4, #new-token: 399, #cached-token: 7, token usage: 0.94, #running-req: 130, #queue-req: 1351, 
[1,0]<stderr>:[2025-10-10 17:21:29 TP0] Prefill batch. #new-seq: 8, #new-token: 1890, #cached-token: 27, token usage: 0.92, #running-req: 133, #queue-req: 1343, 
[1,0]<stderr>:[2025-10-10 17:21:29 TP0] Prefill batch. #new-seq: 3, #new-token: 1317, #cached-token: 3, token usage: 0.94, #running-req: 140, #queue-req: 1340, 
[1,0]<stderr>:[2025-10-10 17:21:30 TP0] Prefill batch. #new-seq: 5, #new-token: 494, #cached-token: 17, token usage: 0.93, #running-req: 139, #queue-req: 1335, 
[1,0]<stderr>:[2025-10-10 17:21:30 TP0] Prefill batch. #new-seq: 2, #new-token: 142, #cached-token: 10, token usage: 0.94, #running-req: 143, #queue-req: 1333, 
[1,0]<stderr>:[2025-10-10 17:21:31 TP0] Prefill batch. #new-seq: 3, #new-token: 838, #cached-token: 8, token usage: 0.93, #running-req: 144, #queue-req: 1330, 
[1,0]<stderr>:[2025-10-10 17:21:31 TP0] Prefill batch. #new-seq: 2, #new-token: 18, #cached-token: 6, token usage: 0.95, #running-req: 145, #queue-req: 1328, 
[1,0]<stderr>:[2025-10-10 17:21:31 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.95, #running-req: 146, #queue-req: 1327, 
[1,0]<stderr>:[2025-10-10 17:21:32 TP0] Prefill batch. #new-seq: 3, #new-token: 456, #cached-token: 4, token usage: 0.95, #running-req: 146, #queue-req: 1324, 
[1,0]<stderr>:[2025-10-10 17:21:32 TP0] Prefill batch. #new-seq: 2, #new-token: 437, #cached-token: 3, token usage: 0.95, #running-req: 148, #queue-req: 1322, 
[1,0]<stderr>:[2025-10-10 17:21:33 TP0] Prefill batch. #new-seq: 5, #new-token: 2022, #cached-token: 7, token usage: 0.92, #running-req: 146, #queue-req: 1317, 
[1,0]<stderr>:[2025-10-10 17:21:33 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.95, #running-req: 148, #queue-req: 1316, 
[1,0]<stderr>:[2025-10-10 17:21:33 TP0] Decode batch. #running-req: 148, #token: 62477, token usage: 0.95, cuda graph: False, gen throughput (token/s): 765.00, #queue-req: 1316, 
[1,0]<stderr>:[2025-10-10 17:21:33 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.94, #running-req: 146, #queue-req: 1315, 
[1,0]<stderr>:[2025-10-10 17:21:34 TP0] Prefill batch. #new-seq: 2, #new-token: 275, #cached-token: 5, token usage: 0.94, #running-req: 146, #queue-req: 1313, 
[1,0]<stderr>:[2025-10-10 17:21:34 TP0] Prefill batch. #new-seq: 4, #new-token: 1371, #cached-token: 6, token usage: 0.93, #running-req: 147, #queue-req: 1309, 
[1,0]<stderr>:[2025-10-10 17:21:34 TP0] Prefill batch. #new-seq: 1, #new-token: 893, #cached-token: 1, token usage: 0.94, #running-req: 144, #queue-req: 1308, 
[1,0]<stderr>:[2025-10-10 17:21:35 TP0] Prefill batch. #new-seq: 5, #new-token: 692, #cached-token: 12, token usage: 0.91, #running-req: 140, #queue-req: 1303, 
[1,0]<stderr>:[2025-10-10 17:21:35 TP0] Prefill batch. #new-seq: 3, #new-token: 1422, #cached-token: 8, token usage: 0.91, #running-req: 142, #queue-req: 1300, 
[1,0]<stderr>:[2025-10-10 17:21:35 TP0] Prefill batch. #new-seq: 5, #new-token: 1294, #cached-token: 9, token usage: 0.93, #running-req: 144, #queue-req: 1295, 
[1,0]<stderr>:[2025-10-10 17:21:35 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.95, #running-req: 148, #queue-req: 1294, 
[1,0]<stderr>:[2025-10-10 17:21:36 TP0] Prefill batch. #new-seq: 2, #new-token: 826, #cached-token: 2, token usage: 0.94, #running-req: 145, #queue-req: 1292, 
[1,0]<stderr>:[2025-10-10 17:21:36 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.95, #running-req: 145, #queue-req: 1291, 
[1,0]<stderr>:[2025-10-10 17:21:37 TP0] Prefill batch. #new-seq: 3, #new-token: 1852, #cached-token: 7, token usage: 0.92, #running-req: 139, #queue-req: 1288, 
[1,0]<stderr>:[2025-10-10 17:21:38 TP0] Prefill batch. #new-seq: 3, #new-token: 273, #cached-token: 8, token usage: 0.95, #running-req: 141, #queue-req: 1285, 
[1,0]<stderr>:[2025-10-10 17:21:38 TP0] Prefill batch. #new-seq: 2, #new-token: 809, #cached-token: 9, token usage: 0.94, #running-req: 141, #queue-req: 1283, 
[1,0]<stderr>:[2025-10-10 17:21:39 TP0] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 1, token usage: 0.94, #running-req: 141, #queue-req: 1282, 
[1,0]<stderr>:[2025-10-10 17:21:39 TP0] Prefill batch. #new-seq: 1, #new-token: 695, #cached-token: 1, token usage: 0.94, #running-req: 141, #queue-req: 1281, 
[1,0]<stderr>:[2025-10-10 17:21:39 TP0] Decode batch. #running-req: 142, #token: 62398, token usage: 0.95, cuda graph: False, gen throughput (token/s): 888.71, #queue-req: 1281, 
[1,0]<stderr>:[2025-10-10 17:21:40 TP0] Prefill batch. #new-seq: 4, #new-token: 830, #cached-token: 6, token usage: 0.93, #running-req: 135, #queue-req: 1277, 
[1,0]<stderr>:[2025-10-10 17:21:40 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 3, token usage: 0.93, #running-req: 136, #queue-req: 1276, 
[1,0]<stderr>:[2025-10-10 17:21:41 TP0] Prefill batch. #new-seq: 2, #new-token: 1456, #cached-token: 4, token usage: 0.92, #running-req: 135, #queue-req: 1274, 
[1,0]<stderr>:[2025-10-10 17:21:41 TP0] Prefill batch. #new-seq: 6, #new-token: 376, #cached-token: 11, token usage: 0.94, #running-req: 135, #queue-req: 1268, 
[1,0]<stderr>:[2025-10-10 17:21:45 TP0] Decode batch. #running-req: 124, #token: 57687, token usage: 0.88, cuda graph: False, gen throughput (token/s): 1046.66, #queue-req: 1268, 
[1,0]<stderr>:[2025-10-10 17:21:45 TP0] Prefill batch. #new-seq: 4, #new-token: 7110, #cached-token: 9, token usage: 0.84, #running-req: 118, #queue-req: 1264, 
[1,0]<stderr>:[2025-10-10 17:21:46 TP0] Prefill batch. #new-seq: 2, #new-token: 291, #cached-token: 3, token usage: 0.95, #running-req: 121, #queue-req: 1262, 
[1,0]<stderr>:[2025-10-10 17:21:46 TP0] Prefill batch. #new-seq: 3, #new-token: 396, #cached-token: 3, token usage: 0.96, #running-req: 122, #queue-req: 1259, 
[1,0]<stderr>:[2025-10-10 17:21:47 TP0] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 2, token usage: 0.96, #running-req: 123, #queue-req: 1258, 
[1,0]<stderr>:[2025-10-10 17:21:47 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 5, token usage: 0.95, #running-req: 121, #queue-req: 1257, 
[1,0]<stderr>:[2025-10-10 17:21:47 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.93, #running-req: 119, #queue-req: 1256, 
[1,0]<stderr>:[2025-10-10 17:21:49 TP0] Prefill batch. #new-seq: 2, #new-token: 2321, #cached-token: 2, token usage: 0.92, #running-req: 111, #queue-req: 1254, 
[1,0]<stderr>:[2025-10-10 17:21:50 TP0] Prefill batch. #new-seq: 2, #new-token: 951, #cached-token: 8, token usage: 0.94, #running-req: 111, #queue-req: 1252, 
[1,0]<stderr>:[2025-10-10 17:21:50 TP0] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 1, token usage: 0.94, #running-req: 111, #queue-req: 1251, 
[1,0]<stderr>:[2025-10-10 17:21:50 TP0] Decode batch. #running-req: 111, #token: 62144, token usage: 0.95, cuda graph: False, gen throughput (token/s): 819.68, #queue-req: 1251, 
[1,0]<stderr>:[2025-10-10 17:21:52 TP0] Prefill batch. #new-seq: 4, #new-token: 1331, #cached-token: 14, token usage: 0.94, #running-req: 107, #queue-req: 1247, 
[1,0]<stderr>:[2025-10-10 17:21:52 TP0] Prefill batch. #new-seq: 3, #new-token: 78, #cached-token: 6, token usage: 0.94, #running-req: 108, #queue-req: 1244, 
[1,0]<stderr>:[2025-10-10 17:21:54 TP0] Prefill batch. #new-seq: 1, #new-token: 2247, #cached-token: 4, token usage: 0.92, #running-req: 103, #queue-req: 1243, 
[1,0]<stderr>:[2025-10-10 17:21:55 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 1, token usage: 0.96, #running-req: 103, #queue-req: 1242, 
[1,0]<stderr>:[2025-10-10 17:21:55 TP0] Decode batch. #running-req: 103, #token: 63014, token usage: 0.96, cuda graph: False, gen throughput (token/s): 838.04, #queue-req: 1242, 
[1,0]<stderr>:[2025-10-10 17:21:56 TP0] Prefill batch. #new-seq: 5, #new-token: 1106, #cached-token: 8, token usage: 0.94, #running-req: 100, #queue-req: 1237, 
[1,0]<stderr>:[2025-10-10 17:21:56 TP0] Prefill batch. #new-seq: 4, #new-token: 183, #cached-token: 6, token usage: 0.95, #running-req: 103, #queue-req: 1233, 
[1,0]<stderr>:[2025-10-10 17:21:57 TP0] Prefill batch. #new-seq: 7, #new-token: 1917, #cached-token: 16, token usage: 0.91, #running-req: 106, #queue-req: 1226, 
[1,0]<stderr>:[2025-10-10 17:21:57 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.94, #running-req: 111, #queue-req: 1225, 
[1,0]<stderr>:[2025-10-10 17:21:58 TP0] Prefill batch. #new-seq: 3, #new-token: 2672, #cached-token: 7, token usage: 0.92, #running-req: 110, #queue-req: 1222, 
[1,0]<stderr>:[2025-10-10 17:21:58 TP0] Prefill batch. #new-seq: 2, #new-token: 176, #cached-token: 2, token usage: 0.95, #running-req: 108, #queue-req: 1220, 
[1,0]<stderr>:[2025-10-10 17:21:59 TP0] Prefill batch. #new-seq: 6, #new-token: 1093, #cached-token: 8, token usage: 0.93, #running-req: 107, #queue-req: 1214, 
[1,0]<stderr>:[2025-10-10 17:22:00 TP0] Prefill batch. #new-seq: 3, #new-token: 844, #cached-token: 5, token usage: 0.94, #running-req: 111, #queue-req: 1211, 
[1,0]<stderr>:[2025-10-10 17:22:01 TP0] Decode batch. #running-req: 109, #token: 61845, token usage: 0.94, cuda graph: False, gen throughput (token/s): 805.87, #queue-req: 1211, 
[1,0]<stderr>:[2025-10-10 17:22:02 TP0] Prefill batch. #new-seq: 1, #new-token: 2044, #cached-token: 1, token usage: 0.93, #running-req: 102, #queue-req: 1210, 
[1,0]<stderr>:[2025-10-10 17:22:02 TP0] Prefill batch. #new-seq: 2, #new-token: 28, #cached-token: 5, token usage: 0.95, #running-req: 102, #queue-req: 1208, 
[1,0]<stderr>:[2025-10-10 17:22:03 TP0] Prefill batch. #new-seq: 1, #new-token: 771, #cached-token: 3, token usage: 0.95, #running-req: 101, #queue-req: 1207, 
[1,0]<stderr>:[2025-10-10 17:22:06 TP0] Decode batch. #running-req: 97, #token: 63332, token usage: 0.97, cuda graph: False, gen throughput (token/s): 837.75, #queue-req: 1207, 
[1,0]<stderr>:[2025-10-10 17:22:06 TP0] Prefill batch. #new-seq: 3, #new-token: 1047, #cached-token: 12, token usage: 0.94, #running-req: 94, #queue-req: 1204, 
[1,0]<stderr>:[2025-10-10 17:22:06 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.96, #running-req: 96, #queue-req: 1203, 
[1,0]<stderr>:[2025-10-10 17:22:07 TP0] Prefill batch. #new-seq: 2, #new-token: 1089, #cached-token: 6, token usage: 0.95, #running-req: 96, #queue-req: 1201, 
[1,0]<stderr>:[2025-10-10 17:22:07 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.96, #running-req: 95, #queue-req: 1200, 
[1,0]<stderr>:[2025-10-10 17:22:08 TP0] Prefill batch. #new-seq: 5, #new-token: 1040, #cached-token: 16, token usage: 0.95, #running-req: 94, #queue-req: 1195, 
[1,0]<stderr>:[2025-10-10 17:22:08 TP0] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.96, #running-req: 98, #queue-req: 1194, 
[1,0]<stderr>:[2025-10-10 17:22:09 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 3, token usage: 0.96, #running-req: 96, #queue-req: 1193, 
[1,0]<stderr>:[2025-10-10 17:22:10 TP0] Prefill batch. #new-seq: 1, #new-token: 691, #cached-token: 1, token usage: 0.95, #running-req: 94, #queue-req: 1192, 
[1,0]<stderr>:[2025-10-10 17:22:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1139, #cached-token: 6, token usage: 0.94, #running-req: 90, #queue-req: 1190, 
[1,0]<stderr>:[2025-10-10 17:22:11 TP0] Decode batch. #running-req: 90, #token: 62736, token usage: 0.96, cuda graph: False, gen throughput (token/s): 703.96, #queue-req: 1190, 
[1,0]<stderr>:[2025-10-10 17:22:11 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.96, #running-req: 91, #queue-req: 1189, 
[1,0]<stderr>:[2025-10-10 17:22:11 TP0] Prefill batch. #new-seq: 3, #new-token: 933, #cached-token: 4, token usage: 0.93, #running-req: 90, #queue-req: 1186, 
[1,0]<stderr>:[2025-10-10 17:22:12 TP0] Prefill batch. #new-seq: 3, #new-token: 2414, #cached-token: 5, token usage: 0.93, #running-req: 91, #queue-req: 1183, 
[1,0]<stderr>:[2025-10-10 17:22:12 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.96, #running-req: 93, #queue-req: 1182, 
[1,0]<stderr>:[2025-10-10 17:22:12 TP0] Prefill batch. #new-seq: 2, #new-token: 28, #cached-token: 4, token usage: 0.95, #running-req: 93, #queue-req: 1180, 
[1,0]<stderr>:[2025-10-10 17:22:14 TP0] Prefill batch. #new-seq: 2, #new-token: 1479, #cached-token: 3, token usage: 0.94, #running-req: 89, #queue-req: 1178, 
[1,0]<stderr>:[2025-10-10 17:22:15 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 8, token usage: 0.97, #running-req: 90, #queue-req: 1177, 
[1,0]<stderr>:[2025-10-10 17:22:15 TP0] Prefill batch. #new-seq: 2, #new-token: 12, #cached-token: 5, token usage: 0.96, #running-req: 89, #queue-req: 1175, 
[1,0]<stderr>:[2025-10-10 17:22:16 TP0] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 1, token usage: 0.96, #running-req: 90, #queue-req: 1174, 
[1,0]<stderr>:[2025-10-10 17:22:16 TP0] Prefill batch. #new-seq: 4, #new-token: 101, #cached-token: 6, token usage: 0.96, #running-req: 90, #queue-req: 1170, 
[1,0]<stderr>:[2025-10-10 17:22:17 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 4, token usage: 0.96, #running-req: 93, #queue-req: 1169, 
[1,0]<stderr>:[2025-10-10 17:22:17 TP0] Decode batch. #running-req: 94, #token: 63399, token usage: 0.97, cuda graph: False, gen throughput (token/s): 631.24, #queue-req: 1169, 
[1,0]<stderr>:[2025-10-10 17:22:17 TP0] Prefill batch. #new-seq: 7, #new-token: 2204, #cached-token: 14, token usage: 0.90, #running-req: 91, #queue-req: 1162, 
[1,0]<stderr>:[2025-10-10 17:22:20 TP0] Prefill batch. #new-seq: 2, #new-token: 2431, #cached-token: 3, token usage: 0.93, #running-req: 92, #queue-req: 1160, 
[1,0]<stderr>:[2025-10-10 17:22:20 TP0] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 2, token usage: 0.96, #running-req: 92, #queue-req: 1159, 
[1,0]<stderr>:[2025-10-10 17:22:20 TP0] Prefill batch. #new-seq: 2, #new-token: 46, #cached-token: 4, token usage: 0.96, #running-req: 92, #queue-req: 1157, 
[1,0]<stderr>:[2025-10-10 17:22:21 TP0] Prefill batch. #new-seq: 2, #new-token: 651, #cached-token: 9, token usage: 0.94, #running-req: 91, #queue-req: 1155, 
[1,0]<stderr>:[2025-10-10 17:22:21 TP0] Prefill batch. #new-seq: 2, #new-token: 971, #cached-token: 2, token usage: 0.95, #running-req: 92, #queue-req: 1153, 
[1,0]<stderr>:[2025-10-10 17:22:22 TP0] Decode batch. #running-req: 93, #token: 63831, token usage: 0.97, cuda graph: False, gen throughput (token/s): 699.64, #queue-req: 1153, 
[1,0]<stderr>:[2025-10-10 17:22:23 TP0] Prefill batch. #new-seq: 3, #new-token: 376, #cached-token: 5, token usage: 0.96, #running-req: 89, #queue-req: 1150, 
[1,0]<stderr>:[2025-10-10 17:22:23 TP0] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 6, token usage: 0.96, #running-req: 91, #queue-req: 1149, 
[1,0]<stderr>:[2025-10-10 17:22:23 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.96, #running-req: 91, #queue-req: 1148, 
[1,0]<stderr>:[2025-10-10 17:22:26 TP0] Prefill batch. #new-seq: 4, #new-token: 2472, #cached-token: 8, token usage: 0.91, #running-req: 83, #queue-req: 1144, 
[1,0]<stderr>:[2025-10-10 17:22:26 TP0] Prefill batch. #new-seq: 2, #new-token: 103, #cached-token: 2, token usage: 0.95, #running-req: 86, #queue-req: 1142, 
[1,0]<stderr>:[2025-10-10 17:22:27 TP0] Prefill batch. #new-seq: 4, #new-token: 775, #cached-token: 5, token usage: 0.94, #running-req: 87, #queue-req: 1138, 
[1,0]<stderr>:[2025-10-10 17:22:27 TP0] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 4, token usage: 0.95, #running-req: 90, #queue-req: 1137, 
[1,0]<stderr>:[2025-10-10 17:22:27 TP0] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 1, token usage: 0.95, #running-req: 90, #queue-req: 1136, 
[1,0]<stderr>:[2025-10-10 17:22:28 TP0] Decode batch. #running-req: 91, #token: 63268, token usage: 0.97, cuda graph: False, gen throughput (token/s): 633.27, #queue-req: 1136, 
[1,0]<stderr>:[2025-10-10 17:22:29 TP0] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 2, token usage: 0.94, #running-req: 86, #queue-req: 1135, 
[1,0]<stderr>:[2025-10-10 17:22:29 TP0] Prefill batch. #new-seq: 3, #new-token: 1253, #cached-token: 3, token usage: 0.95, #running-req: 86, #queue-req: 1132, 
[1,0]<stderr>:[2025-10-10 17:22:30 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.96, #running-req: 88, #queue-req: 1131, 
[1,0]<stderr>:[2025-10-10 17:22:30 TP0] Prefill batch. #new-seq: 2, #new-token: 424, #cached-token: 4, token usage: 0.96, #running-req: 88, #queue-req: 1129, 
[1,0]<stderr>:[2025-10-10 17:22:30 TP0] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 1, token usage: 0.95, #running-req: 88, #queue-req: 1128, 
[1,0]<stderr>:[2025-10-10 17:22:31 TP0] Prefill batch. #new-seq: 2, #new-token: 327, #cached-token: 2, token usage: 0.96, #running-req: 88, #queue-req: 1126, 
[1,0]<stderr>:[2025-10-10 17:22:31 TP0] Prefill batch. #new-seq: 3, #new-token: 739, #cached-token: 3, token usage: 0.94, #running-req: 88, #queue-req: 1123, 
[1,0]<stderr>:[2025-10-10 17:22:32 TP0] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 1, token usage: 0.95, #running-req: 90, #queue-req: 1122, 
[1,0]<stderr>:[2025-10-10 17:22:32 TP0] Prefill batch. #new-seq: 4, #new-token: 1075, #cached-token: 6, token usage: 0.94, #running-req: 90, #queue-req: 1118, 
[1,0]<stderr>:[2025-10-10 17:22:33 TP0] Prefill batch. #new-seq: 1, #new-token: 630, #cached-token: 1, token usage: 0.95, #running-req: 91, #queue-req: 1117, 
[1,0]<stderr>:[2025-10-10 17:22:34 TP0] Decode batch. #running-req: 89, #token: 62958, token usage: 0.96, cuda graph: False, gen throughput (token/s): 618.17, #queue-req: 1117, 
[1,0]<stderr>:[2025-10-10 17:22:34 TP0] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 4, token usage: 0.96, #running-req: 88, #queue-req: 1116, 
[1,0]<stderr>:[2025-10-10 17:22:35 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 4, token usage: 0.96, #running-req: 88, #queue-req: 1115, 
[1,0]<stderr>:[2025-10-10 17:22:35 TP0] Prefill batch. #new-seq: 2, #new-token: 580, #cached-token: 5, token usage: 0.93, #running-req: 88, #queue-req: 1113, 
[1,0]<stderr>:[2025-10-10 17:22:36 TP0] Prefill batch. #new-seq: 1, #new-token: 986, #cached-token: 1, token usage: 0.94, #running-req: 89, #queue-req: 1112, 
[1,0]<stderr>:[2025-10-10 17:22:36 TP0] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 2, token usage: 0.95, #running-req: 89, #queue-req: 1111, 
[1,0]<stderr>:[2025-10-10 17:22:37 TP0] Prefill batch. #new-seq: 8, #new-token: 1964, #cached-token: 18, token usage: 0.91, #running-req: 88, #queue-req: 1103, 
[1,0]<stderr>:[2025-10-10 17:22:37 TP0] Prefill batch. #new-seq: 12, #new-token: 1627, #cached-token: 22, token usage: 0.90, #running-req: 94, #queue-req: 1091, 
[1,0]<stderr>:[2025-10-10 17:22:37 TP0] Prefill batch. #new-seq: 7, #new-token: 2044, #cached-token: 23, token usage: 0.91, #running-req: 104, #queue-req: 1084, 
[1,0]<stderr>:[2025-10-10 17:22:37 TP0] Prefill batch. #new-seq: 10, #new-token: 1762, #cached-token: 23, token usage: 0.92, #running-req: 110, #queue-req: 1074, 
[1,0]<stderr>:[2025-10-10 17:22:38 TP0] Prefill batch. #new-seq: 3, #new-token: 2308, #cached-token: 3, token usage: 0.92, #running-req: 118, #queue-req: 1071, 
[1,0]<stderr>:[2025-10-10 17:22:38 TP0] Prefill batch. #new-seq: 2, #new-token: 622, #cached-token: 2, token usage: 0.94, #running-req: 118, #queue-req: 1069, 
[1,0]<stderr>:[2025-10-10 17:22:39 TP0] Prefill batch. #new-seq: 3, #new-token: 497, #cached-token: 11, token usage: 0.94, #running-req: 119, #queue-req: 1066, 
[1,0]<stderr>:[2025-10-10 17:22:39 TP0] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 3, token usage: 0.94, #running-req: 121, #queue-req: 1065, 
[1,0]<stderr>:[2025-10-10 17:22:39 TP0] Prefill batch. #new-seq: 3, #new-token: 713, #cached-token: 8, token usage: 0.93, #running-req: 119, #queue-req: 1062, 
[1,0]<stderr>:[2025-10-10 17:22:40 TP0] Prefill batch. #new-seq: 3, #new-token: 399, #cached-token: 7, token usage: 0.94, #running-req: 118, #queue-req: 1059, 
[1,0]<stderr>:[2025-10-10 17:22:40 TP0] Prefill batch. #new-seq: 6, #new-token: 658, #cached-token: 8, token usage: 0.93, #running-req: 120, #queue-req: 1053, 
[1,0]<stderr>:[2025-10-10 17:22:40 TP0] Decode batch. #running-req: 126, #token: 61260, token usage: 0.93, cuda graph: False, gen throughput (token/s): 642.62, #queue-req: 1053, 
[1,0]<stderr>:[2025-10-10 17:22:40 TP0] Prefill batch. #new-seq: 2, #new-token: 1234, #cached-token: 11, token usage: 0.92, #running-req: 125, #queue-req: 1051, 
[1,0]<stderr>:[2025-10-10 17:22:41 TP0] Prefill batch. #new-seq: 20, #new-token: 3973, #cached-token: 41, token usage: 0.84, #running-req: 124, #queue-req: 1031, 
[1,0]<stderr>:[2025-10-10 17:22:41 TP0] Prefill batch. #new-seq: 3, #new-token: 929, #cached-token: 3, token usage: 0.90, #running-req: 143, #queue-req: 1028, 
[1,0]<stderr>:[2025-10-10 17:22:41 TP0] Prefill batch. #new-seq: 5, #new-token: 3871, #cached-token: 13, token usage: 0.87, #running-req: 144, #queue-req: 1023, 
[1,0]<stderr>:[2025-10-10 17:22:42 TP0] Prefill batch. #new-seq: 3, #new-token: 925, #cached-token: 6, token usage: 0.92, #running-req: 146, #queue-req: 1020, 
[1,0]<stderr>:[2025-10-10 17:22:42 TP0] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 1, token usage: 0.93, #running-req: 147, #queue-req: 1019, 
[1,0]<stderr>:[2025-10-10 17:22:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 1, token usage: 0.93, #running-req: 145, #queue-req: 1018, 
[1,0]<stderr>:[2025-10-10 17:22:43 TP0] Prefill batch. #new-seq: 5, #new-token: 745, #cached-token: 8, token usage: 0.93, #running-req: 143, #queue-req: 1013, 
[1,0]<stderr>:[2025-10-10 17:22:44 TP0] Prefill batch. #new-seq: 3, #new-token: 1117, #cached-token: 5, token usage: 0.92, #running-req: 144, #queue-req: 1010, 
[1,0]<stderr>:[2025-10-10 17:22:45 TP0] Prefill batch. #new-seq: 5, #new-token: 2912, #cached-token: 14, token usage: 0.89, #running-req: 139, #queue-req: 1005, 
[1,0]<stderr>:[2025-10-10 17:22:46 TP0] Prefill batch. #new-seq: 4, #new-token: 444, #cached-token: 7, token usage: 0.91, #running-req: 137, #queue-req: 1001, 
[1,0]<stderr>:[2025-10-10 17:22:46 TP0] Prefill batch. #new-seq: 4, #new-token: 958, #cached-token: 8, token usage: 0.91, #running-req: 138, #queue-req: 997, 
[1,0]<stderr>:[2025-10-10 17:22:46 TP0] Decode batch. #running-req: 138, #token: 60698, token usage: 0.93, cuda graph: False, gen throughput (token/s): 990.59, #queue-req: 997, 
[1,0]<stderr>:[2025-10-10 17:22:46 TP0] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 1, token usage: 0.93, #running-req: 141, #queue-req: 996, 
[1,0]<stderr>:[2025-10-10 17:22:47 TP0] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 1, token usage: 0.93, #running-req: 139, #queue-req: 995, 
[1,0]<stderr>:[2025-10-10 17:22:48 TP0] Prefill batch. #new-seq: 1, #new-token: 798, #cached-token: 2, token usage: 0.93, #running-req: 136, #queue-req: 994, 
[1,0]<stderr>:[2025-10-10 17:22:49 TP0] Prefill batch. #new-seq: 3, #new-token: 2139, #cached-token: 5, token usage: 0.90, #running-req: 130, #queue-req: 991, 
[1,0]<stderr>:[2025-10-10 17:22:49 TP0] Prefill batch. #new-seq: 2, #new-token: 147, #cached-token: 5, token usage: 0.94, #running-req: 132, #queue-req: 989, 
[1,0]<stderr>:[2025-10-10 17:22:50 TP0] Prefill batch. #new-seq: 6, #new-token: 1382, #cached-token: 10, token usage: 0.92, #running-req: 133, #queue-req: 983, 
[1,0]<stderr>:[2025-10-10 17:22:50 TP0] Prefill batch. #new-seq: 3, #new-token: 774, #cached-token: 12, token usage: 0.93, #running-req: 137, #queue-req: 980, 
[1,0]<stderr>:[2025-10-10 17:22:51 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.94, #running-req: 139, #queue-req: 979, 
[1,0]<stderr>:[2025-10-10 17:22:51 TP0] Prefill batch. #new-seq: 2, #new-token: 641, #cached-token: 4, token usage: 0.94, #running-req: 139, #queue-req: 977, 
[1,0]<stderr>:[2025-10-10 17:22:52 TP0] Decode batch. #running-req: 139, #token: 62603, token usage: 0.96, cuda graph: False, gen throughput (token/s): 969.41, #queue-req: 977, 
[1,0]<stderr>:[2025-10-10 17:22:56 TP0] Decode batch. #running-req: 122, #token: 61458, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1128.70, #queue-req: 977, 
[1,0]<stderr>:[2025-10-10 17:22:56 TP0] Prefill batch. #new-seq: 1, #new-token: 2428, #cached-token: 1, token usage: 0.92, #running-req: 121, #queue-req: 976, 
[1,0]<stderr>:[2025-10-10 17:22:57 TP0] Prefill batch. #new-seq: 7, #new-token: 1617, #cached-token: 18, token usage: 0.93, #running-req: 120, #queue-req: 969, 
[1,0]<stderr>:[2025-10-10 17:22:57 TP0] Prefill batch. #new-seq: 5, #new-token: 615, #cached-token: 11, token usage: 0.94, #running-req: 126, #queue-req: 964, 
[1,0]<stderr>:[2025-10-10 17:22:58 TP0] Prefill batch. #new-seq: 1, #new-token: 2032, #cached-token: 2, token usage: 0.92, #running-req: 126, #queue-req: 963, 
[1,0]<stderr>:[2025-10-10 17:22:59 TP0] Prefill batch. #new-seq: 3, #new-token: 969, #cached-token: 8, token usage: 0.93, #running-req: 124, #queue-req: 960, 
[1,0]<stderr>:[2025-10-10 17:22:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1101, #cached-token: 1, token usage: 0.94, #running-req: 125, #queue-req: 959, 
[1,0]<stderr>:[2025-10-10 17:22:59 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.96, #running-req: 124, #queue-req: 958, 
[1,0]<stderr>:[2025-10-10 17:23:00 TP0] Prefill batch. #new-seq: 2, #new-token: 284, #cached-token: 3, token usage: 0.94, #running-req: 121, #queue-req: 956, 
[1,0]<stderr>:[2025-10-10 17:23:00 TP0] Prefill batch. #new-seq: 4, #new-token: 1069, #cached-token: 8, token usage: 0.93, #running-req: 122, #queue-req: 952, 
[1,0]<stderr>:[2025-10-10 17:23:00 TP0] Prefill batch. #new-seq: 4, #new-token: 1993, #cached-token: 4, token usage: 0.92, #running-req: 124, #queue-req: 948, 
[1,0]<stderr>:[2025-10-10 17:23:01 TP0] Prefill batch. #new-seq: 3, #new-token: 1271, #cached-token: 5, token usage: 0.93, #running-req: 124, #queue-req: 945, 
[1,0]<stderr>:[2025-10-10 17:23:01 TP0] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 1, token usage: 0.95, #running-req: 126, #queue-req: 944, 
[1,0]<stderr>:[2025-10-10 17:23:02 TP0] Prefill batch. #new-seq: 2, #new-token: 556, #cached-token: 3, token usage: 0.95, #running-req: 124, #queue-req: 942, 
[1,0]<stderr>:[2025-10-10 17:23:02 TP0] Decode batch. #running-req: 124, #token: 62507, token usage: 0.95, cuda graph: False, gen throughput (token/s): 846.08, #queue-req: 942, 
[1,0]<stderr>:[2025-10-10 17:23:02 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 1, token usage: 0.95, #running-req: 123, #queue-req: 941, 
[1,0]<stderr>:[2025-10-10 17:23:03 TP0] Prefill batch. #new-seq: 3, #new-token: 725, #cached-token: 6, token usage: 0.94, #running-req: 121, #queue-req: 938, 
[1,0]<stderr>:[2025-10-10 17:23:03 TP0] Prefill batch. #new-seq: 2, #new-token: 339, #cached-token: 3, token usage: 0.95, #running-req: 123, #queue-req: 936, 
[1,0]<stderr>:[2025-10-10 17:23:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1117, #cached-token: 1, token usage: 0.94, #running-req: 117, #queue-req: 935, 
[1,0]<stderr>:[2025-10-10 17:23:06 TP0] Prefill batch. #new-seq: 1, #new-token: 782, #cached-token: 1, token usage: 0.95, #running-req: 112, #queue-req: 934, 
[1,0]<stderr>:[2025-10-10 17:23:06 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.95, #running-req: 112, #queue-req: 933, 
[1,0]<stderr>:[2025-10-10 17:23:07 TP0] Prefill batch. #new-seq: 2, #new-token: 48, #cached-token: 2, token usage: 0.94, #running-req: 111, #queue-req: 931, 
[1,0]<stderr>:[2025-10-10 17:23:07 TP0] Prefill batch. #new-seq: 4, #new-token: 635, #cached-token: 7, token usage: 0.94, #running-req: 109, #queue-req: 927, 
[1,0]<stderr>:[2025-10-10 17:23:08 TP0] Decode batch. #running-req: 113, #token: 60144, token usage: 0.92, cuda graph: False, gen throughput (token/s): 860.72, #queue-req: 927, 
[1,0]<stderr>:[2025-10-10 17:23:08 TP0] Prefill batch. #new-seq: 3, #new-token: 2395, #cached-token: 14, token usage: 0.92, #running-req: 112, #queue-req: 924, 
[1,0]<stderr>:[2025-10-10 17:23:08 TP0] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 2, token usage: 0.96, #running-req: 113, #queue-req: 923, 
[1,0]<stderr>:[2025-10-10 17:23:09 TP0] Prefill batch. #new-seq: 2, #new-token: 38, #cached-token: 3, token usage: 0.95, #running-req: 110, #queue-req: 921, 
[1,0]<stderr>:[2025-10-10 17:23:09 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.95, #running-req: 111, #queue-req: 920, 
[1,0]<stderr>:[2025-10-10 17:23:10 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 1, token usage: 0.95, #running-req: 111, #queue-req: 919, 
[1,0]<stderr>:[2025-10-10 17:23:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1779, #cached-token: 1, token usage: 0.93, #running-req: 106, #queue-req: 918, 
[1,0]<stderr>:[2025-10-10 17:23:13 TP0] Decode batch. #running-req: 106, #token: 62572, token usage: 0.95, cuda graph: False, gen throughput (token/s): 833.02, #queue-req: 918, 
[1,0]<stderr>:[2025-10-10 17:23:14 TP0] Prefill batch. #new-seq: 5, #new-token: 3000, #cached-token: 9, token usage: 0.89, #running-req: 101, #queue-req: 913, 
[1,0]<stderr>:[2025-10-10 17:23:18 TP0] Decode batch. #running-req: 93, #token: 60310, token usage: 0.92, cuda graph: False, gen throughput (token/s): 855.81, #queue-req: 913, 
[1,0]<stderr>:[2025-10-10 17:23:18 TP0] Prefill batch. #new-seq: 4, #new-token: 3539, #cached-token: 5, token usage: 0.90, #running-req: 92, #queue-req: 909, 
[1,0]<stderr>:[2025-10-10 17:23:19 TP0] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 1, token usage: 0.95, #running-req: 95, #queue-req: 908, 
[1,0]<stderr>:[2025-10-10 17:23:19 TP0] Prefill batch. #new-seq: 4, #new-token: 1151, #cached-token: 7, token usage: 0.94, #running-req: 94, #queue-req: 904, 
[1,0]<stderr>:[2025-10-10 17:23:20 TP0] Prefill batch. #new-seq: 3, #new-token: 1021, #cached-token: 8, token usage: 0.94, #running-req: 97, #queue-req: 901, 
[1,0]<stderr>:[2025-10-10 17:23:20 TP0] Prefill batch. #new-seq: 3, #new-token: 335, #cached-token: 3, token usage: 0.95, #running-req: 98, #queue-req: 898, 
[1,0]<stderr>:[2025-10-10 17:23:21 TP0] Prefill batch. #new-seq: 2, #new-token: 372, #cached-token: 4, token usage: 0.95, #running-req: 100, #queue-req: 896, 
[1,0]<stderr>:[2025-10-10 17:23:21 TP0] Prefill batch. #new-seq: 6, #new-token: 683, #cached-token: 16, token usage: 0.94, #running-req: 101, #queue-req: 890, 
[1,0]<stderr>:[2025-10-10 17:23:21 TP0] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 2, token usage: 0.95, #running-req: 105, #queue-req: 889, 
[1,0]<stderr>:[2025-10-10 17:23:22 TP0] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 3, token usage: 0.95, #running-req: 105, #queue-req: 888, 
[1,0]<stderr>:[2025-10-10 17:23:23 TP0] Prefill batch. #new-seq: 2, #new-token: 289, #cached-token: 4, token usage: 0.94, #running-req: 102, #queue-req: 886, 
[1,0]<stderr>:[2025-10-10 17:23:23 TP0] Decode batch. #running-req: 102, #token: 61460, token usage: 0.94, cuda graph: False, gen throughput (token/s): 709.14, #queue-req: 886, 
[1,0]<stderr>:[2025-10-10 17:23:23 TP0] Prefill batch. #new-seq: 3, #new-token: 1112, #cached-token: 5, token usage: 0.94, #running-req: 102, #queue-req: 883, 
[1,0]<stderr>:[2025-10-10 17:23:24 TP0] Prefill batch. #new-seq: 6, #new-token: 1258, #cached-token: 10, token usage: 0.91, #running-req: 102, #queue-req: 877, 
[1,0]<stderr>:[2025-10-10 17:23:24 TP0] Prefill batch. #new-seq: 3, #new-token: 1111, #cached-token: 5, token usage: 0.93, #running-req: 107, #queue-req: 874, 
[1,0]<stderr>:[2025-10-10 17:23:24 TP0] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 1, token usage: 0.94, #running-req: 109, #queue-req: 873, 
[1,0]<stderr>:[2025-10-10 17:23:27 TP0] Prefill batch. #new-seq: 3, #new-token: 3633, #cached-token: 9, token usage: 0.89, #running-req: 101, #queue-req: 870, 
[1,0]<stderr>:[2025-10-10 17:23:27 TP0] Prefill batch. #new-seq: 3, #new-token: 94, #cached-token: 6, token usage: 0.95, #running-req: 103, #queue-req: 867, 
[1,0]<stderr>:[2025-10-10 17:23:28 TP0] Prefill batch. #new-seq: 2, #new-token: 56, #cached-token: 4, token usage: 0.94, #running-req: 104, #queue-req: 865, 
[1,0]<stderr>:[2025-10-10 17:23:29 TP0] Decode batch. #running-req: 106, #token: 61891, token usage: 0.94, cuda graph: False, gen throughput (token/s): 764.21, #queue-req: 865, 
[1,0]<stderr>:[2025-10-10 17:23:29 TP0] Prefill batch. #new-seq: 2, #new-token: 289, #cached-token: 3, token usage: 0.95, #running-req: 105, #queue-req: 863, 
[1,0]<stderr>:[2025-10-10 17:23:29 TP0] Prefill batch. #new-seq: 4, #new-token: 1288, #cached-token: 12, token usage: 0.94, #running-req: 104, #queue-req: 859, 
[1,0]<stderr>:[2025-10-10 17:23:30 TP0] Prefill batch. #new-seq: 3, #new-token: 541, #cached-token: 7, token usage: 0.95, #running-req: 106, #queue-req: 856, 
[1,0]<stderr>:[2025-10-10 17:23:30 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.96, #running-req: 108, #queue-req: 855, 
[1,0]<stderr>:[2025-10-10 17:23:31 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 1, token usage: 0.95, #running-req: 108, #queue-req: 854, 
[1,0]<stderr>:[2025-10-10 17:23:32 TP0] Prefill batch. #new-seq: 3, #new-token: 966, #cached-token: 5, token usage: 0.94, #running-req: 103, #queue-req: 851, 
[1,0]<stderr>:[2025-10-10 17:23:32 TP0] Prefill batch. #new-seq: 2, #new-token: 461, #cached-token: 4, token usage: 0.96, #running-req: 104, #queue-req: 849, 
[1,0]<stderr>:[2025-10-10 17:23:33 TP0] Prefill batch. #new-seq: 3, #new-token: 889, #cached-token: 4, token usage: 0.94, #running-req: 102, #queue-req: 846, 
[1,0]<stderr>:[2025-10-10 17:23:34 TP0] Prefill batch. #new-seq: 1, #new-token: 674, #cached-token: 1, token usage: 0.95, #running-req: 101, #queue-req: 845, 
[1,0]<stderr>:[2025-10-10 17:23:34 TP0] Decode batch. #running-req: 101, #token: 62665, token usage: 0.96, cuda graph: False, gen throughput (token/s): 761.13, #queue-req: 845, 
[1,0]<stderr>:[2025-10-10 17:23:35 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 4, token usage: 0.95, #running-req: 97, #queue-req: 844, 
[1,0]<stderr>:[2025-10-10 17:23:35 TP0] Prefill batch. #new-seq: 2, #new-token: 820, #cached-token: 3, token usage: 0.95, #running-req: 97, #queue-req: 842, 
[1,0]<stderr>:[2025-10-10 17:23:36 TP0] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 1, token usage: 0.95, #running-req: 98, #queue-req: 841, 
[1,0]<stderr>:[2025-10-10 17:23:36 TP0] Prefill batch. #new-seq: 6, #new-token: 1291, #cached-token: 21, token usage: 0.90, #running-req: 96, #queue-req: 835, 
[1,0]<stderr>:[2025-10-10 17:23:37 TP0] Prefill batch. #new-seq: 11, #new-token: 2693, #cached-token: 21, token usage: 0.89, #running-req: 100, #queue-req: 824, 
[1,0]<stderr>:[2025-10-10 17:23:37 TP0] Prefill batch. #new-seq: 11, #new-token: 3412, #cached-token: 23, token usage: 0.89, #running-req: 110, #queue-req: 813, 
[1,0]<stderr>:[2025-10-10 17:23:37 TP0] Prefill batch. #new-seq: 2, #new-token: 838, #cached-token: 3, token usage: 0.94, #running-req: 120, #queue-req: 811, 
[1,0]<stderr>:[2025-10-10 17:23:38 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 3, token usage: 0.95, #running-req: 121, #queue-req: 810, 
[1,0]<stderr>:[2025-10-10 17:23:38 TP0] Prefill batch. #new-seq: 2, #new-token: 665, #cached-token: 2, token usage: 0.94, #running-req: 120, #queue-req: 808, 
[1,0]<stderr>:[2025-10-10 17:23:38 TP0] Prefill batch. #new-seq: 7, #new-token: 1304, #cached-token: 11, token usage: 0.91, #running-req: 119, #queue-req: 801, 
[1,0]<stderr>:[2025-10-10 17:23:38 TP0] Prefill batch. #new-seq: 2, #new-token: 1429, #cached-token: 14, token usage: 0.92, #running-req: 125, #queue-req: 799, 
[1,0]<stderr>:[2025-10-10 17:23:39 TP0] Prefill batch. #new-seq: 3, #new-token: 876, #cached-token: 12, token usage: 0.93, #running-req: 126, #queue-req: 796, 
[1,0]<stderr>:[2025-10-10 17:23:39 TP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.94, #running-req: 126, #queue-req: 792, 
[1,0]<stderr>:[2025-10-10 17:23:39 TP0] Prefill batch. #new-seq: 4, #new-token: 502, #cached-token: 6, token usage: 0.94, #running-req: 129, #queue-req: 788, 
[1,0]<stderr>:[2025-10-10 17:23:40 TP0] Prefill batch. #new-seq: 3, #new-token: 302, #cached-token: 8, token usage: 0.93, #running-req: 131, #queue-req: 785, 
[1,0]<stderr>:[2025-10-10 17:23:40 TP0] Prefill batch. #new-seq: 2, #new-token: 823, #cached-token: 4, token usage: 0.94, #running-req: 133, #queue-req: 783, 
[1,0]<stderr>:[2025-10-10 17:23:41 TP0] Decode batch. #running-req: 134, #token: 61148, token usage: 0.93, cuda graph: False, gen throughput (token/s): 721.87, #queue-req: 783, 
[1,0]<stderr>:[2025-10-10 17:23:41 TP0] Prefill batch. #new-seq: 4, #new-token: 1136, #cached-token: 6, token usage: 0.93, #running-req: 133, #queue-req: 779, 
[1,0]<stderr>:[2025-10-10 17:23:42 TP0] Prefill batch. #new-seq: 2, #new-token: 631, #cached-token: 2, token usage: 0.93, #running-req: 130, #queue-req: 777, 
[1,0]<stderr>:[2025-10-10 17:23:42 TP0] Prefill batch. #new-seq: 4, #new-token: 900, #cached-token: 6, token usage: 0.92, #running-req: 129, #queue-req: 773, 
[1,0]<stderr>:[2025-10-10 17:23:42 TP0] Prefill batch. #new-seq: 1, #new-token: 640, #cached-token: 4, token usage: 0.93, #running-req: 131, #queue-req: 772, 
[1,0]<stderr>:[2025-10-10 17:23:43 TP0] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 2, token usage: 0.93, #running-req: 129, #queue-req: 771, 
[1,0]<stderr>:[2025-10-10 17:23:43 TP0] Prefill batch. #new-seq: 3, #new-token: 182, #cached-token: 8, token usage: 0.94, #running-req: 129, #queue-req: 768, 
[1,0]<stderr>:[2025-10-10 17:23:43 TP0] Prefill batch. #new-seq: 3, #new-token: 846, #cached-token: 24, token usage: 0.93, #running-req: 131, #queue-req: 765, 
[1,0]<stderr>:[2025-10-10 17:23:44 TP0] Prefill batch. #new-seq: 5, #new-token: 794, #cached-token: 10, token usage: 0.92, #running-req: 131, #queue-req: 760, 
[1,0]<stderr>:[2025-10-10 17:23:44 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.94, #running-req: 135, #queue-req: 759, 
[1,0]<stderr>:[2025-10-10 17:23:45 TP0] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 2, token usage: 0.93, #running-req: 133, #queue-req: 758, 
[1,0]<stderr>:[2025-10-10 17:23:45 TP0] Prefill batch. #new-seq: 2, #new-token: 195, #cached-token: 6, token usage: 0.94, #running-req: 132, #queue-req: 756, 
[1,0]<stderr>:[2025-10-10 17:23:45 TP0] Prefill batch. #new-seq: 2, #new-token: 116, #cached-token: 3, token usage: 0.94, #running-req: 133, #queue-req: 754, 
[1,0]<stderr>:[2025-10-10 17:23:45 TP0] Prefill batch. #new-seq: 2, #new-token: 334, #cached-token: 2, token usage: 0.94, #running-req: 134, #queue-req: 752, 
[1,0]<stderr>:[2025-10-10 17:23:46 TP0] Prefill batch. #new-seq: 5, #new-token: 2147, #cached-token: 17, token usage: 0.90, #running-req: 134, #queue-req: 747, 
[1,0]<stderr>:[2025-10-10 17:23:46 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.94, #running-req: 138, #queue-req: 746, 
[1,0]<stderr>:[2025-10-10 17:23:47 TP0] Decode batch. #running-req: 139, #token: 62408, token usage: 0.95, cuda graph: False, gen throughput (token/s): 874.41, #queue-req: 746, 
[1,0]<stderr>:[2025-10-10 17:23:47 TP0] Prefill batch. #new-seq: 7, #new-token: 1387, #cached-token: 12, token usage: 0.92, #running-req: 136, #queue-req: 739, 
[1,0]<stderr>:[2025-10-10 17:23:47 TP0] Prefill batch. #new-seq: 3, #new-token: 417, #cached-token: 6, token usage: 0.94, #running-req: 136, #queue-req: 736, 
[1,0]<stderr>:[2025-10-10 17:23:47 TP0] Prefill batch. #new-seq: 2, #new-token: 61, #cached-token: 4, token usage: 0.94, #running-req: 138, #queue-req: 734, 
[1,0]<stderr>:[2025-10-10 17:23:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1156, #cached-token: 1, token usage: 0.93, #running-req: 130, #queue-req: 733, 
[1,0]<stderr>:[2025-10-10 17:23:50 TP0] Prefill batch. #new-seq: 3, #new-token: 316, #cached-token: 4, token usage: 0.94, #running-req: 127, #queue-req: 730, 
[1,0]<stderr>:[2025-10-10 17:23:51 TP0] Prefill batch. #new-seq: 2, #new-token: 60, #cached-token: 5, token usage: 0.93, #running-req: 129, #queue-req: 728, 
[1,0]<stderr>:[2025-10-10 17:23:51 TP0] Prefill batch. #new-seq: 2, #new-token: 732, #cached-token: 4, token usage: 0.93, #running-req: 129, #queue-req: 726, 
[1,0]<stderr>:[2025-10-10 17:23:51 TP0] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 4, token usage: 0.94, #running-req: 129, #queue-req: 725, 
[1,0]<stderr>:[2025-10-10 17:23:52 TP0] Decode batch. #running-req: 130, #token: 62252, token usage: 0.95, cuda graph: False, gen throughput (token/s): 1011.73, #queue-req: 725, 
[1,0]<stderr>:[2025-10-10 17:23:52 TP0] Prefill batch. #new-seq: 3, #new-token: 1460, #cached-token: 6, token usage: 0.92, #running-req: 128, #queue-req: 722, 
[1,0]<stderr>:[2025-10-10 17:23:54 TP0] Prefill batch. #new-seq: 4, #new-token: 595, #cached-token: 7, token usage: 0.94, #running-req: 125, #queue-req: 718, 
[1,0]<stderr>:[2025-10-10 17:23:55 TP0] Prefill batch. #new-seq: 2, #new-token: 413, #cached-token: 9, token usage: 0.95, #running-req: 127, #queue-req: 716, 
[1,0]<stderr>:[2025-10-10 17:23:56 TP0] Prefill batch. #new-seq: 5, #new-token: 345, #cached-token: 12, token usage: 0.92, #running-req: 125, #queue-req: 711, 
[1,0]<stderr>:[2025-10-10 17:23:56 TP0] Prefill batch. #new-seq: 5, #new-token: 1228, #cached-token: 9, token usage: 0.93, #running-req: 129, #queue-req: 706, 
[1,0]<stderr>:[2025-10-10 17:23:57 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.94, #running-req: 132, #queue-req: 705, 
[1,0]<stderr>:[2025-10-10 17:23:57 TP0] Decode batch. #running-req: 132, #token: 61506, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1020.55, #queue-req: 705, 
[1,0]<stderr>:[2025-10-10 17:23:57 TP0] Prefill batch. #new-seq: 1, #new-token: 833, #cached-token: 1, token usage: 0.94, #running-req: 132, #queue-req: 704, 
[1,0]<stderr>:[2025-10-10 17:23:57 TP0] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 1, token usage: 0.95, #running-req: 131, #queue-req: 703, 
[1,0]<stderr>:[2025-10-10 17:23:58 TP0] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 2, token usage: 0.94, #running-req: 130, #queue-req: 702, 
[1,0]<stderr>:[2025-10-10 17:23:58 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 1, token usage: 0.95, #running-req: 130, #queue-req: 701, 
[1,0]<stderr>:[2025-10-10 17:23:58 TP0] Prefill batch. #new-seq: 2, #new-token: 664, #cached-token: 3, token usage: 0.94, #running-req: 130, #queue-req: 699, 
[1,0]<stderr>:[2025-10-10 17:23:59 TP0] Prefill batch. #new-seq: 2, #new-token: 94, #cached-token: 2, token usage: 0.94, #running-req: 130, #queue-req: 697, 
[1,0]<stderr>:[2025-10-10 17:23:59 TP0] Prefill batch. #new-seq: 3, #new-token: 1836, #cached-token: 4, token usage: 0.90, #running-req: 129, #queue-req: 694, 
[1,0]<stderr>:[2025-10-10 17:24:01 TP0] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 1, token usage: 0.86, #running-req: 123, #queue-req: 693, 
[1,0]<stderr>:[2025-10-10 17:24:01 TP0] Prefill batch. #new-seq: 2, #new-token: 1831, #cached-token: 2, token usage: 0.92, #running-req: 120, #queue-req: 691, 
[1,0]<stderr>:[2025-10-10 17:24:01 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.95, #running-req: 121, #queue-req: 690, 
[1,0]<stderr>:[2025-10-10 17:24:03 TP0] Decode batch. #running-req: 120, #token: 63051, token usage: 0.96, cuda graph: False, gen throughput (token/s): 848.40, #queue-req: 690, 
[1,0]<stderr>:[2025-10-10 17:24:03 TP0] Prefill batch. #new-seq: 4, #new-token: 2286, #cached-token: 5, token usage: 0.89, #running-req: 119, #queue-req: 686, 
[1,0]<stderr>:[2025-10-10 17:24:03 TP0] Prefill batch. #new-seq: 1, #new-token: 454, #cached-token: 3, token usage: 0.92, #running-req: 121, #queue-req: 685, 
[1,0]<stderr>:[2025-10-10 17:24:04 TP0] Prefill batch. #new-seq: 1, #new-token: 2073, #cached-token: 1, token usage: 0.92, #running-req: 121, #queue-req: 684, 
[1,0]<stderr>:[2025-10-10 17:24:04 TP0] Prefill batch. #new-seq: 4, #new-token: 289, #cached-token: 9, token usage: 0.93, #running-req: 119, #queue-req: 680, 
[1,0]<stderr>:[2025-10-10 17:24:06 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 3, token usage: 0.94, #running-req: 120, #queue-req: 679, 
[1,0]<stderr>:[2025-10-10 17:24:06 TP0] Prefill batch. #new-seq: 6, #new-token: 1228, #cached-token: 11, token usage: 0.93, #running-req: 119, #queue-req: 673, 
[1,0]<stderr>:[2025-10-10 17:24:06 TP0] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 3, token usage: 0.94, #running-req: 123, #queue-req: 672, 
[1,0]<stderr>:[2025-10-10 17:24:08 TP0] Prefill batch. #new-seq: 2, #new-token: 1232, #cached-token: 5, token usage: 0.94, #running-req: 120, #queue-req: 670, 
[1,0]<stderr>:[2025-10-10 17:24:08 TP0] Prefill batch. #new-seq: 2, #new-token: 321, #cached-token: 11, token usage: 0.94, #running-req: 119, #queue-req: 668, 
[1,0]<stderr>:[2025-10-10 17:24:08 TP0] Prefill batch. #new-seq: 3, #new-token: 740, #cached-token: 6, token usage: 0.94, #running-req: 119, #queue-req: 665, 
[1,0]<stderr>:[2025-10-10 17:24:09 TP0] Decode batch. #running-req: 122, #token: 62122, token usage: 0.95, cuda graph: False, gen throughput (token/s): 837.06, #queue-req: 665, 
[1,0]<stderr>:[2025-10-10 17:24:09 TP0] Prefill batch. #new-seq: 3, #new-token: 421, #cached-token: 10, token usage: 0.94, #running-req: 121, #queue-req: 662, 
[1,0]<stderr>:[2025-10-10 17:24:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1200, #cached-token: 1, token usage: 0.94, #running-req: 120, #queue-req: 661, 
[1,0]<stderr>:[2025-10-10 17:24:11 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.95, #running-req: 119, #queue-req: 660, 
[1,0]<stderr>:[2025-10-10 17:24:11 TP0] Prefill batch. #new-seq: 2, #new-token: 127, #cached-token: 2, token usage: 0.94, #running-req: 118, #queue-req: 658, 
[1,0]<stderr>:[2025-10-10 17:24:11 TP0] Prefill batch. #new-seq: 3, #new-token: 133, #cached-token: 5, token usage: 0.95, #running-req: 119, #queue-req: 655, 
[1,0]<stderr>:[2025-10-10 17:24:12 TP0] Prefill batch. #new-seq: 2, #new-token: 397, #cached-token: 5, token usage: 0.94, #running-req: 121, #queue-req: 653, 
[1,0]<stderr>:[2025-10-10 17:24:13 TP0] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 1, token usage: 0.94, #running-req: 120, #queue-req: 652, 
[1,0]<stderr>:[2025-10-10 17:24:14 TP0] Decode batch. #running-req: 120, #token: 63898, token usage: 0.98, cuda graph: False, gen throughput (token/s): 899.77, #queue-req: 652, 
[1,0]<stderr>:[2025-10-10 17:24:16 TP0] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 2, token usage: 0.95, #running-req: 113, #queue-req: 651, 
[1,0]<stderr>:[2025-10-10 17:24:17 TP0] Prefill batch. #new-seq: 2, #new-token: 14, #cached-token: 2, token usage: 0.96, #running-req: 112, #queue-req: 649, 
[1,0]<stderr>:[2025-10-10 17:24:17 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.96, #running-req: 113, #queue-req: 648, 
[1,0]<stderr>:[2025-10-10 17:24:18 TP0] Prefill batch. #new-seq: 5, #new-token: 2442, #cached-token: 7, token usage: 0.89, #running-req: 109, #queue-req: 643, 
[1,0]<stderr>:[2025-10-10 17:24:18 TP0] Prefill batch. #new-seq: 4, #new-token: 499, #cached-token: 7, token usage: 0.93, #running-req: 111, #queue-req: 639, 
[1,0]<stderr>:[2025-10-10 17:24:19 TP0] Prefill batch. #new-seq: 2, #new-token: 997, #cached-token: 2, token usage: 0.94, #running-req: 114, #queue-req: 637, 
[1,0]<stderr>:[2025-10-10 17:24:19 TP0] Decode batch. #running-req: 115, #token: 62180, token usage: 0.95, cuda graph: False, gen throughput (token/s): 896.92, #queue-req: 637, 
[1,0]<stderr>:[2025-10-10 17:24:19 TP0] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 2, token usage: 0.95, #running-req: 114, #queue-req: 636, 
[1,0]<stderr>:[2025-10-10 17:24:20 TP0] Prefill batch. #new-seq: 2, #new-token: 74, #cached-token: 5, token usage: 0.96, #running-req: 113, #queue-req: 634, 
[1,0]<stderr>:[2025-10-10 17:24:20 TP0] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 3, token usage: 0.95, #running-req: 113, #queue-req: 633, 
[1,0]<stderr>:[2025-10-10 17:24:22 TP0] Prefill batch. #new-seq: 1, #new-token: 2959, #cached-token: 3, token usage: 0.91, #running-req: 107, #queue-req: 632, 
[1,0]<stderr>:[2025-10-10 17:24:22 TP0] Prefill batch. #new-seq: 2, #new-token: 247, #cached-token: 2, token usage: 0.95, #running-req: 107, #queue-req: 630, 
[1,0]<stderr>:[2025-10-10 17:24:22 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.96, #running-req: 108, #queue-req: 629, 
[1,0]<stderr>:[2025-10-10 17:24:24 TP0] Decode batch. #running-req: 106, #token: 62924, token usage: 0.96, cuda graph: False, gen throughput (token/s): 857.90, #queue-req: 629, 
[1,0]<stderr>:[2025-10-10 17:24:25 TP0] Prefill batch. #new-seq: 3, #new-token: 298, #cached-token: 6, token usage: 0.94, #running-req: 104, #queue-req: 626, 
[1,0]<stderr>:[2025-10-10 17:24:27 TP0] Prefill batch. #new-seq: 2, #new-token: 921, #cached-token: 4, token usage: 0.94, #running-req: 100, #queue-req: 624, 
[1,0]<stderr>:[2025-10-10 17:24:28 TP0] Prefill batch. #new-seq: 2, #new-token: 863, #cached-token: 5, token usage: 0.95, #running-req: 101, #queue-req: 622, 
[1,0]<stderr>:[2025-10-10 17:24:28 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 2, token usage: 0.95, #running-req: 101, #queue-req: 621, 
[1,0]<stderr>:[2025-10-10 17:24:29 TP0] Prefill batch. #new-seq: 12, #new-token: 2041, #cached-token: 20, token usage: 0.91, #running-req: 100, #queue-req: 609, 
[1,0]<stderr>:[2025-10-10 17:24:29 TP0] Prefill batch. #new-seq: 5, #new-token: 379, #cached-token: 11, token usage: 0.93, #running-req: 111, #queue-req: 604, 
[1,0]<stderr>:[2025-10-10 17:24:29 TP0] Prefill batch. #new-seq: 6, #new-token: 1111, #cached-token: 15, token usage: 0.93, #running-req: 115, #queue-req: 598, 
[1,0]<stderr>:[2025-10-10 17:24:29 TP0] Prefill batch. #new-seq: 5, #new-token: 979, #cached-token: 12, token usage: 0.93, #running-req: 119, #queue-req: 593, 
[1,0]<stderr>:[2025-10-10 17:24:29 TP0] Prefill batch. #new-seq: 3, #new-token: 416, #cached-token: 3, token usage: 0.94, #running-req: 123, #queue-req: 590, 
[1,0]<stderr>:[2025-10-10 17:24:30 TP0] Decode batch. #running-req: 126, #token: 61208, token usage: 0.93, cuda graph: False, gen throughput (token/s): 783.62, #queue-req: 590, 
[1,0]<stderr>:[2025-10-10 17:24:30 TP0] Prefill batch. #new-seq: 3, #new-token: 226, #cached-token: 7, token usage: 0.94, #running-req: 124, #queue-req: 587, 
[1,0]<stderr>:[2025-10-10 17:24:30 TP0] Prefill batch. #new-seq: 3, #new-token: 1837, #cached-token: 3, token usage: 0.93, #running-req: 125, #queue-req: 584, 
[1,0]<stderr>:[2025-10-10 17:24:31 TP0] Prefill batch. #new-seq: 3, #new-token: 493, #cached-token: 8, token usage: 0.94, #running-req: 127, #queue-req: 581, 
[1,0]<stderr>:[2025-10-10 17:24:31 TP0] Prefill batch. #new-seq: 1, #new-token: 872, #cached-token: 6, token usage: 0.94, #running-req: 125, #queue-req: 580, 
[1,0]<stderr>:[2025-10-10 17:24:32 TP0] Prefill batch. #new-seq: 4, #new-token: 1334, #cached-token: 12, token usage: 0.93, #running-req: 123, #queue-req: 576, 
[1,0]<stderr>:[2025-10-10 17:24:32 TP0] Prefill batch. #new-seq: 2, #new-token: 872, #cached-token: 7, token usage: 0.94, #running-req: 125, #queue-req: 574, 
[1,0]<stderr>:[2025-10-10 17:24:33 TP0] Prefill batch. #new-seq: 2, #new-token: 116, #cached-token: 3, token usage: 0.95, #running-req: 125, #queue-req: 572, 
[1,0]<stderr>:[2025-10-10 17:24:33 TP0] Prefill batch. #new-seq: 2, #new-token: 400, #cached-token: 3, token usage: 0.95, #running-req: 124, #queue-req: 570, 
[1,0]<stderr>:[2025-10-10 17:24:34 TP0] Prefill batch. #new-seq: 2, #new-token: 858, #cached-token: 5, token usage: 0.94, #running-req: 124, #queue-req: 568, 
[1,0]<stderr>:[2025-10-10 17:24:34 TP0] Prefill batch. #new-seq: 4, #new-token: 1378, #cached-token: 8, token usage: 0.93, #running-req: 122, #queue-req: 564, 
[1,0]<stderr>:[2025-10-10 17:24:35 TP0] Prefill batch. #new-seq: 2, #new-token: 258, #cached-token: 2, token usage: 0.95, #running-req: 125, #queue-req: 562, 
[1,0]<stderr>:[2025-10-10 17:24:35 TP0] Prefill batch. #new-seq: 3, #new-token: 1262, #cached-token: 6, token usage: 0.93, #running-req: 125, #queue-req: 559, 
[1,0]<stderr>:[2025-10-10 17:24:36 TP0] Decode batch. #running-req: 124, #token: 61958, token usage: 0.95, cuda graph: False, gen throughput (token/s): 852.51, #queue-req: 559, 
[1,0]<stderr>:[2025-10-10 17:24:37 TP0] Prefill batch. #new-seq: 1, #new-token: 2196, #cached-token: 1, token usage: 0.93, #running-req: 119, #queue-req: 558, 
[1,0]<stderr>:[2025-10-10 17:24:38 TP0] Prefill batch. #new-seq: 2, #new-token: 17, #cached-token: 5, token usage: 0.95, #running-req: 117, #queue-req: 556, 
[1,0]<stderr>:[2025-10-10 17:24:38 TP0] Prefill batch. #new-seq: 3, #new-token: 813, #cached-token: 6, token usage: 0.94, #running-req: 117, #queue-req: 553, 
[1,0]<stderr>:[2025-10-10 17:24:39 TP0] Prefill batch. #new-seq: 5, #new-token: 140, #cached-token: 8, token usage: 0.93, #running-req: 119, #queue-req: 548, 
[1,0]<stderr>:[2025-10-10 17:24:40 TP0] Prefill batch. #new-seq: 6, #new-token: 828, #cached-token: 15, token usage: 0.93, #running-req: 123, #queue-req: 542, 
[1,0]<stderr>:[2025-10-10 17:24:40 TP0] Prefill batch. #new-seq: 2, #new-token: 1376, #cached-token: 5, token usage: 0.93, #running-req: 128, #queue-req: 540, 
[1,0]<stderr>:[2025-10-10 17:24:40 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.95, #running-req: 129, #queue-req: 539, 
[1,0]<stderr>:[2025-10-10 17:24:41 TP0] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 1, token usage: 0.95, #running-req: 129, #queue-req: 538, 
[1,0]<stderr>:[2025-10-10 17:24:41 TP0] Prefill batch. #new-seq: 3, #new-token: 729, #cached-token: 7, token usage: 0.93, #running-req: 127, #queue-req: 535, 
[1,0]<stderr>:[2025-10-10 17:24:41 TP0] Decode batch. #running-req: 127, #token: 61545, token usage: 0.94, cuda graph: False, gen throughput (token/s): 905.85, #queue-req: 535, 
[1,0]<stderr>:[2025-10-10 17:24:42 TP0] Prefill batch. #new-seq: 2, #new-token: 602, #cached-token: 4, token usage: 0.94, #running-req: 129, #queue-req: 533, 
[1,0]<stderr>:[2025-10-10 17:24:43 TP0] Prefill batch. #new-seq: 2, #new-token: 89, #cached-token: 4, token usage: 0.94, #running-req: 129, #queue-req: 531, 
[1,0]<stderr>:[2025-10-10 17:24:43 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.95, #running-req: 130, #queue-req: 530, 
[1,0]<stderr>:[2025-10-10 17:24:43 TP0] Prefill batch. #new-seq: 3, #new-token: 558, #cached-token: 7, token usage: 0.93, #running-req: 129, #queue-req: 527, 
[1,0]<stderr>:[2025-10-10 17:24:44 TP0] Prefill batch. #new-seq: 7, #new-token: 928, #cached-token: 9, token usage: 0.93, #running-req: 131, #queue-req: 520, 
[1,0]<stderr>:[2025-10-10 17:24:44 TP0] Prefill batch. #new-seq: 7, #new-token: 426, #cached-token: 11, token usage: 0.93, #running-req: 136, #queue-req: 513, 
[1,0]<stderr>:[2025-10-10 17:24:45 TP0] Prefill batch. #new-seq: 3, #new-token: 2046, #cached-token: 4, token usage: 0.91, #running-req: 139, #queue-req: 510, 
[1,0]<stderr>:[2025-10-10 17:24:45 TP0] Prefill batch. #new-seq: 4, #new-token: 810, #cached-token: 7, token usage: 0.94, #running-req: 138, #queue-req: 506, 
[1,0]<stderr>:[2025-10-10 17:24:45 TP0] Prefill batch. #new-seq: 2, #new-token: 501, #cached-token: 2, token usage: 0.94, #running-req: 139, #queue-req: 504, 
[1,0]<stderr>:[2025-10-10 17:24:46 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 2, token usage: 0.94, #running-req: 140, #queue-req: 503, 
[1,0]<stderr>:[2025-10-10 17:24:47 TP0] Decode batch. #running-req: 138, #token: 63125, token usage: 0.96, cuda graph: False, gen throughput (token/s): 942.33, #queue-req: 503, 
[1,0]<stderr>:[2025-10-10 17:24:48 TP0] Prefill batch. #new-seq: 4, #new-token: 840, #cached-token: 10, token usage: 0.93, #running-req: 132, #queue-req: 499, 
[1,0]<stderr>:[2025-10-10 17:24:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1051, #cached-token: 1, token usage: 0.93, #running-req: 130, #queue-req: 498, 
[1,0]<stderr>:[2025-10-10 17:24:50 TP0] Prefill batch. #new-seq: 2, #new-token: 189, #cached-token: 4, token usage: 0.94, #running-req: 129, #queue-req: 496, 
[1,0]<stderr>:[2025-10-10 17:24:50 TP0] Prefill batch. #new-seq: 2, #new-token: 780, #cached-token: 2, token usage: 0.94, #running-req: 130, #queue-req: 494, 
[1,0]<stderr>:[2025-10-10 17:24:52 TP0] Decode batch. #running-req: 126, #token: 62478, token usage: 0.95, cuda graph: False, gen throughput (token/s): 1050.16, #queue-req: 494, 
[1,0]<stderr>:[2025-10-10 17:24:52 TP0] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 2, token usage: 0.95, #running-req: 125, #queue-req: 493, 
[1,0]<stderr>:[2025-10-10 17:24:52 TP0] Prefill batch. #new-seq: 7, #new-token: 1310, #cached-token: 14, token usage: 0.92, #running-req: 124, #queue-req: 486, 
[1,0]<stderr>:[2025-10-10 17:24:53 TP0] Prefill batch. #new-seq: 2, #new-token: 997, #cached-token: 2, token usage: 0.94, #running-req: 129, #queue-req: 484, 
[1,0]<stderr>:[2025-10-10 17:24:54 TP0] Prefill batch. #new-seq: 6, #new-token: 831, #cached-token: 14, token usage: 0.91, #running-req: 127, #queue-req: 478, 
[1,0]<stderr>:[2025-10-10 17:24:54 TP0] Prefill batch. #new-seq: 1, #new-token: 2404, #cached-token: 1, token usage: 0.92, #running-req: 131, #queue-req: 477, 
[1,0]<stderr>:[2025-10-10 17:24:55 TP0] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 2, token usage: 0.95, #running-req: 129, #queue-req: 476, 
[1,0]<stderr>:[2025-10-10 17:24:55 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 2, token usage: 0.95, #running-req: 129, #queue-req: 475, 
[1,0]<stderr>:[2025-10-10 17:24:56 TP0] Prefill batch. #new-seq: 3, #new-token: 448, #cached-token: 9, token usage: 0.94, #running-req: 127, #queue-req: 472, 
[1,0]<stderr>:[2025-10-10 17:24:56 TP0] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 1, token usage: 0.95, #running-req: 127, #queue-req: 471, 
[1,0]<stderr>:[2025-10-10 17:24:57 TP0] Prefill batch. #new-seq: 8, #new-token: 837, #cached-token: 17, token usage: 0.91, #running-req: 124, #queue-req: 463, 
[1,0]<stderr>:[2025-10-10 17:24:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1428, #cached-token: 1, token usage: 0.92, #running-req: 131, #queue-req: 462, 
[1,0]<stderr>:[2025-10-10 17:24:58 TP0] Prefill batch. #new-seq: 2, #new-token: 88, #cached-token: 13, token usage: 0.95, #running-req: 131, #queue-req: 460, 
[1,0]<stderr>:[2025-10-10 17:24:58 TP0] Decode batch. #running-req: 131, #token: 61707, token usage: 0.94, cuda graph: False, gen throughput (token/s): 880.66, #queue-req: 460, 
[1,0]<stderr>:[2025-10-10 17:24:58 TP0] Prefill batch. #new-seq: 2, #new-token: 805, #cached-token: 2, token usage: 0.94, #running-req: 132, #queue-req: 458, 
[1,0]<stderr>:[2025-10-10 17:24:59 TP0] Prefill batch. #new-seq: 2, #new-token: 22, #cached-token: 3, token usage: 0.95, #running-req: 133, #queue-req: 456, 
[1,0]<stderr>:[2025-10-10 17:25:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1958, #cached-token: 1, token usage: 0.93, #running-req: 127, #queue-req: 455, 
[1,0]<stderr>:[2025-10-10 17:25:01 TP0] Prefill batch. #new-seq: 4, #new-token: 274, #cached-token: 5, token usage: 0.95, #running-req: 125, #queue-req: 451, 
[1,0]<stderr>:[2025-10-10 17:25:01 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.95, #running-req: 128, #queue-req: 450, 
[1,0]<stderr>:[2025-10-10 17:25:02 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.96, #running-req: 128, #queue-req: 449, 
[1,0]<stderr>:[2025-10-10 17:25:02 TP0] Prefill batch. #new-seq: 2, #new-token: 269, #cached-token: 3, token usage: 0.95, #running-req: 128, #queue-req: 447, 
[1,0]<stderr>:[2025-10-10 17:25:03 TP0] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 2, token usage: 0.95, #running-req: 127, #queue-req: 446, 
[1,0]<stderr>:[2025-10-10 17:25:03 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.95, #running-req: 127, #queue-req: 445, 
[1,0]<stderr>:[2025-10-10 17:25:03 TP0] Decode batch. #running-req: 127, #token: 62286, token usage: 0.95, cuda graph: False, gen throughput (token/s): 941.19, #queue-req: 445, 
[1,0]<stderr>:[2025-10-10 17:25:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1864, #cached-token: 1, token usage: 0.93, #running-req: 118, #queue-req: 444, 
[1,0]<stderr>:[2025-10-10 17:25:06 TP0] Prefill batch. #new-seq: 6, #new-token: 1230, #cached-token: 14, token usage: 0.93, #running-req: 117, #queue-req: 438, 
[1,0]<stderr>:[2025-10-10 17:25:07 TP0] Prefill batch. #new-seq: 13, #new-token: 2075, #cached-token: 24, token usage: 0.87, #running-req: 120, #queue-req: 425, 
[1,0]<stderr>:[2025-10-10 17:25:08 TP0] Prefill batch. #new-seq: 12, #new-token: 3556, #cached-token: 22, token usage: 0.88, #running-req: 130, #queue-req: 413, 
[1,0]<stderr>:[2025-10-10 17:25:08 TP0] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 5, token usage: 0.94, #running-req: 140, #queue-req: 412, 
[1,0]<stderr>:[2025-10-10 17:25:08 TP0] Prefill batch. #new-seq: 11, #new-token: 5218, #cached-token: 24, token usage: 0.84, #running-req: 134, #queue-req: 401, 
[1,0]<stderr>:[2025-10-10 17:25:09 TP0] Prefill batch. #new-seq: 7, #new-token: 2065, #cached-token: 17, token usage: 0.91, #running-req: 143, #queue-req: 394, 
[1,0]<stderr>:[2025-10-10 17:25:09 TP0] Decode batch. #running-req: 143, #token: 61342, token usage: 0.94, cuda graph: False, gen throughput (token/s): 942.30, #queue-req: 394, 
[1,0]<stderr>:[2025-10-10 17:25:09 TP0] Prefill batch. #new-seq: 4, #new-token: 591, #cached-token: 5, token usage: 0.93, #running-req: 144, #queue-req: 390, 
[1,0]<stderr>:[2025-10-10 17:25:10 TP0] Prefill batch. #new-seq: 6, #new-token: 2608, #cached-token: 9, token usage: 0.88, #running-req: 146, #queue-req: 384, 
[1,0]<stderr>:[2025-10-10 17:25:10 TP0] Prefill batch. #new-seq: 5, #new-token: 2145, #cached-token: 19, token usage: 0.91, #running-req: 147, #queue-req: 379, 
[1,0]<stderr>:[2025-10-10 17:25:10 TP0] Prefill batch. #new-seq: 2, #new-token: 18, #cached-token: 2, token usage: 0.94, #running-req: 151, #queue-req: 377, 
[1,0]<stderr>:[2025-10-10 17:25:11 TP0] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 4, token usage: 0.93, #running-req: 150, #queue-req: 376, 
[1,0]<stderr>:[2025-10-10 17:25:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1017, #cached-token: 9, token usage: 0.93, #running-req: 147, #queue-req: 374, 
[1,0]<stderr>:[2025-10-10 17:25:12 TP0] Prefill batch. #new-seq: 2, #new-token: 1260, #cached-token: 2, token usage: 0.92, #running-req: 146, #queue-req: 372, 
[1,0]<stderr>:[2025-10-10 17:25:12 TP0] Prefill batch. #new-seq: 2, #new-token: 699, #cached-token: 3, token usage: 0.93, #running-req: 144, #queue-req: 370, 
[1,0]<stderr>:[2025-10-10 17:25:12 TP0] Prefill batch. #new-seq: 4, #new-token: 705, #cached-token: 7, token usage: 0.93, #running-req: 144, #queue-req: 366, 
[1,0]<stderr>:[2025-10-10 17:25:13 TP0] Prefill batch. #new-seq: 5, #new-token: 1194, #cached-token: 12, token usage: 0.93, #running-req: 147, #queue-req: 361, 
[1,0]<stderr>:[2025-10-10 17:25:13 TP0] Prefill batch. #new-seq: 3, #new-token: 350, #cached-token: 3, token usage: 0.94, #running-req: 150, #queue-req: 358, 
[1,0]<stderr>:[2025-10-10 17:25:13 TP0] Prefill batch. #new-seq: 2, #new-token: 1151, #cached-token: 4, token usage: 0.93, #running-req: 151, #queue-req: 356, 
[1,0]<stderr>:[2025-10-10 17:25:13 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.95, #running-req: 152, #queue-req: 355, 
[1,0]<stderr>:[2025-10-10 17:25:14 TP0] Prefill batch. #new-seq: 5, #new-token: 575, #cached-token: 9, token usage: 0.93, #running-req: 150, #queue-req: 350, 
[1,0]<stderr>:[2025-10-10 17:25:14 TP0] Prefill batch. #new-seq: 6, #new-token: 962, #cached-token: 13, token usage: 0.93, #running-req: 152, #queue-req: 344, 
[1,0]<stderr>:[2025-10-10 17:25:15 TP0] Prefill batch. #new-seq: 1, #new-token: 486, #cached-token: 2, token usage: 0.94, #running-req: 157, #queue-req: 343, 
[1,0]<stderr>:[2025-10-10 17:25:15 TP0] Prefill batch. #new-seq: 2, #new-token: 1099, #cached-token: 8, token usage: 0.93, #running-req: 155, #queue-req: 341, 
[1,0]<stderr>:[2025-10-10 17:25:15 TP0] Decode batch. #running-req: 157, #token: 60747, token usage: 0.93, cuda graph: False, gen throughput (token/s): 911.57, #queue-req: 341, 
[1,0]<stderr>:[2025-10-10 17:25:15 TP0] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 2, token usage: 0.93, #running-req: 154, #queue-req: 340, 
[1,0]<stderr>:[2025-10-10 17:25:16 TP0] Prefill batch. #new-seq: 2, #new-token: 2125, #cached-token: 2, token usage: 0.92, #running-req: 152, #queue-req: 338, 
[1,0]<stderr>:[2025-10-10 17:25:16 TP0] Prefill batch. #new-seq: 7, #new-token: 1372, #cached-token: 13, token usage: 0.91, #running-req: 148, #queue-req: 331, 
[1,0]<stderr>:[2025-10-10 17:25:17 TP0] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 3, token usage: 0.93, #running-req: 154, #queue-req: 330, 
[1,0]<stderr>:[2025-10-10 17:25:17 TP0] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 1, token usage: 0.94, #running-req: 154, #queue-req: 329, 
[1,0]<stderr>:[2025-10-10 17:25:17 TP0] Prefill batch. #new-seq: 2, #new-token: 650, #cached-token: 5, token usage: 0.93, #running-req: 152, #queue-req: 327, 
[1,0]<stderr>:[2025-10-10 17:25:17 TP0] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 1, token usage: 0.94, #running-req: 153, #queue-req: 326, 
[1,0]<stderr>:[2025-10-10 17:25:18 TP0] Prefill batch. #new-seq: 5, #new-token: 768, #cached-token: 11, token usage: 0.91, #running-req: 152, #queue-req: 321, 
[1,0]<stderr>:[2025-10-10 17:25:18 TP0] Prefill batch. #new-seq: 3, #new-token: 1392, #cached-token: 7, token usage: 0.91, #running-req: 151, #queue-req: 318, 
[1,0]<stderr>:[2025-10-10 17:25:19 TP0] Prefill batch. #new-seq: 3, #new-token: 209, #cached-token: 7, token usage: 0.93, #running-req: 153, #queue-req: 315, 
[1,0]<stderr>:[2025-10-10 17:25:19 TP0] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 2, token usage: 0.93, #running-req: 155, #queue-req: 314, 
[1,0]<stderr>:[2025-10-10 17:25:21 TP0] Decode batch. #running-req: 149, #token: 59612, token usage: 0.91, cuda graph: False, gen throughput (token/s): 1086.28, #queue-req: 314, 
[1,0]<stderr>:[2025-10-10 17:25:21 TP0] Prefill batch. #new-seq: 3, #new-token: 1890, #cached-token: 5, token usage: 0.91, #running-req: 147, #queue-req: 311, 
[1,0]<stderr>:[2025-10-10 17:25:21 TP0] Prefill batch. #new-seq: 4, #new-token: 1006, #cached-token: 7, token usage: 0.93, #running-req: 145, #queue-req: 307, 
[1,0]<stderr>:[2025-10-10 17:25:22 TP0] Prefill batch. #new-seq: 2, #new-token: 36, #cached-token: 4, token usage: 0.94, #running-req: 148, #queue-req: 305, 
[1,0]<stderr>:[2025-10-10 17:25:23 TP0] Prefill batch. #new-seq: 2, #new-token: 1155, #cached-token: 6, token usage: 0.93, #running-req: 147, #queue-req: 303, 
[1,0]<stderr>:[2025-10-10 17:25:23 TP0] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 2, token usage: 0.94, #running-req: 143, #queue-req: 302, 
[1,0]<stderr>:[2025-10-10 17:25:24 TP0] Prefill batch. #new-seq: 1, #new-token: 760, #cached-token: 1, token usage: 0.94, #running-req: 143, #queue-req: 301, 
[1,0]<stderr>:[2025-10-10 17:25:25 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.94, #running-req: 138, #queue-req: 300, 
[1,0]<stderr>:[2025-10-10 17:25:25 TP0] Prefill batch. #new-seq: 3, #new-token: 745, #cached-token: 4, token usage: 0.94, #running-req: 138, #queue-req: 297, 
[1,0]<stderr>:[2025-10-10 17:25:26 TP0] Decode batch. #running-req: 139, #token: 61325, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1088.69, #queue-req: 297, 
[1,0]<stderr>:[2025-10-10 17:25:26 TP0] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 2, token usage: 0.94, #running-req: 138, #queue-req: 296, 
[1,0]<stderr>:[2025-10-10 17:25:26 TP0] Prefill batch. #new-seq: 2, #new-token: 538, #cached-token: 4, token usage: 0.94, #running-req: 136, #queue-req: 294, 
[1,0]<stderr>:[2025-10-10 17:25:27 TP0] Prefill batch. #new-seq: 10, #new-token: 1798, #cached-token: 27, token usage: 0.90, #running-req: 136, #queue-req: 284, 
[1,0]<stderr>:[2025-10-10 17:25:28 TP0] Prefill batch. #new-seq: 2, #new-token: 425, #cached-token: 2, token usage: 0.93, #running-req: 145, #queue-req: 282, 
[1,0]<stderr>:[2025-10-10 17:25:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1342, #cached-token: 4, token usage: 0.92, #running-req: 142, #queue-req: 281, 
[1,0]<stderr>:[2025-10-10 17:25:30 TP0] Prefill batch. #new-seq: 2, #new-token: 2846, #cached-token: 7, token usage: 0.90, #running-req: 136, #queue-req: 279, 
[1,0]<stderr>:[2025-10-10 17:25:30 TP0] Prefill batch. #new-seq: 2, #new-token: 840, #cached-token: 6, token usage: 0.94, #running-req: 136, #queue-req: 277, 
[1,0]<stderr>:[2025-10-10 17:25:31 TP0] Prefill batch. #new-seq: 3, #new-token: 868, #cached-token: 7, token usage: 0.94, #running-req: 135, #queue-req: 274, 
[1,0]<stderr>:[2025-10-10 17:25:31 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.95, #running-req: 137, #queue-req: 273, 
[1,0]<stderr>:[2025-10-10 17:25:32 TP0] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 1, token usage: 0.95, #running-req: 136, #queue-req: 272, 
[1,0]<stderr>:[2025-10-10 17:25:32 TP0] Decode batch. #running-req: 136, #token: 60873, token usage: 0.93, cuda graph: False, gen throughput (token/s): 1028.12, #queue-req: 272, 
[1,0]<stderr>:[2025-10-10 17:25:32 TP0] Prefill batch. #new-seq: 2, #new-token: 12, #cached-token: 5, token usage: 0.93, #running-req: 134, #queue-req: 270, 
[1,0]<stderr>:[2025-10-10 17:25:33 TP0] Prefill batch. #new-seq: 1, #new-token: 3486, #cached-token: 1, token usage: 0.90, #running-req: 129, #queue-req: 269, 
[1,0]<stderr>:[2025-10-10 17:25:35 TP0] Prefill batch. #new-seq: 7, #new-token: 181, #cached-token: 12, token usage: 0.94, #running-req: 125, #queue-req: 262, 
[1,0]<stderr>:[2025-10-10 17:25:36 TP0] Prefill batch. #new-seq: 5, #new-token: 896, #cached-token: 9, token usage: 0.92, #running-req: 131, #queue-req: 257, 
[1,0]<stderr>:[2025-10-10 17:25:37 TP0] Decode batch. #running-req: 133, #token: 61380, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1032.97, #queue-req: 257, 
[1,0]<stderr>:[2025-10-10 17:25:37 TP0] Prefill batch. #new-seq: 2, #new-token: 2146, #cached-token: 10, token usage: 0.91, #running-req: 130, #queue-req: 255, 
[1,0]<stderr>:[2025-10-10 17:25:41 TP0] Prefill batch. #new-seq: 4, #new-token: 3385, #cached-token: 7, token usage: 0.91, #running-req: 119, #queue-req: 251, 
[1,0]<stderr>:[2025-10-10 17:25:42 TP0] Decode batch. #running-req: 122, #token: 61296, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1042.17, #queue-req: 251, 
[1,0]<stderr>:[2025-10-10 17:25:42 TP0] Prefill batch. #new-seq: 6, #new-token: 1570, #cached-token: 11, token usage: 0.94, #running-req: 120, #queue-req: 245, 
[1,0]<stderr>:[2025-10-10 17:25:42 TP0] Prefill batch. #new-seq: 3, #new-token: 588, #cached-token: 8, token usage: 0.95, #running-req: 123, #queue-req: 242, 
[1,0]<stderr>:[2025-10-10 17:25:42 TP0] Prefill batch. #new-seq: 3, #new-token: 295, #cached-token: 9, token usage: 0.95, #running-req: 124, #queue-req: 239, 
[1,0]<stderr>:[2025-10-10 17:25:42 TP0] Prefill batch. #new-seq: 3, #new-token: 195, #cached-token: 4, token usage: 0.95, #running-req: 126, #queue-req: 236, 
[1,0]<stderr>:[2025-10-10 17:25:43 TP0] Prefill batch. #new-seq: 2, #new-token: 899, #cached-token: 6, token usage: 0.95, #running-req: 128, #queue-req: 234, 
[1,0]<stderr>:[2025-10-10 17:25:43 TP0] Prefill batch. #new-seq: 3, #new-token: 898, #cached-token: 4, token usage: 0.94, #running-req: 127, #queue-req: 231, 
[1,0]<stderr>:[2025-10-10 17:25:43 TP0] Prefill batch. #new-seq: 2, #new-token: 351, #cached-token: 3, token usage: 0.95, #running-req: 127, #queue-req: 229, 
[1,0]<stderr>:[2025-10-10 17:25:44 TP0] Prefill batch. #new-seq: 3, #new-token: 700, #cached-token: 8, token usage: 0.95, #running-req: 126, #queue-req: 226, 
[1,0]<stderr>:[2025-10-10 17:25:44 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 1, token usage: 0.94, #running-req: 128, #queue-req: 225, 
[1,0]<stderr>:[2025-10-10 17:25:44 TP0] Prefill batch. #new-seq: 2, #new-token: 592, #cached-token: 2, token usage: 0.95, #running-req: 125, #queue-req: 223, 
[1,0]<stderr>:[2025-10-10 17:25:45 TP0] Prefill batch. #new-seq: 2, #new-token: 744, #cached-token: 4, token usage: 0.93, #running-req: 123, #queue-req: 221, 
[1,0]<stderr>:[2025-10-10 17:25:47 TP0] Prefill batch. #new-seq: 7, #new-token: 3535, #cached-token: 16, token usage: 0.89, #running-req: 118, #queue-req: 214, 
[1,0]<stderr>:[2025-10-10 17:25:47 TP0] Prefill batch. #new-seq: 4, #new-token: 1788, #cached-token: 5, token usage: 0.93, #running-req: 122, #queue-req: 210, 
[1,0]<stderr>:[2025-10-10 17:25:47 TP0] Prefill batch. #new-seq: 2, #new-token: 492, #cached-token: 18, token usage: 0.94, #running-req: 124, #queue-req: 208, 
[1,0]<stderr>:[2025-10-10 17:25:47 TP0] Prefill batch. #new-seq: 4, #new-token: 1049, #cached-token: 9, token usage: 0.93, #running-req: 125, #queue-req: 204, 
[1,0]<stderr>:[2025-10-10 17:25:47 TP0] Prefill batch. #new-seq: 6, #new-token: 680, #cached-token: 21, token usage: 0.94, #running-req: 128, #queue-req: 198, 
[1,0]<stderr>:[2025-10-10 17:25:48 TP0] Prefill batch. #new-seq: 8, #new-token: 2951, #cached-token: 19, token usage: 0.90, #running-req: 133, #queue-req: 190, 
[1,0]<stderr>:[2025-10-10 17:25:48 TP0] Decode batch. #running-req: 133, #token: 61643, token usage: 0.94, cuda graph: False, gen throughput (token/s): 781.85, #queue-req: 190, 
[1,0]<stderr>:[2025-10-10 17:25:48 TP0] Prefill batch. #new-seq: 3, #new-token: 351, #cached-token: 6, token usage: 0.94, #running-req: 138, #queue-req: 187, 
[1,0]<stderr>:[2025-10-10 17:25:48 TP0] Prefill batch. #new-seq: 4, #new-token: 1183, #cached-token: 11, token usage: 0.94, #running-req: 139, #queue-req: 183, 
[1,0]<stderr>:[2025-10-10 17:25:49 TP0] Prefill batch. #new-seq: 2, #new-token: 339, #cached-token: 3, token usage: 0.95, #running-req: 142, #queue-req: 181, 
[1,0]<stderr>:[2025-10-10 17:25:49 TP0] Prefill batch. #new-seq: 2, #new-token: 912, #cached-token: 6, token usage: 0.94, #running-req: 142, #queue-req: 179, 
[1,0]<stderr>:[2025-10-10 17:25:49 TP0] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 2, token usage: 0.95, #running-req: 143, #queue-req: 178, 
[1,0]<stderr>:[2025-10-10 17:25:49 TP0] Prefill batch. #new-seq: 3, #new-token: 276, #cached-token: 8, token usage: 0.95, #running-req: 142, #queue-req: 175, 
[1,0]<stderr>:[2025-10-10 17:25:50 TP0] Prefill batch. #new-seq: 1, #new-token: 638, #cached-token: 3, token usage: 0.95, #running-req: 144, #queue-req: 174, 
[1,0]<stderr>:[2025-10-10 17:25:50 TP0] Prefill batch. #new-seq: 1, #new-token: 867, #cached-token: 2, token usage: 0.95, #running-req: 143, #queue-req: 173, 
[1,0]<stderr>:[2025-10-10 17:25:50 TP0] Prefill batch. #new-seq: 4, #new-token: 1390, #cached-token: 10, token usage: 0.93, #running-req: 143, #queue-req: 169, 
[1,0]<stderr>:[2025-10-10 17:25:51 TP0] Prefill batch. #new-seq: 2, #new-token: 345, #cached-token: 5, token usage: 0.95, #running-req: 142, #queue-req: 167, 
[1,0]<stderr>:[2025-10-10 17:25:51 TP0] Prefill batch. #new-seq: 5, #new-token: 846, #cached-token: 8, token usage: 0.93, #running-req: 140, #queue-req: 162, 
[1,0]<stderr>:[2025-10-10 17:25:51 TP0] Prefill batch. #new-seq: 5, #new-token: 433, #cached-token: 7, token usage: 0.94, #running-req: 142, #queue-req: 157, 
[1,0]<stderr>:[2025-10-10 17:25:52 TP0] Prefill batch. #new-seq: 2, #new-token: 811, #cached-token: 10, token usage: 0.94, #running-req: 146, #queue-req: 155, 
[1,0]<stderr>:[2025-10-10 17:25:52 TP0] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 2, token usage: 0.95, #running-req: 147, #queue-req: 154, 
[1,0]<stderr>:[2025-10-10 17:25:52 TP0] Prefill batch. #new-seq: 2, #new-token: 1734, #cached-token: 8, token usage: 0.93, #running-req: 144, #queue-req: 152, 
[1,0]<stderr>:[2025-10-10 17:25:53 TP0] Prefill batch. #new-seq: 2, #new-token: 2769, #cached-token: 4, token usage: 0.91, #running-req: 136, #queue-req: 150, 
[1,0]<stderr>:[2025-10-10 17:25:54 TP0] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 5, token usage: 0.95, #running-req: 137, #queue-req: 149, 
[1,0]<stderr>:[2025-10-10 17:25:54 TP0] Prefill batch. #new-seq: 6, #new-token: 1727, #cached-token: 10, token usage: 0.92, #running-req: 136, #queue-req: 143, 
[1,0]<stderr>:[2025-10-10 17:25:54 TP0] Prefill batch. #new-seq: 1, #new-token: 665, #cached-token: 1, token usage: 0.93, #running-req: 139, #queue-req: 142, 
[1,0]<stderr>:[2025-10-10 17:25:55 TP0] Prefill batch. #new-seq: 3, #new-token: 1270, #cached-token: 10, token usage: 0.94, #running-req: 138, #queue-req: 139, 
[1,0]<stderr>:[2025-10-10 17:25:55 TP0] Prefill batch. #new-seq: 3, #new-token: 1089, #cached-token: 7, token usage: 0.94, #running-req: 137, #queue-req: 136, 
[1,0]<stderr>:[2025-10-10 17:25:55 TP0] Decode batch. #running-req: 137, #token: 62095, token usage: 0.95, cuda graph: False, gen throughput (token/s): 812.51, #queue-req: 136, 
[1,0]<stderr>:[2025-10-10 17:25:55 TP0] Prefill batch. #new-seq: 2, #new-token: 25, #cached-token: 2, token usage: 0.95, #running-req: 139, #queue-req: 134, 
[1,0]<stderr>:[2025-10-10 17:25:56 TP0] Prefill batch. #new-seq: 2, #new-token: 614, #cached-token: 3, token usage: 0.94, #running-req: 138, #queue-req: 132, 
[1,0]<stderr>:[2025-10-10 17:25:56 TP0] Prefill batch. #new-seq: 2, #new-token: 291, #cached-token: 3, token usage: 0.95, #running-req: 139, #queue-req: 130, 
[1,0]<stderr>:[2025-10-10 17:25:57 TP0] Prefill batch. #new-seq: 3, #new-token: 1597, #cached-token: 10, token usage: 0.93, #running-req: 138, #queue-req: 127, 
[1,0]<stderr>:[2025-10-10 17:25:57 TP0] Prefill batch. #new-seq: 4, #new-token: 1434, #cached-token: 24, token usage: 0.92, #running-req: 135, #queue-req: 123, 
[1,0]<stderr>:[2025-10-10 17:25:58 TP0] Prefill batch. #new-seq: 3, #new-token: 1348, #cached-token: 16, token usage: 0.94, #running-req: 136, #queue-req: 120, 
[1,0]<stderr>:[2025-10-10 17:25:58 TP0] Prefill batch. #new-seq: 5, #new-token: 1079, #cached-token: 23, token usage: 0.91, #running-req: 137, #queue-req: 115, 
[1,0]<stderr>:[2025-10-10 17:25:58 TP0] Prefill batch. #new-seq: 2, #new-token: 1264, #cached-token: 8, token usage: 0.92, #running-req: 139, #queue-req: 113, 
[1,0]<stderr>:[2025-10-10 17:25:59 TP0] Prefill batch. #new-seq: 2, #new-token: 580, #cached-token: 8, token usage: 0.93, #running-req: 140, #queue-req: 111, 
[1,0]<stderr>:[2025-10-10 17:25:59 TP0] Prefill batch. #new-seq: 2, #new-token: 780, #cached-token: 8, token usage: 0.92, #running-req: 137, #queue-req: 109, 
[1,0]<stderr>:[2025-10-10 17:26:00 TP0] Prefill batch. #new-seq: 5, #new-token: 1236, #cached-token: 15, token usage: 0.92, #running-req: 138, #queue-req: 104, 
[1,0]<stderr>:[2025-10-10 17:26:00 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 4, token usage: 0.94, #running-req: 142, #queue-req: 103, 
[1,0]<stderr>:[2025-10-10 17:26:00 TP0] Prefill batch. #new-seq: 2, #new-token: 551, #cached-token: 6, token usage: 0.93, #running-req: 142, #queue-req: 101, 
[1,0]<stderr>:[2025-10-10 17:26:00 TP0] Prefill batch. #new-seq: 4, #new-token: 887, #cached-token: 12, token usage: 0.93, #running-req: 142, #queue-req: 97, 
[1,0]<stderr>:[2025-10-10 17:26:00 TP0] Prefill batch. #new-seq: 5, #new-token: 427, #cached-token: 15, token usage: 0.93, #running-req: 144, #queue-req: 92, 
[1,0]<stderr>:[2025-10-10 17:26:01 TP0] Prefill batch. #new-seq: 7, #new-token: 207, #cached-token: 21, token usage: 0.93, #running-req: 148, #queue-req: 85, 
[1,0]<stderr>:[2025-10-10 17:26:01 TP0] Prefill batch. #new-seq: 2, #new-token: 466, #cached-token: 5, token usage: 0.92, #running-req: 152, #queue-req: 83, 
[1,0]<stderr>:[2025-10-10 17:26:02 TP0] Decode batch. #running-req: 152, #token: 57722, token usage: 0.88, cuda graph: False, gen throughput (token/s): 855.61, #queue-req: 83, 
[1,0]<stderr>:[2025-10-10 17:26:02 TP0] Prefill batch. #new-seq: 7, #new-token: 3565, #cached-token: 14, token usage: 0.88, #running-req: 151, #queue-req: 76, 
[1,0]<stderr>:[2025-10-10 17:26:02 TP0] Prefill batch. #new-seq: 3, #new-token: 302, #cached-token: 6, token usage: 0.94, #running-req: 157, #queue-req: 73, 
[1,0]<stderr>:[2025-10-10 17:26:04 TP0] Prefill batch. #new-seq: 2, #new-token: 1079, #cached-token: 5, token usage: 0.94, #running-req: 153, #queue-req: 71, 
[1,0]<stderr>:[2025-10-10 17:26:06 TP0] Decode batch. #running-req: 140, #token: 61336, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1261.66, #queue-req: 71, 
[1,0]<stderr>:[2025-10-10 17:26:11 TP0] Decode batch. #running-req: 123, #token: 61769, token usage: 0.94, cuda graph: False, gen throughput (token/s): 1170.83, #queue-req: 71, 
[1,0]<stderr>:[2025-10-10 17:26:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1560, #cached-token: 2, token usage: 0.93, #running-req: 115, #queue-req: 70, 
[1,0]<stderr>:[2025-10-10 17:26:13 TP0] Prefill batch. #new-seq: 2, #new-token: 65, #cached-token: 4, token usage: 0.95, #running-req: 115, #queue-req: 68, 
[1,0]<stderr>:[2025-10-10 17:26:13 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.96, #running-req: 116, #queue-req: 67, 
[1,0]<stderr>:[2025-10-10 17:26:15 TP0] Prefill batch. #new-seq: 2, #new-token: 1329, #cached-token: 4, token usage: 0.94, #running-req: 112, #queue-req: 65, 
[1,0]<stderr>:[2025-10-10 17:26:16 TP0] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 1, token usage: 0.96, #running-req: 112, #queue-req: 64, 
[1,0]<stderr>:[2025-10-10 17:26:16 TP0] Decode batch. #running-req: 112, #token: 63101, token usage: 0.96, cuda graph: False, gen throughput (token/s): 902.19, #queue-req: 64, 
[1,0]<stderr>:[2025-10-10 17:26:17 TP0] Prefill batch. #new-seq: 2, #new-token: 1379, #cached-token: 3, token usage: 0.94, #running-req: 107, #queue-req: 62, 
[1,0]<stderr>:[2025-10-10 17:26:18 TP0] Prefill batch. #new-seq: 1, #new-token: 3591, #cached-token: 1, token usage: 0.90, #running-req: 96, #queue-req: 61, 
[1,0]<stderr>:[2025-10-10 17:26:19 TP0] Prefill batch. #new-seq: 3, #new-token: 2032, #cached-token: 3, token usage: 0.94, #running-req: 94, #queue-req: 58, 
[1,0]<stderr>:[2025-10-10 17:26:20 TP0] Prefill batch. #new-seq: 9, #new-token: 3388, #cached-token: 9, token usage: 0.88, #running-req: 92, #queue-req: 49, 
[1,0]<stderr>:[2025-10-10 17:26:20 TP0] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 4, token usage: 0.94, #running-req: 99, #queue-req: 48, 
[1,0]<stderr>:[2025-10-10 17:26:21 TP0] Decode batch. #running-req: 99, #token: 62014, token usage: 0.95, cuda graph: False, gen throughput (token/s): 800.12, #queue-req: 48, 
[1,0]<stderr>:[2025-10-10 17:26:21 TP0] Prefill batch. #new-seq: 2, #new-token: 2489, #cached-token: 2, token usage: 0.93, #running-req: 98, #queue-req: 46, 
[1,0]<stderr>:[2025-10-10 17:26:21 TP0] Prefill batch. #new-seq: 2, #new-token: 676, #cached-token: 2, token usage: 0.95, #running-req: 97, #queue-req: 44, 
[1,0]<stderr>:[2025-10-10 17:26:22 TP0] Prefill batch. #new-seq: 2, #new-token: 896, #cached-token: 4, token usage: 0.95, #running-req: 97, #queue-req: 42, 
[1,0]<stderr>:[2025-10-10 17:26:22 TP0] Prefill batch. #new-seq: 1, #new-token: 452, #cached-token: 2, token usage: 0.96, #running-req: 98, #queue-req: 41, 
[1,0]<stderr>:[2025-10-10 17:26:22 TP0] Prefill batch. #new-seq: 6, #new-token: 1691, #cached-token: 9, token usage: 0.92, #running-req: 97, #queue-req: 35, 
[1,0]<stderr>:[2025-10-10 17:26:23 TP0] Prefill batch. #new-seq: 6, #new-token: 763, #cached-token: 7, token usage: 0.94, #running-req: 102, #queue-req: 29, 
[1,0]<stderr>:[2025-10-10 17:26:23 TP0] Prefill batch. #new-seq: 3, #new-token: 398, #cached-token: 4, token usage: 0.95, #running-req: 107, #queue-req: 26, 
[1,0]<stderr>:[2025-10-10 17:26:23 TP0] Prefill batch. #new-seq: 1, #new-token: 823, #cached-token: 1, token usage: 0.93, #running-req: 109, #queue-req: 25, 
[1,0]<stderr>:[2025-10-10 17:26:25 TP0] Prefill batch. #new-seq: 1, #new-token: 2187, #cached-token: 1, token usage: 0.92, #running-req: 100, #queue-req: 24, 
[1,0]<stderr>:[2025-10-10 17:26:25 TP0] Prefill batch. #new-seq: 6, #new-token: 749, #cached-token: 6, token usage: 0.95, #running-req: 99, #queue-req: 18, 
[1,0]<stderr>:[2025-10-10 17:26:26 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 1, token usage: 0.96, #running-req: 104, #queue-req: 17, 
[1,0]<stderr>:[2025-10-10 17:26:26 TP0] Prefill batch. #new-seq: 2, #new-token: 755, #cached-token: 4, token usage: 0.96, #running-req: 104, #queue-req: 15, 
[1,0]<stderr>:[2025-10-10 17:26:27 TP0] Decode batch. #running-req: 99, #token: 61919, token usage: 0.94, cuda graph: False, gen throughput (token/s): 706.75, #queue-req: 15, 
[1,0]<stderr>:[2025-10-10 17:26:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1886, #cached-token: 1, token usage: 0.94, #running-req: 97, #queue-req: 14, 
[1,0]<stderr>:[2025-10-10 17:26:27 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.97, #running-req: 97, #queue-req: 13, 
[1,0]<stderr>:[2025-10-10 17:26:28 TP0] Prefill batch. #new-seq: 3, #new-token: 31, #cached-token: 3, token usage: 0.95, #running-req: 97, #queue-req: 10, 
[1,0]<stderr>:[2025-10-10 17:26:28 TP0] Prefill batch. #new-seq: 2, #new-token: 243, #cached-token: 2, token usage: 0.95, #running-req: 99, #queue-req: 8, 
[1,0]<stderr>:[2025-10-10 17:26:28 TP0] Prefill batch. #new-seq: 6, #new-token: 965, #cached-token: 6, token usage: 0.92, #running-req: 98, #queue-req: 2, 
[1,0]<stderr>:[2025-10-10 17:26:29 TP0] Prefill batch. #new-seq: 2, #new-token: 526, #cached-token: 4, token usage: 0.93, #running-req: 103, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:26:32 TP0] Decode batch. #running-req: 87, #token: 52888, token usage: 0.81, cuda graph: False, gen throughput (token/s): 743.09, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:26:37 TP0] Decode batch. #running-req: 76, #token: 51551, token usage: 0.79, cuda graph: False, gen throughput (token/s): 715.82, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:26:41 TP0] Decode batch. #running-req: 66, #token: 45748, token usage: 0.70, cuda graph: False, gen throughput (token/s): 606.39, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:26:46 TP0] Decode batch. #running-req: 55, #token: 40205, token usage: 0.61, cuda graph: False, gen throughput (token/s): 528.89, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:26:50 TP0] Decode batch. #running-req: 47, #token: 37653, token usage: 0.57, cuda graph: False, gen throughput (token/s): 445.52, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:26:55 TP0] Decode batch. #running-req: 36, #token: 26242, token usage: 0.40, cuda graph: False, gen throughput (token/s): 381.49, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:26:59 TP0] Decode batch. #running-req: 32, #token: 25126, token usage: 0.38, cuda graph: False, gen throughput (token/s): 298.43, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:04 TP0] Decode batch. #running-req: 29, #token: 24914, token usage: 0.38, cuda graph: False, gen throughput (token/s): 261.73, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:08 TP0] Decode batch. #running-req: 27, #token: 23853, token usage: 0.36, cuda graph: False, gen throughput (token/s): 238.80, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:13 TP0] Decode batch. #running-req: 24, #token: 23107, token usage: 0.35, cuda graph: False, gen throughput (token/s): 216.20, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:17 TP0] Decode batch. #running-req: 20, #token: 20487, token usage: 0.31, cuda graph: False, gen throughput (token/s): 189.45, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:22 TP0] Decode batch. #running-req: 17, #token: 16374, token usage: 0.25, cuda graph: False, gen throughput (token/s): 157.61, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:27 TP0] Decode batch. #running-req: 12, #token: 10677, token usage: 0.16, cuda graph: False, gen throughput (token/s): 134.83, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:31 TP0] Decode batch. #running-req: 11, #token: 7339, token usage: 0.11, cuda graph: False, gen throughput (token/s): 102.65, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:36 TP0] Decode batch. #running-req: 8, #token: 7040, token usage: 0.11, cuda graph: False, gen throughput (token/s): 72.01, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:40 TP0] Decode batch. #running-req: 6, #token: 5967, token usage: 0.09, cuda graph: False, gen throughput (token/s): 68.72, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:45 TP0] Decode batch. #running-req: 6, #token: 6207, token usage: 0.09, cuda graph: False, gen throughput (token/s): 54.21, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:49 TP0] Decode batch. #running-req: 4, #token: 3335, token usage: 0.05, cuda graph: False, gen throughput (token/s): 46.12, #queue-req: 0, 
[1,0]<stderr>:[2025-10-10 17:27:55 TP0] Decode batch. #running-req: 1, #token: 992, token usage: 0.02, cuda graph: False, gen throughput (token/s): 16.54, #queue-req: 0, 
[1,0]<stdout>:
[1,0]<stdout>:====== Offline Throughput Benchmark Result =======
[1,0]<stdout>:Backend:                                 engine    
[1,0]<stdout>:Successful requests:                     2000      
[1,0]<stdout>:Benchmark duration (s):                  505.16    
[1,0]<stdout>:Total input tokens:                      626729    
[1,0]<stdout>:Total generated tokens:                  388685    
[1,0]<stdout>:Last generation throughput (tok/s):      16.54     
[1,0]<stdout>:Request throughput (req/s):              3.96      
[1,0]<stdout>:Input token throughput (tok/s):          1240.65   
[1,0]<stdout>:Output token throughput (tok/s):         769.42    
[1,0]<stdout>:Total token throughput (tok/s):          2010.07   
[1,0]<stdout>:==================================================
[1,1]<stderr>:[2025-10-10 17:27:58 TP12] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.95]:61330
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 17:27:58 TP8] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.95]:58273
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 17:27:58 TP13] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.95]:39862
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 17:27:58 TP15] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.95]:13196
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 17:27:58] Received sigquit from a child process. It usually means the child failed.
[1,1]<stderr>:[2025-10-10 17:27:58 TP14] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.95]:10160
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 17:27:58 TP10] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.95]:58797
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 17:27:58] Received sigquit from a child process. It usually means the child failed.
[1,1]<stderr>:[2025-10-10 17:27:58 TP11] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.95]:32666
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 17:27:58 TP9] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2578, in run_scheduler_process
[1,1]<stderr>:    scheduler.event_loop_overlap()
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 789, in event_loop_overlap
[1,1]<stderr>:    recv_reqs = self.recv_requests()
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stderr>:    recv_reqs = broadcast_pyobj(
[1,1]<stderr>:                ^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stderr>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stderr>:    return func(*args, **kwargs)
[1,1]<stderr>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stderr>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stderr>:    work.wait()
[1,1]<stderr>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.95]:30600
[1,1]<stderr>:
[1,1]<stderr>:[2025-10-10 17:27:58] Received sigquit from a child process. It usually means the child failed.
[1,1]<stderr>:[2025-10-10 17:27:58] Received sigquit from a child process. It usually means the child failed.
[1,1]<stderr>:[rank14]:[W1010 17:27:58.705176144 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=101, addr=[a2ap-dgx023.asp2p.nscc.sg]:33800, remote=[a2ap-dgx021.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank8]:[W1010 17:27:58.705192195 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx023.asp2p.nscc.sg]:33770, remote=[a2ap-dgx021.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank12]:[W1010 17:27:58.705183796 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx023.asp2p.nscc.sg]:33784, remote=[a2ap[1,1]<stderr>:-dgx021.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank15]:[W1010 17:27:58.705192412 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx023.asp2p.nscc.sg]:33756, remote=[a2ap-dgx021.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank9]:[W1010 17:27:58.705201013 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx023.asp2p.nscc.sg]:33754, remote=[a2ap-dgx021.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank14]:[W1010 17:27:58.710760464 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 14] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stderr>:[rank8]:[W1010 17:27:58.710766169 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 8] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stderr>:[rank12]:[W1010 17:27:58.710769832 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 12] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stderr>:[rank15]:[W1010 17:27:58.710767720 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 15] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stderr>:[rank9]:[W1010 17:27:58.710774846 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 9] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stderr>:[rank11]:[W1010 17:27:58.718470219 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx023.asp2p.nscc.sg]:33726, remote=[a2ap-dgx021.asp2p.nscc.sg]:5000): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a8cd (0x7ffe591f08cd in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank11]:[W1010 17:27:58.722000709 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 11] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[1,1]<stderr>:[rank10]:[W1010 17:27:58.719244771 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=101, addr=[a2ap-dgx023.asp2p.nscc.sg]:33740, remote=[a2ap-dgx021.asp2p.nscc.sg]:5000): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a8cd (0x7ffe591f08cd in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank10]:[W1010 17:27:58.722633052 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 10] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[1,1]<stderr>:[rank13]:[W1010 17:27:58.749006355 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx023.asp2p.nscc.sg]:33738, remote=[a2ap-dgx021.asp2p.nscc.sg]:5000): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[1,1]<stderr>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stderr>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #2: <unknown function> + 0x5d6a8cd (0x7ffe591f08cd in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stderr>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stderr>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stderr>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stderr>:
[1,1]<stderr>:[rank13]:[W1010 17:27:58.752938984 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 13] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[1,1]<stderr>:bash: line 4: 2812685 Killed                  '/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/bin/python3' -m sglang.bench_offline_throughput --model-path '/home/users/industry/ai-hpc/apacsc34/scratch/model/DeepSeek-R1' --dataset-path '/home/users/industry/ai-hpc/apacsc34/scratch/ShareGPT_V3_unfiltered_cleaned_split.json' --num-prompts 2000 --load-format dummy --seed 2025 --dtype bfloat16 --tp 16 --nnodes 2 --trust-remote-code --dist-init-addr ${DIST_INIT_ADDR}:5000 --node-rank ${OMPI_COMM_WORLD_RANK} --max-running-requests 512 --max-total-tokens 65536 --chunked-prefill-size 8192 --schedule-policy lpm --disable-cuda-graph
[1,1]<stderr>:
[1,1]<stderr>:real	10m4.738s
[1,1]<stderr>:user	0m21.599s
[1,1]<stderr>:sys	0m8.135s
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[6252,1],1]
  Exit code:    137
--------------------------------------------------------------------------

real	10m8.735s
user	0m0.053s
sys	0m0.145s
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-10 17:28:11.082478:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 96767.pbs111
	Project: 50000128
	Exit Status: 137
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 02:13:06
	Memory: Requested(3760gb), Used(27585336kb)
	Vmem Used: 21437190760kb
	Walltime: Requested(00:30:00), Used(00:10:13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx021:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx023:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 10.37mins
	GPU Power Consumed: 410.03999999999996W
	GPU Max GPU Memory Used: 804.81GB
	Memory Throughput Rate (Average): a2ap-dgx021:(gpu1:4%+gpu0:4%+gpu2:4%+gpu3:5%+gpu5:4%+gpu4:4%+gpu6:4%+gpu7:4%)+a2ap-dgx023:(gpu1:4%+gpu0:4%+gpu2:4%+gpu3:4%+gpu5:4%+gpu4:4%+gpu6:4%+gpu7:3%)
	Memory Throughput Rate (Max): a2ap-dgx021:(gpu1:28%+gpu0:45%+gpu2:31%+gpu3:45%+gpu5:45%+gpu4:45%+gpu6:45%+gpu7:33%)+a2ap-dgx023:(gpu1:18%+gpu0:34%+gpu2:21%+gpu3:34%+gpu5:46%+gpu4:39%+gpu6:34%+gpu7:10%)
	Memory Throughput Rate (Min): a2ap-dgx021:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx023:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx021:(gpu1:76%+gpu0:78%+gpu2:81%+gpu3:42%+gpu5:81%+gpu4:81%+gpu6:81%+gpu7:71%)+a2ap-dgx023:(gpu1:83%+gpu0:81%+gpu2:82%+gpu3:67%+gpu5:82%+gpu4:83%+gpu6:76%+gpu7:73%)
	GPU SM Utilization (Max): a2ap-dgx021:(gpu1:100%+gpu0:100%+gpu2:100%+gpu3:100%+gpu5:100%+gpu4:100%+gpu6:100%+gpu7:100%)+a2ap-dgx023:(gpu1:100%+gpu0:100%+gpu2:100%+gpu3:100%+gpu5:100%+gpu4:100%+gpu6:100%+gpu7:100%)
	GPU SM Utilization (Min): a2ap-dgx021:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx023:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: None
GPU application profile: High
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

