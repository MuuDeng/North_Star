========== OPTIMIZED TP16+DP2+MTP BENCHMARK ==========
Prepaid SU: 341.334 | 7min SU: 238.934 | Balance: 46060.020
N/A
Job ID: 97052.pbs111 | GPUs: 16 | Master: a2ap-dgx006.asp2p.nscc.sg:5000
Config: TP16 + DP2 + DP-Attention + Multi-Token Prediction (EAGLE)
Architecture: 2 DP groups × 8 TP GPUs | MLA + EP + FlashInfer
MTP Config: EAGLE steps=1, topk=1, draft_tokens=2
=========================================================
[20:24:04] Launching SGLang offline throughput benchmark...
[1,1]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 4096 to avoid MoE kernel issues. 
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:Mixed chunked prefill is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 4096 to avoid MoE kernel issues. 
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:Mixed chunked prefill is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,0]<stdout>:[2025-10-11 20:24:38] Using default HuggingFace chat template with detected content format: string
[1,0]<stdout>:[2025-10-11 20:25:24 DP0 TP0] MLA optimization is turned on. Use flashinfer backend.
[1,0]<stdout>:[2025-10-11 20:25:24 DP0 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-11 20:25:24 DP0 TP0] Init torch distributed begin.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-11 20:25:28 DP0 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:NCCL version 2.27.3+cuda12.9
[1,0]<stdout>:[2025-10-11 20:25:36 DP0 TP0] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-11 20:25:36 DP0 TP1] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-11 20:25:36 DP0 TP6] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-11 20:25:36 DP0 TP5] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-11 20:25:36 DP0 TP2] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-11 20:25:36 DP0 TP4] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-11 20:25:36 DP0 TP7] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-11 20:25:36 DP0 TP3] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-11 20:25:36 DP1 TP15] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-11 20:25:36 DP1 TP14] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-11 20:25:36 DP1 TP13] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-11 20:25:36 DP1 TP12] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-11 20:25:36 DP1 TP11] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-11 20:25:36 DP1 TP10] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-11 20:25:36 DP1 TP9] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-11 20:25:36 DP1 TP8] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-11 20:25:36 DP0 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[2025-10-11 20:25:38 DP0 TP0] Init torch distributed ends. mem usage=2.18 GB
[1,0]<stdout>:[2025-10-11 20:25:39 DP0 TP6] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-11 20:25:39 DP0 TP1] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-11 20:25:39 DP0 TP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-11 20:25:39 DP0 TP2] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-11 20:25:39 DP0 TP5] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-11 20:25:39 DP0 TP3] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-11 20:25:39 DP0 TP7] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-11 20:25:39 DP0 TP4] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-11 20:25:39 DP1 TP15] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-11 20:25:39 DP1 TP14] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-11 20:25:39 DP1 TP12] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-11 20:25:39 DP1 TP10] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-11 20:25:39 DP1 TP13] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-11 20:25:39 DP1 TP11] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-11 20:25:39 DP1 TP8] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-11 20:25:39 DP1 TP9] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-11 20:25:40 DP0 TP0] Load weight begin. avail mem=76.36 GB
[1,0]<stdout>:[2025-10-11 20:25:40 DP0 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-11 20:26:01 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=33.68 GB, mem usage=42.69 GB.
[1,0]<stdout>:[2025-10-11 20:26:11 DP0 TP7] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,0]<stdout>:[2025-10-11 20:26:12 DP0 TP6] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,1]<stdout>:[2025-10-11 20:26:12 DP1 TP13] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,1]<stdout>:[2025-10-11 20:26:12 DP1 TP11] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,0]<stdout>:[2025-10-11 20:26:12 DP0 TP3] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,1]<stdout>:[2025-10-11 20:26:12 DP1 TP12] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,0]<stdout>:[2025-10-11 20:26:12 DP0 TP4] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,0]<stdout>:[2025-10-11 20:26:12 DP0 TP1] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,0]<stdout>:[2025-10-11 20:26:12 DP0 TP5] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,1]<stdout>:[2025-10-11 20:26:12 DP1 TP14] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,1]<stdout>:[2025-10-11 20:26:12 DP1 TP15] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,0]<stdout>:[2025-10-11 20:26:12 DP0 TP2] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,1]<stdout>:[2025-10-11 20:26:12 DP1 TP9] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,1]<stdout>:[2025-10-11 20:26:12 DP1 TP10] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,0]<stdout>:[2025-10-11 20:26:12 DP0 TP0] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,0]<stdout>:[2025-10-11 20:26:12 DP0 TP0] Memory pool end. avail mem=9.16 GB
[1,1]<stdout>:[2025-10-11 20:26:12 DP1 TP8] KV Cache is allocated. #tokens: 374136, KV size: 24.49 GB
[1,0]<stdout>:[2025-10-11 20:26:14 DP0 TP0] MLA optimization is turned on. Use flashinfer backend.
[1,0]<stdout>:[2025-10-11 20:26:14 DP0 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-11 20:26:14 DP0 TP0] Init torch distributed begin.
[1,0]<stdout>:[2025-10-11 20:26:14 DP0 TP0] Init torch distributed ends. mem usage=0.00 GB
[1,0]<stdout>:[2025-10-11 20:26:14 DP0 TP0] Load weight begin. avail mem=8.70 GB
[1,0]<stdout>:[2025-10-11 20:26:14 DP0 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=5.97 GB, mem usage=2.73 GB.
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP7] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP2] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP1] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP4] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP0] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP3] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP0] Memory pool end. avail mem=5.58 GB
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP5] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,0]<stdout>:[2025-10-11 20:26:15 DP0 TP6] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,1]<stdout>:[2025-10-11 20:26:15 DP1 TP13] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,1]<stdout>:[2025-10-11 20:26:15 DP1 TP10] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,1]<stdout>:[2025-10-11 20:26:15 DP1 TP15] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,1]<stdout>:[2025-10-11 20:26:15 DP1 TP8] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,1]<stdout>:[2025-10-11 20:26:15 DP1 TP11] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,1]<stdout>:[2025-10-11 20:26:15 DP1 TP9] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,1]<stdout>:[2025-10-11 20:26:15 DP1 TP14] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,1]<stdout>:[2025-10-11 20:26:15 DP1 TP12] KV Cache is allocated. #tokens: 374136, KV size: 0.40 GB
[1,0]<stdout>:[2025-10-11 20:26:16 DP0 TP0] max_total_num_tokens=374136, chunked_prefill_size=2048, max_prefill_tokens=16384, max_running_requests=16, context_len=163840, available_gpu_mem=7.32 GB
[1,1]<stdout>:[2025-10-11 20:26:17] Starting dummy health check server at 127.0.0.1:30000
[1,0]<stdout>:#Input tokens: 626729
[1,0]<stdout>:#Output tokens: 388685
[1,0]<stdout>:#Input tokens: 4096
[1,0]<stdout>:#Output tokens: 256
[1,0]<stdout>:[2025-10-11 20:26:30] 
[1,0]<stdout>:Warmup...
[1,1]<stdout>:[2025-10-11 20:26:30 DP1 TP8] Prefill batch. #new-seq: 3, #new-token: 771, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stdout>:[2025-10-11 20:26:30 DP0 TP0] Prefill batch. #new-seq: 4, #new-token: 1028, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,1]<stdout>:[2025-10-11 20:26:31 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:31 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:31 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:31 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:31 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:31 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-11 20:26:31 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:31 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:26:31 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:31 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 5105.76it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 2177.32it/s]
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:32 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:32 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 6437.47it/s][1,1]<stdout>:
[1,1]<stdout>:[2025-10-11 20:26:32 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 6093.96it/s]
[1,1]<stdout>:[2025-10-11 20:26:32 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 6630.20it/s]
[1,1]<stdout>:[2025-10-11 20:26:32 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 7023.85it/s]
[1,1]<stdout>:[2025-10-11 20:26:32 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-11 20:26:32 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 6461.21it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 2191.42it/s]
[1,1]<stdout>:[2025-10-11 20:26:32 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 6823.37it/s]
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:32 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5439.44it/s]
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5239.11it/s]
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5200.14it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5259.42it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5280.68it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5786.94it/s]
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5437.30it/s]
[1,0]<stdout>:[2025-10-11 20:26:32 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:  3% 1/29 [00:02<01:17,  2.77s/it][1,1]<stdout>:  3% 1/29 [00:03<01:34,  3.37s/it][1,1]<stdout>:  3% 1/29 [00:03<01:34,  3.39s/it][1,1]<stdout>:  3% 1/29 [00:03<01:32,  3.32s/it]  3% 1/29 [00:03<01:31,  3.29s/it][1,1]<stdout>:  3% 1/29 [00:03<01:35,  3.41s/it][1,1]<stdout>:  3% 1/29 [00:03<01:30,  3.24s/it][1,1]<stdout>:  7% 2/29 [00:03<00:38,  1.43s/it][1,0]<stdout>:  3% 1/29 [00:02<01:17,  2.77s/it][1,1]<stdout>:  3% 1/29 [00:03<01:24,  3.01s/it][1,1]<stdout>:  7% 2/29 [00:03<00:40,  1.49s/it][1,1]<stdout>:  7% 2/29 [00:03<00:40,  1.50s/it][1,1]<stdout>:  7% 2/29 [00:03<00:38,  1.43s/it][1,1]<stdout>:  7% 2/29 [00:03<00:39,  1.45s/it][1,1]<stdout>:  7% 2/29 [00:03<00:41,  1.54s/it][1,0]<stdout>:  7% 2/29 [00:02<00:34,  1.27s/it][1,1]<stdout>:  7% 2/29 [00:03<00:36,  1.37s/it][1,0]<stdout>:  3% 1/29 [00:03<01:32,  3.30s/it][1,0]<stdout>:  3% 1/29 [00:03<01:30,  3.23s/it][1,0]<stdout>:  3% 1/29 [00:03<01:27,  3.13s/it]  3% 1/29 [00:03<01:31,  3.28s/it][1,0]<stdout>:  3% 1/29 [00:03<01:27,  3.12s/it][1,0]<stdout>:  3% 1/29 [00:03<01:26,  3.08s/it][1,0]<stdout>:  3% 1/29 [00:03<01:27,  3.13s/it][1,0]<stdout>:  7% 2/29 [00:03<00:38,  1.41s/it][1,0]<stdout>:  7% 2/29 [00:03<00:39,  1.47s/it]  7% 2/29 [00:03<00:40,  1.52s/it][1,0]<stdout>:  7% 2/29 [00:03<00:39,  1.45s/it][1,0]<stdout>:  7% 2/29 [00:03<00:38,  1.42s/it][1,0]<stdout>:  7% 2/29 [00:03<00:37,  1.40s/it][1,1]<stdout>: 14% 4/29 [00:03<00:20,  1.23it/s][1,1]<stdout>: 14% 4/29 [00:04<00:22,  1.12it/s][1,1]<stdout>: 14% 4/29 [00:04<00:21,  1.15it/s][1,1]<stdout>: 14% 4/29 [00:04<00:22,  1.12it/s][1,1]<stdout>: 14% 4/29 [00:04<00:22,  1.11it/s][1,1]<stdout>: 14% 4/29 [00:04<00:22,  1.11it/s][1,1]<stdout>: 14% 4/29 [00:04<00:21,  1.14it/s][1,0]<stdout>: 14% 4/29 [00:04<00:19,  1.25it/s][1,1]<stdout>: 14% 4/29 [00:04<00:21,  1.14it/s][1,0]<stdout>: 14% 4/29 [00:04<00:22,  1.12it/s][1,0]<stdout>: 14% 4/29 [00:04<00:23,  1.08it/s][1,0]<stdout>: 14% 4/29 [00:04<00:22,  1.11it/s][1,0]<stdout>: 14% 4/29 [00:04<00:22,  1.12it/s][1,0]<stdout>: 14% 4/29 [00:04<00:22,  1.12it/s][1,0]<stdout>: 14% 4/29 [00:04<00:23,  1.05it/s][1,0]<stdout>: 14% 4/29 [00:04<00:23,  1.06it/s][1,1]<stdout>: 17% 5/29 [00:05<00:24,  1.01s/it][1,1]<stdout>: 17% 5/29 [00:05<00:24,  1.02s/it][1,1]<stdout>: 17% 5/29 [00:05<00:24,  1.01s/it][1,1]<stdout>: 17% 5/29 [00:05<00:24,  1.03s/it][1,1]<stdout>: 17% 5/29 [00:05<00:24,  1.03s/it][1,1]<stdout>: 17% 5/29 [00:06<00:25,  1.05s/it][1,1]<stdout>: 17% 5/29 [00:06<00:26,  1.09s/it][1,1]<stdout>: 17% 5/29 [00:05<00:23,  1.00it/s][1,0]<stdout>: 17% 5/29 [00:05<00:24,  1.00s/it][1,0]<stdout>: 17% 5/29 [00:05<00:22,  1.06it/s][1,0]<stdout>: 17% 5/29 [00:05<00:23,  1.02it/s][1,0]<stdout>: 17% 5/29 [00:05<00:23,  1.02it/s][1,0]<stdout>: 17% 5/29 [00:05<00:24,  1.01s/it][1,0]<stdout>: 17% 5/29 [00:05<00:24,  1.04s/it][1,0]<stdout>: 17% 5/29 [00:05<00:23,  1.04it/s][1,0]<stdout>: 17% 5/29 [00:05<00:24,  1.03s/it][1,1]<stdout>: 21% 6/29 [00:06<00:22,  1.02it/s][1,1]<stdout>: 21% 6/29 [00:07<00:23,  1.03s/it][1,1]<stdout>: 21% 6/29 [00:07<00:24,  1.06s/it][1,1]<stdout>: 21% 6/29 [00:07<00:24,  1.05s/it][1,1]<stdout>: 21% 6/29 [00:07<00:23,  1.04s/it][1,0]<stdout>: 21% 6/29 [00:06<00:22,  1.03it/s][1,1]<stdout>: 21% 6/29 [00:07<00:24,  1.06s/it][1,1]<stdout>: 21% 6/29 [00:06<00:24,  1.06s/it][1,1]<stdout>: 21% 6/29 [00:06<00:23,  1.01s/it][1,0]<stdout>: 21% 6/29 [00:07<00:23,  1.04s/it][1,0]<stdout>: 21% 6/29 [00:07<00:24,  1.06s/it][1,0]<stdout>: 21% 6/29 [00:06<00:24,  1.05s/it][1,0]<stdout>: 21% 6/29 [00:06<00:24,  1.06s/it][1,0]<stdout>: 21% 6/29 [00:06<00:24,  1.04s/it][1,0]<stdout>: 21% 6/29 [00:06<00:24,  1.07s/it][1,0]<stdout>: 21% 6/29 [00:06<00:23,  1.03s/it][1,1]<stdout>: 28% 8/29 [00:08<00:23,  1.11s/it][1,0]<stdout>: 28% 8/29 [00:08<00:23,  1.12s/it][1,1]<stdout>: 28% 8/29 [00:09<00:24,  1.19s/it][1,1]<stdout>: 28% 8/29 [00:09<00:25,  1.21s/it][1,1]<stdout>: 28% 8/29 [00:09<00:25,  1.21s/it][1,1]<stdout>: 28% 8/29 [00:09<00:25,  1.19s/it][1,1]<stdout>: 28% 8/29 [00:09<00:25,  1.20s/it][1,1]<stdout>: 28% 8/29 [00:09<00:25,  1.23s/it][1,1]<stdout>: 28% 8/29 [00:09<00:24,  1.19s/it][1,0]<stdout>: 28% 8/29 [00:09<00:25,  1.21s/it][1,0]<stdout>: 28% 8/29 [00:09<00:25,  1.23s/it][1,0]<stdout>: 28% 8/29 [00:09<00:25,  1.23s/it][1,0]<stdout>: 28% 8/29 [00:09<00:25,  1.23s/it][1,0]<stdout>: 28% 8/29 [00:09<00:25,  1.23s/it][1,0]<stdout>: 28% 8/29 [00:09<00:26,  1.26s/it][1,0]<stdout>: 28% 8/29 [00:09<00:26,  1.26s/it][1,1]<stdout>: 48% 14/29 [00:11<00:08,  1.67it/s][1,1]<stdout>: 48% 14/29 [00:11<00:08,  1.67it/s][1,1]<stdout>: 48% 14/29 [00:11<00:09,  1.65it/s][1,1]<stdout>: 48% 14/29 [00:11<00:09,  1.66it/s][1,1]<stdout>: 48% 14/29 [00:11<00:09,  1.65it/s][1,1]<stdout>: 48% 14/29 [00:11<00:09,  1.65it/s][1,1]<stdout>: 48% 14/29 [00:11<00:09,  1.57it/s][1,1]<stdout>: 52% 15/29 [00:11<00:07,  1.84it/s][1,1]<stdout>: 52% 15/29 [00:11<00:07,  1.83it/s][1,1]<stdout>: 52% 15/29 [00:11<00:07,  1.83it/s][1,1]<stdout>: 48% 14/29 [00:11<00:09,  1.66it/s][1,0]<stdout>: 48% 14/29 [00:11<00:09,  1.63it/s][1,1]<stdout>: 52% 15/29 [00:11<00:07,  1.83it/s][1,1]<stdout>: 52% 15/29 [00:11<00:07,  1.79it/s][1,0]<stdout>: 48% 14/29 [00:11<00:08,  1.72it/s][1,0]<stdout>: 48% 14/29 [00:11<00:08,  1.70it/s][1,0]<stdout>: 48% 14/29 [00:11<00:09,  1.67it/s][1,0]<stdout>: 48% 14/29 [00:11<00:09,  1.59it/s][1,0]<stdout>: 48% 14/29 [00:11<00:09,  1.60it/s] 48% 14/29 [00:12<00:09,  1.54it/s][1,0]<stdout>: 48% 14/29 [00:11<00:09,  1.54it/s][1,1]<stdout>: 55% 16/29 [00:12<00:08,  1.47it/s][1,0]<stdout>: 55% 16/29 [00:12<00:08,  1.60it/s][1,0]<stdout>: 55% 16/29 [00:12<00:08,  1.45it/s][1,1]<stdout>: 86% 25/29 [00:13<00:01,  3.37it/s][1,1]<stdout>: 55% 16/29 [00:13<00:10,  1.26it/s][1,1]<stdout>: 55% 16/29 [00:13<00:10,  1.25it/s][1,0]<stdout>: 55% 16/29 [00:13<00:08,  1.52it/s][1,1]<stdout>: 55% 16/29 [00:13<00:10,  1.25it/s][1,1]<stdout>: 55% 16/29 [00:13<00:10,  1.24it/s][1,1]<stdout>: 55% 16/29 [00:13<00:09,  1.36it/s][1,1]<stdout>: 55% 16/29 [00:13<00:10,  1.23it/s][1,0]<stdout>: 55% 16/29 [00:13<00:08,  1.46it/s][1,1]<stdout>: 55% 16/29 [00:13<00:09,  1.38it/s][1,0]<stdout>: 55% 16/29 [00:13<00:09,  1.43it/s][1,0]<stdout>: 55% 16/29 [00:13<00:08,  1.46it/s][1,0]<stdout>: 55% 16/29 [00:13<00:08,  1.48it/s][1,0]<stdout>: 55% 16/29 [00:13<00:08,  1.51it/s][1,1]<stdout>: 86% 25/29 [00:14<00:01,  3.71it/s][1,1]<stdout>: 86% 25/29 [00:14<00:01,  3.63it/s][1,1]<stdout>: 86% 25/29 [00:14<00:01,  3.64it/s][1,1]<stdout>: 86% 25/29 [00:14<00:01,  3.62it/s][1,1]<stdout>: 86% 25/29 [00:14<00:01,  3.60it/s][1,1]<stdout>: 86% 25/29 [00:14<00:01,  3.26it/s][1,1]<stdout>: 86% 25/29 [00:13<00:01,  3.30it/s][1,0]<stdout>: 86% 25/29 [00:13<00:01,  3.16it/s][1,1]<stdout>: 93% 27/29 [00:14<00:00,  3.09it/s][1,1]<stdout>: 93% 27/29 [00:14<00:00,  3.42it/s][1,0]<stdout>: 93% 27/29 [00:14<00:00,  3.32it/s][1,0]<stdout>: 93% 27/29 [00:14<00:00,  3.44it/s][1,1]<stdout>: 93% 27/29 [00:14<00:00,  3.39it/s][1,1]<stdout>: 93% 27/29 [00:14<00:00,  3.39it/s][1,0]<stdout>: 93% 27/29 [00:14<00:00,  3.39it/s][1,1]<stdout>: 93% 27/29 [00:15<00:00,  3.36it/s][1,1]<stdout>: 93% 27/29 [00:14<00:00,  3.24it/s][1,1]<stdout>: 93% 27/29 [00:15<00:00,  3.28it/s][1,0]<stdout>: 93% 27/29 [00:14<00:00,  3.39it/s][1,0]<stdout>: 97% 28/29 [00:14<00:00,  3.16it/s][1,1]<stdout>: 97% 28/29 [00:15<00:00,  3.23it/s][1,1]<stdout>: 97% 28/29 [00:15<00:00,  3.25it/s][1,1]<stdout>: 97% 28/29 [00:15<00:00,  2.99it/s][1,1]<stdout>: 97% 28/29 [00:15<00:00,  3.24it/s][1,0]<stdout>: 97% 28/29 [00:14<00:00,  3.31it/s][1,0]<stdout>: 93% 27/29 [00:14<00:00,  3.12it/s][1,1]<stdout>: 97% 28/29 [00:15<00:00,  3.09it/s][1,1]<stdout>: 97% 28/29 [00:15<00:00,  3.04it/s][1,0]<stdout>: 93% 27/29 [00:14<00:00,  3.18it/s][1,0]<stdout>: 93% 27/29 [00:15<00:00,  3.07it/s][1,0]<stdout>: 93% 27/29 [00:14<00:00,  3.01it/s][1,0]<stdout>: 97% 28/29 [00:15<00:00,  3.20it/s][1,0]<stdout>: 97% 28/29 [00:15<00:00,  2.95it/s][1,0]<stdout>: 97% 28/29 [00:15<00:00,  2.94it/s][1,0]<stdout>: 97% 28/29 [00:15<00:00,  3.07it/s][1,0]<stdout>: 97% 28/29 [00:15<00:00,  3.04it/s][1,1]<stdout>:100% 29/29 [00:15<00:00,  2.59it/s][1,1]<stdout>:100% 29/29 [00:15<00:00,  1.88it/s]
[1,1]<stdout>:[2025-10-11 20:26:48 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>: 97% 28/29 [00:15<00:00,  3.05it/s][1,0]<stdout>:100% 29/29 [00:15<00:00,  3.17it/s][1,0]<stdout>:100% 29/29 [00:15<00:00,  1.85it/s]
[1,0]<stdout>:[2025-10-11 20:26:48 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 29/29 [00:15<00:00,  2.93it/s][1,0]<stdout>:100% 29/29 [00:15<00:00,  1.88it/s]
[1,0]<stdout>:[2025-10-11 20:26:48 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 29/29 [00:15<00:00,  2.91it/s][1,0]<stdout>:100% 29/29 [00:15<00:00,  1.85it/s]
[1,0]<stdout>:[2025-10-11 20:26:48 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 29/29 [00:15<00:00,  2.90it/s][1,0]<stdout>:100% 29/29 [00:15<00:00,  3.06it/s]100% 29/29 [00:15<00:00,  1.87it/s][1,0]<stdout>:
[1,0]<stdout>:100% 29/29 [00:15<00:00,  3.06it/s]100% 29/29 [00:15<00:00,  1.86it/s][1,0]<stdout>:
[1,0]<stdout>:100% 29/29 [00:15<00:00,  1.88it/s]
[1,0]<stdout>:[2025-10-11 20:26:48 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:26:48 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:26:48 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-11 20:26:48 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 29/29 [00:15<00:00,  3.08it/s]100% 29/29 [00:15<00:00,  1.87it/s]
[1,0]<stdout>:[2025-10-11 20:26:49 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 29/29 [00:15<00:00,  2.43it/s]100% 29/29 [00:15<00:00,  1.86it/s]
[1,0]<stdout>:[2025-10-11 20:26:49 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:16<00:00,  2.26it/s]100% 29/29 [00:16<00:00,  1.76it/s]
[1,1]<stdout>:[2025-10-11 20:26:49 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:16<00:00,  2.15it/s]100% 29/29 [00:16<00:00,  1.72it/s]
[1,1]<stdout>:100% 29/29 [00:16<00:00,  2.16it/s][1,1]<stdout>:100% 29/29 [00:16<00:00,  1.72it/s]
[1,1]<stdout>:[2025-10-11 20:26:49 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:26:49 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 29/29 [00:16<00:00,  2.12it/s][1,1]<stdout>:100% 29/29 [00:16<00:00,  1.74it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:[2025-10-11 20:26:49 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-11 20:26:49 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:16<00:00,  2.32it/s][1,1]<stdout>:100% 29/29 [00:16<00:00,  1.72it/s]
[1,1]<stdout>:[2025-10-11 20:26:49 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 29/29 [00:16<00:00,  1.73it/s]
[1,1]<stdout>:[2025-10-11 20:26:49 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 29/29 [00:16<00:00,  2.13it/s][1,1]<stdout>:100% 29/29 [00:16<00:00,  1.76it/s]
[1,1]<stdout>:[2025-10-11 20:26:49 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:  4% 1/24 [00:02<01:03,  2.76s/it][1,0]<stdout>:  4% 1/24 [00:02<01:05,  2.84s/it][1,0]<stdout>:  4% 1/24 [00:03<01:14,  3.23s/it][1,0]<stdout>:  4% 1/24 [00:03<01:14,  3.23s/it][1,0]<stdout>:  4% 1/24 [00:03<01:14,  3.22s/it][1,0]<stdout>:  4% 1/24 [00:03<01:15,  3.29s/it][1,0]<stdout>:  4% 1/24 [00:03<01:16,  3.31s/it][1,0]<stdout>:  4% 1/24 [00:03<01:16,  3.30s/it][1,0]<stdout>:  8% 2/24 [00:03<00:30,  1.40s/it][1,0]<stdout>:  4% 1/24 [00:03<01:15,  3.29s/it][1,1]<stdout>:  4% 1/24 [00:03<01:13,  3.19s/it][1,1]<stdout>:  4% 1/24 [00:03<01:12,  3.17s/it][1,1]<stdout>:  4% 1/24 [00:03<01:14,  3.22s/it][1,1]<stdout>:  4% 1/24 [00:03<01:13,  3.20s/it][1,1]<stdout>:  4% 1/24 [00:03<01:14,  3.22s/it][1,1]<stdout>:  4% 1/24 [00:03<01:14,  3.22s/it][1,1]<stdout>:  4% 1/24 [00:03<01:13,  3.18s/it][1,1]<stdout>: 21% 5/24 [00:05<00:17,  1.10it/s][1,0]<stdout>: 21% 5/24 [00:05<00:16,  1.13it/s][1,0]<stdout>: 21% 5/24 [00:05<00:18,  1.02it/s][1,0]<stdout>: 21% 5/24 [00:05<00:18,  1.02it/s][1,1]<stdout>: 29% 7/24 [00:06<00:14,  1.20it/s][1,0]<stdout>: 29% 7/24 [00:06<00:14,  1.19it/s][1,0]<stdout>: 29% 7/24 [00:06<00:13,  1.23it/s][1,0]<stdout>: 29% 7/24 [00:06<00:14,  1.15it/s][1,0]<stdout>: 29% 7/24 [00:06<00:14,  1.15it/s][1,0]<stdout>: 29% 7/24 [00:06<00:14,  1.15it/s][1,0]<stdout>: 29% 7/24 [00:06<00:14,  1.16it/s][1,1]<stdout>: 29% 7/24 [00:06<00:13,  1.26it/s][1,1]<stdout>: 29% 7/24 [00:06<00:14,  1.20it/s][1,1]<stdout>: 29% 7/24 [00:06<00:13,  1.24it/s][1,1]<stdout>: 38% 9/24 [00:06<00:08,  1.74it/s][1,1]<stdout>: 29% 7/24 [00:06<00:14,  1.18it/s][1,0]<stdout>: 29% 7/24 [00:07<00:16,  1.04it/s][1,1]<stdout>: 29% 7/24 [00:06<00:14,  1.18it/s][1,0]<stdout>: 29% 7/24 [00:07<00:16,  1.03it/s][1,1]<stdout>: 29% 7/24 [00:06<00:14,  1.18it/s][1,1]<stdout>: 29% 7/24 [00:06<00:14,  1.17it/s][1,1]<stdout>: 42% 10/24 [00:07<00:09,  1.49it/s][1,1]<stdout>: 58% 14/24 [00:08<00:03,  2.58it/s][1,0]<stdout>: 42% 10/24 [00:07<00:09,  1.49it/s][1,0]<stdout>: 46% 11/24 [00:08<00:08,  1.51it/s][1,0]<stdout>: 46% 11/24 [00:08<00:08,  1.58it/s][1,0]<stdout>: 46% 11/24 [00:08<00:08,  1.52it/s][1,0]<stdout>: 58% 14/24 [00:08<00:04,  2.42it/s][1,0]<stdout>: 46% 11/24 [00:08<00:08,  1.51it/s][1,0]<stdout>: 46% 11/24 [00:08<00:08,  1.52it/s][1,0]<stdout>: 42% 10/24 [00:08<00:10,  1.40it/s][1,0]<stdout>: 42% 10/24 [00:08<00:10,  1.39it/s][1,1]<stdout>: 46% 11/24 [00:08<00:08,  1.55it/s][1,1]<stdout>: 46% 11/24 [00:08<00:08,  1.49it/s][1,1]<stdout>: 46% 11/24 [00:08<00:08,  1.55it/s][1,0]<stdout>: 58% 14/24 [00:09<00:04,  2.28it/s][1,1]<stdout>: 46% 11/24 [00:08<00:08,  1.51it/s][1,1]<stdout>: 46% 11/24 [00:08<00:08,  1.52it/s][1,1]<stdout>: 46% 11/24 [00:08<00:08,  1.53it/s][1,0]<stdout>: 58% 14/24 [00:09<00:04,  2.22it/s][1,0]<stdout>: 58% 14/24 [00:09<00:04,  2.01it/s][1,0]<stdout>: 58% 14/24 [00:09<00:05,  1.90it/s][1,0]<stdout>: 58% 14/24 [00:09<00:05,  1.91it/s][1,1]<stdout>: 46% 11/24 [00:08<00:08,  1.55it/s][1,0]<stdout>: 58% 14/24 [00:09<00:05,  1.89it/s][1,0]<stdout>: 58% 14/24 [00:09<00:05,  1.89it/s][1,1]<stdout>: 58% 14/24 [00:08<00:05,  1.97it/s][1,1]<stdout>: 58% 14/24 [00:08<00:05,  1.95it/s][1,1]<stdout>: 58% 14/24 [00:08<00:05,  1.96it/s][1,1]<stdout>: 58% 14/24 [00:08<00:05,  1.96it/s][1,1]<stdout>: 58% 14/24 [00:09<00:05,  1.91it/s][1,1]<stdout>: 58% 14/24 [00:09<00:05,  1.92it/s][1,1]<stdout>: 58% 14/24 [00:09<00:05,  1.94it/s][1,1]<stdout>: 62% 15/24 [00:10<00:05,  1.55it/s][1,0]<stdout>: 62% 15/24 [00:10<00:05,  1.57it/s] 62% 15/24 [00:10<00:05,  1.55it/s][1,0]<stdout>: 62% 15/24 [00:10<00:05,  1.60it/s][1,0]<stdout>: 62% 15/24 [00:10<00:05,  1.55it/s][1,0]<stdout>: 62% 15/24 [00:10<00:05,  1.52it/s][1,0]<stdout>: 62% 15/24 [00:10<00:05,  1.54it/s][1,1]<stdout>: 62% 15/24 [00:10<00:05,  1.60it/s][1,1]<stdout>: 62% 15/24 [00:10<00:05,  1.60it/s][1,1]<stdout>: 62% 15/24 [00:10<00:05,  1.55it/s][1,1]<stdout>: 62% 15/24 [00:10<00:06,  1.50it/s][1,1]<stdout>: 62% 15/24 [00:10<00:05,  1.56it/s][1,1]<stdout>: 62% 15/24 [00:10<00:05,  1.57it/s][1,0]<stdout>: 83% 20/24 [00:11<00:01,  2.52it/s][1,0]<stdout>: 83% 20/24 [00:11<00:01,  2.54it/s][1,0]<stdout>: 62% 15/24 [00:11<00:06,  1.39it/s][1,1]<stdout>: 62% 15/24 [00:10<00:05,  1.53it/s][1,1]<stdout>: 83% 20/24 [00:11<00:01,  2.15it/s][1,0]<stdout>: 83% 20/24 [00:11<00:01,  2.45it/s][1,0]<stdout>: 62% 15/24 [00:11<00:06,  1.36it/s][1,0]<stdout>: 83% 20/24 [00:11<00:01,  2.37it/s][1,0]<stdout>: 83% 20/24 [00:11<00:01,  2.44it/s][1,1]<stdout>: 83% 20/24 [00:11<00:01,  2.47it/s][1,1]<stdout>: 83% 20/24 [00:11<00:01,  2.68it/s][1,1]<stdout>: 83% 20/24 [00:11<00:01,  2.57it/s][1,0]<stdout>: 92% 22/24 [00:11<00:00,  2.82it/s][1,0]<stdout>: 92% 22/24 [00:11<00:00,  2.71it/s][1,0]<stdout>: 92% 22/24 [00:11<00:00,  2.79it/s][1,0]<stdout>: 92% 22/24 [00:11<00:00,  2.78it/s][1,1]<stdout>: 83% 20/24 [00:11<00:01,  2.45it/s][1,0]<stdout>: 92% 22/24 [00:11<00:00,  2.77it/s][1,0]<stdout>: 83% 20/24 [00:11<00:01,  2.15it/s][1,1]<stdout>: 83% 20/24 [00:11<00:01,  2.49it/s][1,1]<stdout>: 92% 22/24 [00:11<00:00,  2.83it/s][1,1]<stdout>: 92% 22/24 [00:11<00:00,  2.98it/s][1,1]<stdout>: 92% 22/24 [00:11<00:00,  3.03it/s][1,1]<stdout>: 83% 20/24 [00:11<00:01,  2.42it/s][1,1]<stdout>: 92% 22/24 [00:11<00:00,  2.84it/s][1,1]<stdout>: 83% 20/24 [00:11<00:01,  2.45it/s][1,1]<stdout>: 92% 22/24 [00:11<00:00,  2.79it/s][1,1]<stdout>: 92% 22/24 [00:11<00:00,  2.82it/s][1,1]<stdout>: 92% 22/24 [00:11<00:00,  2.88it/s][1,0]<stdout>: 83% 20/24 [00:12<00:01,  2.04it/s][1,1]<stdout>: 96% 23/24 [00:13<00:00,  2.19it/s][1,1]<stdout>:100% 24/24 [00:13<00:00,  1.83it/s]
[1,0]<stdout>: 83% 20/24 [00:12<00:01,  2.02it/s][1,1]<stdout>:[2025-10-11 20:27:02 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>: 96% 23/24 [00:13<00:00,  2.23it/s][1,0]<stdout>:100% 24/24 [00:13<00:00,  1.82it/s]
[1,0]<stdout>:[2025-10-11 20:27:02 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>: 96% 23/24 [00:13<00:00,  1.91it/s][1,0]<stdout>: 96% 23/24 [00:13<00:00,  1.84it/s][1,0]<stdout>: 96% 23/24 [00:13<00:00,  1.84it/s][1,1]<stdout>: 96% 23/24 [00:13<00:00,  1.88it/s][1,0]<stdout>: 96% 23/24 [00:13<00:00,  1.80it/s][1,0]<stdout>: 96% 23/24 [00:13<00:00,  1.81it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>: 96% 23/24 [00:13<00:00,  1.88it/s][1,0]<stdout>:100% 24/24 [00:13<00:00,  1.92it/s][1,0]<stdout>:100% 24/24 [00:13<00:00,  1.72it/s]
[1,0]<stdout>:[2025-10-11 20:27:03 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 24/24 [00:14<00:00,  1.89it/s][1,0]<stdout>:100% 24/24 [00:14<00:00,  1.71it/s]
[1,0]<stdout>:100% 24/24 [00:14<00:00,  1.93it/s][1,0]<stdout>:100% 24/24 [00:14<00:00,  1.71it/s]
[1,0]<stdout>:[2025-10-11 20:27:03 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 24/24 [00:14<00:00,  1.81it/s]100% 24/24 [00:14<00:00,  1.71it/s]
[1,0]<stdout>:[2025-10-11 20:27:03 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-11 20:27:03 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 24/24 [00:13<00:00,  1.94it/s][1,0]<stdout>:100% 24/24 [00:13<00:00,  1.72it/s]
[1,0]<stdout>:[2025-10-11 20:27:03 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>: 96% 23/24 [00:13<00:00,  1.78it/s][1,0]<stdout>:[2025-10-11 20:27:03 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>: 96% 23/24 [00:13<00:00,  1.77it/s][1,1]<stdout>:100% 24/24 [00:13<00:00,  1.79it/s]
[1,1]<stdout>:[2025-10-11 20:27:03 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-11 20:27:03 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>: 96% 23/24 [00:14<00:00,  2.09it/s][1,0]<stdout>: 96% 23/24 [00:14<00:00,  2.09it/s][1,1]<stdout>: 96% 23/24 [00:13<00:00,  1.83it/s] 96% 23/24 [00:13<00:00,  1.85it/s][1,1]<stdout>:100% 24/24 [00:13<00:00,  1.90it/s][1,1]<stdout>:100% 24/24 [00:13<00:00,  1.75it/s]
[1,1]<stdout>:[2025-10-11 20:27:03 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 24/24 [00:14<00:00,  1.67it/s]
[1,0]<stdout>:[2025-10-11 20:27:03 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 24/24 [00:14<00:00,  2.25it/s][1,0]<stdout>:100% 24/24 [00:14<00:00,  1.66it/s]
[1,1]<stdout>: 96% 23/24 [00:13<00:00,  1.81it/s][1,0]<stdout>:[2025-10-11 20:27:03 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 24/24 [00:13<00:00,  1.90it/s]100% 24/24 [00:13<00:00,  1.75it/s]
[1,1]<stdout>:[2025-10-11 20:27:03 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 24/24 [00:13<00:00,  1.94it/s][1,1]<stdout>:100% 24/24 [00:13<00:00,  1.74it/s]
[1,1]<stdout>:100% 24/24 [00:13<00:00,  1.96it/s][1,1]<stdout>:100% 24/24 [00:13<00:00,  1.74it/s][1,1]<stdout>:
[1,1]<stdout>:100% 24/24 [00:13<00:00,  1.84it/s][1,1]<stdout>:100% 24/24 [00:13<00:00,  1.74it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:[2025-10-11 20:27:04 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:04 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:04 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 24/24 [00:13<00:00,  2.01it/s][1,1]<stdout>:100% 24/24 [00:13<00:00,  1.76it/s]
[1,1]<stdout>:[2025-10-11 20:27:04 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  6% 1/16 [00:02<00:38,  2.57s/it][1,0]<stdout>:  6% 1/16 [00:02<00:40,  2.70s/it][1,0]<stdout>:  6% 1/16 [00:02<00:44,  2.95s/it][1,1]<stdout>:  6% 1/16 [00:02<00:41,  2.80s/it][1,0]<stdout>:  6% 1/16 [00:02<00:42,  2.82s/it][1,0]<stdout>:  6% 1/16 [00:02<00:44,  2.99s/it][1,1]<stdout>: 12% 2/16 [00:02<00:17,  1.22s/it][1,0]<stdout>:  6% 1/16 [00:02<00:44,  2.98s/it][1,0]<stdout>:  6% 1/16 [00:03<00:45,  3.00s/it][1,1]<stdout>:  6% 1/16 [00:02<00:43,  2.89s/it][1,0]<stdout>:  6% 1/16 [00:02<00:44,  2.97s/it][1,1]<stdout>:  6% 1/16 [00:02<00:43,  2.93s/it][1,0]<stdout>:  6% 1/16 [00:02<00:44,  2.99s/it][1,1]<stdout>:  6% 1/16 [00:02<00:44,  2.94s/it][1,1]<stdout>:  6% 1/16 [00:02<00:44,  2.96s/it][1,1]<stdout>:  6% 1/16 [00:02<00:44,  2.94s/it][1,1]<stdout>:  6% 1/16 [00:02<00:44,  2.98s/it][1,1]<stdout>: 31% 5/16 [00:05<00:10,  1.08it/s][1,0]<stdout>: 31% 5/16 [00:05<00:10,  1.03it/s][1,1]<stdout>: 38% 6/16 [00:06<00:09,  1.04it/s][1,1]<stdout>: 31% 5/16 [00:05<00:10,  1.08it/s][1,0]<stdout>: 31% 5/16 [00:05<00:11,  1.01s/it][1,0]<stdout>: 31% 5/16 [00:05<00:11,  1.05s/it][1,0]<stdout>: 31% 5/16 [00:05<00:11,  1.05s/it][1,1]<stdout>: 31% 5/16 [00:05<00:11,  1.01s/it][1,0]<stdout>: 38% 6/16 [00:06<00:10,  1.04s/it][1,0]<stdout>: 31% 5/16 [00:05<00:11,  1.06s/it][1,0]<stdout>: 31% 5/16 [00:05<00:11,  1.07s/it][1,1]<stdout>: 31% 5/16 [00:05<00:10,  1.03it/s][1,1]<stdout>: 31% 5/16 [00:05<00:10,  1.03it/s][1,1]<stdout>: 31% 5/16 [00:05<00:11,  1.03s/it][1,0]<stdout>: 31% 5/16 [00:05<00:11,  1.06s/it][1,0]<stdout>: 31% 5/16 [00:05<00:11,  1.05s/it][1,1]<stdout>: 31% 5/16 [00:05<00:11,  1.05s/it] 31% 5/16 [00:05<00:11,  1.05s/it][1,1]<stdout>: 75% 12/16 [00:07<00:01,  2.01it/s][1,1]<stdout>:100% 16/16 [00:07<00:00,  2.03it/s]
[1,0]<stdout>: 38% 6/16 [00:06<00:10,  1.06s/it][1,1]<stdout>: 38% 6/16 [00:06<00:10,  1.06s/it][1,0]<stdout>: 38% 6/16 [00:07<00:11,  1.11s/it][1,0]<stdout>: 38% 6/16 [00:07<00:10,  1.09s/it][1,0]<stdout>: 38% 6/16 [00:07<00:10,  1.09s/it][1,1]<stdout>: 38% 6/16 [00:06<00:10,  1.08s/it][1,0]<stdout>: 38% 6/16 [00:07<00:10,  1.09s/it][1,0]<stdout>: 38% 6/16 [00:07<00:10,  1.08s/it][1,1]<stdout>: 38% 6/16 [00:06<00:10,  1.08s/it][1,0]<stdout>: 75% 12/16 [00:08<00:02,  1.93it/s][1,0]<stdout>: 38% 6/16 [00:07<00:10,  1.09s/it][1,0]<stdout>:100% 16/16 [00:08<00:00,  1.94it/s]
[1,1]<stdout>: 38% 6/16 [00:06<00:10,  1.08s/it][1,1]<stdout>: 38% 6/16 [00:07<00:10,  1.08s/it][1,1]<stdout>: 38% 6/16 [00:07<00:11,  1.11s/it][1,1]<stdout>: 38% 6/16 [00:07<00:11,  1.11s/it][1,1]<stdout>: 75% 12/16 [00:07<00:01,  2.16it/s][1,0]<stdout>: 75% 12/16 [00:08<00:02,  1.92it/s][1,0]<stdout>: 88% 14/16 [00:08<00:00,  2.44it/s][1,0]<stdout>:100% 16/16 [00:08<00:00,  1.90it/s]
[1,1]<stdout>: 75% 12/16 [00:07<00:01,  2.11it/s][1,1]<stdout>: 75% 12/16 [00:07<00:01,  2.10it/s][1,1]<stdout>: 75% 12/16 [00:08<00:02,  1.86it/s][1,1]<stdout>: 88% 14/16 [00:08<00:00,  2.28it/s][1,1]<stdout>:100% 16/16 [00:08<00:00,  1.85it/s]
[1,0]<stdout>: 75% 12/16 [00:08<00:02,  1.79it/s][1,0]<stdout>: 75% 12/16 [00:08<00:02,  1.81it/s][1,1]<stdout>:NCCL version 2.27.3+cuda12.9
[1,0]<stdout>:100% 16/16 [00:08<00:00,  1.81it/s]
[1,1]<stdout>: 88% 14/16 [00:08<00:00,  2.35it/s]100% 16/16 [00:08<00:00,  1.85it/s]
[1,0]<stdout>: 75% 12/16 [00:08<00:02,  1.80it/s][1,0]<stdout>: 88% 14/16 [00:08<00:00,  2.30it/s][1,0]<stdout>:100% 16/16 [00:08<00:00,  1.80it/s]
[1,0]<stdout>: 75% 12/16 [00:08<00:02,  1.78it/s][1,0]<stdout>:100% 16/16 [00:08<00:00,  1.79it/s]
[1,0]<stdout>:100% 16/16 [00:08<00:00,  1.80it/s]
[1,1]<stdout>: 75% 12/16 [00:08<00:02,  1.86it/s][1,1]<stdout>: 88% 14/16 [00:08<00:00,  2.36it/s]100% 16/16 [00:08<00:00,  1.84it/s]
[1,0]<stdout>: 75% 12/16 [00:08<00:02,  1.82it/s][1,0]<stdout>: 75% 12/16 [00:08<00:02,  1.76it/s][1,0]<stdout>:100% 16/16 [00:08<00:00,  1.80it/s]
[1,0]<stdout>:100% 16/16 [00:08<00:00,  1.82it/s]
[1,1]<stdout>: 75% 12/16 [00:08<00:02,  1.84it/s] 75% 12/16 [00:08<00:02,  1.83it/s][1,1]<stdout>:100% 16/16 [00:08<00:00,  1.83it/s]
[1,1]<stdout>:100% 16/16 [00:08<00:00,  1.84it/s]
[1,1]<stdout>: 88% 14/16 [00:08<00:00,  2.20it/s] 88% 14/16 [00:08<00:00,  2.21it/s]100% 16/16 [00:08<00:00,  1.83it/s]
[1,1]<stdout>:100% 16/16 [00:08<00:00,  1.83it/s]
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 4328.63it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 32/32 [00:00<00:00, 14657.39it/s]
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 14876.72it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 16996.04it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 13944.70it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 12959.13it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 13927.34it/s][1,0]<stdout>:
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 12708.81it/s]
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-11 20:27:16 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 4537.91it/s]
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 16274.73it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 17034.87it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 16322.23it/s]
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 32/32 [00:00<00:00, 16720.78it/s]
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 15727.41it/s]
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 32/32 [00:00<00:00, 16258.96it/s]
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-11 20:27:16 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 18569.14it/s]
[1,1]<stdout>:[2025-10-11 20:27:17 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 5104.89it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15910.11it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 4459.65it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 13637.24it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 13740.55it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 17159.00it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 14010.20it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 13949.05it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 12865.96it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 15029.98it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 18714.13it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 16533.35it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 16336.14it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 15523.68it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 14254.22it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 16533.35it/s]
[1,1]<stdout>:[2025-10-11 20:27:17 DP1 TP13] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-11 20:27:17 DP1 TP15] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-11 20:27:17 DP1 TP10] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-11 20:27:17 DP1 TP8] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-11 20:27:17 DP1 TP9] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-11 20:27:17 DP1 TP12] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-11 20:27:17 DP1 TP14] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-11 20:27:17 DP0 TP7] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-11 20:27:17 DP0 TP0] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-11 20:27:17 DP0 TP4] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-11 20:27:17 DP0 TP3] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-11 20:27:17 DP0 TP5] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-11 20:27:17 DP0 TP6] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-11 20:27:17 DP0 TP1] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-11 20:27:17 DP0 TP2] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-11 20:27:17 DP1 TP11] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-11 20:27:18 DP0 TP0] Prefill batch. #new-seq: 4, #new-token: 1020, #cached-token: 8, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[1,1]<stdout>:[2025-10-11 20:27:18 DP1 TP8] Prefill batch. #new-seq: 5, #new-token: 1274, #cached-token: 11, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[1,0]<stdout>:[2025-10-11 20:27:26] 
[1,0]<stdout>:Benchmark...
[1,0]<stdout>:[2025-10-11 20:27:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,1]<stdout>:[2025-10-11 20:27:26 DP1 TP8] Prefill batch. #new-seq: 13, #new-token: 2048, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 133, 
[1,0]<stdout>:[2025-10-11 20:27:26 DP0 TP0] Prefill batch. #new-seq: 14, #new-token: 2048, #cached-token: 19, token usage: 0.00, #running-req: 1, #queue-req: 137, 
[1,1]<stdout>:[2025-10-11 20:27:26 DP1 TP8] Prefill batch. #new-seq: 3, #new-token: 2048, #cached-token: 2, token usage: 0.01, #running-req: 12, #queue-req: 372, 
[1,0]<stdout>:[2025-10-11 20:27:26 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 2048, #cached-token: 1, token usage: 0.01, #running-req: 14, #queue-req: 372, 
[1,1]<stdout>:[2025-10-11 20:27:26 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 426, #cached-token: 1, token usage: 0.01, #running-req: 14, #queue-req: 480, 
[1,0]<stdout>:[2025-10-11 20:27:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 0, token usage: 0.01, #running-req: 15, #queue-req: 480, 
[1,1]<stdout>:[2025-10-11 20:27:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 685, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 983, 
[1,0]<stdout>:[2025-10-11 20:27:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 983, 
[1,1]<stdout>:[2025-10-11 20:27:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 982, 
[1,0]<stdout>:[2025-10-11 20:27:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 982, 
[1,1]<stdout>:[2025-10-11 20:27:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 981, 
[1,0]<stdout>:[2025-10-11 20:27:32 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 804, #cached-token: 4, token usage: 0.01, #running-req: 14, #queue-req: 980, 
[1,1]<stdout>:[2025-10-11 20:27:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 477, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 980, 
[1,0]<stdout>:[2025-10-11 20:27:34 DP0 TP0] Decode batch. #running-req: 16, #token: 4701, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 6.64, #queue-req: 980, 
[1,1]<stdout>:[2025-10-11 20:27:34 DP1 TP8] Decode batch. #running-req: 16, #token: 4247, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 6.64, #queue-req: 980, 
[1,0]<stdout>:[2025-10-11 20:27:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 979, 
[1,0]<stdout>:[2025-10-11 20:27:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 302, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 978, 
[1,0]<stdout>:[2025-10-11 20:27:40 DP0 TP0] Decode batch. #running-req: 16, #token: 5231, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.03, #queue-req: 978, 
[1,1]<stdout>:[2025-10-11 20:27:40 DP1 TP8] Decode batch. #running-req: 16, #token: 4887, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.36, #queue-req: 980, 
[1,1]<stdout>:[2025-10-11 20:27:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 725, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 979, 
[1,1]<stdout>:[2025-10-11 20:27:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 978, 
[1,0]<stdout>:[2025-10-11 20:27:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 977, 
[1,0]<stdout>:[2025-10-11 20:27:46 DP0 TP0] Decode batch. #running-req: 16, #token: 6036, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.19, #queue-req: 977, 
[1,1]<stdout>:[2025-10-11 20:27:46 DP1 TP8] Decode batch. #running-req: 16, #token: 6059, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.03, #queue-req: 978, 
[1,1]<stdout>:[2025-10-11 20:27:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 977, 
[1,0]<stdout>:[2025-10-11 20:27:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 976, 
[1,1]<stdout>:[2025-10-11 20:27:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 976, 
[1,1]<stdout>:[2025-10-11 20:27:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 975, 
[1,1]<stdout>:[2025-10-11 20:27:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 974, 
[1,1]<stdout>:[2025-10-11 20:27:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 973, 
[1,1]<stdout>:[2025-10-11 20:27:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 972, 
[1,0]<stdout>:[2025-10-11 20:27:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1904, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 975, 
[1,0]<stdout>:[2025-10-11 20:27:54 DP0 TP0] Decode batch. #running-req: 16, #token: 8889, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 88.68, #queue-req: 975, 
[1,1]<stdout>:[2025-10-11 20:27:54 DP1 TP8] Decode batch. #running-req: 16, #token: 6150, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 88.13, #queue-req: 972, 
[1,1]<stdout>:[2025-10-11 20:27:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 971, 
[1,1]<stdout>:[2025-10-11 20:27:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 970, 
[1,0]<stdout>:[2025-10-11 20:27:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 974, 
[1,0]<stdout>:[2025-10-11 20:27:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 973, 
[1,0]<stdout>:[2025-10-11 20:28:00 DP0 TP0] Decode batch. #running-req: 16, #token: 8831, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.27, #queue-req: 973, 
[1,1]<stdout>:[2025-10-11 20:28:00 DP1 TP8] Decode batch. #running-req: 16, #token: 6459, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.27, #queue-req: 970, 
[1,0]<stdout>:[2025-10-11 20:28:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 972, 
[1,0]<stdout>:[2025-10-11 20:28:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 971, 
[1,0]<stdout>:[2025-10-11 20:28:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 970, 
[1,0]<stdout>:[2025-10-11 20:28:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 969, 
[1,0]<stdout>:[2025-10-11 20:28:06 DP0 TP0] Decode batch. #running-req: 16, #token: 6230, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 100.09, #queue-req: 969, 
[1,1]<stdout>:[2025-10-11 20:28:06 DP1 TP8] Decode batch. #running-req: 16, #token: 7099, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 100.71, #queue-req: 970, 
[1,0]<stdout>:[2025-10-11 20:28:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 968, 
[1,0]<stdout>:[2025-10-11 20:28:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 967, 
[1,1]<stdout>:[2025-10-11 20:28:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 969, 
[1,0]<stdout>:[2025-10-11 20:28:13 DP0 TP0] Decode batch. #running-req: 16, #token: 4843, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.60, #queue-req: 967, 
[1,1]<stdout>:[2025-10-11 20:28:13 DP1 TP8] Decode batch. #running-req: 16, #token: 7481, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.76, #queue-req: 969, 
[1,1]<stdout>:[2025-10-11 20:28:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 968, 
[1,0]<stdout>:[2025-10-11 20:28:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 966, 
[1,1]<stdout>:[2025-10-11 20:28:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 967, 
[1,1]<stdout>:[2025-10-11 20:28:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 966, 
[1,0]<stdout>:[2025-10-11 20:28:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 965, 
[1,0]<stdout>:[2025-10-11 20:28:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 964, 
[1,0]<stdout>:[2025-10-11 20:28:19 DP0 TP0] Decode batch. #running-req: 16, #token: 5008, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.78, #queue-req: 964, 
[1,1]<stdout>:[2025-10-11 20:28:19 DP1 TP8] Decode batch. #running-req: 16, #token: 6951, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.78, #queue-req: 966, 
[1,1]<stdout>:[2025-10-11 20:28:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 965, 
[1,1]<stdout>:[2025-10-11 20:28:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 964, 
[1,1]<stdout>:[2025-10-11 20:28:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 963, 
[1,0]<stdout>:[2025-10-11 20:28:26 DP0 TP0] Decode batch. #running-req: 16, #token: 5648, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 100.90, #queue-req: 964, 
[1,1]<stdout>:[2025-10-11 20:28:26 DP1 TP8] Decode batch. #running-req: 16, #token: 5684, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 100.43, #queue-req: 963, 
[1,1]<stdout>:[2025-10-11 20:28:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 962, 
[1,0]<stdout>:[2025-10-11 20:28:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 774, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 963, 
[1,0]<stdout>:[2025-10-11 20:28:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 962, 
[1,1]<stdout>:[2025-10-11 20:28:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 961, 
[1,0]<stdout>:[2025-10-11 20:28:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 961, 
[1,0]<stdout>:[2025-10-11 20:28:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 960, 
[1,1]<stdout>:[2025-10-11 20:28:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 411, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 960, 
[1,1]<stdout>:[2025-10-11 20:28:33 DP1 TP8] Decode batch. #running-req: 16, #token: 6410, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.89, #queue-req: 960, 
[1,0]<stdout>:[2025-10-11 20:28:33 DP0 TP0] Decode batch. #running-req: 16, #token: 6616, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.71, #queue-req: 960, 
[1,0]<stdout>:[2025-10-11 20:28:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 959, 
[1,0]<stdout>:[2025-10-11 20:28:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1381, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 958, 
[1,1]<stdout>:[2025-10-11 20:28:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 959, 
[1,1]<stdout>:[2025-10-11 20:28:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1818, #cached-token: 0, token usage: 0.02, #running-req: 15, #queue-req: 959, 
[1,0]<stdout>:[2025-10-11 20:28:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 957, 
[1,1]<stdout>:[2025-10-11 20:28:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 958, 
[1,1]<stdout>:[2025-10-11 20:28:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 957, 
[1,1]<stdout>:[2025-10-11 20:28:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 956, 
[1,0]<stdout>:[2025-10-11 20:28:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 460, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 956, 
[1,1]<stdout>:[2025-10-11 20:28:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 955, 
[1,1]<stdout>:[2025-10-11 20:28:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 954, 
[1,0]<stdout>:[2025-10-11 20:28:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 955, 
[1,0]<stdout>:[2025-10-11 20:28:40 DP0 TP0] Decode batch. #running-req: 16, #token: 6401, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 82.86, #queue-req: 955, 
[1,1]<stdout>:[2025-10-11 20:28:40 DP1 TP8] Decode batch. #running-req: 16, #token: 5087, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 82.71, #queue-req: 954, 
[1,0]<stdout>:[2025-10-11 20:28:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 773, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 954, 
[1,0]<stdout>:[2025-10-11 20:28:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 953, 
[1,0]<stdout>:[2025-10-11 20:28:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 952, 
[1,0]<stdout>:[2025-10-11 20:28:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 951, 
[1,0]<stdout>:[2025-10-11 20:28:47 DP0 TP0] Decode batch. #running-req: 16, #token: 6084, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.09, #queue-req: 951, 
[1,1]<stdout>:[2025-10-11 20:28:47 DP1 TP8] Decode batch. #running-req: 15, #token: 5233, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.57, #queue-req: 954, 
[1,1]<stdout>:[2025-10-11 20:28:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 953, 
[1,1]<stdout>:[2025-10-11 20:28:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 952, 
[1,1]<stdout>:[2025-10-11 20:28:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 951, 
[1,1]<stdout>:[2025-10-11 20:28:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 950, 
[1,1]<stdout>:[2025-10-11 20:28:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 949, 
[1,1]<stdout>:[2025-10-11 20:28:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 575, #cached-token: 5, token usage: 0.01, #running-req: 15, #queue-req: 948, 
[1,1]<stdout>:[2025-10-11 20:28:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 947, 
[1,0]<stdout>:[2025-10-11 20:28:54 DP0 TP0] Decode batch. #running-req: 16, #token: 6724, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.84, #queue-req: 951, 
[1,1]<stdout>:[2025-10-11 20:28:54 DP1 TP8] Decode batch. #running-req: 16, #token: 5452, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.96, #queue-req: 947, 
[1,1]<stdout>:[2025-10-11 20:28:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 946, 
[1,0]<stdout>:[2025-10-11 20:28:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 950, 
[1,0]<stdout>:[2025-10-11 20:28:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 949, 
[1,1]<stdout>:[2025-10-11 20:28:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 945, 
[1,1]<stdout>:[2025-10-11 20:28:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 944, 
[1,1]<stdout>:[2025-10-11 20:28:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 0, token usage: 0.02, #running-req: 15, #queue-req: 944, 
[1,1]<stdout>:[2025-10-11 20:29:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 943, 
[1,1]<stdout>:[2025-10-11 20:29:00 DP1 TP8] Decode batch. #running-req: 16, #token: 4553, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.54, #queue-req: 943, 
[1,0]<stdout>:[2025-10-11 20:29:00 DP0 TP0] Decode batch. #running-req: 15, #token: 5935, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.68, #queue-req: 949, 
[1,0]<stdout>:[2025-10-11 20:29:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 948, 
[1,0]<stdout>:[2025-10-11 20:29:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 947, 
[1,0]<stdout>:[2025-10-11 20:29:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 946, 
[1,0]<stdout>:[2025-10-11 20:29:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 945, 
[1,0]<stdout>:[2025-10-11 20:29:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 944, 
[1,0]<stdout>:[2025-10-11 20:29:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 943, 
[1,0]<stdout>:[2025-10-11 20:29:07 DP0 TP0] Decode batch. #running-req: 15, #token: 5108, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.32, #queue-req: 943, 
[1,1]<stdout>:[2025-10-11 20:29:07 DP1 TP8] Decode batch. #running-req: 16, #token: 5193, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 97.23, #queue-req: 943, 
[1,0]<stdout>:[2025-10-11 20:29:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 11, token usage: 0.01, #running-req: 15, #queue-req: 942, 
[1,0]<stdout>:[2025-10-11 20:29:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 941, 
[1,0]<stdout>:[2025-10-11 20:29:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 940, 
[1,0]<stdout>:[2025-10-11 20:29:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 5, token usage: 0.01, #running-req: 15, #queue-req: 939, 
[1,1]<stdout>:[2025-10-11 20:29:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 942, 
[1,0]<stdout>:[2025-10-11 20:29:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 938, 
[1,1]<stdout>:[2025-10-11 20:29:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 941, 
[1,1]<stdout>:[2025-10-11 20:29:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 940, 
[1,0]<stdout>:[2025-10-11 20:29:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 937, 
[1,0]<stdout>:[2025-10-11 20:29:14 DP0 TP0] Decode batch. #running-req: 16, #token: 4803, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.84, #queue-req: 937, 
[1,1]<stdout>:[2025-10-11 20:29:14 DP1 TP8] Decode batch. #running-req: 16, #token: 4590, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 91.12, #queue-req: 940, 
[1,0]<stdout>:[2025-10-11 20:29:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 936, 
[1,0]<stdout>:[2025-10-11 20:29:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 935, 
[1,0]<stdout>:[2025-10-11 20:29:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 934, 
[1,1]<stdout>:[2025-10-11 20:29:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 939, 
[1,0]<stdout>:[2025-10-11 20:29:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 933, 
[1,1]<stdout>:[2025-10-11 20:29:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 938, 
[1,0]<stdout>:[2025-10-11 20:29:21 DP0 TP0] Decode batch. #running-req: 16, #token: 4769, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.77, #queue-req: 933, 
[1,1]<stdout>:[2025-10-11 20:29:21 DP1 TP8] Decode batch. #running-req: 16, #token: 6117, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.07, #queue-req: 938, 
[1,1]<stdout>:[2025-10-11 20:29:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 429, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 937, 
[1,0]<stdout>:[2025-10-11 20:29:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 932, 
[1,1]<stdout>:[2025-10-11 20:29:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 936, 
[1,0]<stdout>:[2025-10-11 20:29:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 806, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 931, 
[1,1]<stdout>:[2025-10-11 20:29:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 935, 
[1,1]<stdout>:[2025-10-11 20:29:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 934, 
[1,0]<stdout>:[2025-10-11 20:29:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 930, 
[1,0]<stdout>:[2025-10-11 20:29:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 929, 
[1,0]<stdout>:[2025-10-11 20:29:28 DP0 TP0] Decode batch. #running-req: 16, #token: 5134, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.63, #queue-req: 929, 
[1,1]<stdout>:[2025-10-11 20:29:28 DP1 TP8] Decode batch. #running-req: 16, #token: 5407, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.61, #queue-req: 934, 
[1,1]<stdout>:[2025-10-11 20:29:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 933, 
[1,0]<stdout>:[2025-10-11 20:29:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 617, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 928, 
[1,0]<stdout>:[2025-10-11 20:29:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 927, 
[1,1]<stdout>:[2025-10-11 20:29:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1978, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 932, 
[1,0]<stdout>:[2025-10-11 20:29:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 926, 
[1,0]<stdout>:[2025-10-11 20:29:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1389, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 925, 
[1,0]<stdout>:[2025-10-11 20:29:34 DP0 TP0] Decode batch. #running-req: 16, #token: 6719, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.60, #queue-req: 925, 
[1,1]<stdout>:[2025-10-11 20:29:34 DP1 TP8] Decode batch. #running-req: 16, #token: 8006, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.92, #queue-req: 932, 
[1,0]<stdout>:[2025-10-11 20:29:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 924, 
[1,0]<stdout>:[2025-10-11 20:29:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 699, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 923, 
[1,0]<stdout>:[2025-10-11 20:29:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.01, #running-req: 15, #queue-req: 922, 
[1,0]<stdout>:[2025-10-11 20:29:41 DP0 TP0] Decode batch. #running-req: 16, #token: 5120, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.98, #queue-req: 922, 
[1,1]<stdout>:[2025-10-11 20:29:41 DP1 TP8] Decode batch. #running-req: 16, #token: 8452, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 103.45, #queue-req: 932, 
[1,1]<stdout>:[2025-10-11 20:29:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 931, 
[1,1]<stdout>:[2025-10-11 20:29:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 930, 
[1,0]<stdout>:[2025-10-11 20:29:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 921, 
[1,0]<stdout>:[2025-10-11 20:29:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 920, 
[1,0]<stdout>:[2025-10-11 20:29:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 919, 
[1,1]<stdout>:[2025-10-11 20:29:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 929, 
[1,0]<stdout>:[2025-10-11 20:29:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 918, 
[1,0]<stdout>:[2025-10-11 20:29:47 DP0 TP0] Decode batch. #running-req: 16, #token: 4139, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.57, #queue-req: 918, 
[1,1]<stdout>:[2025-10-11 20:29:47 DP1 TP8] Decode batch. #running-req: 16, #token: 7103, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.72, #queue-req: 929, 
[1,0]<stdout>:[2025-10-11 20:29:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 917, 
[1,1]<stdout>:[2025-10-11 20:29:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 928, 
[1,0]<stdout>:[2025-10-11 20:29:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 916, 
[1,0]<stdout>:[2025-10-11 20:29:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 915, 
[1,1]<stdout>:[2025-10-11 20:29:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 927, 
[1,0]<stdout>:[2025-10-11 20:29:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 914, 
[1,1]<stdout>:[2025-10-11 20:29:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 926, 
[1,1]<stdout>:[2025-10-11 20:29:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 703, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 925, 
[1,0]<stdout>:[2025-10-11 20:29:54 DP0 TP0] Decode batch. #running-req: 15, #token: 4223, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.40, #queue-req: 914, 
[1,1]<stdout>:[2025-10-11 20:29:54 DP1 TP8] Decode batch. #running-req: 16, #token: 6892, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.55, #queue-req: 925, 
[1,0]<stdout>:[2025-10-11 20:29:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 913, 
[1,0]<stdout>:[2025-10-11 20:29:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 385, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 912, 
[1,1]<stdout>:[2025-10-11 20:29:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 924, 
[1,0]<stdout>:[2025-10-11 20:29:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1066, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 911, 
[1,0]<stdout>:[2025-10-11 20:30:01 DP0 TP0] Decode batch. #running-req: 16, #token: 6190, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.54, #queue-req: 911, 
[1,1]<stdout>:[2025-10-11 20:30:01 DP1 TP8] Decode batch. #running-req: 16, #token: 7150, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.68, #queue-req: 924, 
[1,0]<stdout>:[2025-10-11 20:30:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 910, 
[1,1]<stdout>:[2025-10-11 20:30:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 923, 
[1,1]<stdout>:[2025-10-11 20:30:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 922, 
[1,1]<stdout>:[2025-10-11 20:30:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 810, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 921, 
[1,1]<stdout>:[2025-10-11 20:30:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 920, 
[1,0]<stdout>:[2025-10-11 20:30:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 909, 
[1,0]<stdout>:[2025-10-11 20:30:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 908, 
[1,1]<stdout>:[2025-10-11 20:30:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 919, 
[1,0]<stdout>:[2025-10-11 20:30:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 907, 
[1,1]<stdout>:[2025-10-11 20:30:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 918, 
[1,1]<stdout>:[2025-10-11 20:30:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 917, 
[1,1]<stdout>:[2025-10-11 20:30:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 916, 
[1,0]<stdout>:[2025-10-11 20:30:08 DP0 TP0] Decode batch. #running-req: 16, #token: 6760, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 84.97, #queue-req: 907, 
[1,1]<stdout>:[2025-10-11 20:30:08 DP1 TP8] Decode batch. #running-req: 16, #token: 6769, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 84.43, #queue-req: 916, 
[1,1]<stdout>:[2025-10-11 20:30:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 494, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 915, 
[1,0]<stdout>:[2025-10-11 20:30:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 906, 
[1,0]<stdout>:[2025-10-11 20:30:11 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 596, #cached-token: 3, token usage: 0.02, #running-req: 14, #queue-req: 904, 
[1,1]<stdout>:[2025-10-11 20:30:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 914, 
[1,1]<stdout>:[2025-10-11 20:30:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 913, 
[1,0]<stdout>:[2025-10-11 20:30:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 903, 
[1,0]<stdout>:[2025-10-11 20:30:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 902, 
[1,0]<stdout>:[2025-10-11 20:30:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 901, 
[1,0]<stdout>:[2025-10-11 20:30:15 DP0 TP0] Decode batch. #running-req: 16, #token: 6523, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.30, #queue-req: 901, 
[1,1]<stdout>:[2025-10-11 20:30:15 DP1 TP8] Decode batch. #running-req: 16, #token: 7232, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.72, #queue-req: 913, 
[1,0]<stdout>:[2025-10-11 20:30:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 900, 
[1,0]<stdout>:[2025-10-11 20:30:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 899, 
[1,0]<stdout>:[2025-10-11 20:30:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 5, token usage: 0.01, #running-req: 15, #queue-req: 898, 
[1,1]<stdout>:[2025-10-11 20:30:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 912, 
[1,0]<stdout>:[2025-10-11 20:30:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 897, 
[1,0]<stdout>:[2025-10-11 20:30:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.01, #running-req: 15, #queue-req: 896, 
[1,1]<stdout>:[2025-10-11 20:30:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 911, 
[1,0]<stdout>:[2025-10-11 20:30:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 895, 
[1,1]<stdout>:[2025-10-11 20:30:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 910, 
[1,1]<stdout>:[2025-10-11 20:30:22 DP1 TP8] Decode batch. #running-req: 16, #token: 7135, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.48, #queue-req: 910, 
[1,0]<stdout>:[2025-10-11 20:30:22 DP0 TP0] Decode batch. #running-req: 16, #token: 5785, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.04, #queue-req: 895, 
[1,0]<stdout>:[2025-10-11 20:30:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 894, 
[1,1]<stdout>:[2025-10-11 20:30:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 909, 
[1,0]<stdout>:[2025-10-11 20:30:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 893, 
[1,1]<stdout>:[2025-10-11 20:30:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 765, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 908, 
[1,1]<stdout>:[2025-10-11 20:30:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1228, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 907, 
[1,0]<stdout>:[2025-10-11 20:30:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 892, 
[1,1]<stdout>:[2025-10-11 20:30:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 906, 
[1,0]<stdout>:[2025-10-11 20:30:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 891, 
[1,1]<stdout>:[2025-10-11 20:30:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 905, 
[1,1]<stdout>:[2025-10-11 20:30:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 904, 
[1,0]<stdout>:[2025-10-11 20:30:29 DP0 TP0] Decode batch. #running-req: 16, #token: 6255, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 88.42, #queue-req: 891, 
[1,1]<stdout>:[2025-10-11 20:30:29 DP1 TP8] Decode batch. #running-req: 16, #token: 5636, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 88.14, #queue-req: 904, 
[1,0]<stdout>:[2025-10-11 20:30:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 890, 
[1,1]<stdout>:[2025-10-11 20:30:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 903, 
[1,0]<stdout>:[2025-10-11 20:30:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 7, token usage: 0.01, #running-req: 15, #queue-req: 889, 
[1,0]<stdout>:[2025-10-11 20:30:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 888, 
[1,0]<stdout>:[2025-10-11 20:30:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 8, token usage: 0.01, #running-req: 15, #queue-req: 887, 
[1,1]<stdout>:[2025-10-11 20:30:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 902, 
[1,0]<stdout>:[2025-10-11 20:30:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 886, 
[1,0]<stdout>:[2025-10-11 20:30:36 DP0 TP0] Decode batch. #running-req: 16, #token: 5454, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.20, #queue-req: 886, 
[1,1]<stdout>:[2025-10-11 20:30:36 DP1 TP8] Decode batch. #running-req: 16, #token: 4293, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.64, #queue-req: 902, 
[1,0]<stdout>:[2025-10-11 20:30:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 529, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 885, 
[1,1]<stdout>:[2025-10-11 20:30:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 901, 
[1,0]<stdout>:[2025-10-11 20:30:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 884, 
[1,0]<stdout>:[2025-10-11 20:30:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 883, 
[1,1]<stdout>:[2025-10-11 20:30:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 900, 
[1,0]<stdout>:[2025-10-11 20:30:43 DP0 TP0] Decode batch. #running-req: 16, #token: 6167, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 100.75, #queue-req: 883, 
[1,1]<stdout>:[2025-10-11 20:30:43 DP1 TP8] Decode batch. #running-req: 16, #token: 4613, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 100.91, #queue-req: 900, 
[1,1]<stdout>:[2025-10-11 20:30:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 899, 
[1,1]<stdout>:[2025-10-11 20:30:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 898, 
[1,0]<stdout>:[2025-10-11 20:30:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 882, 
[1,0]<stdout>:[2025-10-11 20:30:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 881, 
[1,1]<stdout>:[2025-10-11 20:30:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 897, 
[1,0]<stdout>:[2025-10-11 20:30:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 880, 
[1,0]<stdout>:[2025-10-11 20:30:49 DP0 TP0] Decode batch. #running-req: 16, #token: 5986, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.14, #queue-req: 880, 
[1,1]<stdout>:[2025-10-11 20:30:49 DP1 TP8] Decode batch. #running-req: 16, #token: 4348, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.13, #queue-req: 897, 
[1,1]<stdout>:[2025-10-11 20:30:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 896, 
[1,0]<stdout>:[2025-10-11 20:30:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 879, 
[1,0]<stdout>:[2025-10-11 20:30:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 878, 
[1,1]<stdout>:[2025-10-11 20:30:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 895, 
[1,1]<stdout>:[2025-10-11 20:30:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 894, 
[1,0]<stdout>:[2025-10-11 20:30:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 877, 
[1,0]<stdout>:[2025-10-11 20:30:56 DP0 TP0] Decode batch. #running-req: 15, #token: 6338, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 94.81, #queue-req: 877, 
[1,1]<stdout>:[2025-10-11 20:30:56 DP1 TP8] Decode batch. #running-req: 16, #token: 3768, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 94.96, #queue-req: 894, 
[1,0]<stdout>:[2025-10-11 20:30:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 876, 
[1,1]<stdout>:[2025-10-11 20:30:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 893, 
[1,0]<stdout>:[2025-10-11 20:30:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 430, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 875, 
[1,0]<stdout>:[2025-10-11 20:30:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 874, 
[1,1]<stdout>:[2025-10-11 20:30:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 892, 
[1,0]<stdout>:[2025-10-11 20:31:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 873, 
[1,1]<stdout>:[2025-10-11 20:31:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 891, 
[1,0]<stdout>:[2025-10-11 20:31:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 872, 
[1,1]<stdout>:[2025-10-11 20:31:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 890, 
[1,0]<stdout>:[2025-10-11 20:31:03 DP0 TP0] Decode batch. #running-req: 16, #token: 6235, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.72, #queue-req: 872, 
[1,1]<stdout>:[2025-10-11 20:31:03 DP1 TP8] Decode batch. #running-req: 16, #token: 4316, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.72, #queue-req: 890, 
[1,0]<stdout>:[2025-10-11 20:31:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 871, 
[1,1]<stdout>:[2025-10-11 20:31:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 889, 
[1,0]<stdout>:[2025-10-11 20:31:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 870, 
[1,0]<stdout>:[2025-10-11 20:31:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 869, 
[1,0]<stdout>:[2025-10-11 20:31:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 868, 
[1,0]<stdout>:[2025-10-11 20:31:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 867, 
[1,1]<stdout>:[2025-10-11 20:31:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 888, 
[1,0]<stdout>:[2025-10-11 20:31:10 DP0 TP0] Decode batch. #running-req: 16, #token: 6701, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.40, #queue-req: 867, 
[1,1]<stdout>:[2025-10-11 20:31:10 DP1 TP8] Decode batch. #running-req: 16, #token: 4385, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.83, #queue-req: 888, 
[1,1]<stdout>:[2025-10-11 20:31:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 887, 
[1,0]<stdout>:[2025-10-11 20:31:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 866, 
[1,0]<stdout>:[2025-10-11 20:31:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 868, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 865, 
[1,1]<stdout>:[2025-10-11 20:31:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 886, 
[1,1]<stdout>:[2025-10-11 20:31:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 885, 
[1,0]<stdout>:[2025-10-11 20:31:16 DP0 TP0] Decode batch. #running-req: 16, #token: 7237, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.26, #queue-req: 865, 
[1,1]<stdout>:[2025-10-11 20:31:16 DP1 TP8] Decode batch. #running-req: 16, #token: 4111, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.11, #queue-req: 885, 
[1,1]<stdout>:[2025-10-11 20:31:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 884, 
[1,1]<stdout>:[2025-10-11 20:31:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 883, 
[1,0]<stdout>:[2025-10-11 20:31:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 864, 
[1,1]<stdout>:[2025-10-11 20:31:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 882, 
[1,1]<stdout>:[2025-10-11 20:31:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 881, 
[1,1]<stdout>:[2025-10-11 20:31:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 880, 
[1,0]<stdout>:[2025-10-11 20:31:23 DP0 TP0] Decode batch. #running-req: 15, #token: 6713, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.20, #queue-req: 864, 
[1,1]<stdout>:[2025-10-11 20:31:23 DP1 TP8] Decode batch. #running-req: 16, #token: 3566, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.74, #queue-req: 880, 
[1,0]<stdout>:[2025-10-11 20:31:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 863, 
[1,1]<stdout>:[2025-10-11 20:31:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 879, 
[1,1]<stdout>:[2025-10-11 20:31:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 878, 
[1,1]<stdout>:[2025-10-11 20:31:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 877, 
[1,0]<stdout>:[2025-10-11 20:31:29 DP0 TP0] Decode batch. #running-req: 16, #token: 7453, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.79, #queue-req: 863, 
[1,1]<stdout>:[2025-10-11 20:31:29 DP1 TP8] Decode batch. #running-req: 16, #token: 4059, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.31, #queue-req: 877, 
[1,1]<stdout>:[2025-10-11 20:31:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 876, 
[1,0]<stdout>:[2025-10-11 20:31:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 862, 
[1,1]<stdout>:[2025-10-11 20:31:35 DP1 TP8] Decode batch. #running-req: 16, #token: 4493, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 104.87, #queue-req: 876, 
[1,0]<stdout>:[2025-10-11 20:31:35 DP0 TP0] Decode batch. #running-req: 16, #token: 6988, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 104.85, #queue-req: 862, 
[1,0]<stdout>:[2025-10-11 20:31:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 493, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 861, 
[1,1]<stdout>:[2025-10-11 20:31:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 875, 
[1,0]<stdout>:[2025-10-11 20:31:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 860, 
[1,1]<stdout>:[2025-10-11 20:31:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 734, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 874, 
[1,0]<stdout>:[2025-10-11 20:31:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 859, 
[1,1]<stdout>:[2025-10-11 20:31:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 873, 
[1,0]<stdout>:[2025-10-11 20:31:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 858, 
[1,1]<stdout>:[2025-10-11 20:31:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 872, 
[1,1]<stdout>:[2025-10-11 20:31:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 871, 
[1,0]<stdout>:[2025-10-11 20:31:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 857, 
[1,1]<stdout>:[2025-10-11 20:31:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 923, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 870, 
[1,0]<stdout>:[2025-10-11 20:31:43 DP0 TP0] Decode batch. #running-req: 16, #token: 6587, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 85.10, #queue-req: 857, 
[1,1]<stdout>:[2025-10-11 20:31:43 DP1 TP8] Decode batch. #running-req: 16, #token: 5127, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 84.97, #queue-req: 870, 
[1,1]<stdout>:[2025-10-11 20:31:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 869, 
[1,1]<stdout>:[2025-10-11 20:31:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 868, 
[1,1]<stdout>:[2025-10-11 20:31:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 867, 
[1,1]<stdout>:[2025-10-11 20:31:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 866, 
[1,0]<stdout>:[2025-10-11 20:31:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 856, 
[1,1]<stdout>:[2025-10-11 20:31:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 673, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 865, 
[1,1]<stdout>:[2025-10-11 20:31:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 864, 
[1,0]<stdout>:[2025-10-11 20:31:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 855, 
[1,0]<stdout>:[2025-10-11 20:31:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 854, 
[1,0]<stdout>:[2025-10-11 20:31:50 DP0 TP0] Decode batch. #running-req: 14, #token: 6826, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.71, #queue-req: 854, 
[1,1]<stdout>:[2025-10-11 20:31:50 DP1 TP8] Decode batch. #running-req: 16, #token: 5465, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.56, #queue-req: 864, 
[1,0]<stdout>:[2025-10-11 20:31:50 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 663, #cached-token: 7, token usage: 0.02, #running-req: 14, #queue-req: 852, 
[1,1]<stdout>:[2025-10-11 20:31:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 660, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 863, 
[1,1]<stdout>:[2025-10-11 20:31:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 862, 
[1,1]<stdout>:[2025-10-11 20:31:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 861, 
[1,0]<stdout>:[2025-10-11 20:31:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 851, 
[1,0]<stdout>:[2025-10-11 20:31:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 850, 
[1,1]<stdout>:[2025-10-11 20:31:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 860, 
[1,0]<stdout>:[2025-10-11 20:31:55 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 560, #cached-token: 7, token usage: 0.02, #running-req: 14, #queue-req: 848, 
[1,1]<stdout>:[2025-10-11 20:31:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 859, 
[1,0]<stdout>:[2025-10-11 20:31:57 DP0 TP0] Decode batch. #running-req: 16, #token: 7068, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.75, #queue-req: 848, 
[1,1]<stdout>:[2025-10-11 20:31:57 DP1 TP8] Decode batch. #running-req: 15, #token: 4524, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.47, #queue-req: 859, 
[1,1]<stdout>:[2025-10-11 20:31:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 858, 
[1,1]<stdout>:[2025-10-11 20:32:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 669, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 857, 
[1,1]<stdout>:[2025-10-11 20:32:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 856, 
[1,1]<stdout>:[2025-10-11 20:32:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 855, 
[1,0]<stdout>:[2025-10-11 20:32:03 DP0 TP0] Decode batch. #running-req: 16, #token: 7023, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.96, #queue-req: 848, 
[1,1]<stdout>:[2025-10-11 20:32:03 DP1 TP8] Decode batch. #running-req: 16, #token: 5227, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.50, #queue-req: 855, 
[1,0]<stdout>:[2025-10-11 20:32:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 847, 
[1,1]<stdout>:[2025-10-11 20:32:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 854, 
[1,1]<stdout>:[2025-10-11 20:32:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 853, 
[1,1]<stdout>:[2025-10-11 20:32:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 6, token usage: 0.01, #running-req: 15, #queue-req: 852, 
[1,1]<stdout>:[2025-10-11 20:32:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 851, 
[1,0]<stdout>:[2025-10-11 20:32:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 452, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 846, 
[1,0]<stdout>:[2025-10-11 20:32:10 DP0 TP0] Decode batch. #running-req: 16, #token: 8663, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.84, #queue-req: 846, 
[1,1]<stdout>:[2025-10-11 20:32:10 DP1 TP8] Decode batch. #running-req: 16, #token: 5729, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.53, #queue-req: 851, 
[1,0]<stdout>:[2025-10-11 20:32:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 845, 
[1,1]<stdout>:[2025-10-11 20:32:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 850, 
[1,0]<stdout>:[2025-10-11 20:32:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 844, 
[1,1]<stdout>:[2025-10-11 20:32:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 849, 
[1,0]<stdout>:[2025-10-11 20:32:16 DP0 TP0] Decode batch. #running-req: 16, #token: 8556, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.73, #queue-req: 844, 
[1,1]<stdout>:[2025-10-11 20:32:16 DP1 TP8] Decode batch. #running-req: 16, #token: 5785, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.73, #queue-req: 849, 
[1,0]<stdout>:[2025-10-11 20:32:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 843, 
[1,0]<stdout>:[2025-10-11 20:32:17 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 116, #cached-token: 3, token usage: 0.02, #running-req: 14, #queue-req: 841, 
[1,0]<stdout>:[2025-10-11 20:32:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 840, 
[1,0]<stdout>:[2025-10-11 20:32:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 839, 
[1,0]<stdout>:[2025-10-11 20:32:22 DP0 TP0] Decode batch. #running-req: 16, #token: 8565, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 100.48, #queue-req: 839, 
[1,1]<stdout>:[2025-10-11 20:32:22 DP1 TP8] Decode batch. #running-req: 16, #token: 6425, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 101.27, #queue-req: 849, 
[1,0]<stdout>:[2025-10-11 20:32:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 903, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 838, 
[1,1]<stdout>:[2025-10-11 20:32:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 224, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 848, 
[1,1]<stdout>:[2025-10-11 20:32:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 847, 
[1,0]<stdout>:[2025-10-11 20:32:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 837, 
[1,1]<stdout>:[2025-10-11 20:32:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 846, 
[1,1]<stdout>:[2025-10-11 20:32:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 845, 
[1,0]<stdout>:[2025-10-11 20:32:29 DP0 TP0] Decode batch. #running-req: 15, #token: 9153, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 97.27, #queue-req: 837, 
[1,1]<stdout>:[2025-10-11 20:32:29 DP1 TP8] Decode batch. #running-req: 16, #token: 6218, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 97.12, #queue-req: 845, 
[1,0]<stdout>:[2025-10-11 20:32:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 836, 
[1,1]<stdout>:[2025-10-11 20:32:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 844, 
[1,1]<stdout>:[2025-10-11 20:32:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 843, 
[1,1]<stdout>:[2025-10-11 20:32:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 842, 
[1,0]<stdout>:[2025-10-11 20:32:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 835, 
[1,1]<stdout>:[2025-10-11 20:32:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 841, 
[1,1]<stdout>:[2025-10-11 20:32:32 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 481, #cached-token: 9, token usage: 0.02, #running-req: 14, #queue-req: 839, 
[1,0]<stdout>:[2025-10-11 20:32:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 834, 
[1,1]<stdout>:[2025-10-11 20:32:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 838, 
[1,1]<stdout>:[2025-10-11 20:32:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 837, 
[1,1]<stdout>:[2025-10-11 20:32:36 DP1 TP8] Decode batch. #running-req: 16, #token: 5487, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 86.63, #queue-req: 837, 
[1,0]<stdout>:[2025-10-11 20:32:36 DP0 TP0] Decode batch. #running-req: 16, #token: 6942, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 87.44, #queue-req: 834, 
[1,0]<stdout>:[2025-10-11 20:32:36 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 428, #cached-token: 5, token usage: 0.02, #running-req: 14, #queue-req: 832, 
[1,1]<stdout>:[2025-10-11 20:32:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 836, 
[1,1]<stdout>:[2025-10-11 20:32:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 835, 
[1,0]<stdout>:[2025-10-11 20:32:43 DP0 TP0] Decode batch. #running-req: 16, #token: 8011, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.04, #queue-req: 832, 
[1,1]<stdout>:[2025-10-11 20:32:43 DP1 TP8] Decode batch. #running-req: 16, #token: 5456, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.03, #queue-req: 835, 
[1,1]<stdout>:[2025-10-11 20:32:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 834, 
[1,0]<stdout>:[2025-10-11 20:32:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 831, 
[1,0]<stdout>:[2025-10-11 20:32:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 830, 
[1,1]<stdout>:[2025-10-11 20:32:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 833, 
[1,0]<stdout>:[2025-10-11 20:32:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 829, 
[1,1]<stdout>:[2025-10-11 20:32:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 832, 
[1,1]<stdout>:[2025-10-11 20:32:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 831, 
[1,1]<stdout>:[2025-10-11 20:32:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 670, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 830, 
[1,0]<stdout>:[2025-10-11 20:32:49 DP0 TP0] Decode batch. #running-req: 16, #token: 8206, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.50, #queue-req: 829, 
[1,1]<stdout>:[2025-10-11 20:32:49 DP1 TP8] Decode batch. #running-req: 16, #token: 5096, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.20, #queue-req: 830, 
[1,0]<stdout>:[2025-10-11 20:32:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 463, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 828, 
[1,1]<stdout>:[2025-10-11 20:32:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 829, 
[1,0]<stdout>:[2025-10-11 20:32:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 827, 
[1,1]<stdout>:[2025-10-11 20:32:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 828, 
[1,0]<stdout>:[2025-10-11 20:32:56 DP0 TP0] Decode batch. #running-req: 16, #token: 8995, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 100.38, #queue-req: 827, 
[1,1]<stdout>:[2025-10-11 20:32:56 DP1 TP8] Decode batch. #running-req: 16, #token: 5077, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 100.37, #queue-req: 828, 
[1,1]<stdout>:[2025-10-11 20:32:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 827, 
[1,0]<stdout>:[2025-10-11 20:32:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 822, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 826, 
[1,1]<stdout>:[2025-10-11 20:33:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 826, 
[1,0]<stdout>:[2025-10-11 20:33:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 825, 
[1,0]<stdout>:[2025-10-11 20:33:02 DP0 TP0] Decode batch. #running-req: 16, #token: 8796, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 101.00, #queue-req: 825, 
[1,1]<stdout>:[2025-10-11 20:33:02 DP1 TP8] Decode batch. #running-req: 16, #token: 5186, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 101.01, #queue-req: 826, 
[1,0]<stdout>:[2025-10-11 20:33:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 824, 
[1,0]<stdout>:[2025-10-11 20:33:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1132, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 823, 
[1,0]<stdout>:[2025-10-11 20:33:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 735, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 822, 
[1,0]<stdout>:[2025-10-11 20:33:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 821, 
[1,0]<stdout>:[2025-10-11 20:33:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 820, 
[1,0]<stdout>:[2025-10-11 20:33:09 DP0 TP0] Decode batch. #running-req: 16, #token: 9917, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.13, #queue-req: 820, 
[1,1]<stdout>:[2025-10-11 20:33:09 DP1 TP8] Decode batch. #running-req: 16, #token: 5826, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.90, #queue-req: 826, 
[1,0]<stdout>:[2025-10-11 20:33:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 819, 
[1,0]<stdout>:[2025-10-11 20:33:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 818, 
[1,0]<stdout>:[2025-10-11 20:33:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1231, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 817, 
[1,0]<stdout>:[2025-10-11 20:33:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 816, 
[1,0]<stdout>:[2025-10-11 20:33:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 7, token usage: 0.02, #running-req: 15, #queue-req: 815, 
[1,0]<stdout>:[2025-10-11 20:33:15 DP0 TP0] Decode batch. #running-req: 16, #token: 9333, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.56, #queue-req: 815, 
[1,1]<stdout>:[2025-10-11 20:33:15 DP1 TP8] Decode batch. #running-req: 16, #token: 6466, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.33, #queue-req: 826, 
[1,1]<stdout>:[2025-10-11 20:33:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 825, 
[1,1]<stdout>:[2025-10-11 20:33:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 824, 
[1,1]<stdout>:[2025-10-11 20:33:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 823, 
[1,1]<stdout>:[2025-10-11 20:33:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 822, 
[1,1]<stdout>:[2025-10-11 20:33:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 821, 
[1,0]<stdout>:[2025-10-11 20:33:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 814, 
[1,0]<stdout>:[2025-10-11 20:33:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 813, 
[1,0]<stdout>:[2025-10-11 20:33:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 812, 
[1,0]<stdout>:[2025-10-11 20:33:22 DP0 TP0] Decode batch. #running-req: 16, #token: 7740, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.18, #queue-req: 812, 
[1,1]<stdout>:[2025-10-11 20:33:22 DP1 TP8] Decode batch. #running-req: 16, #token: 6177, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 91.88, #queue-req: 821, 
[1,0]<stdout>:[2025-10-11 20:33:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 811, 
[1,0]<stdout>:[2025-10-11 20:33:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 992, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 810, 
[1,0]<stdout>:[2025-10-11 20:33:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 809, 
[1,0]<stdout>:[2025-10-11 20:33:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1940, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 808, 
[1,1]<stdout>:[2025-10-11 20:33:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 820, 
[1,1]<stdout>:[2025-10-11 20:33:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 0, token usage: 0.02, #running-req: 15, #queue-req: 820, 
[1,1]<stdout>:[2025-10-11 20:33:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 819, 
[1,0]<stdout>:[2025-10-11 20:33:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 770, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 807, 
[1,0]<stdout>:[2025-10-11 20:33:29 DP0 TP0] Decode batch. #running-req: 16, #token: 11031, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.47, #queue-req: 807, 
[1,1]<stdout>:[2025-10-11 20:33:29 DP1 TP8] Decode batch. #running-req: 16, #token: 8742, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.90, #queue-req: 819, 
[1,0]<stdout>:[2025-10-11 20:33:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 806, 
[1,1]<stdout>:[2025-10-11 20:33:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 818, 
[1,1]<stdout>:[2025-10-11 20:33:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 817, 
[1,0]<stdout>:[2025-10-11 20:33:33 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 26, #cached-token: 5, token usage: 0.03, #running-req: 14, #queue-req: 804, 
[1,0]<stdout>:[2025-10-11 20:33:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 803, 
[1,0]<stdout>:[2025-10-11 20:33:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 802, 
[1,0]<stdout>:[2025-10-11 20:33:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 801, 
[1,0]<stdout>:[2025-10-11 20:33:36 DP0 TP0] Decode batch. #running-req: 16, #token: 7864, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.46, #queue-req: 801, 
[1,1]<stdout>:[2025-10-11 20:33:36 DP1 TP8] Decode batch. #running-req: 16, #token: 9027, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 94.04, #queue-req: 817, 
[1,0]<stdout>:[2025-10-11 20:33:39 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 815, #cached-token: 3, token usage: 0.02, #running-req: 14, #queue-req: 799, 
[1,0]<stdout>:[2025-10-11 20:33:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 798, 
[1,0]<stdout>:[2025-10-11 20:33:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 797, 
[1,0]<stdout>:[2025-10-11 20:33:42 DP0 TP0] Decode batch. #running-req: 15, #token: 8416, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.44, #queue-req: 797, 
[1,1]<stdout>:[2025-10-11 20:33:42 DP1 TP8] Decode batch. #running-req: 16, #token: 9667, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 103.25, #queue-req: 817, 
[1,0]<stdout>:[2025-10-11 20:33:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 796, 
[1,0]<stdout>:[2025-10-11 20:33:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 759, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 795, 
[1,0]<stdout>:[2025-10-11 20:33:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 794, 
[1,1]<stdout>:[2025-10-11 20:33:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 816, 
[1,0]<stdout>:[2025-10-11 20:33:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 793, 
[1,0]<stdout>:[2025-10-11 20:33:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 792, 
[1,0]<stdout>:[2025-10-11 20:33:48 DP0 TP0] Decode batch. #running-req: 16, #token: 9129, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.86, #queue-req: 792, 
[1,1]<stdout>:[2025-10-11 20:33:48 DP1 TP8] Decode batch. #running-req: 16, #token: 10516, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.32, #queue-req: 816, 
[1,0]<stdout>:[2025-10-11 20:33:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 791, 
[1,0]<stdout>:[2025-10-11 20:33:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 790, 
[1,1]<stdout>:[2025-10-11 20:33:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 815, 
[1,0]<stdout>:[2025-10-11 20:33:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 789, 
[1,1]<stdout>:[2025-10-11 20:33:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 724, #cached-token: 9, token usage: 0.03, #running-req: 15, #queue-req: 814, 
[1,0]<stdout>:[2025-10-11 20:33:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 788, 
[1,1]<stdout>:[2025-10-11 20:33:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 905, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 813, 
[1,0]<stdout>:[2025-10-11 20:33:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 787, 
[1,0]<stdout>:[2025-10-11 20:33:55 DP0 TP0] Decode batch. #running-req: 16, #token: 8564, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.40, #queue-req: 787, 
[1,1]<stdout>:[2025-10-11 20:33:55 DP1 TP8] Decode batch. #running-req: 16, #token: 10188, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.69, #queue-req: 813, 
[1,1]<stdout>:[2025-10-11 20:33:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 812, 
[1,1]<stdout>:[2025-10-11 20:34:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 811, 
[1,0]<stdout>:[2025-10-11 20:34:01 DP0 TP0] Decode batch. #running-req: 16, #token: 9204, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 104.87, #queue-req: 787, 
[1,1]<stdout>:[2025-10-11 20:34:01 DP1 TP8] Decode batch. #running-req: 16, #token: 9965, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 104.53, #queue-req: 811, 
[1,0]<stdout>:[2025-10-11 20:34:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 786, 
[1,0]<stdout>:[2025-10-11 20:34:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 785, 
[1,1]<stdout>:[2025-10-11 20:34:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 810, 
[1,0]<stdout>:[2025-10-11 20:34:07 DP0 TP0] Decode batch. #running-req: 16, #token: 9280, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 103.67, #queue-req: 785, 
[1,1]<stdout>:[2025-10-11 20:34:07 DP1 TP8] Decode batch. #running-req: 16, #token: 9453, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 103.84, #queue-req: 810, 
[1,0]<stdout>:[2025-10-11 20:34:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 784, 
[1,0]<stdout>:[2025-10-11 20:34:13 DP0 TP0] Decode batch. #running-req: 16, #token: 9638, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 107.65, #queue-req: 784, 
[1,1]<stdout>:[2025-10-11 20:34:13 DP1 TP8] Decode batch. #running-req: 16, #token: 10093, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 107.82, #queue-req: 810, 
[1,1]<stdout>:[2025-10-11 20:34:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 809, 
[1,1]<stdout>:[2025-10-11 20:34:16 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 1546, #cached-token: 3, token usage: 0.02, #running-req: 14, #queue-req: 807, 
[1,1]<stdout>:[2025-10-11 20:34:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 755, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 806, 
[1,1]<stdout>:[2025-10-11 20:34:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 805, 
[1,1]<stdout>:[2025-10-11 20:34:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 804, 
[1,0]<stdout>:[2025-10-11 20:34:20 DP0 TP0] Decode batch. #running-req: 16, #token: 10278, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.12, #queue-req: 784, 
[1,1]<stdout>:[2025-10-11 20:34:20 DP1 TP8] Decode batch. #running-req: 16, #token: 7543, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.21, #queue-req: 804, 
[1,0]<stdout>:[2025-10-11 20:34:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 783, 
[1,1]<stdout>:[2025-10-11 20:34:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 803, 
[1,0]<stdout>:[2025-10-11 20:34:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 775, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 782, 
[1,0]<stdout>:[2025-10-11 20:34:25 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 10, #cached-token: 4, token usage: 0.02, #running-req: 14, #queue-req: 780, 
[1,1]<stdout>:[2025-10-11 20:34:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 802, 
[1,0]<stdout>:[2025-10-11 20:34:26 DP0 TP0] Decode batch. #running-req: 15, #token: 7558, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.47, #queue-req: 780, 
[1,1]<stdout>:[2025-10-11 20:34:26 DP1 TP8] Decode batch. #running-req: 16, #token: 7121, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.94, #queue-req: 802, 
[1,0]<stdout>:[2025-10-11 20:34:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 832, #cached-token: 7, token usage: 0.02, #running-req: 15, #queue-req: 779, 
[1,0]<stdout>:[2025-10-11 20:34:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 8, token usage: 0.02, #running-req: 15, #queue-req: 778, 
[1,0]<stdout>:[2025-10-11 20:34:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 777, 
[1,1]<stdout>:[2025-10-11 20:34:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 801, 
[1,0]<stdout>:[2025-10-11 20:34:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 7, token usage: 0.02, #running-req: 15, #queue-req: 776, 
[1,1]<stdout>:[2025-10-11 20:34:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 800, 
[1,1]<stdout>:[2025-10-11 20:34:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 799, 
[1,1]<stdout>:[2025-10-11 20:34:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1044, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 798, 
[1,1]<stdout>:[2025-10-11 20:34:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1051, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 797, 
[1,0]<stdout>:[2025-10-11 20:34:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 775, 
[1,0]<stdout>:[2025-10-11 20:34:34 DP0 TP0] Decode batch. #running-req: 16, #token: 7919, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 87.53, #queue-req: 775, 
[1,1]<stdout>:[2025-10-11 20:34:34 DP1 TP8] Decode batch. #running-req: 16, #token: 8068, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 87.39, #queue-req: 797, 
[1,0]<stdout>:[2025-10-11 20:34:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 774, 
[1,1]<stdout>:[2025-10-11 20:34:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 796, 
[1,1]<stdout>:[2025-10-11 20:34:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 795, 
[1,0]<stdout>:[2025-10-11 20:34:36 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 72, #cached-token: 3, token usage: 0.02, #running-req: 14, #queue-req: 772, 
[1,0]<stdout>:[2025-10-11 20:34:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 771, 
[1,1]<stdout>:[2025-10-11 20:34:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 794, 
[1,0]<stdout>:[2025-10-11 20:34:40 DP0 TP0] Decode batch. #running-req: 16, #token: 7225, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.62, #queue-req: 771, 
[1,1]<stdout>:[2025-10-11 20:34:40 DP1 TP8] Decode batch. #running-req: 16, #token: 6158, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.77, #queue-req: 794, 
[1,1]<stdout>:[2025-10-11 20:34:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 793, 
[1,0]<stdout>:[2025-10-11 20:34:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 770, 
[1,1]<stdout>:[2025-10-11 20:34:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 792, 
[1,0]<stdout>:[2025-10-11 20:34:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 769, 
[1,0]<stdout>:[2025-10-11 20:34:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 768, 
[1,0]<stdout>:[2025-10-11 20:34:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 767, 
[1,1]<stdout>:[2025-10-11 20:34:46 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 269, #cached-token: 9, token usage: 0.02, #running-req: 14, #queue-req: 790, 
[1,0]<stdout>:[2025-10-11 20:34:47 DP0 TP0] Decode batch. #running-req: 16, #token: 6912, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.97, #queue-req: 767, 
[1,1]<stdout>:[2025-10-11 20:34:47 DP1 TP8] Decode batch. #running-req: 16, #token: 6949, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.97, #queue-req: 790, 
[1,1]<stdout>:[2025-10-11 20:34:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 789, 
[1,0]<stdout>:[2025-10-11 20:34:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 766, 
[1,1]<stdout>:[2025-10-11 20:34:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 788, 
[1,0]<stdout>:[2025-10-11 20:34:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 765, 
[1,0]<stdout>:[2025-10-11 20:34:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 764, 
[1,1]<stdout>:[2025-10-11 20:34:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 787, 
[1,0]<stdout>:[2025-10-11 20:34:53 DP0 TP0] Decode batch. #running-req: 16, #token: 6355, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.56, #queue-req: 764, 
[1,1]<stdout>:[2025-10-11 20:34:53 DP1 TP8] Decode batch. #running-req: 16, #token: 7256, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.57, #queue-req: 787, 
[1,0]<stdout>:[2025-10-11 20:34:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 763, 
[1,1]<stdout>:[2025-10-11 20:34:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 786, 
[1,1]<stdout>:[2025-10-11 20:34:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 785, 
[1,1]<stdout>:[2025-10-11 20:34:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 784, 
[1,1]<stdout>:[2025-10-11 20:34:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 783, 
[1,1]<stdout>:[2025-10-11 20:34:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 782, 
[1,0]<stdout>:[2025-10-11 20:34:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 5, token usage: 0.01, #running-req: 15, #queue-req: 762, 
[1,0]<stdout>:[2025-10-11 20:35:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 761, 
[1,0]<stdout>:[2025-10-11 20:35:00 DP0 TP0] Decode batch. #running-req: 16, #token: 5401, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.45, #queue-req: 761, 
[1,1]<stdout>:[2025-10-11 20:35:00 DP1 TP8] Decode batch. #running-req: 16, #token: 6802, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.15, #queue-req: 782, 
[1,0]<stdout>:[2025-10-11 20:35:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 760, 
[1,1]<stdout>:[2025-10-11 20:35:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 781, 
[1,0]<stdout>:[2025-10-11 20:35:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 759, 
[1,1]<stdout>:[2025-10-11 20:35:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 780, 
[1,0]<stdout>:[2025-10-11 20:35:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 758, 
[1,1]<stdout>:[2025-10-11 20:35:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 779, 
[1,1]<stdout>:[2025-10-11 20:35:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1414, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 778, 
[1,1]<stdout>:[2025-10-11 20:35:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 777, 
[1,1]<stdout>:[2025-10-11 20:35:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 706, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 776, 
[1,0]<stdout>:[2025-10-11 20:35:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1019, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 757, 
[1,1]<stdout>:[2025-10-11 20:35:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 775, 
[1,0]<stdout>:[2025-10-11 20:35:07 DP0 TP0] Decode batch. #running-req: 16, #token: 6461, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.83, #queue-req: 757, 
[1,1]<stdout>:[2025-10-11 20:35:07 DP1 TP8] Decode batch. #running-req: 16, #token: 6630, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.40, #queue-req: 775, 
[1,1]<stdout>:[2025-10-11 20:35:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 774, 
[1,0]<stdout>:[2025-10-11 20:35:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 756, 
[1,0]<stdout>:[2025-10-11 20:35:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 755, 
[1,0]<stdout>:[2025-10-11 20:35:14 DP0 TP0] Decode batch. #running-req: 16, #token: 6193, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 103.46, #queue-req: 755, 
[1,1]<stdout>:[2025-10-11 20:35:14 DP1 TP8] Decode batch. #running-req: 16, #token: 6554, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 103.62, #queue-req: 774, 
[1,1]<stdout>:[2025-10-11 20:35:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 773, 
[1,0]<stdout>:[2025-10-11 20:35:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 754, 
[1,1]<stdout>:[2025-10-11 20:35:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 772, 
[1,1]<stdout>:[2025-10-11 20:35:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 0, token usage: 0.02, #running-req: 15, #queue-req: 772, 
[1,1]<stdout>:[2025-10-11 20:35:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 771, 
[1,1]<stdout>:[2025-10-11 20:35:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 770, 
[1,1]<stdout>:[2025-10-11 20:35:20 DP1 TP8] Decode batch. #running-req: 16, #token: 9014, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.37, #queue-req: 770, 
[1,0]<stdout>:[2025-10-11 20:35:20 DP0 TP0] Decode batch. #running-req: 16, #token: 6480, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.82, #queue-req: 754, 
[1,1]<stdout>:[2025-10-11 20:35:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 769, 
[1,1]<stdout>:[2025-10-11 20:35:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 768, 
[1,1]<stdout>:[2025-10-11 20:35:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 767, 
[1,0]<stdout>:[2025-10-11 20:35:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 753, 
[1,0]<stdout>:[2025-10-11 20:35:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 752, 
[1,0]<stdout>:[2025-10-11 20:35:26 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 567, #cached-token: 4, token usage: 0.02, #running-req: 14, #queue-req: 750, 
[1,0]<stdout>:[2025-10-11 20:35:27 DP0 TP0] Decode batch. #running-req: 16, #token: 6927, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.34, #queue-req: 750, 
[1,1]<stdout>:[2025-10-11 20:35:27 DP1 TP8] Decode batch. #running-req: 16, #token: 6814, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.49, #queue-req: 767, 
[1,0]<stdout>:[2025-10-11 20:35:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 749, 
[1,0]<stdout>:[2025-10-11 20:35:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 748, 
[1,0]<stdout>:[2025-10-11 20:35:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 747, 
[1,0]<stdout>:[2025-10-11 20:35:33 DP0 TP0] Decode batch. #running-req: 16, #token: 5237, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 102.97, #queue-req: 747, 
[1,1]<stdout>:[2025-10-11 20:35:33 DP1 TP8] Decode batch. #running-req: 16, #token: 7454, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 103.45, #queue-req: 767, 
[1,0]<stdout>:[2025-10-11 20:35:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 746, 
[1,1]<stdout>:[2025-10-11 20:35:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 766, 
[1,0]<stdout>:[2025-10-11 20:35:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 819, #cached-token: 8, token usage: 0.01, #running-req: 15, #queue-req: 745, 
[1,0]<stdout>:[2025-10-11 20:35:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 744, 
[1,1]<stdout>:[2025-10-11 20:35:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 765, 
[1,1]<stdout>:[2025-10-11 20:35:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 764, 
[1,0]<stdout>:[2025-10-11 20:35:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 743, 
[1,0]<stdout>:[2025-10-11 20:35:40 DP0 TP0] Decode batch. #running-req: 16, #token: 6420, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 94.53, #queue-req: 743, 
[1,1]<stdout>:[2025-10-11 20:35:40 DP1 TP8] Decode batch. #running-req: 16, #token: 7359, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 94.67, #queue-req: 764, 
[1,1]<stdout>:[2025-10-11 20:35:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1532, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 763, 
[1,0]<stdout>:[2025-10-11 20:35:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 742, 
[1,0]<stdout>:[2025-10-11 20:35:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 881, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 741, 
[1,0]<stdout>:[2025-10-11 20:35:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 740, 
[1,1]<stdout>:[2025-10-11 20:35:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 762, 
[1,0]<stdout>:[2025-10-11 20:35:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 739, 
[1,0]<stdout>:[2025-10-11 20:35:46 DP0 TP0] Decode batch. #running-req: 16, #token: 6885, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.45, #queue-req: 739, 
[1,1]<stdout>:[2025-10-11 20:35:46 DP1 TP8] Decode batch. #running-req: 16, #token: 8740, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.76, #queue-req: 762, 
[1,0]<stdout>:[2025-10-11 20:35:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 738, 
[1,1]<stdout>:[2025-10-11 20:35:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 761, 
[1,0]<stdout>:[2025-10-11 20:35:52 DP0 TP0] Decode batch. #running-req: 16, #token: 7367, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 106.54, #queue-req: 738, 
[1,1]<stdout>:[2025-10-11 20:35:52 DP1 TP8] Decode batch. #running-req: 15, #token: 8763, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 106.37, #queue-req: 761, 
[1,1]<stdout>:[2025-10-11 20:35:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 760, 
[1,1]<stdout>:[2025-10-11 20:35:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 759, 
[1,0]<stdout>:[2025-10-11 20:35:58 DP0 TP0] Decode batch. #running-req: 16, #token: 8007, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 106.24, #queue-req: 738, 
[1,1]<stdout>:[2025-10-11 20:35:58 DP1 TP8] Decode batch. #running-req: 16, #token: 8024, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 106.08, #queue-req: 759, 
[1,1]<stdout>:[2025-10-11 20:35:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 758, 
[1,0]<stdout>:[2025-10-11 20:35:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 737, 
[1,1]<stdout>:[2025-10-11 20:36:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 757, 
[1,0]<stdout>:[2025-10-11 20:36:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 736, 
[1,1]<stdout>:[2025-10-11 20:36:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 849, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 756, 
[1,0]<stdout>:[2025-10-11 20:36:05 DP0 TP0] Decode batch. #running-req: 15, #token: 7979, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.64, #queue-req: 736, 
[1,1]<stdout>:[2025-10-11 20:36:05 DP1 TP8] Decode batch. #running-req: 16, #token: 9238, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.63, #queue-req: 756, 
[1,0]<stdout>:[2025-10-11 20:36:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 735, 
[1,0]<stdout>:[2025-10-11 20:36:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 734, 
[1,0]<stdout>:[2025-10-11 20:36:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 733, 
[1,0]<stdout>:[2025-10-11 20:36:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 7, token usage: 0.02, #running-req: 15, #queue-req: 732, 
[1,0]<stdout>:[2025-10-11 20:36:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 514, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 731, 
[1,1]<stdout>:[2025-10-11 20:36:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 755, 
[1,1]<stdout>:[2025-10-11 20:36:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 754, 
[1,0]<stdout>:[2025-10-11 20:36:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 730, 
[1,1]<stdout>:[2025-10-11 20:36:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 753, 
[1,0]<stdout>:[2025-10-11 20:36:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 729, 
[1,0]<stdout>:[2025-10-11 20:36:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 728, 
[1,1]<stdout>:[2025-10-11 20:36:10 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 593, #cached-token: 8, token usage: 0.02, #running-req: 14, #queue-req: 751, 
[1,0]<stdout>:[2025-10-11 20:36:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 727, 
[1,1]<stdout>:[2025-10-11 20:36:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 750, 
[1,1]<stdout>:[2025-10-11 20:36:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 749, 
[1,0]<stdout>:[2025-10-11 20:36:12 DP0 TP0] Decode batch. #running-req: 16, #token: 7515, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 84.05, #queue-req: 727, 
[1,1]<stdout>:[2025-10-11 20:36:12 DP1 TP8] Decode batch. #running-req: 16, #token: 8488, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 84.18, #queue-req: 749, 
[1,1]<stdout>:[2025-10-11 20:36:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 571, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 748, 
[1,1]<stdout>:[2025-10-11 20:36:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 486, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 747, 
[1,1]<stdout>:[2025-10-11 20:36:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 746, 
[1,0]<stdout>:[2025-10-11 20:36:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 726, 
[1,0]<stdout>:[2025-10-11 20:36:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 725, 
[1,0]<stdout>:[2025-10-11 20:36:19 DP0 TP0] Decode batch. #running-req: 16, #token: 7677, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.73, #queue-req: 725, 
[1,1]<stdout>:[2025-10-11 20:36:19 DP1 TP8] Decode batch. #running-req: 16, #token: 6985, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.57, #queue-req: 746, 
[1,0]<stdout>:[2025-10-11 20:36:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 724, 
[1,0]<stdout>:[2025-10-11 20:36:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 795, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 723, 
[1,1]<stdout>:[2025-10-11 20:36:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 745, 
[1,0]<stdout>:[2025-10-11 20:36:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 722, 
[1,0]<stdout>:[2025-10-11 20:36:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 721, 
[1,0]<stdout>:[2025-10-11 20:36:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 720, 
[1,1]<stdout>:[2025-10-11 20:36:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 744, 
[1,0]<stdout>:[2025-10-11 20:36:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 479, #cached-token: 7, token usage: 0.02, #running-req: 15, #queue-req: 719, 
[1,0]<stdout>:[2025-10-11 20:36:25 DP0 TP0] Decode batch. #running-req: 16, #token: 7537, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 94.70, #queue-req: 719, 
[1,1]<stdout>:[2025-10-11 20:36:25 DP1 TP8] Decode batch. #running-req: 16, #token: 7221, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.30, #queue-req: 744, 
[1,1]<stdout>:[2025-10-11 20:36:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 743, 
[1,0]<stdout>:[2025-10-11 20:36:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 718, 
[1,1]<stdout>:[2025-10-11 20:36:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 742, 
[1,0]<stdout>:[2025-10-11 20:36:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1595, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 717, 
[1,1]<stdout>:[2025-10-11 20:36:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 741, 
[1,1]<stdout>:[2025-10-11 20:36:32 DP1 TP8] Decode batch. #running-req: 16, #token: 7286, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.67, #queue-req: 741, 
[1,0]<stdout>:[2025-10-11 20:36:32 DP0 TP0] Decode batch. #running-req: 16, #token: 8729, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.83, #queue-req: 717, 
[1,0]<stdout>:[2025-10-11 20:36:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 716, 
[1,1]<stdout>:[2025-10-11 20:36:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 740, 
[1,1]<stdout>:[2025-10-11 20:36:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 739, 
[1,0]<stdout>:[2025-10-11 20:36:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 715, 
[1,0]<stdout>:[2025-10-11 20:36:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 714, 
[1,0]<stdout>:[2025-10-11 20:36:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1146, #cached-token: 0, token usage: 0.03, #running-req: 15, #queue-req: 714, 
[1,0]<stdout>:[2025-10-11 20:36:38 DP0 TP0] Decode batch. #running-req: 16, #token: 11357, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.87, #queue-req: 714, 
[1,1]<stdout>:[2025-10-11 20:36:38 DP1 TP8] Decode batch. #running-req: 16, #token: 7514, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 97.02, #queue-req: 739, 
[1,1]<stdout>:[2025-10-11 20:36:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 738, 
[1,0]<stdout>:[2025-10-11 20:36:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 713, 
[1,1]<stdout>:[2025-10-11 20:36:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 737, 
[1,0]<stdout>:[2025-10-11 20:36:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 8, token usage: 0.03, #running-req: 15, #queue-req: 712, 
[1,1]<stdout>:[2025-10-11 20:36:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 736, 
[1,0]<stdout>:[2025-10-11 20:36:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 711, 
[1,0]<stdout>:[2025-10-11 20:36:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 710, 
[1,0]<stdout>:[2025-10-11 20:36:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 7, token usage: 0.03, #running-req: 15, #queue-req: 709, 
[1,1]<stdout>:[2025-10-11 20:36:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 735, 
[1,0]<stdout>:[2025-10-11 20:36:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 708, 
[1,0]<stdout>:[2025-10-11 20:36:45 DP0 TP0] Decode batch. #running-req: 16, #token: 8846, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.98, #queue-req: 708, 
[1,1]<stdout>:[2025-10-11 20:36:45 DP1 TP8] Decode batch. #running-req: 16, #token: 6356, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.26, #queue-req: 735, 
[1,1]<stdout>:[2025-10-11 20:36:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 734, 
[1,1]<stdout>:[2025-10-11 20:36:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 733, 
[1,0]<stdout>:[2025-10-11 20:36:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 707, 
[1,0]<stdout>:[2025-10-11 20:36:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 706, 
[1,1]<stdout>:[2025-10-11 20:36:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 732, 
[1,0]<stdout>:[2025-10-11 20:36:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 705, 
[1,0]<stdout>:[2025-10-11 20:36:52 DP0 TP0] Decode batch. #running-req: 16, #token: 9253, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.02, #queue-req: 705, 
[1,1]<stdout>:[2025-10-11 20:36:52 DP1 TP8] Decode batch. #running-req: 16, #token: 6475, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.02, #queue-req: 732, 
[1,0]<stdout>:[2025-10-11 20:36:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 8, token usage: 0.02, #running-req: 15, #queue-req: 704, 
[1,0]<stdout>:[2025-10-11 20:36:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 703, 
[1,1]<stdout>:[2025-10-11 20:36:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 731, 
[1,1]<stdout>:[2025-10-11 20:36:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 730, 
[1,0]<stdout>:[2025-10-11 20:36:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 14, token usage: 0.03, #running-req: 15, #queue-req: 702, 
[1,0]<stdout>:[2025-10-11 20:36:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 701, 
[1,0]<stdout>:[2025-10-11 20:36:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 700, 
[1,1]<stdout>:[2025-10-11 20:36:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 729, 
[1,0]<stdout>:[2025-10-11 20:36:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 699, 
[1,0]<stdout>:[2025-10-11 20:36:59 DP0 TP0] Decode batch. #running-req: 16, #token: 9680, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.73, #queue-req: 699, 
[1,1]<stdout>:[2025-10-11 20:36:59 DP1 TP8] Decode batch. #running-req: 15, #token: 6229, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.01, #queue-req: 729, 
[1,1]<stdout>:[2025-10-11 20:36:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 728, 
[1,0]<stdout>:[2025-10-11 20:37:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 930, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 698, 
[1,1]<stdout>:[2025-10-11 20:37:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 727, 
[1,1]<stdout>:[2025-10-11 20:37:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 726, 
[1,1]<stdout>:[2025-10-11 20:37:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 725, 
[1,1]<stdout>:[2025-10-11 20:37:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 720, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 724, 
[1,0]<stdout>:[2025-10-11 20:37:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 697, 
[1,1]<stdout>:[2025-10-11 20:37:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1255, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 723, 
[1,0]<stdout>:[2025-10-11 20:37:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 825, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 696, 
[1,0]<stdout>:[2025-10-11 20:37:06 DP0 TP0] Decode batch. #running-req: 16, #token: 8301, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.96, #queue-req: 696, 
[1,1]<stdout>:[2025-10-11 20:37:06 DP1 TP8] Decode batch. #running-req: 16, #token: 8363, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.68, #queue-req: 723, 
[1,0]<stdout>:[2025-10-11 20:37:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 695, 
[1,0]<stdout>:[2025-10-11 20:37:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 694, 
[1,0]<stdout>:[2025-10-11 20:37:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 693, 
[1,0]<stdout>:[2025-10-11 20:37:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 692, 
[1,1]<stdout>:[2025-10-11 20:37:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 7, token usage: 0.02, #running-req: 15, #queue-req: 722, 
[1,0]<stdout>:[2025-10-11 20:37:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 691, 
[1,1]<stdout>:[2025-10-11 20:37:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 405, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 721, 
[1,1]<stdout>:[2025-10-11 20:37:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 720, 
[1,0]<stdout>:[2025-10-11 20:37:13 DP0 TP0] Decode batch. #running-req: 16, #token: 9530, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.97, #queue-req: 691, 
[1,1]<stdout>:[2025-10-11 20:37:13 DP1 TP8] Decode batch. #running-req: 16, #token: 7066, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.26, #queue-req: 720, 
[1,1]<stdout>:[2025-10-11 20:37:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 719, 
[1,1]<stdout>:[2025-10-11 20:37:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 718, 
[1,0]<stdout>:[2025-10-11 20:37:19 DP0 TP0] Decode batch. #running-req: 16, #token: 10170, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 106.50, #queue-req: 691, 
[1,1]<stdout>:[2025-10-11 20:37:19 DP1 TP8] Decode batch. #running-req: 16, #token: 6766, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 106.16, #queue-req: 718, 
[1,1]<stdout>:[2025-10-11 20:37:23 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 1301, #cached-token: 3, token usage: 0.02, #running-req: 14, #queue-req: 716, 
[1,0]<stdout>:[2025-10-11 20:37:25 DP0 TP0] Decode batch. #running-req: 16, #token: 10810, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 108.71, #queue-req: 691, 
[1,1]<stdout>:[2025-10-11 20:37:25 DP1 TP8] Decode batch. #running-req: 15, #token: 7905, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 108.20, #queue-req: 716, 
[1,1]<stdout>:[2025-10-11 20:37:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 715, 
[1,0]<stdout>:[2025-10-11 20:37:26 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 1203, #cached-token: 6, token usage: 0.02, #running-req: 14, #queue-req: 689, 
[1,0]<stdout>:[2025-10-11 20:37:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 688, 
[1,1]<stdout>:[2025-10-11 20:37:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 714, 
[1,0]<stdout>:[2025-10-11 20:37:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 687, 
[1,0]<stdout>:[2025-10-11 20:37:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 686, 
[1,1]<stdout>:[2025-10-11 20:37:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 808, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 713, 
[1,1]<stdout>:[2025-10-11 20:37:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 712, 
[1,0]<stdout>:[2025-10-11 20:37:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 685, 
[1,1]<stdout>:[2025-10-11 20:37:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 694, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 711, 
[1,0]<stdout>:[2025-10-11 20:37:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 684, 
[1,0]<stdout>:[2025-10-11 20:37:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 931, #cached-token: 6, token usage: 0.03, #running-req: 15, #queue-req: 683, 
[1,1]<stdout>:[2025-10-11 20:37:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 710, 
[1,1]<stdout>:[2025-10-11 20:37:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 709, 
[1,0]<stdout>:[2025-10-11 20:37:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 682, 
[1,0]<stdout>:[2025-10-11 20:37:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 681, 
[1,1]<stdout>:[2025-10-11 20:37:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 708, 
[1,0]<stdout>:[2025-10-11 20:37:33 DP0 TP0] Decode batch. #running-req: 16, #token: 9989, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 79.76, #queue-req: 681, 
[1,1]<stdout>:[2025-10-11 20:37:33 DP1 TP8] Decode batch. #running-req: 16, #token: 6477, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 80.14, #queue-req: 708, 
[1,1]<stdout>:[2025-10-11 20:37:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 707, 
[1,0]<stdout>:[2025-10-11 20:37:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 6, token usage: 0.03, #running-req: 15, #queue-req: 680, 
[1,1]<stdout>:[2025-10-11 20:37:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 706, 
[1,0]<stdout>:[2025-10-11 20:37:39 DP0 TP0] Decode batch. #running-req: 16, #token: 10815, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 103.32, #queue-req: 680, 
[1,1]<stdout>:[2025-10-11 20:37:39 DP1 TP8] Decode batch. #running-req: 16, #token: 6711, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 103.16, #queue-req: 706, 
[1,1]<stdout>:[2025-10-11 20:37:39 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 20, #cached-token: 5, token usage: 0.02, #running-req: 14, #queue-req: 704, 
[1,0]<stdout>:[2025-10-11 20:37:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 679, 
[1,1]<stdout>:[2025-10-11 20:37:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 703, 
[1,0]<stdout>:[2025-10-11 20:37:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 678, 
[1,0]<stdout>:[2025-10-11 20:37:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 908, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 677, 
[1,1]<stdout>:[2025-10-11 20:37:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 702, 
[1,0]<stdout>:[2025-10-11 20:37:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 676, 
[1,1]<stdout>:[2025-10-11 20:37:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 805, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 701, 
[1,1]<stdout>:[2025-10-11 20:37:46 DP1 TP8] Decode batch. #running-req: 16, #token: 6785, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 91.67, #queue-req: 701, 
[1,0]<stdout>:[2025-10-11 20:37:46 DP0 TP0] Decode batch. #running-req: 16, #token: 11338, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 91.82, #queue-req: 676, 
[1,1]<stdout>:[2025-10-11 20:37:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 700, 
[1,0]<stdout>:[2025-10-11 20:37:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 675, 
[1,1]<stdout>:[2025-10-11 20:37:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 699, 
[1,0]<stdout>:[2025-10-11 20:37:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 674, 
[1,0]<stdout>:[2025-10-11 20:37:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 673, 
[1,1]<stdout>:[2025-10-11 20:37:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 698, 
[1,0]<stdout>:[2025-10-11 20:37:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 672, 
[1,1]<stdout>:[2025-10-11 20:37:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 697, 
[1,0]<stdout>:[2025-10-11 20:37:53 DP0 TP0] Decode batch. #running-req: 16, #token: 10831, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.18, #queue-req: 672, 
[1,1]<stdout>:[2025-10-11 20:37:53 DP1 TP8] Decode batch. #running-req: 16, #token: 6941, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.18, #queue-req: 697, 
[1,0]<stdout>:[2025-10-11 20:37:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 7, token usage: 0.03, #running-req: 15, #queue-req: 671, 
[1,0]<stdout>:[2025-10-11 20:37:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 765, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 670, 
[1,0]<stdout>:[2025-10-11 20:37:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 669, 
[1,0]<stdout>:[2025-10-11 20:37:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 668, 
[1,1]<stdout>:[2025-10-11 20:37:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 696, 
[1,1]<stdout>:[2025-10-11 20:37:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 695, 
[1,1]<stdout>:[2025-10-11 20:37:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 694, 
[1,0]<stdout>:[2025-10-11 20:37:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 667, 
[1,1]<stdout>:[2025-10-11 20:37:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 693, 
[1,0]<stdout>:[2025-10-11 20:38:00 DP0 TP0] Decode batch. #running-req: 16, #token: 11365, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.64, #queue-req: 667, 
[1,1]<stdout>:[2025-10-11 20:38:00 DP1 TP8] Decode batch. #running-req: 16, #token: 6548, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.78, #queue-req: 693, 
[1,0]<stdout>:[2025-10-11 20:38:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 666, 
[1,0]<stdout>:[2025-10-11 20:38:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 665, 
[1,0]<stdout>:[2025-10-11 20:38:06 DP0 TP0] Decode batch. #running-req: 16, #token: 9261, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 104.76, #queue-req: 665, 
[1,1]<stdout>:[2025-10-11 20:38:06 DP1 TP8] Decode batch. #running-req: 16, #token: 7188, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 105.10, #queue-req: 693, 
[1,0]<stdout>:[2025-10-11 20:38:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 664, 
[1,1]<stdout>:[2025-10-11 20:38:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 692, 
[1,0]<stdout>:[2025-10-11 20:38:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 663, 
[1,0]<stdout>:[2025-10-11 20:38:12 DP0 TP0] Decode batch. #running-req: 16, #token: 6078, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 104.48, #queue-req: 663, 
[1,1]<stdout>:[2025-10-11 20:38:12 DP1 TP8] Decode batch. #running-req: 16, #token: 7000, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 104.64, #queue-req: 692, 
[1,1]<stdout>:[2025-10-11 20:38:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 691, 
[1,0]<stdout>:[2025-10-11 20:38:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 662, 
[1,1]<stdout>:[2025-10-11 20:38:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 690, 
[1,0]<stdout>:[2025-10-11 20:38:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 661, 
[1,0]<stdout>:[2025-10-11 20:38:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 660, 
[1,0]<stdout>:[2025-10-11 20:38:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 659, 
[1,1]<stdout>:[2025-10-11 20:38:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 689, 
[1,1]<stdout>:[2025-10-11 20:38:18 DP1 TP8] Decode batch. #running-req: 15, #token: 6713, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.04, #queue-req: 689, 
[1,0]<stdout>:[2025-10-11 20:38:18 DP0 TP0] Decode batch. #running-req: 16, #token: 5477, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.04, #queue-req: 659, 
[1,1]<stdout>:[2025-10-11 20:38:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 688, 
[1,1]<stdout>:[2025-10-11 20:38:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 687, 
[1,0]<stdout>:[2025-10-11 20:38:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 794, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 658, 
[1,0]<stdout>:[2025-10-11 20:38:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 657, 
[1,0]<stdout>:[2025-10-11 20:38:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 656, 
[1,1]<stdout>:[2025-10-11 20:38:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 686, 
[1,0]<stdout>:[2025-10-11 20:38:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 5, token usage: 0.01, #running-req: 15, #queue-req: 655, 
[1,1]<stdout>:[2025-10-11 20:38:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 685, 
[1,0]<stdout>:[2025-10-11 20:38:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 654, 
[1,0]<stdout>:[2025-10-11 20:38:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 653, 
[1,0]<stdout>:[2025-10-11 20:38:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 652, 
[1,1]<stdout>:[2025-10-11 20:38:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 885, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 684, 
[1,0]<stdout>:[2025-10-11 20:38:26 DP0 TP0] Decode batch. #running-req: 16, #token: 5262, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 87.22, #queue-req: 652, 
[1,1]<stdout>:[2025-10-11 20:38:26 DP1 TP8] Decode batch. #running-req: 16, #token: 7882, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 87.63, #queue-req: 684, 
[1,0]<stdout>:[2025-10-11 20:38:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 651, 
[1,0]<stdout>:[2025-10-11 20:38:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 6, token usage: 0.01, #running-req: 15, #queue-req: 650, 
[1,0]<stdout>:[2025-10-11 20:38:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 754, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 649, 
[1,0]<stdout>:[2025-10-11 20:38:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 648, 
[1,0]<stdout>:[2025-10-11 20:38:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 647, 
[1,1]<stdout>:[2025-10-11 20:38:32 DP1 TP8] Decode batch. #running-req: 16, #token: 8522, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.04, #queue-req: 684, 
[1,0]<stdout>:[2025-10-11 20:38:32 DP0 TP0] Decode batch. #running-req: 16, #token: 5132, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 97.27, #queue-req: 647, 
[1,0]<stdout>:[2025-10-11 20:38:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 788, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 646, 
[1,0]<stdout>:[2025-10-11 20:38:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 645, 
[1,1]<stdout>:[2025-10-11 20:38:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 683, 
[1,1]<stdout>:[2025-10-11 20:38:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 682, 
[1,1]<stdout>:[2025-10-11 20:38:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 681, 
[1,1]<stdout>:[2025-10-11 20:38:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 680, 
[1,1]<stdout>:[2025-10-11 20:38:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 679, 
[1,0]<stdout>:[2025-10-11 20:38:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 644, 
[1,1]<stdout>:[2025-10-11 20:38:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 678, 
[1,1]<stdout>:[2025-10-11 20:38:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 677, 
[1,0]<stdout>:[2025-10-11 20:38:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 643, 
[1,0]<stdout>:[2025-10-11 20:38:40 DP0 TP0] Decode batch. #running-req: 16, #token: 5079, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 85.57, #queue-req: 643, 
[1,1]<stdout>:[2025-10-11 20:38:40 DP1 TP8] Decode batch. #running-req: 16, #token: 7177, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 85.16, #queue-req: 677, 
[1,1]<stdout>:[2025-10-11 20:38:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 676, 
[1,0]<stdout>:[2025-10-11 20:38:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 642, 
[1,1]<stdout>:[2025-10-11 20:38:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 675, 
[1,0]<stdout>:[2025-10-11 20:38:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 6, token usage: 0.01, #running-req: 15, #queue-req: 641, 
[1,1]<stdout>:[2025-10-11 20:38:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 674, 
[1,0]<stdout>:[2025-10-11 20:38:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 694, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 640, 
[1,1]<stdout>:[2025-10-11 20:38:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 673, 
[1,0]<stdout>:[2025-10-11 20:38:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 639, 
[1,1]<stdout>:[2025-10-11 20:38:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 672, 
[1,1]<stdout>:[2025-10-11 20:38:47 DP1 TP8] Decode batch. #running-req: 16, #token: 7121, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.94, #queue-req: 672, 
[1,0]<stdout>:[2025-10-11 20:38:47 DP0 TP0] Decode batch. #running-req: 16, #token: 5211, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.08, #queue-req: 639, 
[1,1]<stdout>:[2025-10-11 20:38:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 671, 
[1,1]<stdout>:[2025-10-11 20:38:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 670, 
[1,0]<stdout>:[2025-10-11 20:38:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 638, 
[1,0]<stdout>:[2025-10-11 20:38:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 862, #cached-token: 5, token usage: 0.01, #running-req: 15, #queue-req: 637, 
[1,0]<stdout>:[2025-10-11 20:38:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 636, 
[1,0]<stdout>:[2025-10-11 20:38:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.01, #running-req: 15, #queue-req: 635, 
[1,1]<stdout>:[2025-10-11 20:38:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 669, 
[1,1]<stdout>:[2025-10-11 20:38:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 668, 
[1,1]<stdout>:[2025-10-11 20:38:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 7, token usage: 0.02, #running-req: 15, #queue-req: 667, 
[1,0]<stdout>:[2025-10-11 20:38:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.01, #running-req: 15, #queue-req: 634, 
[1,0]<stdout>:[2025-10-11 20:38:53 DP0 TP0] Decode batch. #running-req: 16, #token: 3893, token usage: 0.01, accept len: 1.00, cuda graph: False, gen throughput (token/s): 91.30, #queue-req: 634, 
[1,1]<stdout>:[2025-10-11 20:38:53 DP1 TP8] Decode batch. #running-req: 16, #token: 6050, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 91.29, #queue-req: 667, 
[1,1]<stdout>:[2025-10-11 20:38:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 666, 
[1,0]<stdout>:[2025-10-11 20:38:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 633, 
[1,0]<stdout>:[2025-10-11 20:38:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.02, #running-req: 15, #queue-req: 633, 
[1,0]<stdout>:[2025-10-11 20:38:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.02, #running-req: 15, #queue-req: 633, 
[1,0]<stdout>:[2025-10-11 20:38:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 0, token usage: 0.03, #running-req: 15, #queue-req: 633, 
[1,1]<stdout>:[2025-10-11 20:38:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 665, 
[1,0]<stdout>:[2025-10-11 20:38:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 632, 
[1,0]<stdout>:[2025-10-11 20:38:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 631, 
[1,0]<stdout>:[2025-10-11 20:38:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 630, 
[1,0]<stdout>:[2025-10-11 20:38:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 629, 
[1,1]<stdout>:[2025-10-11 20:39:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 664, 
[1,0]<stdout>:[2025-10-11 20:39:01 DP0 TP0] Decode batch. #running-req: 16, #token: 10245, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 87.23, #queue-req: 629, 
[1,1]<stdout>:[2025-10-11 20:39:01 DP1 TP8] Decode batch. #running-req: 16, #token: 6618, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 87.50, #queue-req: 664, 
[1,1]<stdout>:[2025-10-11 20:39:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 663, 
[1,0]<stdout>:[2025-10-11 20:39:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 628, 
[1,0]<stdout>:[2025-10-11 20:39:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1966, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 627, 
[1,1]<stdout>:[2025-10-11 20:39:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 662, 
[1,1]<stdout>:[2025-10-11 20:39:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 661, 
[1,0]<stdout>:[2025-10-11 20:39:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 626, 
[1,1]<stdout>:[2025-10-11 20:39:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 407, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 660, 
[1,1]<stdout>:[2025-10-11 20:39:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 353, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 659, 
[1,0]<stdout>:[2025-10-11 20:39:08 DP0 TP0] Decode batch. #running-req: 16, #token: 12574, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.78, #queue-req: 626, 
[1,1]<stdout>:[2025-10-11 20:39:08 DP1 TP8] Decode batch. #running-req: 16, #token: 7063, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 92.50, #queue-req: 659, 
[1,1]<stdout>:[2025-10-11 20:39:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 658, 
[1,0]<stdout>:[2025-10-11 20:39:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 625, 
[1,0]<stdout>:[2025-10-11 20:39:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 624, 
[1,0]<stdout>:[2025-10-11 20:39:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 6, token usage: 0.03, #running-req: 15, #queue-req: 623, 
[1,1]<stdout>:[2025-10-11 20:39:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 657, 
[1,0]<stdout>:[2025-10-11 20:39:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 622, 
[1,0]<stdout>:[2025-10-11 20:39:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 621, 
[1,0]<stdout>:[2025-10-11 20:39:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 0, token usage: 0.04, #running-req: 15, #queue-req: 621, 
[1,0]<stdout>:[2025-10-11 20:39:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1012, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 620, 
[1,0]<stdout>:[2025-10-11 20:39:15 DP0 TP0] Decode batch. #running-req: 16, #token: 15863, token usage: 0.04, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.48, #queue-req: 620, 
[1,1]<stdout>:[2025-10-11 20:39:15 DP1 TP8] Decode batch. #running-req: 16, #token: 7174, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 91.05, #queue-req: 657, 
[1,0]<stdout>:[2025-10-11 20:39:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 619, 
[1,1]<stdout>:[2025-10-11 20:39:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 656, 
[1,1]<stdout>:[2025-10-11 20:39:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 655, 
[1,0]<stdout>:[2025-10-11 20:39:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 618, 
[1,1]<stdout>:[2025-10-11 20:39:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 892, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 654, 
[1,0]<stdout>:[2025-10-11 20:39:21 DP0 TP0] Decode batch. #running-req: 16, #token: 15573, token usage: 0.04, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.53, #queue-req: 618, 
[1,1]<stdout>:[2025-10-11 20:39:21 DP1 TP8] Decode batch. #running-req: 16, #token: 7954, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 98.35, #queue-req: 654, 
[1,1]<stdout>:[2025-10-11 20:39:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 653, 
[1,0]<stdout>:[2025-10-11 20:39:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 617, 
[1,0]<stdout>:[2025-10-11 20:39:27 DP0 TP0] Decode batch. #running-req: 16, #token: 16029, token usage: 0.04, accept len: 1.00, cuda graph: False, gen throughput (token/s): 106.41, #queue-req: 617, 
[1,1]<stdout>:[2025-10-11 20:39:27 DP1 TP8] Decode batch. #running-req: 16, #token: 8885, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 106.42, #queue-req: 653, 
[1,1]<stdout>:[2025-10-11 20:39:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 652, 
[1,1]<stdout>:[2025-10-11 20:39:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1021, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 651, 
[1,0]<stdout>:[2025-10-11 20:39:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 616, 
[1,0]<stdout>:[2025-10-11 20:39:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 615, 
[1,0]<stdout>:[2025-10-11 20:39:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 614, 
[1,0]<stdout>:[2025-10-11 20:39:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 613, 
[1,1]<stdout>:[2025-10-11 20:39:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 650, 
[1,0]<stdout>:[2025-10-11 20:39:34 DP0 TP0] Decode batch. #running-req: 16, #token: 16659, token usage: 0.04, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.72, #queue-req: 613, 
[1,1]<stdout>:[2025-10-11 20:39:34 DP1 TP8] Decode batch. #running-req: 16, #token: 9110, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 93.87, #queue-req: 650, 
[1,0]<stdout>:[2025-10-11 20:39:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 391, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 612, 
[1,1]<stdout>:[2025-10-11 20:39:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 649, 
[1,0]<stdout>:[2025-10-11 20:39:37 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 791, #cached-token: 3, token usage: 0.04, #running-req: 14, #queue-req: 610, 
[1,0]<stdout>:[2025-10-11 20:39:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 609, 
[1,1]<stdout>:[2025-10-11 20:39:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 648, 
[1,1]<stdout>:[2025-10-11 20:39:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 647, 
[1,0]<stdout>:[2025-10-11 20:39:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 608, 
[1,0]<stdout>:[2025-10-11 20:39:41 DP0 TP0] Decode batch. #running-req: 16, #token: 16197, token usage: 0.04, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.54, #queue-req: 608, 
[1,1]<stdout>:[2025-10-11 20:39:41 DP1 TP8] Decode batch. #running-req: 16, #token: 7432, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.85, #queue-req: 647, 
[1,0]<stdout>:[2025-10-11 20:39:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 607, 
[1,1]<stdout>:[2025-10-11 20:39:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 646, 
[1,0]<stdout>:[2025-10-11 20:39:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 606, 
[1,0]<stdout>:[2025-10-11 20:39:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 605, 
[1,0]<stdout>:[2025-10-11 20:39:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 604, 
[1,0]<stdout>:[2025-10-11 20:39:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 772, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 603, 
[1,0]<stdout>:[2025-10-11 20:39:47 DP0 TP0] Decode batch. #running-req: 16, #token: 16879, token usage: 0.05, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.64, #queue-req: 603, 
[1,1]<stdout>:[2025-10-11 20:39:47 DP1 TP8] Decode batch. #running-req: 16, #token: 8068, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 97.24, #queue-req: 646, 
[1,0]<stdout>:[2025-10-11 20:39:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 602, 
[1,0]<stdout>:[2025-10-11 20:39:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 601, 
[1,0]<stdout>:[2025-10-11 20:39:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 600, 
[1,1]<stdout>:[2025-10-11 20:39:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1386, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 645, 
[1,0]<stdout>:[2025-10-11 20:39:53 DP0 TP0] Decode batch. #running-req: 16, #token: 14597, token usage: 0.04, accept len: 1.00, cuda graph: False, gen throughput (token/s): 101.44, #queue-req: 600, 
[1,1]<stdout>:[2025-10-11 20:39:53 DP1 TP8] Decode batch. #running-req: 16, #token: 9741, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 101.77, #queue-req: 645, 
[1,1]<stdout>:[2025-10-11 20:39:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 644, 
[1,1]<stdout>:[2025-10-11 20:39:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 643, 
[1,1]<stdout>:[2025-10-11 20:39:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 708, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 642, 
[1,1]<stdout>:[2025-10-11 20:39:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 641, 
[1,1]<stdout>:[2025-10-11 20:39:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 640, 
[1,0]<stdout>:[2025-10-11 20:39:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 599, 
[1,1]<stdout>:[2025-10-11 20:39:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 639, 
[1,1]<stdout>:[2025-10-11 20:39:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 638, 
[1,1]<stdout>:[2025-10-11 20:39:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 637, 
[1,1]<stdout>:[2025-10-11 20:40:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 636, 
[1,0]<stdout>:[2025-10-11 20:40:00 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 320, #cached-token: 11, token usage: 0.02, #running-req: 14, #queue-req: 597, 
[1,0]<stdout>:[2025-10-11 20:40:01 DP0 TP0] Decode batch. #running-req: 16, #token: 7477, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 87.76, #queue-req: 597, 
[1,1]<stdout>:[2025-10-11 20:40:01 DP1 TP8] Decode batch. #running-req: 16, #token: 7530, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 86.92, #queue-req: 636, 
[1,1]<stdout>:[2025-10-11 20:40:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 635, 
[1,0]<stdout>:[2025-10-11 20:40:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 596, 
[1,1]<stdout>:[2025-10-11 20:40:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 634, 
[1,1]<stdout>:[2025-10-11 20:40:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 633, 
[1,1]<stdout>:[2025-10-11 20:40:03 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 409, #cached-token: 7, token usage: 0.02, #running-req: 14, #queue-req: 631, 
[1,0]<stdout>:[2025-10-11 20:40:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1119, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 595, 
[1,0]<stdout>:[2025-10-11 20:40:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 594, 
[1,1]<stdout>:[2025-10-11 20:40:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 630, 
[1,1]<stdout>:[2025-10-11 20:40:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 629, 
[1,1]<stdout>:[2025-10-11 20:40:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 628, 
[1,0]<stdout>:[2025-10-11 20:40:08 DP0 TP0] Decode batch. #running-req: 16, #token: 8895, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 90.21, #queue-req: 594, 
[1,1]<stdout>:[2025-10-11 20:40:08 DP1 TP8] Decode batch. #running-req: 16, #token: 6711, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 89.50, #queue-req: 628, 
[1,0]<stdout>:[2025-10-11 20:40:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 593, 
[1,1]<stdout>:[2025-10-11 20:40:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 627, 
[1,1]<stdout>:[2025-10-11 20:40:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 749, #cached-token: 6, token usage: 0.02, #running-req: 15, #queue-req: 626, 
[1,1]<stdout>:[2025-10-11 20:40:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 781, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 625, 
[1,0]<stdout>:[2025-10-11 20:40:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1538, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 592, 
[1,0]<stdout>:[2025-10-11 20:40:14 DP0 TP0] Decode batch. #running-req: 16, #token: 10747, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.72, #queue-req: 592, 
[1,1]<stdout>:[2025-10-11 20:40:14 DP1 TP8] Decode batch. #running-req: 15, #token: 7551, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 96.42, #queue-req: 625, 
[1,1]<stdout>:[2025-10-11 20:40:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 624, 
[1,1]<stdout>:[2025-10-11 20:40:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 623, 
[1,1]<stdout>:[2025-10-11 20:40:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 622, 
[1,0]<stdout>:[2025-10-11 20:40:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 11, token usage: 0.03, #running-req: 15, #queue-req: 591, 
[1,1]<stdout>:[2025-10-11 20:40:21 DP1 TP8] Decode batch. #running-req: 16, #token: 7374, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 101.49, #queue-req: 622, 
[1,0]<stdout>:[2025-10-11 20:40:21 DP0 TP0] Decode batch. #running-req: 16, #token: 10696, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 101.64, #queue-req: 591, 
[1,0]<stdout>:[2025-10-11 20:40:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 590, 
[1,1]<stdout>:[2025-10-11 20:40:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 621, 
[1,1]<stdout>:[2025-10-11 20:40:23 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 65, #cached-token: 4, token usage: 0.02, #running-req: 14, #queue-req: 619, 
[1,1]<stdout>:[2025-10-11 20:40:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 618, 
[1,1]<stdout>:[2025-10-11 20:40:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 617, 
[1,0]<stdout>:[2025-10-11 20:40:27 DP0 TP0] Decode batch. #running-req: 16, #token: 11352, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.98, #queue-req: 590, 
[1,1]<stdout>:[2025-10-11 20:40:27 DP1 TP8] Decode batch. #running-req: 16, #token: 7171, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 99.35, #queue-req: 617, 
[1,1]<stdout>:[2025-10-11 20:40:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 616, 
[1,0]<stdout>:[2025-10-11 20:40:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1474, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 589, 
[1,1]<stdout>:[2025-10-11 20:40:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 615, 
[1,0]<stdout>:[2025-10-11 20:40:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 8, token usage: 0.03, #running-req: 15, #queue-req: 588, 
[1,0]<stdout>:[2025-10-11 20:40:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 587, 
[1,1]<stdout>:[2025-10-11 20:40:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 5, token usage: 0.02, #running-req: 15, #queue-req: 614, 
[1,0]<stdout>:[2025-10-11 20:40:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 586, 
[1,0]<stdout>:[2025-10-11 20:40:34 DP0 TP0] Decode batch. #running-req: 16, #token: 11394, token usage: 0.03, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.39, #queue-req: 586, 
[1,1]<stdout>:[2025-10-11 20:40:34 DP1 TP8] Decode batch. #running-req: 16, #token: 6310, token usage: 0.02, accept len: 1.00, cuda graph: False, gen throughput (token/s): 95.53, #queue-req: 614, 
[1,1]<stdout>:[2025-10-11 20:40:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 820, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 613, 
=>> PBS: job killed: walltime 991 exceeded limit 900
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-11 20:40:53.268976:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 97052.pbs111
	Project: 50000128
	Exit Status: -29
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 03:38:11
	Memory: Requested(3760gb), Used(42462736kb)
	Vmem Used: 74628562384kb
	Walltime: Requested(00:15:00), Used(00:16:46)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx006:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx019:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 16.9mins
	GPU Power Consumed: 298.5W
	GPU Max GPU Memory Used: 1.24TB
	Memory Throughput Rate (Average): a2ap-dgx006:(gpu1:1%+gpu0:2%+gpu2:1%+gpu3:2%+gpu5:1%+gpu4:2%+gpu6:2%+gpu7:1%)+a2ap-dgx019:(gpu1:1%+gpu0:2%+gpu2:2%+gpu3:2%+gpu5:2%+gpu4:2%+gpu6:2%+gpu7:1%)
	Memory Throughput Rate (Max): a2ap-dgx006:(gpu1:10%+gpu0:13%+gpu2:6%+gpu3:35%+gpu5:7%+gpu4:9%+gpu6:17%+gpu7:7%)+a2ap-dgx019:(gpu1:8%+gpu0:24%+gpu2:13%+gpu3:25%+gpu5:26%+gpu4:14%+gpu6:9%+gpu7:14%)
	Memory Throughput Rate (Min): a2ap-dgx006:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx019:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx006:(gpu1:50%+gpu0:74%+gpu2:79%+gpu3:82%+gpu5:84%+gpu4:80%+gpu6:77%+gpu7:84%)+a2ap-dgx019:(gpu1:84%+gpu0:59%+gpu2:65%+gpu3:84%+gpu5:76%+gpu4:78%+gpu6:85%+gpu7:73%)
	GPU SM Utilization (Max): a2ap-dgx006:(gpu1:98%+gpu0:98%+gpu2:98%+gpu3:98%+gpu5:98%+gpu4:98%+gpu6:98%+gpu7:98%)+a2ap-dgx019:(gpu1:98%+gpu0:98%+gpu2:98%+gpu3:98%+gpu5:98%+gpu4:98%+gpu6:99%+gpu7:99%)
	GPU SM Utilization (Min): a2ap-dgx006:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx019:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: None
GPU application profile: High
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

