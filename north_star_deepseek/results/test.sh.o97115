========== SIMPLIFIED BENCHMARK ==========
Target: <15min | Est. SU: 238.934 | Balance: 41926.189
N/A
Job ID: 97115.pbs111 | GPUs: 16 | Master: a2ap-dgx007.asp2p.nscc.sg:5000
Config: TP16+DP2 | NCCL: Auto-tuned defaults
==========================================
[01:56:30] Launching optimized benchmark...
[1,0]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 4096 to avoid MoE kernel issues. 
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:Mixed chunked prefill is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,1]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 4096 to avoid MoE kernel issues. 
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:Mixed chunked prefill is disabled because of using eagle speculative decoding.
[1,0]<stdout>:[2025-10-12 01:56:49] Using default HuggingFace chat template with detected content format: string
[1,1]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,0]<stdout>:[2025-10-12 01:57:35 DP0 TP0] MLA optimization is turned on. Use flashinfer backend.
[1,0]<stdout>:[2025-10-12 01:57:35 DP0 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-12 01:57:35 DP0 TP0] Init torch distributed begin.
[1,1]<stdout>:[W1012 01:57:37.738839860 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 01:57:37.272395670 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 01:57:37.774524185 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 01:57:37.779204360 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 01:57:37.845843478 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 01:57:37.569152035 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 01:57:37.659296063 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 01:57:37.187537324 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 01:57:37.714870981 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 01:57:37.725119768 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 01:57:37.226015500 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 01:57:37.267264895 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 01:57:37.845241453 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 01:57:37.387280029 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 01:57:37.916562901 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 01:57:37.926080819 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 01:57:37 DP0 TP0] sglang is using nccl==2.27.3
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 01:57:45 DP0 TP0] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 01:57:45 DP1 TP15] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 01:57:45 DP1 TP14] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 01:57:45 DP1 TP13] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 01:57:45 DP1 TP12] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 01:57:45 DP0 TP1] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 01:57:45 DP1 TP11] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 01:57:45 DP0 TP2] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 01:57:45 DP1 TP10] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 01:57:45 DP0 TP3] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 01:57:45 DP0 TP4] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 01:57:45 DP1 TP9] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 01:57:45 DP0 TP5] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 01:57:45 DP0 TP7] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 01:57:45 DP1 TP8] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 01:57:45 DP0 TP6] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 01:57:46 DP0 TP0] sglang is using nccl==2.27.3
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[2025-10-12 01:57:48 DP0 TP0] Init torch distributed ends. mem usage=1.75 GB
[1,0]<stdout>:[2025-10-12 01:57:49 DP0 TP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 01:57:49 DP0 TP2] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 01:57:49 DP0 TP6] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 01:57:49 DP0 TP1] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 01:57:49 DP0 TP3] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 01:57:49 DP0 TP5] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 01:57:49 DP0 TP4] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 01:57:49 DP0 TP7] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 01:57:49 DP1 TP11] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 01:57:49 DP1 TP15] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 01:57:49 DP1 TP10] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 01:57:49 DP1 TP13] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 01:57:49 DP1 TP9] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 01:57:49 DP1 TP8] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 01:57:49 DP1 TP14] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 01:57:49 DP1 TP12] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 01:57:50 DP0 TP0] Load weight begin. avail mem=76.79 GB
[1,0]<stdout>:[2025-10-12 01:57:50 DP0 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-12 01:58:19 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=32.87 GB, mem usage=43.92 GB.
[1,0]<stdout>:[2025-10-12 01:58:22 DP0 TP4] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,0]<stdout>:[2025-10-12 01:58:22 DP0 TP5] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,1]<stdout>:[2025-10-12 01:58:22 DP1 TP14] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,1]<stdout>:[2025-10-12 01:58:23 DP1 TP15] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,0]<stdout>:[2025-10-12 01:58:23 DP0 TP7] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,0]<stdout>:[2025-10-12 01:58:23 DP0 TP3] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,0]<stdout>:[2025-10-12 01:58:23 DP0 TP2] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,0]<stdout>:[2025-10-12 01:58:23 DP0 TP0] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,0]<stdout>:[2025-10-12 01:58:23 DP0 TP0] Memory pool end. avail mem=22.36 GB
[1,1]<stdout>:[2025-10-12 01:58:23 DP1 TP10] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,0]<stdout>:[2025-10-12 01:58:23 DP0 TP1] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,1]<stdout>:[2025-10-12 01:58:23 DP1 TP12] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,1]<stdout>:[2025-10-12 01:58:23 DP1 TP13] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,1]<stdout>:[2025-10-12 01:58:23 DP1 TP9] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,1]<stdout>:[2025-10-12 01:58:23 DP1 TP11] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,0]<stdout>:[2025-10-12 01:58:23 DP0 TP6] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,1]<stdout>:[2025-10-12 01:58:23 DP1 TP8] KV Cache is allocated. #tokens: 155509, KV size: 10.18 GB
[1,0]<stdout>:[2025-10-12 01:58:23 DP0 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=21.88 GB
[1,0]<stdout>:[2025-10-12 01:58:25 DP0 TP0] Capture cuda graph bs [8, 16, 24, 32]
[1,0]<stdout>:  0% 0/4 [00:00<?, ?it/s]Capturing batches (bs=32 avail_mem=21.84 GB):   0% 0/4 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-12 01:58:28 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:28 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 01:58:28 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:28 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:28 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:28 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:28 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:28 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:28 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:28 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:28 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:28 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:28 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:28 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:28 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 01:58:28 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:28 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:28 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][A[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 1103.09it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 1466.03it/s]100% 33/33 [00:00<00:00, 3848.52it/s]100% 33/33 [00:00<00:00, 924.26it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 1701.29it/s]
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:100% 33/33 [00:00<00:00, 2515.90it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 537.52it/s]100% 33/33 [00:00<00:00, 1081.96it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 935.69it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 1153.30it/s]
[1,1]<stdout>:
[1,1]<stdout>:100% 33/33 [00:00<00:00, 1085.95it/s]100% 33/33 [00:00<00:00, 3155.77it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 1162.81it/s]
[1,1]<stdout>:
[1,1]<stdout>:
[1,0]<stdout>:100% 33/33 [00:00<00:00, 4997.55it/s]
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5276.26it/s]
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 5468.67it/s]
[1,1]<stdout>:[2025-10-12 01:58:30 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:30 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 01:58:30 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:30 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:30 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:30 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:30 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:30 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:30 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:30 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:30 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 01:58:30 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:30 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:30 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:30 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:30 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:30 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:30 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][A[1,0]<stdout>:100% 29/29 [00:00<00:00, 4033.92it/s]
[1,0]<stdout>:100% 29/29 [00:00<00:00, 2219.21it/s]
[1,0]<stdout>:100% 29/29 [00:00<00:00, 1321.51it/s]
[1,0]<stdout>:100% 29/29 [00:00<00:00, 4039.28it/s]
[1,1]<stdout>:100% 29/29 [00:00<00:00, 369.45it/s]
[1,0]<stdout>:100% 29/29 [00:00<00:00, 12859.16it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 14670.71it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 12081.33it/s][1,1]<stdout>:
[1,1]<stdout>:100% 29/29 [00:00<00:00, 12966.08it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 14975.97it/s][1,1]<stdout>:
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:100% 29/29 [00:00<00:00, 13341.54it/s]
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:100% 29/29 [00:00<00:00, 12415.52it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 12566.88it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 14056.95it/s]
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:100% 29/29 [00:00<00:00, 13759.59it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 13335.69it/s]
[1,1]<stdout>:[2025-10-12 01:58:32 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:32 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:32 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:32 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:32 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:32 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:32 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:32 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:32 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 01:58:32 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:32 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:32 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:32 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:32 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:32 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 01:58:32 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:32 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:32 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 667.51it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 6710.89it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 11703.67it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 18861.40it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 17848.10it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 11278.80it/s]
[1,0]<stdout>:
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:[A[1,1]<stdout>:100% 16/16 [00:00<00:00, 17194.17it/s][1,1]<stdout>:
[1,0]<stdout>:100% 16/16 [00:00<00:00, 13839.73it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 11804.55it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 14220.99it/s][1,1]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 13226.03it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 12612.08it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 12104.77it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 12913.00it/s][1,1]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15297.21it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 13246.91it/s]
[1,0]<stdout>:[2025-10-12 01:58:36 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:36 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:37 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:37 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:37 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:37 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 01:58:37 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:37 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:37 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:37 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:37 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 01:58:37 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:37 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:37 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:37 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:37 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:37 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:37 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 3593.99it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 1081.17it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 13808.41it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 13275.74it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 13306.01it/s][1,1]<stdout>:
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 13159.89it/s]
[1,1]<stdout>:100% 32/32 [00:00<00:00, 13397.66it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 13539.57it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 12737.76it/s][1,1]<stdout>:
[1,1]<stdout>:100% 32/32 [00:00<00:00, 14923.03it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 14377.90it/s]
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][A[1,0]<stdout>:100% 32/32 [00:00<00:00, 13144.43it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 12880.78it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 11416.96it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 12863.50it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 13771.57it/s]
[1,0]<stdout>:[2025-10-12 01:58:37 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:37 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:38 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 01:58:38 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:38 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 01:58:38 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:38 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:38 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:38 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:38 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:38 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:38 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:38 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:38 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:38 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:38 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 01:58:38 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 01:58:38 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 524.72it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 253.29it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 17814.94it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 13598.55it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 13486.51it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 15473.57it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 12993.00it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15974.50it/s][1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:[A[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 16360.04it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 15023.25it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 11560.53it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 12100.41it/s][1,0]<stdout>:
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 13135.42it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15727.41it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 12246.14it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 12952.88it/s]
[1,1]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,1]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,1]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,1]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,1]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,1]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,1]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,1]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,1]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,1]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,1]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,1]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,1]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,1]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,1]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,1]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,0]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,0]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,0]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,0]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,0]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,0]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,0]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,0]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,0]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,0]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,0]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,0]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,0]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,0]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,0]<stdout>:/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
[1,0]<stdout>:  torch._dynamo.utils.warn_once(msg)
[1,1]<stdout>:[2025-10-12 01:58:43 DP1 TP9] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 01:58:43 DP1 TP10] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 01:58:43 DP1 TP15] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 01:58:43 DP1 TP12] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 01:58:43 DP1 TP14] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 01:58:43 DP1 TP8] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 01:58:43 DP1 TP11] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 01:58:43 DP0 TP2] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 01:58:43 DP0 TP7] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 01:58:43 DP0 TP1] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 01:58:43 DP0 TP6] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 01:58:43 DP0 TP0] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 01:58:43 DP1 TP13] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 01:58:43 DP0 TP4] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 01:58:43 DP0 TP5] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 01:58:43 DP0 TP3] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:Capturing batches (bs=32 avail_mem=21.84 GB):  25% 1/4 [00:32<01:38, 32.90s/it][1,0]<stdout>:Capturing batches (bs=24 avail_mem=20.24 GB):  25% 1/4 [00:32<01:38, 32.90s/it][1,0]<stdout>:Capturing batches (bs=24 avail_mem=20.24 GB):  50% 2/4 [00:54<00:52, 26.36s/it][1,0]<stdout>:Capturing batches (bs=16 avail_mem=20.17 GB):  50% 2/4 [00:54<00:52, 26.36s/it][1,0]<stdout>:Capturing batches (bs=16 avail_mem=20.17 GB):  75% 3/4 [01:13<00:23, 23.07s/it][1,0]<stdout>:Capturing batches (bs=8 avail_mem=20.12 GB):  75% 3/4 [01:13<00:23, 23.07s/it] [1,0]<stdout>:Capturing batches (bs=8 avail_mem=20.12 GB): 100% 4/4 [01:33<00:00, 21.61s/it][1,0]<stdout>:Capturing batches (bs=8 avail_mem=20.12 GB): 100% 4/4 [01:33<00:00, 23.30s/it]
[1,0]<stdout>:[2025-10-12 01:59:58 DP0 TP0] Capture cuda graph end. Time elapsed: 94.74 s. mem usage=1.83 GB. avail mem=20.06 GB.
[1,0]<stdout>:[2025-10-12 01:59:58 DP0 TP0] MLA optimization is turned on. Use flashinfer backend.
[1,0]<stdout>:[2025-10-12 01:59:58 DP0 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-12 01:59:58 DP0 TP0] Init torch distributed begin.
[1,0]<stdout>:[2025-10-12 01:59:59 DP0 TP0] Init torch distributed ends. mem usage=0.00 GB
[1,0]<stdout>:[2025-10-12 01:59:59 DP0 TP0] Load weight begin. avail mem=20.06 GB
[1,0]<stdout>:[2025-10-12 01:59:59 DP0 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=17.28 GB, mem usage=2.77 GB.
[1,1]<stdout>:[2025-10-12 02:00:00 DP1 TP11] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,1]<stdout>:[2025-10-12 02:00:00 DP1 TP12] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,1]<stdout>:[2025-10-12 02:00:00 DP1 TP8] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,1]<stdout>:[2025-10-12 02:00:00 DP1 TP9] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,1]<stdout>:[2025-10-12 02:00:00 DP1 TP14] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,1]<stdout>:[2025-10-12 02:00:00 DP1 TP13] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,1]<stdout>:[2025-10-12 02:00:00 DP1 TP10] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,1]<stdout>:[2025-10-12 02:00:00 DP1 TP15] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP2] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP1] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP4] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP0] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP5] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP0] Memory pool end. avail mem=17.11 GB
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP7] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP3] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,0]<stdout>:[2025-10-12 02:00:00 DP0 TP6] KV Cache is allocated. #tokens: 155509, KV size: 0.17 GB
[1,1]<stdout>:[2025-10-12 02:00:01 DP1 TP8] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.82 GB
[1,1]<stdout>:[2025-10-12 02:00:01 DP1 TP15] Capture draft cuda graph begin. This can take up to several minutes. avail mem=19.05 GB
[1,1]<stdout>:[2025-10-12 02:00:01 DP1 TP13] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.82 GB
[1,1]<stdout>:[2025-10-12 02:00:01 DP1 TP12] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.77 GB
[1,1]<stdout>:[2025-10-12 02:00:01 DP1 TP14] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.77 GB
[1,1]<stdout>:[2025-10-12 02:00:01 DP1 TP11] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.82 GB
[1,0]<stdout>:[2025-10-12 02:00:01 DP0 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.77 GB
[1,0]<stdout>:[2025-10-12 02:00:01 DP0 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.78 GB
[1,1]<stdout>:[2025-10-12 02:00:01 DP1 TP10] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.77 GB
[1,1]<stdout>:[2025-10-12 02:00:01 DP1 TP9] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.82 GB
[1,0]<stdout>:[2025-10-12 02:00:01 DP0 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.82 GB
[1,0]<stdout>:[2025-10-12 02:00:01 DP0 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.82 GB
[1,0]<stdout>:[2025-10-12 02:00:01 DP0 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.82 GB
[1,0]<stdout>:[2025-10-12 02:00:01 DP0 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=19.01 GB
[1,0]<stdout>:[2025-10-12 02:00:01 DP0 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.87 GB
[1,0]<stdout>:[2025-10-12 02:00:01 DP0 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.77 GB
[1,0]<stdout>:  0% 0/4 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=18.85 GB):   0% 0/4 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=18.85 GB):  25% 1/4 [00:00<00:02,  1.26it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=18.84 GB):  25% 1/4 [00:00<00:02,  1.26it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=18.84 GB):  50% 2/4 [00:01<00:01,  1.30it/s]Capturing batches (bs=16 avail_mem=18.84 GB):  50% 2/4 [00:01<00:01,  1.30it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=18.84 GB):  75% 3/4 [00:01<00:00,  1.88it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.84 GB):  75% 3/4 [00:01<00:00,  1.88it/s] [1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP4] Capture draft cuda graph end. Time elapsed: 4.01 s. mem usage=0.02 GB. avail mem=18.80 GB.
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP3] Capture draft cuda graph end. Time elapsed: 4.03 s. mem usage=0.02 GB. avail mem=18.75 GB.
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP1] Capture draft cuda graph end. Time elapsed: 3.93 s. mem usage=0.02 GB. avail mem=18.75 GB.
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP5] Capture draft cuda graph end. Time elapsed: 4.03 s. mem usage=0.02 GB. avail mem=18.75 GB.
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP2] Capture draft cuda graph end. Time elapsed: 3.97 s. mem usage=0.02 GB. avail mem=18.80 GB.
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.80 GB
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.75 GB
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.75 GB
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.75 GB
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP6] Capture draft cuda graph end. Time elapsed: 4.00 s. mem usage=0.02 GB. avail mem=18.80 GB.
[1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.84 GB): 100% 4/4 [00:02<00:00,  2.39it/s][2025-10-12 02:00:05 DP0 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.80 GB
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.80 GB
[1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.84 GB): 100% 4/4 [00:02<00:00,  1.96it/s][2025-10-12 02:00:05 DP0 TP7] Capture draft cuda graph end. Time elapsed: 3.97 s. mem usage=0.02 GB. avail mem=18.99 GB.
[1,0]<stdout>:
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP15] Capture draft cuda graph end. Time elapsed: 4.06 s. mem usage=0.02 GB. avail mem=19.03 GB.
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP12] Capture draft cuda graph end. Time elapsed: 4.06 s. mem usage=0.02 GB. avail mem=18.75 GB.
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP10] Capture draft cuda graph end. Time elapsed: 4.03 s. mem usage=0.02 GB. avail mem=18.75 GB.
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP14] Capture draft cuda graph end. Time elapsed: 4.05 s. mem usage=0.02 GB. avail mem=18.75 GB.
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP8] Capture draft cuda graph end. Time elapsed: 4.07 s. mem usage=0.02 GB. avail mem=18.80 GB.
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP11] Capture draft cuda graph end. Time elapsed: 4.04 s. mem usage=0.02 GB. avail mem=18.80 GB.
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP9] Capture draft cuda graph end. Time elapsed: 4.02 s. mem usage=0.02 GB. avail mem=18.80 GB.
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.99 GB
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP15] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=19.03 GB
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP10] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.75 GB
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP12] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.75 GB
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP14] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.75 GB
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP8] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.80 GB
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP11] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.80 GB
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP9] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.80 GB
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP0] Capture draft cuda graph end. Time elapsed: 3.96 s. mem usage=0.02 GB. avail mem=18.84 GB.
[1,0]<stdout>:[2025-10-12 02:00:05 DP0 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.84 GB
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP13] Capture draft cuda graph end. Time elapsed: 4.06 s. mem usage=0.02 GB. avail mem=18.80 GB.
[1,1]<stdout>:[2025-10-12 02:00:05 DP1 TP13] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.80 GB
[1,0]<stdout>:  0% 0/4 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=18.80 GB):   0% 0/4 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=18.80 GB):  25% 1/4 [00:00<00:02,  1.39it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=18.65 GB):  25% 1/4 [00:00<00:02,  1.39it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=18.65 GB):  50% 2/4 [00:01<00:00,  2.02it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=18.65 GB):  50% 2/4 [00:01<00:00,  2.02it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=18.65 GB):  75% 3/4 [00:01<00:00,  3.08it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.65 GB):  75% 3/4 [00:01<00:00,  3.08it/s] [1,1]<stdout>:[2025-10-12 02:00:08 DP1 TP15] Capture draft extend cuda graph end. Time elapsed: 3.03 s. mem usage=0.22 GB. avail mem=18.82 GB.
[1,1]<stdout>:[2025-10-12 02:00:08 DP1 TP14] Capture draft extend cuda graph end. Time elapsed: 3.03 s. mem usage=0.22 GB. avail mem=18.54 GB.
[1,1]<stdout>:[2025-10-12 02:00:08 DP1 TP11] Capture draft extend cuda graph end. Time elapsed: 3.03 s. mem usage=0.22 GB. avail mem=18.58 GB.
[1,1]<stdout>:[2025-10-12 02:00:08 DP1 TP8] Capture draft extend cuda graph end. Time elapsed: 3.03 s. mem usage=0.21 GB. avail mem=18.58 GB.
[1,1]<stdout>:[2025-10-12 02:00:08 DP1 TP9] Capture draft extend cuda graph end. Time elapsed: 3.04 s. mem usage=0.22 GB. avail mem=18.58 GB.
[1,1]<stdout>:[2025-10-12 02:00:08 DP1 TP13] Capture draft extend cuda graph end. Time elapsed: 3.03 s. mem usage=0.22 GB. avail mem=18.58 GB.
[1,1]<stdout>:[2025-10-12 02:00:08 DP1 TP12] Capture draft extend cuda graph end. Time elapsed: 3.04 s. mem usage=0.22 GB. avail mem=18.54 GB.
[1,1]<stdout>:[2025-10-12 02:00:08 DP1 TP10] Capture draft extend cuda graph end. Time elapsed: 3.04 s. mem usage=0.22 GB. avail mem=18.54 GB.
[1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.65 GB): 100% 4/4 [00:01<00:00,  3.59it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.65 GB): 100% 4/4 [00:01<00:00,  2.88it/s]
[1,0]<stdout>:[2025-10-12 02:00:08 DP0 TP0] Capture draft extend cuda graph end. Time elapsed: 3.07 s. mem usage=0.21 GB. avail mem=18.63 GB.
[1,0]<stdout>:[2025-10-12 02:00:08 DP0 TP0] max_total_num_tokens=155509, chunked_prefill_size=2048, max_prefill_tokens=16384, max_running_requests=16, context_len=163840, available_gpu_mem=18.63 GB
[1,0]<stdout>:[2025-10-12 02:00:08 DP0 TP4] Capture draft extend cuda graph end. Time elapsed: 3.08 s. mem usage=0.22 GB. avail mem=18.58 GB.
[1,0]<stdout>:[2025-10-12 02:00:08 DP0 TP1] Capture draft extend cuda graph end. Time elapsed: 3.08 s. mem usage=0.22 GB. avail mem=18.54 GB.
[1,0]<stdout>:[2025-10-12 02:00:08 DP0 TP2] Capture draft extend cuda graph end. Time elapsed: 3.08 s. mem usage=0.22 GB. avail mem=18.58 GB.
[1,0]<stdout>:[2025-10-12 02:00:08 DP0 TP5] Capture draft extend cuda graph end. Time elapsed: 3.08 s. mem usage=0.22 GB. avail mem=18.54 GB.
[1,0]<stdout>:[2025-10-12 02:00:08 DP0 TP7] Capture draft extend cuda graph end. Time elapsed: 3.09 s. mem usage=0.22 GB. avail mem=18.77 GB.
[1,0]<stdout>:[2025-10-12 02:00:08 DP0 TP3] Capture draft extend cuda graph end. Time elapsed: 3.09 s. mem usage=0.22 GB. avail mem=18.54 GB.
[1,0]<stdout>:[2025-10-12 02:00:08 DP0 TP6] Capture draft extend cuda graph end. Time elapsed: 3.12 s. mem usage=0.22 GB. avail mem=18.58 GB.
[1,1]<stdout>:[2025-10-12 02:00:08] Starting dummy health check server at 127.0.0.1:30000
[1,0]<stdout>:#Input tokens: 626729
[1,0]<stdout>:#Output tokens: 388685
[1,0]<stdout>:#Input tokens: 4096
[1,0]<stdout>:#Output tokens: 256
[1,0]<stdout>:[2025-10-12 02:00:22] 
[1,0]<stdout>:Warmup...
[1,0]<stdout>:[2025-10-12 02:00:22 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 514, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 02:00:22 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 02:00:22 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 02:00:23 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 02:00:23 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 02:00:23 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 02:00:23 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 02:00:23 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 02:00:23 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 02:00:23 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 1000.89it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 14084.69it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 17534.10it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 13755.57it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 12940.39it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 13573.80it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 14195.92it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 13553.70it/s]
[1,0]<stdout>:[2025-10-12 02:00:24 DP0 TP0] Prefill batch. #new-seq: 6, #new-token: 1530, #cached-token: 12, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP8] Prefill batch. #new-seq: 8, #new-token: 2048, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 02:00:24 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 6766.83it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 15366.10it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 16134.52it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 13776.28it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 15139.61it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 13992.67it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 15192.17it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 15254.33it/s]
[1,1]<stdout>:[2025-10-12 02:00:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 0, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 02:00:27] 
[1,0]<stdout>:Benchmark...
[1,0]<stdout>:[2025-10-12 02:00:27 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 515, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 02:00:27 DP1 TP8] Prefill batch. #new-seq: 13, #new-token: 2048, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 78, 
[1,0]<stdout>:[2025-10-12 02:00:27 DP0 TP0] Prefill batch. #new-seq: 13, #new-token: 2048, #cached-token: 18, token usage: 0.00, #running-req: 2, #queue-req: 78, 
[1,1]<stdout>:[2025-10-12 02:00:27 DP1 TP8] Prefill batch. #new-seq: 3, #new-token: 2048, #cached-token: 2, token usage: 0.01, #running-req: 12, #queue-req: 206, 
[1,0]<stdout>:[2025-10-12 02:00:27 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 2048, #cached-token: 1, token usage: 0.02, #running-req: 14, #queue-req: 206, 
[1,1]<stdout>:[2025-10-12 02:00:27 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 426, #cached-token: 1, token usage: 0.03, #running-req: 14, #queue-req: 329, 
[1,0]<stdout>:[2025-10-12 02:00:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 0, token usage: 0.03, #running-req: 15, #queue-req: 329, 
[1,1]<stdout>:[2025-10-12 02:00:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 685, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 983, 
[1,0]<stdout>:[2025-10-12 02:00:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 983, 
[1,1]<stdout>:[2025-10-12 02:00:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 982, 
[1,0]<stdout>:[2025-10-12 02:00:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 982, 
[1,1]<stdout>:[2025-10-12 02:00:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 981, 
[1,0]<stdout>:[2025-10-12 02:00:30 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 804, #cached-token: 4, token usage: 0.02, #running-req: 14, #queue-req: 980, 
[1,1]<stdout>:[2025-10-12 02:00:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 477, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 980, 
[1,0]<stdout>:[2025-10-12 02:00:31 DP0 TP0] Decode batch. #running-req: 16, #token: 4701, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 22.27, #queue-req: 980, 
[1,1]<stdout>:[2025-10-12 02:00:31 DP1 TP8] Decode batch. #running-req: 16, #token: 4247, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 22.23, #queue-req: 980, 
[1,0]<stdout>:[2025-10-12 02:00:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 979, 
[1,0]<stdout>:[2025-10-12 02:00:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 302, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 978, 
[1,0]<stdout>:[2025-10-12 02:00:32 DP0 TP0] Decode batch. #running-req: 16, #token: 5231, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.79, #queue-req: 978, 
[1,1]<stdout>:[2025-10-12 02:00:32 DP1 TP8] Decode batch. #running-req: 16, #token: 4887, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 451.18, #queue-req: 980, 
[1,1]<stdout>:[2025-10-12 02:00:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 725, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 979, 
[1,1]<stdout>:[2025-10-12 02:00:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 978, 
[1,0]<stdout>:[2025-10-12 02:00:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 977, 
[1,1]<stdout>:[2025-10-12 02:00:34 DP1 TP8] Decode batch. #running-req: 16, #token: 6059, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 403.45, #queue-req: 978, 
[1,0]<stdout>:[2025-10-12 02:00:34 DP0 TP0] Decode batch. #running-req: 16, #token: 6036, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 404.02, #queue-req: 977, 
[1,1]<stdout>:[2025-10-12 02:00:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 977, 
[1,0]<stdout>:[2025-10-12 02:00:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 976, 
[1,1]<stdout>:[2025-10-12 02:00:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 976, 
[1,1]<stdout>:[2025-10-12 02:00:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 975, 
[1,1]<stdout>:[2025-10-12 02:00:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 974, 
[1,1]<stdout>:[2025-10-12 02:00:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 973, 
[1,1]<stdout>:[2025-10-12 02:00:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 972, 
[1,0]<stdout>:[2025-10-12 02:00:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1904, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 975, 
[1,1]<stdout>:[2025-10-12 02:00:36 DP1 TP8] Decode batch. #running-req: 16, #token: 6150, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 258.39, #queue-req: 972, 
[1,0]<stdout>:[2025-10-12 02:00:36 DP0 TP0] Decode batch. #running-req: 16, #token: 8889, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 260.02, #queue-req: 975, 
[1,1]<stdout>:[2025-10-12 02:00:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 971, 
[1,1]<stdout>:[2025-10-12 02:00:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 970, 
[1,0]<stdout>:[2025-10-12 02:00:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 974, 
[1,0]<stdout>:[2025-10-12 02:00:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 973, 
[1,1]<stdout>:[2025-10-12 02:00:38 DP1 TP8] Decode batch. #running-req: 16, #token: 6459, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 368.06, #queue-req: 970, 
[1,0]<stdout>:[2025-10-12 02:00:38 DP0 TP0] Decode batch. #running-req: 16, #token: 8831, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 368.04, #queue-req: 973, 
[1,0]<stdout>:[2025-10-12 02:00:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 972, 
[1,0]<stdout>:[2025-10-12 02:00:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 971, 
[1,0]<stdout>:[2025-10-12 02:00:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 970, 
[1,0]<stdout>:[2025-10-12 02:00:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 969, 
[1,0]<stdout>:[2025-10-12 02:00:40 DP0 TP0] Decode batch. #running-req: 16, #token: 6230, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.95, #queue-req: 969, 
[1,1]<stdout>:[2025-10-12 02:00:40 DP1 TP8] Decode batch. #running-req: 16, #token: 7099, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.37, #queue-req: 970, 
[1,0]<stdout>:[2025-10-12 02:00:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 968, 
[1,0]<stdout>:[2025-10-12 02:00:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 967, 
[1,1]<stdout>:[2025-10-12 02:00:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 969, 
[1,0]<stdout>:[2025-10-12 02:00:41 DP0 TP0] Decode batch. #running-req: 16, #token: 4843, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 429.06, #queue-req: 967, 
[1,1]<stdout>:[2025-10-12 02:00:41 DP1 TP8] Decode batch. #running-req: 16, #token: 7481, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 429.62, #queue-req: 969, 
[1,1]<stdout>:[2025-10-12 02:00:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 968, 
[1,0]<stdout>:[2025-10-12 02:00:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 966, 
[1,1]<stdout>:[2025-10-12 02:00:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 967, 
[1,1]<stdout>:[2025-10-12 02:00:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 966, 
[1,0]<stdout>:[2025-10-12 02:00:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 965, 
[1,0]<stdout>:[2025-10-12 02:00:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 964, 
[1,0]<stdout>:[2025-10-12 02:00:43 DP0 TP0] Decode batch. #running-req: 16, #token: 5008, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 295.76, #queue-req: 964, 
[1,1]<stdout>:[2025-10-12 02:00:43 DP1 TP8] Decode batch. #running-req: 16, #token: 6951, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 295.81, #queue-req: 966, 
[1,1]<stdout>:[2025-10-12 02:00:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 965, 
[1,1]<stdout>:[2025-10-12 02:00:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 964, 
[1,1]<stdout>:[2025-10-12 02:00:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 963, 
[1,0]<stdout>:[2025-10-12 02:00:45 DP0 TP0] Decode batch. #running-req: 16, #token: 5648, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 425.63, #queue-req: 964, 
[1,1]<stdout>:[2025-10-12 02:00:45 DP1 TP8] Decode batch. #running-req: 16, #token: 5684, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 423.61, #queue-req: 963, 
[1,1]<stdout>:[2025-10-12 02:00:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 962, 
[1,0]<stdout>:[2025-10-12 02:00:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 774, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 963, 
[1,0]<stdout>:[2025-10-12 02:00:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 962, 
[1,1]<stdout>:[2025-10-12 02:00:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 961, 
[1,0]<stdout>:[2025-10-12 02:00:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 961, 
[1,0]<stdout>:[2025-10-12 02:00:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 960, 
[1,1]<stdout>:[2025-10-12 02:00:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 411, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 960, 
[1,1]<stdout>:[2025-10-12 02:00:47 DP1 TP8] Decode batch. #running-req: 16, #token: 6410, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 296.38, #queue-req: 960, 
[1,0]<stdout>:[2025-10-12 02:00:47 DP0 TP0] Decode batch. #running-req: 16, #token: 6616, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 295.89, #queue-req: 960, 
[1,0]<stdout>:[2025-10-12 02:00:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 959, 
[1,0]<stdout>:[2025-10-12 02:00:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1381, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 958, 
[1,1]<stdout>:[2025-10-12 02:00:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 959, 
[1,1]<stdout>:[2025-10-12 02:00:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1818, #cached-token: 0, token usage: 0.05, #running-req: 15, #queue-req: 959, 
[1,0]<stdout>:[2025-10-12 02:00:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 957, 
[1,1]<stdout>:[2025-10-12 02:00:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 958, 
[1,1]<stdout>:[2025-10-12 02:00:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 957, 
[1,1]<stdout>:[2025-10-12 02:00:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 956, 
[1,0]<stdout>:[2025-10-12 02:00:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 460, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 956, 
[1,1]<stdout>:[2025-10-12 02:00:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 955, 
[1,1]<stdout>:[2025-10-12 02:00:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 954, 
[1,0]<stdout>:[2025-10-12 02:00:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 5, token usage: 0.04, #running-req: 15, #queue-req: 955, 
[1,0]<stdout>:[2025-10-12 02:00:50 DP0 TP0] Decode batch. #running-req: 16, #token: 6401, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 224.29, #queue-req: 955, 
[1,1]<stdout>:[2025-10-12 02:00:50 DP1 TP8] Decode batch. #running-req: 16, #token: 5087, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 223.93, #queue-req: 954, 
[1,0]<stdout>:[2025-10-12 02:00:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 773, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 954, 
[1,0]<stdout>:[2025-10-12 02:00:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 953, 
[1,0]<stdout>:[2025-10-12 02:00:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 952, 
[1,0]<stdout>:[2025-10-12 02:00:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 951, 
[1,0]<stdout>:[2025-10-12 02:00:52 DP0 TP0] Decode batch. #running-req: 16, #token: 6084, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 368.52, #queue-req: 951, 
[1,1]<stdout>:[2025-10-12 02:00:52 DP1 TP8] Decode batch. #running-req: 15, #token: 5233, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 370.21, #queue-req: 954, 
[1,1]<stdout>:[2025-10-12 02:00:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 953, 
[1,1]<stdout>:[2025-10-12 02:00:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 952, 
[1,1]<stdout>:[2025-10-12 02:00:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 951, 
[1,1]<stdout>:[2025-10-12 02:00:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 950, 
[1,1]<stdout>:[2025-10-12 02:00:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 949, 
[1,1]<stdout>:[2025-10-12 02:00:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 575, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 948, 
[1,1]<stdout>:[2025-10-12 02:00:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 947, 
[1,0]<stdout>:[2025-10-12 02:00:54 DP0 TP0] Decode batch. #running-req: 16, #token: 6724, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 306.27, #queue-req: 951, 
[1,1]<stdout>:[2025-10-12 02:00:54 DP1 TP8] Decode batch. #running-req: 16, #token: 5452, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 303.42, #queue-req: 947, 
[1,1]<stdout>:[2025-10-12 02:00:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 946, 
[1,0]<stdout>:[2025-10-12 02:00:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 950, 
[1,0]<stdout>:[2025-10-12 02:00:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 949, 
[1,1]<stdout>:[2025-10-12 02:00:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 945, 
[1,1]<stdout>:[2025-10-12 02:00:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 944, 
[1,1]<stdout>:[2025-10-12 02:00:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 0, token usage: 0.04, #running-req: 15, #queue-req: 944, 
[1,1]<stdout>:[2025-10-12 02:00:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 943, 
[1,1]<stdout>:[2025-10-12 02:00:56 DP1 TP8] Decode batch. #running-req: 16, #token: 4553, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 301.96, #queue-req: 943, 
[1,0]<stdout>:[2025-10-12 02:00:56 DP0 TP0] Decode batch. #running-req: 15, #token: 5935, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 302.34, #queue-req: 949, 
[1,0]<stdout>:[2025-10-12 02:00:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 948, 
[1,0]<stdout>:[2025-10-12 02:00:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 947, 
[1,0]<stdout>:[2025-10-12 02:00:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 946, 
[1,0]<stdout>:[2025-10-12 02:00:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 945, 
[1,0]<stdout>:[2025-10-12 02:00:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 944, 
[1,0]<stdout>:[2025-10-12 02:00:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 943, 
[1,1]<stdout>:[2025-10-12 02:00:58 DP1 TP8] Decode batch. #running-req: 16, #token: 5193, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 329.82, #queue-req: 943, 
[1,0]<stdout>:[2025-10-12 02:00:58 DP0 TP0] Decode batch. #running-req: 15, #token: 5108, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 326.80, #queue-req: 943, 
[1,0]<stdout>:[2025-10-12 02:00:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 11, token usage: 0.03, #running-req: 15, #queue-req: 942, 
[1,0]<stdout>:[2025-10-12 02:00:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 941, 
[1,0]<stdout>:[2025-10-12 02:00:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 940, 
[1,0]<stdout>:[2025-10-12 02:00:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 939, 
[1,1]<stdout>:[2025-10-12 02:00:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 942, 
[1,1]<stdout>:[2025-10-12 02:00:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 941, 
[1,0]<stdout>:[2025-10-12 02:00:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 938, 
[1,1]<stdout>:[2025-10-12 02:00:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 940, 
[1,0]<stdout>:[2025-10-12 02:01:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 937, 
[1,1]<stdout>:[2025-10-12 02:01:00 DP1 TP8] Decode batch. #running-req: 16, #token: 4590, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 272.07, #queue-req: 940, 
[1,0]<stdout>:[2025-10-12 02:01:00 DP0 TP0] Decode batch. #running-req: 16, #token: 4803, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 271.24, #queue-req: 937, 
[1,0]<stdout>:[2025-10-12 02:01:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 936, 
[1,0]<stdout>:[2025-10-12 02:01:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 935, 
[1,0]<stdout>:[2025-10-12 02:01:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 934, 
[1,1]<stdout>:[2025-10-12 02:01:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 939, 
[1,1]<stdout>:[2025-10-12 02:01:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 938, 
[1,0]<stdout>:[2025-10-12 02:01:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 933, 
[1,1]<stdout>:[2025-10-12 02:01:02 DP1 TP8] Decode batch. #running-req: 16, #token: 6117, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.51, #queue-req: 938, 
[1,0]<stdout>:[2025-10-12 02:01:02 DP0 TP0] Decode batch. #running-req: 16, #token: 4769, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.37, #queue-req: 933, 
[1,1]<stdout>:[2025-10-12 02:01:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 429, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 937, 
[1,0]<stdout>:[2025-10-12 02:01:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 932, 
[1,1]<stdout>:[2025-10-12 02:01:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 936, 
[1,0]<stdout>:[2025-10-12 02:01:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 806, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 931, 
[1,1]<stdout>:[2025-10-12 02:01:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 935, 
[1,1]<stdout>:[2025-10-12 02:01:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 934, 
[1,0]<stdout>:[2025-10-12 02:01:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 930, 
[1,0]<stdout>:[2025-10-12 02:01:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 929, 
[1,0]<stdout>:[2025-10-12 02:01:04 DP0 TP0] Decode batch. #running-req: 16, #token: 5134, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.56, #queue-req: 929, 
[1,1]<stdout>:[2025-10-12 02:01:04 DP1 TP8] Decode batch. #running-req: 16, #token: 5407, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.50, #queue-req: 934, 
[1,1]<stdout>:[2025-10-12 02:01:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 933, 
[1,0]<stdout>:[2025-10-12 02:01:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 617, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 928, 
[1,0]<stdout>:[2025-10-12 02:01:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 927, 
[1,1]<stdout>:[2025-10-12 02:01:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1978, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 932, 
[1,0]<stdout>:[2025-10-12 02:01:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 926, 
[1,0]<stdout>:[2025-10-12 02:01:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1389, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 925, 
[1,0]<stdout>:[2025-10-12 02:01:06 DP0 TP0] Decode batch. #running-req: 16, #token: 6719, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 324.29, #queue-req: 925, 
[1,1]<stdout>:[2025-10-12 02:01:06 DP1 TP8] Decode batch. #running-req: 16, #token: 8006, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 325.30, #queue-req: 932, 
[1,0]<stdout>:[2025-10-12 02:01:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 924, 
[1,0]<stdout>:[2025-10-12 02:01:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 699, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 923, 
[1,0]<stdout>:[2025-10-12 02:01:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.03, #running-req: 15, #queue-req: 922, 
[1,0]<stdout>:[2025-10-12 02:01:07 DP0 TP0] Decode batch. #running-req: 16, #token: 5120, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 427.09, #queue-req: 922, 
[1,1]<stdout>:[2025-10-12 02:01:07 DP1 TP8] Decode batch. #running-req: 16, #token: 8452, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 429.09, #queue-req: 932, 
[1,1]<stdout>:[2025-10-12 02:01:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 931, 
[1,1]<stdout>:[2025-10-12 02:01:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 930, 
[1,0]<stdout>:[2025-10-12 02:01:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 921, 
[1,0]<stdout>:[2025-10-12 02:01:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 920, 
[1,0]<stdout>:[2025-10-12 02:01:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 919, 
[1,1]<stdout>:[2025-10-12 02:01:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 929, 
[1,0]<stdout>:[2025-10-12 02:01:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 918, 
[1,1]<stdout>:[2025-10-12 02:01:10 DP1 TP8] Decode batch. #running-req: 16, #token: 7103, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 308.66, #queue-req: 929, 
[1,0]<stdout>:[2025-10-12 02:01:10 DP0 TP0] Decode batch. #running-req: 16, #token: 4139, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 308.11, #queue-req: 918, 
[1,0]<stdout>:[2025-10-12 02:01:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 917, 
[1,1]<stdout>:[2025-10-12 02:01:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 928, 
[1,0]<stdout>:[2025-10-12 02:01:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 916, 
[1,0]<stdout>:[2025-10-12 02:01:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 915, 
[1,1]<stdout>:[2025-10-12 02:01:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 927, 
[1,0]<stdout>:[2025-10-12 02:01:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 914, 
[1,1]<stdout>:[2025-10-12 02:01:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 926, 
[1,1]<stdout>:[2025-10-12 02:01:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 703, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 925, 
[1,1]<stdout>:[2025-10-12 02:01:12 DP1 TP8] Decode batch. #running-req: 16, #token: 6892, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 307.83, #queue-req: 925, 
[1,0]<stdout>:[2025-10-12 02:01:12 DP0 TP0] Decode batch. #running-req: 15, #token: 4223, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 307.32, #queue-req: 914, 
[1,0]<stdout>:[2025-10-12 02:01:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 913, 
[1,0]<stdout>:[2025-10-12 02:01:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 385, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 912, 
[1,1]<stdout>:[2025-10-12 02:01:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 924, 
[1,0]<stdout>:[2025-10-12 02:01:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1066, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 911, 
[1,1]<stdout>:[2025-10-12 02:01:13 DP1 TP8] Decode batch. #running-req: 16, #token: 7150, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 370.91, #queue-req: 924, 
[1,0]<stdout>:[2025-10-12 02:01:13 DP0 TP0] Decode batch. #running-req: 16, #token: 6190, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 370.14, #queue-req: 911, 
[1,0]<stdout>:[2025-10-12 02:01:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 910, 
[1,1]<stdout>:[2025-10-12 02:01:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 923, 
[1,1]<stdout>:[2025-10-12 02:01:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 922, 
[1,1]<stdout>:[2025-10-12 02:01:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 810, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 921, 
[1,1]<stdout>:[2025-10-12 02:01:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 920, 
[1,0]<stdout>:[2025-10-12 02:01:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 909, 
[1,0]<stdout>:[2025-10-12 02:01:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 908, 
[1,1]<stdout>:[2025-10-12 02:01:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 919, 
[1,0]<stdout>:[2025-10-12 02:01:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 907, 
[1,1]<stdout>:[2025-10-12 02:01:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 918, 
[1,1]<stdout>:[2025-10-12 02:01:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 917, 
[1,1]<stdout>:[2025-10-12 02:01:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 916, 
[1,0]<stdout>:[2025-10-12 02:01:16 DP0 TP0] Decode batch. #running-req: 16, #token: 6760, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 237.89, #queue-req: 907, 
[1,1]<stdout>:[2025-10-12 02:01:16 DP1 TP8] Decode batch. #running-req: 16, #token: 6769, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 236.26, #queue-req: 916, 
[1,1]<stdout>:[2025-10-12 02:01:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 494, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 915, 
[1,0]<stdout>:[2025-10-12 02:01:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 906, 
[1,0]<stdout>:[2025-10-12 02:01:17 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 596, #cached-token: 3, token usage: 0.04, #running-req: 14, #queue-req: 904, 
[1,1]<stdout>:[2025-10-12 02:01:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 914, 
[1,1]<stdout>:[2025-10-12 02:01:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 913, 
[1,0]<stdout>:[2025-10-12 02:01:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 903, 
[1,0]<stdout>:[2025-10-12 02:01:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 902, 
[1,0]<stdout>:[2025-10-12 02:01:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 901, 
[1,0]<stdout>:[2025-10-12 02:01:18 DP0 TP0] Decode batch. #running-req: 16, #token: 6523, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 280.78, #queue-req: 901, 
[1,1]<stdout>:[2025-10-12 02:01:18 DP1 TP8] Decode batch. #running-req: 16, #token: 7232, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 282.15, #queue-req: 913, 
[1,0]<stdout>:[2025-10-12 02:01:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 900, 
[1,0]<stdout>:[2025-10-12 02:01:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 899, 
[1,0]<stdout>:[2025-10-12 02:01:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 898, 
[1,1]<stdout>:[2025-10-12 02:01:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 912, 
[1,0]<stdout>:[2025-10-12 02:01:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 897, 
[1,0]<stdout>:[2025-10-12 02:01:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 896, 
[1,1]<stdout>:[2025-10-12 02:01:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 911, 
[1,0]<stdout>:[2025-10-12 02:01:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 895, 
[1,1]<stdout>:[2025-10-12 02:01:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 910, 
[1,0]<stdout>:[2025-10-12 02:01:21 DP0 TP0] Decode batch. #running-req: 16, #token: 5785, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 266.55, #queue-req: 895, 
[1,1]<stdout>:[2025-10-12 02:01:21 DP1 TP8] Decode batch. #running-req: 16, #token: 7135, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 267.83, #queue-req: 910, 
[1,0]<stdout>:[2025-10-12 02:01:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 894, 
[1,1]<stdout>:[2025-10-12 02:01:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 909, 
[1,0]<stdout>:[2025-10-12 02:01:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 893, 
[1,1]<stdout>:[2025-10-12 02:01:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 765, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 908, 
[1,1]<stdout>:[2025-10-12 02:01:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1228, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 907, 
[1,0]<stdout>:[2025-10-12 02:01:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 892, 
[1,1]<stdout>:[2025-10-12 02:01:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 906, 
[1,0]<stdout>:[2025-10-12 02:01:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 891, 
[1,1]<stdout>:[2025-10-12 02:01:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 5, token usage: 0.04, #running-req: 15, #queue-req: 905, 
[1,1]<stdout>:[2025-10-12 02:01:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 904, 
[1,0]<stdout>:[2025-10-12 02:01:23 DP0 TP0] Decode batch. #running-req: 16, #token: 6255, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 248.73, #queue-req: 891, 
[1,1]<stdout>:[2025-10-12 02:01:23 DP1 TP8] Decode batch. #running-req: 16, #token: 5636, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 247.93, #queue-req: 904, 
[1,0]<stdout>:[2025-10-12 02:01:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 890, 
[1,1]<stdout>:[2025-10-12 02:01:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 903, 
[1,0]<stdout>:[2025-10-12 02:01:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 7, token usage: 0.04, #running-req: 15, #queue-req: 889, 
[1,0]<stdout>:[2025-10-12 02:01:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 888, 
[1,0]<stdout>:[2025-10-12 02:01:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 8, token usage: 0.03, #running-req: 15, #queue-req: 887, 
[1,1]<stdout>:[2025-10-12 02:01:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 902, 
[1,0]<stdout>:[2025-10-12 02:01:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 886, 
[1,0]<stdout>:[2025-10-12 02:01:25 DP0 TP0] Decode batch. #running-req: 16, #token: 5454, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 304.30, #queue-req: 886, 
[1,1]<stdout>:[2025-10-12 02:01:25 DP1 TP8] Decode batch. #running-req: 16, #token: 4293, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 305.72, #queue-req: 902, 
[1,0]<stdout>:[2025-10-12 02:01:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 529, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 885, 
[1,1]<stdout>:[2025-10-12 02:01:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 901, 
[1,0]<stdout>:[2025-10-12 02:01:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 884, 
[1,0]<stdout>:[2025-10-12 02:01:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 883, 
[1,1]<stdout>:[2025-10-12 02:01:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 900, 
[1,0]<stdout>:[2025-10-12 02:01:27 DP0 TP0] Decode batch. #running-req: 16, #token: 6167, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.37, #queue-req: 883, 
[1,1]<stdout>:[2025-10-12 02:01:27 DP1 TP8] Decode batch. #running-req: 16, #token: 4613, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.86, #queue-req: 900, 
[1,1]<stdout>:[2025-10-12 02:01:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 899, 
[1,1]<stdout>:[2025-10-12 02:01:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 898, 
[1,0]<stdout>:[2025-10-12 02:01:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 882, 
[1,0]<stdout>:[2025-10-12 02:01:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 881, 
[1,1]<stdout>:[2025-10-12 02:01:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 897, 
[1,0]<stdout>:[2025-10-12 02:01:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 880, 
[1,0]<stdout>:[2025-10-12 02:01:29 DP0 TP0] Decode batch. #running-req: 16, #token: 5986, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.26, #queue-req: 880, 
[1,1]<stdout>:[2025-10-12 02:01:29 DP1 TP8] Decode batch. #running-req: 16, #token: 4348, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.28, #queue-req: 897, 
[1,1]<stdout>:[2025-10-12 02:01:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 896, 
[1,0]<stdout>:[2025-10-12 02:01:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 879, 
[1,0]<stdout>:[2025-10-12 02:01:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 878, 
[1,1]<stdout>:[2025-10-12 02:01:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 895, 
[1,1]<stdout>:[2025-10-12 02:01:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 894, 
[1,0]<stdout>:[2025-10-12 02:01:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 877, 
[1,0]<stdout>:[2025-10-12 02:01:31 DP0 TP0] Decode batch. #running-req: 15, #token: 6338, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 329.59, #queue-req: 877, 
[1,1]<stdout>:[2025-10-12 02:01:31 DP1 TP8] Decode batch. #running-req: 16, #token: 3768, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 330.20, #queue-req: 894, 
[1,0]<stdout>:[2025-10-12 02:01:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 876, 
[1,1]<stdout>:[2025-10-12 02:01:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 893, 
[1,0]<stdout>:[2025-10-12 02:01:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 430, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 875, 
[1,0]<stdout>:[2025-10-12 02:01:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 874, 
[1,1]<stdout>:[2025-10-12 02:01:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 892, 
[1,0]<stdout>:[2025-10-12 02:01:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 873, 
[1,1]<stdout>:[2025-10-12 02:01:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 891, 
[1,0]<stdout>:[2025-10-12 02:01:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 872, 
[1,1]<stdout>:[2025-10-12 02:01:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 890, 
[1,0]<stdout>:[2025-10-12 02:01:33 DP0 TP0] Decode batch. #running-req: 16, #token: 6235, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 285.04, #queue-req: 872, 
[1,1]<stdout>:[2025-10-12 02:01:33 DP1 TP8] Decode batch. #running-req: 16, #token: 4316, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 285.07, #queue-req: 890, 
[1,0]<stdout>:[2025-10-12 02:01:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 871, 
[1,1]<stdout>:[2025-10-12 02:01:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 889, 
[1,0]<stdout>:[2025-10-12 02:01:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 870, 
[1,0]<stdout>:[2025-10-12 02:01:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 869, 
[1,0]<stdout>:[2025-10-12 02:01:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 868, 
[1,0]<stdout>:[2025-10-12 02:01:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 867, 
[1,1]<stdout>:[2025-10-12 02:01:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 888, 
[1,0]<stdout>:[2025-10-12 02:01:35 DP0 TP0] Decode batch. #running-req: 16, #token: 6701, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 304.08, #queue-req: 867, 
[1,1]<stdout>:[2025-10-12 02:01:35 DP1 TP8] Decode batch. #running-req: 16, #token: 4385, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 305.47, #queue-req: 888, 
[1,1]<stdout>:[2025-10-12 02:01:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 887, 
[1,0]<stdout>:[2025-10-12 02:01:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 866, 
[1,0]<stdout>:[2025-10-12 02:01:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 868, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 865, 
[1,1]<stdout>:[2025-10-12 02:01:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 886, 
[1,1]<stdout>:[2025-10-12 02:01:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 885, 
[1,0]<stdout>:[2025-10-12 02:01:37 DP0 TP0] Decode batch. #running-req: 16, #token: 7237, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 357.74, #queue-req: 865, 
[1,1]<stdout>:[2025-10-12 02:01:37 DP1 TP8] Decode batch. #running-req: 16, #token: 4111, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 357.13, #queue-req: 885, 
[1,1]<stdout>:[2025-10-12 02:01:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 884, 
[1,1]<stdout>:[2025-10-12 02:01:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 883, 
[1,0]<stdout>:[2025-10-12 02:01:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 864, 
[1,1]<stdout>:[2025-10-12 02:01:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 882, 
[1,1]<stdout>:[2025-10-12 02:01:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 881, 
[1,1]<stdout>:[2025-10-12 02:01:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 880, 
[1,0]<stdout>:[2025-10-12 02:01:39 DP0 TP0] Decode batch. #running-req: 15, #token: 6713, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 329.46, #queue-req: 864, 
[1,1]<stdout>:[2025-10-12 02:01:39 DP1 TP8] Decode batch. #running-req: 16, #token: 3566, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 327.93, #queue-req: 880, 
[1,0]<stdout>:[2025-10-12 02:01:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 863, 
[1,1]<stdout>:[2025-10-12 02:01:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 879, 
[1,1]<stdout>:[2025-10-12 02:01:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 878, 
[1,1]<stdout>:[2025-10-12 02:01:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 877, 
[1,0]<stdout>:[2025-10-12 02:01:40 DP0 TP0] Decode batch. #running-req: 16, #token: 7453, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 387.21, #queue-req: 863, 
[1,1]<stdout>:[2025-10-12 02:01:40 DP1 TP8] Decode batch. #running-req: 16, #token: 4059, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 385.39, #queue-req: 877, 
[1,1]<stdout>:[2025-10-12 02:01:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 876, 
[1,0]<stdout>:[2025-10-12 02:01:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 862, 
[1,0]<stdout>:[2025-10-12 02:01:42 DP0 TP0] Decode batch. #running-req: 16, #token: 6988, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 474.64, #queue-req: 862, 
[1,1]<stdout>:[2025-10-12 02:01:42 DP1 TP8] Decode batch. #running-req: 16, #token: 4493, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 474.71, #queue-req: 876, 
[1,0]<stdout>:[2025-10-12 02:01:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 493, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 861, 
[1,1]<stdout>:[2025-10-12 02:01:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 875, 
[1,0]<stdout>:[2025-10-12 02:01:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 860, 
[1,1]<stdout>:[2025-10-12 02:01:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 734, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 874, 
[1,0]<stdout>:[2025-10-12 02:01:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 859, 
[1,1]<stdout>:[2025-10-12 02:01:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 873, 
[1,0]<stdout>:[2025-10-12 02:01:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 858, 
[1,1]<stdout>:[2025-10-12 02:01:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 872, 
[1,1]<stdout>:[2025-10-12 02:01:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 871, 
[1,0]<stdout>:[2025-10-12 02:01:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 857, 
[1,1]<stdout>:[2025-10-12 02:01:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 923, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 870, 
[1,0]<stdout>:[2025-10-12 02:01:44 DP0 TP0] Decode batch. #running-req: 16, #token: 6587, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 238.00, #queue-req: 857, 
[1,1]<stdout>:[2025-10-12 02:01:44 DP1 TP8] Decode batch. #running-req: 16, #token: 5127, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 237.60, #queue-req: 870, 
[1,1]<stdout>:[2025-10-12 02:01:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 869, 
[1,1]<stdout>:[2025-10-12 02:01:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 868, 
[1,1]<stdout>:[2025-10-12 02:01:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 867, 
[1,1]<stdout>:[2025-10-12 02:01:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 866, 
[1,0]<stdout>:[2025-10-12 02:01:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 856, 
[1,1]<stdout>:[2025-10-12 02:01:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 673, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 865, 
[1,1]<stdout>:[2025-10-12 02:01:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 864, 
[1,0]<stdout>:[2025-10-12 02:01:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 855, 
[1,0]<stdout>:[2025-10-12 02:01:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 854, 
[1,0]<stdout>:[2025-10-12 02:01:47 DP0 TP0] Decode batch. #running-req: 14, #token: 6826, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 266.88, #queue-req: 854, 
[1,1]<stdout>:[2025-10-12 02:01:47 DP1 TP8] Decode batch. #running-req: 16, #token: 5465, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 266.49, #queue-req: 864, 
[1,0]<stdout>:[2025-10-12 02:01:47 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 663, #cached-token: 7, token usage: 0.04, #running-req: 14, #queue-req: 852, 
[1,1]<stdout>:[2025-10-12 02:01:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 660, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 863, 
[1,1]<stdout>:[2025-10-12 02:01:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 862, 
[1,1]<stdout>:[2025-10-12 02:01:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 861, 
[1,0]<stdout>:[2025-10-12 02:01:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 851, 
[1,0]<stdout>:[2025-10-12 02:01:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 850, 
[1,1]<stdout>:[2025-10-12 02:01:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 860, 
[1,0]<stdout>:[2025-10-12 02:01:49 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 560, #cached-token: 7, token usage: 0.04, #running-req: 14, #queue-req: 848, 
[1,1]<stdout>:[2025-10-12 02:01:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 859, 
[1,0]<stdout>:[2025-10-12 02:01:49 DP0 TP0] Decode batch. #running-req: 16, #token: 7068, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 269.10, #queue-req: 848, 
[1,1]<stdout>:[2025-10-12 02:01:49 DP1 TP8] Decode batch. #running-req: 15, #token: 4524, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 268.24, #queue-req: 859, 
[1,1]<stdout>:[2025-10-12 02:01:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 858, 
[1,1]<stdout>:[2025-10-12 02:01:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 669, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 857, 
[1,1]<stdout>:[2025-10-12 02:01:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 856, 
[1,1]<stdout>:[2025-10-12 02:01:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 855, 
[1,1]<stdout>:[2025-10-12 02:01:51 DP1 TP8] Decode batch. #running-req: 16, #token: 5227, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 386.87, #queue-req: 855, 
[1,0]<stdout>:[2025-10-12 02:01:51 DP0 TP0] Decode batch. #running-req: 16, #token: 7023, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 388.64, #queue-req: 848, 
[1,0]<stdout>:[2025-10-12 02:01:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 847, 
[1,1]<stdout>:[2025-10-12 02:01:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 854, 
[1,1]<stdout>:[2025-10-12 02:01:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 853, 
[1,1]<stdout>:[2025-10-12 02:01:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 6, token usage: 0.03, #running-req: 15, #queue-req: 852, 
[1,1]<stdout>:[2025-10-12 02:01:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 851, 
[1,0]<stdout>:[2025-10-12 02:01:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 452, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 846, 
[1,0]<stdout>:[2025-10-12 02:01:53 DP0 TP0] Decode batch. #running-req: 16, #token: 8663, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 327.92, #queue-req: 846, 
[1,1]<stdout>:[2025-10-12 02:01:53 DP1 TP8] Decode batch. #running-req: 16, #token: 5729, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 326.92, #queue-req: 851, 
[1,0]<stdout>:[2025-10-12 02:01:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 845, 
[1,1]<stdout>:[2025-10-12 02:01:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 850, 
[1,0]<stdout>:[2025-10-12 02:01:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 844, 
[1,1]<stdout>:[2025-10-12 02:01:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 849, 
[1,0]<stdout>:[2025-10-12 02:01:54 DP0 TP0] Decode batch. #running-req: 16, #token: 8556, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 423.50, #queue-req: 844, 
[1,1]<stdout>:[2025-10-12 02:01:54 DP1 TP8] Decode batch. #running-req: 16, #token: 5785, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 423.39, #queue-req: 849, 
[1,0]<stdout>:[2025-10-12 02:01:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 843, 
[1,0]<stdout>:[2025-10-12 02:01:54 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 116, #cached-token: 3, token usage: 0.05, #running-req: 14, #queue-req: 841, 
[1,0]<stdout>:[2025-10-12 02:01:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 840, 
[1,0]<stdout>:[2025-10-12 02:01:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 839, 
[1,0]<stdout>:[2025-10-12 02:01:56 DP0 TP0] Decode batch. #running-req: 16, #token: 8565, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 391.14, #queue-req: 839, 
[1,1]<stdout>:[2025-10-12 02:01:56 DP1 TP8] Decode batch. #running-req: 16, #token: 6425, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 394.24, #queue-req: 849, 
[1,0]<stdout>:[2025-10-12 02:01:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 903, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 838, 
[1,1]<stdout>:[2025-10-12 02:01:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 224, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 848, 
[1,1]<stdout>:[2025-10-12 02:01:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 847, 
[1,0]<stdout>:[2025-10-12 02:01:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 837, 
[1,1]<stdout>:[2025-10-12 02:01:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 5, token usage: 0.04, #running-req: 15, #queue-req: 846, 
[1,1]<stdout>:[2025-10-12 02:01:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 845, 
[1,0]<stdout>:[2025-10-12 02:01:58 DP0 TP0] Decode batch. #running-req: 15, #token: 9153, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.96, #queue-req: 837, 
[1,1]<stdout>:[2025-10-12 02:01:58 DP1 TP8] Decode batch. #running-req: 16, #token: 6218, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.41, #queue-req: 845, 
[1,0]<stdout>:[2025-10-12 02:01:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 836, 
[1,1]<stdout>:[2025-10-12 02:01:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 844, 
[1,1]<stdout>:[2025-10-12 02:01:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 843, 
[1,1]<stdout>:[2025-10-12 02:01:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 842, 
[1,0]<stdout>:[2025-10-12 02:01:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 835, 
[1,1]<stdout>:[2025-10-12 02:01:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 841, 
[1,1]<stdout>:[2025-10-12 02:01:59 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 481, #cached-token: 9, token usage: 0.04, #running-req: 14, #queue-req: 839, 
[1,0]<stdout>:[2025-10-12 02:01:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 834, 
[1,1]<stdout>:[2025-10-12 02:02:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 838, 
[1,1]<stdout>:[2025-10-12 02:02:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 837, 
[1,1]<stdout>:[2025-10-12 02:02:00 DP1 TP8] Decode batch. #running-req: 16, #token: 5487, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 247.49, #queue-req: 837, 
[1,0]<stdout>:[2025-10-12 02:02:00 DP0 TP0] Decode batch. #running-req: 16, #token: 6942, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 249.83, #queue-req: 834, 
[1,0]<stdout>:[2025-10-12 02:02:00 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 428, #cached-token: 5, token usage: 0.04, #running-req: 14, #queue-req: 832, 
[1,1]<stdout>:[2025-10-12 02:02:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 836, 
[1,1]<stdout>:[2025-10-12 02:02:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 835, 
[1,1]<stdout>:[2025-10-12 02:02:02 DP1 TP8] Decode batch. #running-req: 16, #token: 5456, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 435.18, #queue-req: 835, 
[1,0]<stdout>:[2025-10-12 02:02:02 DP0 TP0] Decode batch. #running-req: 16, #token: 8011, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 435.08, #queue-req: 832, 
[1,1]<stdout>:[2025-10-12 02:02:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 834, 
[1,0]<stdout>:[2025-10-12 02:02:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 831, 
[1,0]<stdout>:[2025-10-12 02:02:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 830, 
[1,1]<stdout>:[2025-10-12 02:02:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 833, 
[1,0]<stdout>:[2025-10-12 02:02:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 829, 
[1,1]<stdout>:[2025-10-12 02:02:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 832, 
[1,1]<stdout>:[2025-10-12 02:02:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 831, 
[1,1]<stdout>:[2025-10-12 02:02:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 670, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 830, 
[1,0]<stdout>:[2025-10-12 02:02:04 DP0 TP0] Decode batch. #running-req: 16, #token: 8206, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 309.00, #queue-req: 829, 
[1,1]<stdout>:[2025-10-12 02:02:04 DP1 TP8] Decode batch. #running-req: 16, #token: 5096, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 307.90, #queue-req: 830, 
[1,0]<stdout>:[2025-10-12 02:02:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 463, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 828, 
[1,1]<stdout>:[2025-10-12 02:02:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 829, 
[1,0]<stdout>:[2025-10-12 02:02:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 827, 
[1,1]<stdout>:[2025-10-12 02:02:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 828, 
[1,0]<stdout>:[2025-10-12 02:02:05 DP0 TP0] Decode batch. #running-req: 16, #token: 8995, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.02, #queue-req: 827, 
[1,1]<stdout>:[2025-10-12 02:02:05 DP1 TP8] Decode batch. #running-req: 16, #token: 5077, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.05, #queue-req: 828, 
[1,1]<stdout>:[2025-10-12 02:02:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 827, 
[1,0]<stdout>:[2025-10-12 02:02:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 822, #cached-token: 5, token usage: 0.05, #running-req: 15, #queue-req: 826, 
[1,1]<stdout>:[2025-10-12 02:02:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 826, 
[1,0]<stdout>:[2025-10-12 02:02:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 5, token usage: 0.05, #running-req: 15, #queue-req: 825, 
[1,0]<stdout>:[2025-10-12 02:02:07 DP0 TP0] Decode batch. #running-req: 16, #token: 8796, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 390.76, #queue-req: 825, 
[1,1]<stdout>:[2025-10-12 02:02:07 DP1 TP8] Decode batch. #running-req: 16, #token: 5186, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 390.84, #queue-req: 826, 
[1,0]<stdout>:[2025-10-12 02:02:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 824, 
[1,0]<stdout>:[2025-10-12 02:02:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1132, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 823, 
[1,0]<stdout>:[2025-10-12 02:02:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 735, #cached-token: 6, token usage: 0.06, #running-req: 15, #queue-req: 822, 
[1,0]<stdout>:[2025-10-12 02:02:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 821, 
[1,0]<stdout>:[2025-10-12 02:02:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 820, 
[1,0]<stdout>:[2025-10-12 02:02:09 DP0 TP0] Decode batch. #running-req: 16, #token: 9917, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.75, #queue-req: 820, 
[1,1]<stdout>:[2025-10-12 02:02:09 DP1 TP8] Decode batch. #running-req: 16, #token: 5826, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 361.55, #queue-req: 826, 
[1,0]<stdout>:[2025-10-12 02:02:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 819, 
[1,0]<stdout>:[2025-10-12 02:02:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 818, 
[1,0]<stdout>:[2025-10-12 02:02:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1231, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 817, 
[1,0]<stdout>:[2025-10-12 02:02:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 816, 
[1,0]<stdout>:[2025-10-12 02:02:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 7, token usage: 0.06, #running-req: 15, #queue-req: 815, 
[1,0]<stdout>:[2025-10-12 02:02:10 DP0 TP0] Decode batch. #running-req: 16, #token: 9333, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 353.79, #queue-req: 815, 
[1,1]<stdout>:[2025-10-12 02:02:11 DP1 TP8] Decode batch. #running-req: 16, #token: 6466, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.48, #queue-req: 826, 
[1,1]<stdout>:[2025-10-12 02:02:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 825, 
[1,1]<stdout>:[2025-10-12 02:02:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 824, 
[1,1]<stdout>:[2025-10-12 02:02:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 823, 
[1,1]<stdout>:[2025-10-12 02:02:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 822, 
[1,1]<stdout>:[2025-10-12 02:02:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 821, 
[1,0]<stdout>:[2025-10-12 02:02:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 814, 
[1,0]<stdout>:[2025-10-12 02:02:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 813, 
[1,0]<stdout>:[2025-10-12 02:02:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 812, 
[1,0]<stdout>:[2025-10-12 02:02:13 DP0 TP0] Decode batch. #running-req: 16, #token: 7740, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.52, #queue-req: 812, 
[1,1]<stdout>:[2025-10-12 02:02:13 DP1 TP8] Decode batch. #running-req: 16, #token: 6177, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 285.70, #queue-req: 821, 
[1,0]<stdout>:[2025-10-12 02:02:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 811, 
[1,0]<stdout>:[2025-10-12 02:02:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 992, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 810, 
[1,0]<stdout>:[2025-10-12 02:02:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 809, 
[1,0]<stdout>:[2025-10-12 02:02:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1940, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 808, 
[1,1]<stdout>:[2025-10-12 02:02:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 820, 
[1,1]<stdout>:[2025-10-12 02:02:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 0, token usage: 0.05, #running-req: 15, #queue-req: 820, 
[1,1]<stdout>:[2025-10-12 02:02:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 819, 
[1,0]<stdout>:[2025-10-12 02:02:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 770, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 807, 
[1,1]<stdout>:[2025-10-12 02:02:15 DP1 TP8] Decode batch. #running-req: 16, #token: 8742, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 288.18, #queue-req: 819, 
[1,0]<stdout>:[2025-10-12 02:02:15 DP0 TP0] Decode batch. #running-req: 16, #token: 11031, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.81, #queue-req: 807, 
[1,0]<stdout>:[2025-10-12 02:02:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 806, 
[1,1]<stdout>:[2025-10-12 02:02:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 818, 
[1,1]<stdout>:[2025-10-12 02:02:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 817, 
[1,0]<stdout>:[2025-10-12 02:02:16 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 26, #cached-token: 5, token usage: 0.06, #running-req: 14, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 02:02:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 803, 
[1,0]<stdout>:[2025-10-12 02:02:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 802, 
[1,0]<stdout>:[2025-10-12 02:02:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 801, 
[1,0]<stdout>:[2025-10-12 02:02:17 DP0 TP0] Decode batch. #running-req: 16, #token: 7864, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 306.22, #queue-req: 801, 
[1,1]<stdout>:[2025-10-12 02:02:17 DP1 TP8] Decode batch. #running-req: 16, #token: 9027, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 308.14, #queue-req: 817, 
[1,0]<stdout>:[2025-10-12 02:02:18 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 815, #cached-token: 3, token usage: 0.05, #running-req: 14, #queue-req: 799, 
[1,0]<stdout>:[2025-10-12 02:02:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 798, 
[1,0]<stdout>:[2025-10-12 02:02:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 797, 
[1,0]<stdout>:[2025-10-12 02:02:19 DP0 TP0] Decode batch. #running-req: 15, #token: 8416, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 424.29, #queue-req: 797, 
[1,1]<stdout>:[2025-10-12 02:02:19 DP1 TP8] Decode batch. #running-req: 16, #token: 9667, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 427.55, #queue-req: 817, 
[1,0]<stdout>:[2025-10-12 02:02:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 796, 
[1,0]<stdout>:[2025-10-12 02:02:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 759, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 795, 
[1,0]<stdout>:[2025-10-12 02:02:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 794, 
[1,1]<stdout>:[2025-10-12 02:02:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 816, 
[1,0]<stdout>:[2025-10-12 02:02:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 793, 
[1,0]<stdout>:[2025-10-12 02:02:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 792, 
[1,0]<stdout>:[2025-10-12 02:02:20 DP0 TP0] Decode batch. #running-req: 16, #token: 9129, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 360.52, #queue-req: 792, 
[1,1]<stdout>:[2025-10-12 02:02:20 DP1 TP8] Decode batch. #running-req: 16, #token: 10516, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 362.21, #queue-req: 816, 
[1,0]<stdout>:[2025-10-12 02:02:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 791, 
[1,0]<stdout>:[2025-10-12 02:02:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 790, 
[1,1]<stdout>:[2025-10-12 02:02:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 815, 
[1,0]<stdout>:[2025-10-12 02:02:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 789, 
[1,1]<stdout>:[2025-10-12 02:02:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 724, #cached-token: 9, token usage: 0.06, #running-req: 15, #queue-req: 814, 
[1,0]<stdout>:[2025-10-12 02:02:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 788, 
[1,1]<stdout>:[2025-10-12 02:02:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 905, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 813, 
[1,0]<stdout>:[2025-10-12 02:02:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 787, 
[1,0]<stdout>:[2025-10-12 02:02:23 DP0 TP0] Decode batch. #running-req: 16, #token: 8564, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.45, #queue-req: 787, 
[1,1]<stdout>:[2025-10-12 02:02:23 DP1 TP8] Decode batch. #running-req: 16, #token: 10188, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 285.35, #queue-req: 813, 
[1,1]<stdout>:[2025-10-12 02:02:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 812, 
[1,1]<stdout>:[2025-10-12 02:02:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 811, 
[1,0]<stdout>:[2025-10-12 02:02:24 DP0 TP0] Decode batch. #running-req: 16, #token: 9204, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 478.61, #queue-req: 787, 
[1,1]<stdout>:[2025-10-12 02:02:24 DP1 TP8] Decode batch. #running-req: 16, #token: 9965, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 477.04, #queue-req: 811, 
[1,0]<stdout>:[2025-10-12 02:02:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 6, token usage: 0.06, #running-req: 15, #queue-req: 786, 
[1,0]<stdout>:[2025-10-12 02:02:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 785, 
[1,1]<stdout>:[2025-10-12 02:02:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 810, 
[1,0]<stdout>:[2025-10-12 02:02:25 DP0 TP0] Decode batch. #running-req: 16, #token: 9280, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 431.73, #queue-req: 785, 
[1,1]<stdout>:[2025-10-12 02:02:25 DP1 TP8] Decode batch. #running-req: 16, #token: 9453, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 432.50, #queue-req: 810, 
[1,0]<stdout>:[2025-10-12 02:02:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 784, 
[1,0]<stdout>:[2025-10-12 02:02:26 DP0 TP0] Decode batch. #running-req: 16, #token: 9638, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 541.57, #queue-req: 784, 
[1,1]<stdout>:[2025-10-12 02:02:26 DP1 TP8] Decode batch. #running-req: 16, #token: 10093, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 542.48, #queue-req: 810, 
[1,1]<stdout>:[2025-10-12 02:02:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 809, 
[1,1]<stdout>:[2025-10-12 02:02:27 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 1546, #cached-token: 3, token usage: 0.05, #running-req: 14, #queue-req: 807, 
[1,1]<stdout>:[2025-10-12 02:02:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 755, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 806, 
[1,1]<stdout>:[2025-10-12 02:02:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 805, 
[1,1]<stdout>:[2025-10-12 02:02:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 02:02:28 DP0 TP0] Decode batch. #running-req: 16, #token: 10278, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 342.92, #queue-req: 784, 
[1,1]<stdout>:[2025-10-12 02:02:28 DP1 TP8] Decode batch. #running-req: 16, #token: 7543, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 339.65, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 02:02:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 783, 
[1,1]<stdout>:[2025-10-12 02:02:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 803, 
[1,0]<stdout>:[2025-10-12 02:02:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 775, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 782, 
[1,0]<stdout>:[2025-10-12 02:02:30 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 10, #cached-token: 4, token usage: 0.05, #running-req: 14, #queue-req: 780, 
[1,1]<stdout>:[2025-10-12 02:02:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 5, token usage: 0.05, #running-req: 15, #queue-req: 802, 
[1,0]<stdout>:[2025-10-12 02:02:30 DP0 TP0] Decode batch. #running-req: 15, #token: 7558, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 360.97, #queue-req: 780, 
[1,1]<stdout>:[2025-10-12 02:02:30 DP1 TP8] Decode batch. #running-req: 16, #token: 7121, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 362.71, #queue-req: 802, 
[1,0]<stdout>:[2025-10-12 02:02:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 832, #cached-token: 7, token usage: 0.05, #running-req: 15, #queue-req: 779, 
[1,0]<stdout>:[2025-10-12 02:02:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 8, token usage: 0.05, #running-req: 15, #queue-req: 778, 
[1,0]<stdout>:[2025-10-12 02:02:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 5, token usage: 0.05, #running-req: 15, #queue-req: 777, 
[1,1]<stdout>:[2025-10-12 02:02:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 801, 
[1,0]<stdout>:[2025-10-12 02:02:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 7, token usage: 0.05, #running-req: 15, #queue-req: 776, 
[1,1]<stdout>:[2025-10-12 02:02:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 800, 
[1,1]<stdout>:[2025-10-12 02:02:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 799, 
[1,1]<stdout>:[2025-10-12 02:02:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1044, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 798, 
[1,1]<stdout>:[2025-10-12 02:02:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1051, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 797, 
[1,0]<stdout>:[2025-10-12 02:02:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 775, 
[1,1]<stdout>:[2025-10-12 02:02:33 DP1 TP8] Decode batch. #running-req: 16, #token: 8068, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 252.10, #queue-req: 797, 
[1,0]<stdout>:[2025-10-12 02:02:33 DP0 TP0] Decode batch. #running-req: 16, #token: 7919, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 252.50, #queue-req: 775, 
[1,1]<stdout>:[2025-10-12 02:02:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 796, 
[1,0]<stdout>:[2025-10-12 02:02:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 774, 
[1,1]<stdout>:[2025-10-12 02:02:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 795, 
[1,0]<stdout>:[2025-10-12 02:02:33 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 72, #cached-token: 3, token usage: 0.04, #running-req: 14, #queue-req: 772, 
[1,0]<stdout>:[2025-10-12 02:02:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 771, 
[1,1]<stdout>:[2025-10-12 02:02:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 794, 
[1,0]<stdout>:[2025-10-12 02:02:34 DP0 TP0] Decode batch. #running-req: 16, #token: 7225, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.62, #queue-req: 771, 
[1,1]<stdout>:[2025-10-12 02:02:34 DP1 TP8] Decode batch. #running-req: 16, #token: 6158, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 359.15, #queue-req: 794, 
[1,1]<stdout>:[2025-10-12 02:02:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 793, 
[1,0]<stdout>:[2025-10-12 02:02:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 770, 
[1,1]<stdout>:[2025-10-12 02:02:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 792, 
[1,0]<stdout>:[2025-10-12 02:02:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 769, 
[1,0]<stdout>:[2025-10-12 02:02:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 768, 
[1,0]<stdout>:[2025-10-12 02:02:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 767, 
[1,1]<stdout>:[2025-10-12 02:02:36 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 269, #cached-token: 9, token usage: 0.04, #running-req: 14, #queue-req: 790, 
[1,0]<stdout>:[2025-10-12 02:02:36 DP0 TP0] Decode batch. #running-req: 16, #token: 6912, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 308.58, #queue-req: 767, 
[1,1]<stdout>:[2025-10-12 02:02:36 DP1 TP8] Decode batch. #running-req: 16, #token: 6949, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 308.61, #queue-req: 790, 
[1,1]<stdout>:[2025-10-12 02:02:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 789, 
[1,0]<stdout>:[2025-10-12 02:02:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 766, 
[1,1]<stdout>:[2025-10-12 02:02:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 788, 
[1,0]<stdout>:[2025-10-12 02:02:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 765, 
[1,0]<stdout>:[2025-10-12 02:02:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 764, 
[1,1]<stdout>:[2025-10-12 02:02:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 787, 
[1,0]<stdout>:[2025-10-12 02:02:38 DP0 TP0] Decode batch. #running-req: 16, #token: 6355, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 362.71, #queue-req: 764, 
[1,1]<stdout>:[2025-10-12 02:02:38 DP1 TP8] Decode batch. #running-req: 16, #token: 7256, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 362.67, #queue-req: 787, 
[1,0]<stdout>:[2025-10-12 02:02:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 763, 
[1,1]<stdout>:[2025-10-12 02:02:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 786, 
[1,1]<stdout>:[2025-10-12 02:02:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 785, 
[1,1]<stdout>:[2025-10-12 02:02:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 784, 
[1,1]<stdout>:[2025-10-12 02:02:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 783, 
[1,1]<stdout>:[2025-10-12 02:02:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 782, 
[1,0]<stdout>:[2025-10-12 02:02:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 762, 
[1,0]<stdout>:[2025-10-12 02:02:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 761, 
[1,0]<stdout>:[2025-10-12 02:02:40 DP0 TP0] Decode batch. #running-req: 16, #token: 5401, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 287.60, #queue-req: 761, 
[1,1]<stdout>:[2025-10-12 02:02:40 DP1 TP8] Decode batch. #running-req: 16, #token: 6802, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.69, #queue-req: 782, 
[1,0]<stdout>:[2025-10-12 02:02:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 760, 
[1,1]<stdout>:[2025-10-12 02:02:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 781, 
[1,0]<stdout>:[2025-10-12 02:02:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 759, 
[1,1]<stdout>:[2025-10-12 02:02:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 780, 
[1,0]<stdout>:[2025-10-12 02:02:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 758, 
[1,1]<stdout>:[2025-10-12 02:02:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 779, 
[1,1]<stdout>:[2025-10-12 02:02:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1414, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 778, 
[1,1]<stdout>:[2025-10-12 02:02:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 777, 
[1,1]<stdout>:[2025-10-12 02:02:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 706, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 776, 
[1,0]<stdout>:[2025-10-12 02:02:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1019, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 757, 
[1,1]<stdout>:[2025-10-12 02:02:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 775, 
[1,0]<stdout>:[2025-10-12 02:02:43 DP0 TP0] Decode batch. #running-req: 16, #token: 6461, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 266.84, #queue-req: 757, 
[1,1]<stdout>:[2025-10-12 02:02:43 DP1 TP8] Decode batch. #running-req: 16, #token: 6630, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 265.58, #queue-req: 775, 
[1,1]<stdout>:[2025-10-12 02:02:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 774, 
[1,0]<stdout>:[2025-10-12 02:02:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 756, 
[1,0]<stdout>:[2025-10-12 02:02:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 755, 
[1,0]<stdout>:[2025-10-12 02:02:44 DP0 TP0] Decode batch. #running-req: 16, #token: 6193, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 435.47, #queue-req: 755, 
[1,1]<stdout>:[2025-10-12 02:02:44 DP1 TP8] Decode batch. #running-req: 16, #token: 6554, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 436.10, #queue-req: 774, 
[1,1]<stdout>:[2025-10-12 02:02:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 5, token usage: 0.04, #running-req: 15, #queue-req: 773, 
[1,0]<stdout>:[2025-10-12 02:02:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 754, 
[1,1]<stdout>:[2025-10-12 02:02:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 772, 
[1,1]<stdout>:[2025-10-12 02:02:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 0, token usage: 0.06, #running-req: 15, #queue-req: 772, 
[1,1]<stdout>:[2025-10-12 02:02:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 771, 
[1,1]<stdout>:[2025-10-12 02:02:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 770, 
[1,0]<stdout>:[2025-10-12 02:02:46 DP0 TP0] Decode batch. #running-req: 16, #token: 6480, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 330.16, #queue-req: 754, 
[1,1]<stdout>:[2025-10-12 02:02:46 DP1 TP8] Decode batch. #running-req: 16, #token: 9014, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 328.60, #queue-req: 770, 
[1,1]<stdout>:[2025-10-12 02:02:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 769, 
[1,1]<stdout>:[2025-10-12 02:02:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 768, 
[1,1]<stdout>:[2025-10-12 02:02:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 767, 
[1,0]<stdout>:[2025-10-12 02:02:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 753, 
[1,0]<stdout>:[2025-10-12 02:02:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 752, 
[1,0]<stdout>:[2025-10-12 02:02:48 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 567, #cached-token: 4, token usage: 0.04, #running-req: 14, #queue-req: 750, 
[1,0]<stdout>:[2025-10-12 02:02:48 DP0 TP0] Decode batch. #running-req: 16, #token: 6927, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 329.18, #queue-req: 750, 
[1,1]<stdout>:[2025-10-12 02:02:48 DP1 TP8] Decode batch. #running-req: 16, #token: 6814, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 329.77, #queue-req: 767, 
[1,0]<stdout>:[2025-10-12 02:02:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 749, 
[1,0]<stdout>:[2025-10-12 02:02:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 748, 
[1,0]<stdout>:[2025-10-12 02:02:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 747, 
[1,0]<stdout>:[2025-10-12 02:02:50 DP0 TP0] Decode batch. #running-req: 16, #token: 5237, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 427.84, #queue-req: 747, 
[1,1]<stdout>:[2025-10-12 02:02:50 DP1 TP8] Decode batch. #running-req: 16, #token: 7454, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 429.76, #queue-req: 767, 
[1,0]<stdout>:[2025-10-12 02:02:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 746, 
[1,1]<stdout>:[2025-10-12 02:02:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 766, 
[1,0]<stdout>:[2025-10-12 02:02:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 819, #cached-token: 8, token usage: 0.03, #running-req: 15, #queue-req: 745, 
[1,0]<stdout>:[2025-10-12 02:02:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 5, token usage: 0.04, #running-req: 15, #queue-req: 744, 
[1,1]<stdout>:[2025-10-12 02:02:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 765, 
[1,1]<stdout>:[2025-10-12 02:02:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 764, 
[1,0]<stdout>:[2025-10-12 02:02:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 743, 
[1,0]<stdout>:[2025-10-12 02:02:52 DP0 TP0] Decode batch. #running-req: 16, #token: 6420, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 309.33, #queue-req: 743, 
[1,1]<stdout>:[2025-10-12 02:02:52 DP1 TP8] Decode batch. #running-req: 16, #token: 7359, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 309.84, #queue-req: 764, 
[1,1]<stdout>:[2025-10-12 02:02:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1532, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 763, 
[1,0]<stdout>:[2025-10-12 02:02:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 742, 
[1,0]<stdout>:[2025-10-12 02:02:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 881, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 741, 
[1,0]<stdout>:[2025-10-12 02:02:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 740, 
[1,1]<stdout>:[2025-10-12 02:02:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 762, 
[1,0]<stdout>:[2025-10-12 02:02:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 739, 
[1,0]<stdout>:[2025-10-12 02:02:54 DP0 TP0] Decode batch. #running-req: 16, #token: 6885, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 327.86, #queue-req: 739, 
[1,1]<stdout>:[2025-10-12 02:02:54 DP1 TP8] Decode batch. #running-req: 16, #token: 8740, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 328.89, #queue-req: 762, 
[1,0]<stdout>:[2025-10-12 02:02:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 738, 
[1,1]<stdout>:[2025-10-12 02:02:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 761, 
[1,0]<stdout>:[2025-10-12 02:02:55 DP0 TP0] Decode batch. #running-req: 16, #token: 7367, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 481.10, #queue-req: 738, 
[1,1]<stdout>:[2025-10-12 02:02:55 DP1 TP8] Decode batch. #running-req: 15, #token: 8763, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 480.33, #queue-req: 761, 
[1,1]<stdout>:[2025-10-12 02:02:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 760, 
[1,1]<stdout>:[2025-10-12 02:02:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 759, 
[1,0]<stdout>:[2025-10-12 02:02:56 DP0 TP0] Decode batch. #running-req: 16, #token: 8007, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 477.85, #queue-req: 738, 
[1,1]<stdout>:[2025-10-12 02:02:56 DP1 TP8] Decode batch. #running-req: 16, #token: 8024, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 477.17, #queue-req: 759, 
[1,1]<stdout>:[2025-10-12 02:02:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 758, 
[1,0]<stdout>:[2025-10-12 02:02:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 737, 
[1,1]<stdout>:[2025-10-12 02:02:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 757, 
[1,0]<stdout>:[2025-10-12 02:02:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 736, 
[1,1]<stdout>:[2025-10-12 02:02:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 849, #cached-token: 6, token usage: 0.05, #running-req: 15, #queue-req: 756, 
[1,0]<stdout>:[2025-10-12 02:02:58 DP0 TP0] Decode batch. #running-req: 15, #token: 7979, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.21, #queue-req: 736, 
[1,1]<stdout>:[2025-10-12 02:02:58 DP1 TP8] Decode batch. #running-req: 16, #token: 9238, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.19, #queue-req: 756, 
[1,0]<stdout>:[2025-10-12 02:02:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 735, 
[1,0]<stdout>:[2025-10-12 02:02:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 734, 
[1,0]<stdout>:[2025-10-12 02:02:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 733, 
[1,0]<stdout>:[2025-10-12 02:02:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 7, token usage: 0.05, #running-req: 15, #queue-req: 732, 
[1,0]<stdout>:[2025-10-12 02:02:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 514, #cached-token: 5, token usage: 0.05, #running-req: 15, #queue-req: 731, 
[1,1]<stdout>:[2025-10-12 02:02:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 755, 
[1,0]<stdout>:[2025-10-12 02:03:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 730, 
[1,1]<stdout>:[2025-10-12 02:03:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 754, 
[1,0]<stdout>:[2025-10-12 02:03:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 729, 
[1,1]<stdout>:[2025-10-12 02:03:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 753, 
[1,0]<stdout>:[2025-10-12 02:03:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 728, 
[1,1]<stdout>:[2025-10-12 02:03:00 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 593, #cached-token: 8, token usage: 0.05, #running-req: 14, #queue-req: 751, 
[1,0]<stdout>:[2025-10-12 02:03:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 727, 
[1,1]<stdout>:[2025-10-12 02:03:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 750, 
[1,1]<stdout>:[2025-10-12 02:03:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 749, 
[1,0]<stdout>:[2025-10-12 02:03:01 DP0 TP0] Decode batch. #running-req: 16, #token: 7515, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 214.06, #queue-req: 727, 
[1,1]<stdout>:[2025-10-12 02:03:01 DP1 TP8] Decode batch. #running-req: 16, #token: 8488, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 214.38, #queue-req: 749, 
[1,1]<stdout>:[2025-10-12 02:03:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 571, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 748, 
[1,1]<stdout>:[2025-10-12 02:03:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 486, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 747, 
[1,1]<stdout>:[2025-10-12 02:03:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 746, 
[1,0]<stdout>:[2025-10-12 02:03:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 726, 
[1,0]<stdout>:[2025-10-12 02:03:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 725, 
[1,1]<stdout>:[2025-10-12 02:03:03 DP1 TP8] Decode batch. #running-req: 16, #token: 6985, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.24, #queue-req: 746, 
[1,0]<stdout>:[2025-10-12 02:03:03 DP0 TP0] Decode batch. #running-req: 16, #token: 7677, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.75, #queue-req: 725, 
[1,0]<stdout>:[2025-10-12 02:03:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 724, 
[1,0]<stdout>:[2025-10-12 02:03:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 795, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 723, 
[1,1]<stdout>:[2025-10-12 02:03:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 745, 
[1,0]<stdout>:[2025-10-12 02:03:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 722, 
[1,0]<stdout>:[2025-10-12 02:03:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 721, 
[1,0]<stdout>:[2025-10-12 02:03:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 720, 
[1,1]<stdout>:[2025-10-12 02:03:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 744, 
[1,0]<stdout>:[2025-10-12 02:03:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 479, #cached-token: 7, token usage: 0.05, #running-req: 15, #queue-req: 719, 
[1,0]<stdout>:[2025-10-12 02:03:05 DP0 TP0] Decode batch. #running-req: 16, #token: 7537, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 306.23, #queue-req: 719, 
[1,1]<stdout>:[2025-10-12 02:03:05 DP1 TP8] Decode batch. #running-req: 16, #token: 7221, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 308.16, #queue-req: 744, 
[1,1]<stdout>:[2025-10-12 02:03:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 743, 
[1,0]<stdout>:[2025-10-12 02:03:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 718, 
[1,1]<stdout>:[2025-10-12 02:03:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 742, 
[1,0]<stdout>:[2025-10-12 02:03:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1595, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 717, 
[1,1]<stdout>:[2025-10-12 02:03:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 741, 
[1,1]<stdout>:[2025-10-12 02:03:07 DP1 TP8] Decode batch. #running-req: 16, #token: 7286, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 351.15, #queue-req: 741, 
[1,0]<stdout>:[2025-10-12 02:03:07 DP0 TP0] Decode batch. #running-req: 16, #token: 8729, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 351.69, #queue-req: 717, 
[1,0]<stdout>:[2025-10-12 02:03:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 716, 
[1,1]<stdout>:[2025-10-12 02:03:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 740, 
[1,1]<stdout>:[2025-10-12 02:03:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 739, 
[1,0]<stdout>:[2025-10-12 02:03:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 715, 
[1,0]<stdout>:[2025-10-12 02:03:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 714, 
[1,0]<stdout>:[2025-10-12 02:03:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1146, #cached-token: 0, token usage: 0.06, #running-req: 15, #queue-req: 714, 
[1,1]<stdout>:[2025-10-12 02:03:09 DP1 TP8] Decode batch. #running-req: 16, #token: 7514, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 333.57, #queue-req: 739, 
[1,0]<stdout>:[2025-10-12 02:03:09 DP0 TP0] Decode batch. #running-req: 16, #token: 11357, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 333.02, #queue-req: 714, 
[1,1]<stdout>:[2025-10-12 02:03:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 738, 
[1,0]<stdout>:[2025-10-12 02:03:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 713, 
[1,1]<stdout>:[2025-10-12 02:03:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 737, 
[1,0]<stdout>:[2025-10-12 02:03:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 8, token usage: 0.07, #running-req: 15, #queue-req: 712, 
[1,1]<stdout>:[2025-10-12 02:03:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 736, 
[1,0]<stdout>:[2025-10-12 02:03:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 711, 
[1,0]<stdout>:[2025-10-12 02:03:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.07, #running-req: 15, #queue-req: 710, 
[1,0]<stdout>:[2025-10-12 02:03:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 7, token usage: 0.06, #running-req: 15, #queue-req: 709, 
[1,1]<stdout>:[2025-10-12 02:03:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 735, 
[1,0]<stdout>:[2025-10-12 02:03:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 6, token usage: 0.05, #running-req: 15, #queue-req: 708, 
[1,0]<stdout>:[2025-10-12 02:03:11 DP0 TP0] Decode batch. #running-req: 16, #token: 8846, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 268.64, #queue-req: 708, 
[1,1]<stdout>:[2025-10-12 02:03:11 DP1 TP8] Decode batch. #running-req: 16, #token: 6356, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 269.47, #queue-req: 735, 
[1,1]<stdout>:[2025-10-12 02:03:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 734, 
[1,1]<stdout>:[2025-10-12 02:03:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 733, 
[1,0]<stdout>:[2025-10-12 02:03:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 707, 
[1,0]<stdout>:[2025-10-12 02:03:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 706, 
[1,1]<stdout>:[2025-10-12 02:03:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 732, 
[1,0]<stdout>:[2025-10-12 02:03:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 705, 
[1,0]<stdout>:[2025-10-12 02:03:13 DP0 TP0] Decode batch. #running-req: 16, #token: 9253, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 331.54, #queue-req: 705, 
[1,1]<stdout>:[2025-10-12 02:03:13 DP1 TP8] Decode batch. #running-req: 16, #token: 6475, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 331.46, #queue-req: 732, 
[1,0]<stdout>:[2025-10-12 02:03:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 8, token usage: 0.06, #running-req: 15, #queue-req: 704, 
[1,0]<stdout>:[2025-10-12 02:03:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 703, 
[1,1]<stdout>:[2025-10-12 02:03:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 731, 
[1,1]<stdout>:[2025-10-12 02:03:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 730, 
[1,0]<stdout>:[2025-10-12 02:03:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 14, token usage: 0.06, #running-req: 15, #queue-req: 702, 
[1,0]<stdout>:[2025-10-12 02:03:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 701, 
[1,0]<stdout>:[2025-10-12 02:03:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 700, 
[1,1]<stdout>:[2025-10-12 02:03:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 729, 
[1,0]<stdout>:[2025-10-12 02:03:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 699, 
[1,0]<stdout>:[2025-10-12 02:03:15 DP0 TP0] Decode batch. #running-req: 16, #token: 9680, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 270.25, #queue-req: 699, 
[1,1]<stdout>:[2025-10-12 02:03:15 DP1 TP8] Decode batch. #running-req: 15, #token: 6229, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 271.12, #queue-req: 729, 
[1,1]<stdout>:[2025-10-12 02:03:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 728, 
[1,0]<stdout>:[2025-10-12 02:03:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 930, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 698, 
[1,1]<stdout>:[2025-10-12 02:03:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 727, 
[1,1]<stdout>:[2025-10-12 02:03:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 726, 
[1,1]<stdout>:[2025-10-12 02:03:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 725, 
[1,1]<stdout>:[2025-10-12 02:03:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 720, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 724, 
[1,0]<stdout>:[2025-10-12 02:03:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 697, 
[1,1]<stdout>:[2025-10-12 02:03:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1255, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 723, 
[1,0]<stdout>:[2025-10-12 02:03:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 825, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 696, 
[1,1]<stdout>:[2025-10-12 02:03:18 DP1 TP8] Decode batch. #running-req: 16, #token: 8363, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 269.33, #queue-req: 723, 
[1,0]<stdout>:[2025-10-12 02:03:18 DP0 TP0] Decode batch. #running-req: 16, #token: 8301, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 270.08, #queue-req: 696, 
[1,0]<stdout>:[2025-10-12 02:03:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 695, 
[1,0]<stdout>:[2025-10-12 02:03:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 694, 
[1,0]<stdout>:[2025-10-12 02:03:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 693, 
[1,0]<stdout>:[2025-10-12 02:03:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 692, 
[1,1]<stdout>:[2025-10-12 02:03:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 7, token usage: 0.05, #running-req: 15, #queue-req: 722, 
[1,0]<stdout>:[2025-10-12 02:03:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 691, 
[1,1]<stdout>:[2025-10-12 02:03:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 405, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 721, 
[1,1]<stdout>:[2025-10-12 02:03:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 720, 
[1,0]<stdout>:[2025-10-12 02:03:20 DP0 TP0] Decode batch. #running-req: 16, #token: 9530, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.73, #queue-req: 691, 
[1,1]<stdout>:[2025-10-12 02:03:20 DP1 TP8] Decode batch. #running-req: 16, #token: 7066, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 287.55, #queue-req: 720, 
[1,1]<stdout>:[2025-10-12 02:03:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 719, 
[1,1]<stdout>:[2025-10-12 02:03:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 718, 
[1,0]<stdout>:[2025-10-12 02:03:21 DP0 TP0] Decode batch. #running-req: 16, #token: 10170, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 479.43, #queue-req: 691, 
[1,1]<stdout>:[2025-10-12 02:03:21 DP1 TP8] Decode batch. #running-req: 16, #token: 6766, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 477.98, #queue-req: 718, 
[1,1]<stdout>:[2025-10-12 02:03:22 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 1301, #cached-token: 3, token usage: 0.04, #running-req: 14, #queue-req: 716, 
[1,0]<stdout>:[2025-10-12 02:03:22 DP0 TP0] Decode batch. #running-req: 16, #token: 10810, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 526.71, #queue-req: 691, 
[1,1]<stdout>:[2025-10-12 02:03:22 DP1 TP8] Decode batch. #running-req: 15, #token: 7905, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 524.05, #queue-req: 716, 
[1,1]<stdout>:[2025-10-12 02:03:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 715, 
[1,0]<stdout>:[2025-10-12 02:03:23 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 1203, #cached-token: 6, token usage: 0.06, #running-req: 14, #queue-req: 689, 
[1,0]<stdout>:[2025-10-12 02:03:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 688, 
[1,1]<stdout>:[2025-10-12 02:03:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 714, 
[1,0]<stdout>:[2025-10-12 02:03:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 687, 
[1,0]<stdout>:[2025-10-12 02:03:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 686, 
[1,1]<stdout>:[2025-10-12 02:03:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 808, #cached-token: 5, token usage: 0.05, #running-req: 15, #queue-req: 713, 
[1,1]<stdout>:[2025-10-12 02:03:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 712, 
[1,0]<stdout>:[2025-10-12 02:03:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 685, 
[1,1]<stdout>:[2025-10-12 02:03:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 694, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 711, 
[1,0]<stdout>:[2025-10-12 02:03:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 684, 
[1,0]<stdout>:[2025-10-12 02:03:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 931, #cached-token: 6, token usage: 0.06, #running-req: 15, #queue-req: 683, 
[1,1]<stdout>:[2025-10-12 02:03:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 710, 
[1,1]<stdout>:[2025-10-12 02:03:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 709, 
[1,0]<stdout>:[2025-10-12 02:03:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 682, 
[1,0]<stdout>:[2025-10-12 02:03:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 681, 
[1,1]<stdout>:[2025-10-12 02:03:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 708, 
[1,0]<stdout>:[2025-10-12 02:03:26 DP0 TP0] Decode batch. #running-req: 16, #token: 9989, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 191.59, #queue-req: 681, 
[1,1]<stdout>:[2025-10-12 02:03:26 DP1 TP8] Decode batch. #running-req: 16, #token: 6477, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 192.53, #queue-req: 708, 
[1,1]<stdout>:[2025-10-12 02:03:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 707, 
[1,0]<stdout>:[2025-10-12 02:03:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 6, token usage: 0.07, #running-req: 15, #queue-req: 680, 
[1,1]<stdout>:[2025-10-12 02:03:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 706, 
[1,0]<stdout>:[2025-10-12 02:03:27 DP0 TP0] Decode batch. #running-req: 16, #token: 10815, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 426.00, #queue-req: 680, 
[1,1]<stdout>:[2025-10-12 02:03:27 DP1 TP8] Decode batch. #running-req: 16, #token: 6711, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 425.25, #queue-req: 706, 
[1,1]<stdout>:[2025-10-12 02:03:27 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 20, #cached-token: 5, token usage: 0.04, #running-req: 14, #queue-req: 704, 
[1,0]<stdout>:[2025-10-12 02:03:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 679, 
[1,1]<stdout>:[2025-10-12 02:03:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 703, 
[1,0]<stdout>:[2025-10-12 02:03:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 678, 
[1,0]<stdout>:[2025-10-12 02:03:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 908, #cached-token: 5, token usage: 0.07, #running-req: 15, #queue-req: 677, 
[1,1]<stdout>:[2025-10-12 02:03:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 702, 
[1,0]<stdout>:[2025-10-12 02:03:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 676, 
[1,1]<stdout>:[2025-10-12 02:03:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 805, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 701, 
[1,0]<stdout>:[2025-10-12 02:03:29 DP0 TP0] Decode batch. #running-req: 16, #token: 11338, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.65, #queue-req: 676, 
[1,1]<stdout>:[2025-10-12 02:03:29 DP1 TP8] Decode batch. #running-req: 16, #token: 6785, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.24, #queue-req: 701, 
[1,1]<stdout>:[2025-10-12 02:03:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 700, 
[1,0]<stdout>:[2025-10-12 02:03:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 675, 
[1,1]<stdout>:[2025-10-12 02:03:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 699, 
[1,0]<stdout>:[2025-10-12 02:03:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 674, 
[1,0]<stdout>:[2025-10-12 02:03:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.07, #running-req: 15, #queue-req: 673, 
[1,1]<stdout>:[2025-10-12 02:03:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 698, 
[1,0]<stdout>:[2025-10-12 02:03:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 672, 
[1,1]<stdout>:[2025-10-12 02:03:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 697, 
[1,1]<stdout>:[2025-10-12 02:03:32 DP1 TP8] Decode batch. #running-req: 16, #token: 6941, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.99, #queue-req: 697, 
[1,0]<stdout>:[2025-10-12 02:03:32 DP0 TP0] Decode batch. #running-req: 16, #token: 10831, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.96, #queue-req: 672, 
[1,0]<stdout>:[2025-10-12 02:03:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 7, token usage: 0.07, #running-req: 15, #queue-req: 671, 
[1,0]<stdout>:[2025-10-12 02:03:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 765, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 670, 
[1,0]<stdout>:[2025-10-12 02:03:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 669, 
[1,0]<stdout>:[2025-10-12 02:03:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 668, 
[1,1]<stdout>:[2025-10-12 02:03:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 696, 
[1,1]<stdout>:[2025-10-12 02:03:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 695, 
[1,1]<stdout>:[2025-10-12 02:03:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 694, 
[1,0]<stdout>:[2025-10-12 02:03:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 5, token usage: 0.07, #running-req: 15, #queue-req: 667, 
[1,1]<stdout>:[2025-10-12 02:03:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 693, 
[1,1]<stdout>:[2025-10-12 02:03:34 DP1 TP8] Decode batch. #running-req: 16, #token: 6548, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 287.29, #queue-req: 693, 
[1,0]<stdout>:[2025-10-12 02:03:34 DP0 TP0] Decode batch. #running-req: 16, #token: 11365, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.86, #queue-req: 667, 
[1,0]<stdout>:[2025-10-12 02:03:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 666, 
[1,0]<stdout>:[2025-10-12 02:03:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 665, 
[1,0]<stdout>:[2025-10-12 02:03:35 DP0 TP0] Decode batch. #running-req: 16, #token: 9261, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 472.93, #queue-req: 665, 
[1,1]<stdout>:[2025-10-12 02:03:35 DP1 TP8] Decode batch. #running-req: 16, #token: 7188, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 474.32, #queue-req: 693, 
[1,0]<stdout>:[2025-10-12 02:03:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 664, 
[1,1]<stdout>:[2025-10-12 02:03:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 692, 
[1,0]<stdout>:[2025-10-12 02:03:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 663, 
[1,0]<stdout>:[2025-10-12 02:03:37 DP0 TP0] Decode batch. #running-req: 16, #token: 6078, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 429.95, #queue-req: 663, 
[1,1]<stdout>:[2025-10-12 02:03:37 DP1 TP8] Decode batch. #running-req: 16, #token: 7000, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 430.63, #queue-req: 692, 
[1,1]<stdout>:[2025-10-12 02:03:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 691, 
[1,0]<stdout>:[2025-10-12 02:03:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 662, 
[1,1]<stdout>:[2025-10-12 02:03:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 690, 
[1,0]<stdout>:[2025-10-12 02:03:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 661, 
[1,0]<stdout>:[2025-10-12 02:03:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 660, 
[1,0]<stdout>:[2025-10-12 02:03:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 659, 
[1,1]<stdout>:[2025-10-12 02:03:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 689, 
[1,0]<stdout>:[2025-10-12 02:03:39 DP0 TP0] Decode batch. #running-req: 16, #token: 5477, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 307.40, #queue-req: 659, 
[1,1]<stdout>:[2025-10-12 02:03:39 DP1 TP8] Decode batch. #running-req: 15, #token: 6713, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 307.43, #queue-req: 689, 
[1,1]<stdout>:[2025-10-12 02:03:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 688, 
[1,1]<stdout>:[2025-10-12 02:03:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 687, 
[1,0]<stdout>:[2025-10-12 02:03:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 794, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 658, 
[1,0]<stdout>:[2025-10-12 02:03:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 657, 
[1,0]<stdout>:[2025-10-12 02:03:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 656, 
[1,1]<stdout>:[2025-10-12 02:03:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 686, 
[1,0]<stdout>:[2025-10-12 02:03:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 655, 
[1,1]<stdout>:[2025-10-12 02:03:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 685, 
[1,0]<stdout>:[2025-10-12 02:03:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 654, 
[1,0]<stdout>:[2025-10-12 02:03:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 653, 
[1,0]<stdout>:[2025-10-12 02:03:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 652, 
[1,1]<stdout>:[2025-10-12 02:03:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 885, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 684, 
[1,1]<stdout>:[2025-10-12 02:03:41 DP1 TP8] Decode batch. #running-req: 16, #token: 7882, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 238.07, #queue-req: 684, 
[1,0]<stdout>:[2025-10-12 02:03:41 DP0 TP0] Decode batch. #running-req: 16, #token: 5262, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 236.94, #queue-req: 652, 
[1,0]<stdout>:[2025-10-12 02:03:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 651, 
[1,0]<stdout>:[2025-10-12 02:03:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 6, token usage: 0.03, #running-req: 15, #queue-req: 650, 
[1,0]<stdout>:[2025-10-12 02:03:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 754, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 649, 
[1,0]<stdout>:[2025-10-12 02:03:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 648, 
[1,0]<stdout>:[2025-10-12 02:03:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 647, 
[1,0]<stdout>:[2025-10-12 02:03:43 DP0 TP0] Decode batch. #running-req: 16, #token: 5132, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.27, #queue-req: 647, 
[1,1]<stdout>:[2025-10-12 02:03:43 DP1 TP8] Decode batch. #running-req: 16, #token: 8522, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 361.07, #queue-req: 684, 
[1,0]<stdout>:[2025-10-12 02:03:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 788, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 646, 
[1,0]<stdout>:[2025-10-12 02:03:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 645, 
[1,1]<stdout>:[2025-10-12 02:03:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 683, 
[1,1]<stdout>:[2025-10-12 02:03:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 682, 
[1,1]<stdout>:[2025-10-12 02:03:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 6, token usage: 0.06, #running-req: 15, #queue-req: 681, 
[1,1]<stdout>:[2025-10-12 02:03:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 680, 
[1,1]<stdout>:[2025-10-12 02:03:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 6, token usage: 0.05, #running-req: 15, #queue-req: 679, 
[1,0]<stdout>:[2025-10-12 02:03:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 644, 
[1,1]<stdout>:[2025-10-12 02:03:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 678, 
[1,1]<stdout>:[2025-10-12 02:03:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 677, 
[1,0]<stdout>:[2025-10-12 02:03:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 643, 
[1,0]<stdout>:[2025-10-12 02:03:46 DP0 TP0] Decode batch. #running-req: 16, #token: 5079, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 239.62, #queue-req: 643, 
[1,1]<stdout>:[2025-10-12 02:03:46 DP1 TP8] Decode batch. #running-req: 16, #token: 7177, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 238.47, #queue-req: 677, 
[1,1]<stdout>:[2025-10-12 02:03:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 676, 
[1,0]<stdout>:[2025-10-12 02:03:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 642, 
[1,1]<stdout>:[2025-10-12 02:03:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 675, 
[1,0]<stdout>:[2025-10-12 02:03:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 6, token usage: 0.03, #running-req: 15, #queue-req: 641, 
[1,1]<stdout>:[2025-10-12 02:03:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 674, 
[1,0]<stdout>:[2025-10-12 02:03:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 694, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 640, 
[1,1]<stdout>:[2025-10-12 02:03:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 673, 
[1,0]<stdout>:[2025-10-12 02:03:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 639, 
[1,1]<stdout>:[2025-10-12 02:03:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 672, 
[1,0]<stdout>:[2025-10-12 02:03:48 DP0 TP0] Decode batch. #running-req: 16, #token: 5211, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.97, #queue-req: 639, 
[1,1]<stdout>:[2025-10-12 02:03:48 DP1 TP8] Decode batch. #running-req: 16, #token: 7121, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.53, #queue-req: 672, 
[1,1]<stdout>:[2025-10-12 02:03:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 671, 
[1,1]<stdout>:[2025-10-12 02:03:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 670, 
[1,0]<stdout>:[2025-10-12 02:03:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 638, 
[1,0]<stdout>:[2025-10-12 02:03:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 862, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 637, 
[1,0]<stdout>:[2025-10-12 02:03:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 636, 
[1,0]<stdout>:[2025-10-12 02:03:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.02, #running-req: 15, #queue-req: 635, 
[1,1]<stdout>:[2025-10-12 02:03:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 669, 
[1,1]<stdout>:[2025-10-12 02:03:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 668, 
[1,1]<stdout>:[2025-10-12 02:03:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 7, token usage: 0.04, #running-req: 15, #queue-req: 667, 
[1,0]<stdout>:[2025-10-12 02:03:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.02, #running-req: 15, #queue-req: 634, 
[1,0]<stdout>:[2025-10-12 02:03:50 DP0 TP0] Decode batch. #running-req: 16, #token: 3893, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 260.66, #queue-req: 634, 
[1,1]<stdout>:[2025-10-12 02:03:50 DP1 TP8] Decode batch. #running-req: 16, #token: 6050, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 260.65, #queue-req: 667, 
[1,1]<stdout>:[2025-10-12 02:03:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 5, token usage: 0.04, #running-req: 15, #queue-req: 666, 
[1,0]<stdout>:[2025-10-12 02:03:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 3, token usage: 0.02, #running-req: 15, #queue-req: 633, 
[1,0]<stdout>:[2025-10-12 02:03:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.04, #running-req: 15, #queue-req: 633, 
[1,0]<stdout>:[2025-10-12 02:03:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.05, #running-req: 15, #queue-req: 633, 
[1,0]<stdout>:[2025-10-12 02:03:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 0, token usage: 0.06, #running-req: 15, #queue-req: 633, 
[1,1]<stdout>:[2025-10-12 02:03:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 665, 
[1,0]<stdout>:[2025-10-12 02:03:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 632, 
[1,0]<stdout>:[2025-10-12 02:03:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 631, 
[1,0]<stdout>:[2025-10-12 02:03:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 630, 
[1,0]<stdout>:[2025-10-12 02:03:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 629, 
[1,1]<stdout>:[2025-10-12 02:03:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 664, 
[1,0]<stdout>:[2025-10-12 02:03:53 DP0 TP0] Decode batch. #running-req: 16, #token: 10245, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 239.10, #queue-req: 629, 
[1,1]<stdout>:[2025-10-12 02:03:53 DP1 TP8] Decode batch. #running-req: 16, #token: 6618, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 239.83, #queue-req: 664, 
[1,1]<stdout>:[2025-10-12 02:03:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 663, 
[1,0]<stdout>:[2025-10-12 02:03:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 628, 
[1,0]<stdout>:[2025-10-12 02:03:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1966, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 627, 
[1,1]<stdout>:[2025-10-12 02:03:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 662, 
[1,1]<stdout>:[2025-10-12 02:03:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 661, 
[1,0]<stdout>:[2025-10-12 02:03:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 626, 
[1,1]<stdout>:[2025-10-12 02:03:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 407, #cached-token: 5, token usage: 0.04, #running-req: 15, #queue-req: 660, 
[1,1]<stdout>:[2025-10-12 02:03:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 353, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 659, 
[1,0]<stdout>:[2025-10-12 02:03:55 DP0 TP0] Decode batch. #running-req: 16, #token: 12574, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 285.56, #queue-req: 626, 
[1,1]<stdout>:[2025-10-12 02:03:55 DP1 TP8] Decode batch. #running-req: 16, #token: 7063, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.73, #queue-req: 659, 
[1,1]<stdout>:[2025-10-12 02:03:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 658, 
[1,0]<stdout>:[2025-10-12 02:03:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 625, 
[1,0]<stdout>:[2025-10-12 02:03:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 624, 
[1,0]<stdout>:[2025-10-12 02:03:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 6, token usage: 0.08, #running-req: 15, #queue-req: 623, 
[1,1]<stdout>:[2025-10-12 02:03:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 657, 
[1,0]<stdout>:[2025-10-12 02:03:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.08, #running-req: 15, #queue-req: 622, 
[1,0]<stdout>:[2025-10-12 02:03:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 621, 
[1,0]<stdout>:[2025-10-12 02:03:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 0, token usage: 0.09, #running-req: 15, #queue-req: 621, 
[1,0]<stdout>:[2025-10-12 02:03:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1012, #cached-token: 1, token usage: 0.09, #running-req: 15, #queue-req: 620, 
[1,0]<stdout>:[2025-10-12 02:03:58 DP0 TP0] Decode batch. #running-req: 16, #token: 15863, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 267.52, #queue-req: 620, 
[1,1]<stdout>:[2025-10-12 02:03:58 DP1 TP8] Decode batch. #running-req: 16, #token: 7174, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 269.20, #queue-req: 657, 
[1,0]<stdout>:[2025-10-12 02:03:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.10, #running-req: 15, #queue-req: 619, 
[1,1]<stdout>:[2025-10-12 02:03:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 656, 
[1,1]<stdout>:[2025-10-12 02:03:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 655, 
[1,0]<stdout>:[2025-10-12 02:03:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.10, #running-req: 15, #queue-req: 618, 
[1,1]<stdout>:[2025-10-12 02:03:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 893, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 654, 
[1,0]<stdout>:[2025-10-12 02:04:00 DP0 TP0] Decode batch. #running-req: 16, #token: 15573, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.66, #queue-req: 618, 
[1,1]<stdout>:[2025-10-12 02:04:00 DP1 TP8] Decode batch. #running-req: 16, #token: 7954, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.04, #queue-req: 654, 
[1,1]<stdout>:[2025-10-12 02:04:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 653, 
[1,0]<stdout>:[2025-10-12 02:04:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 3, token usage: 0.10, #running-req: 15, #queue-req: 617, 
[1,0]<stdout>:[2025-10-12 02:04:01 DP0 TP0] Decode batch. #running-req: 16, #token: 16029, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 465.89, #queue-req: 617, 
[1,1]<stdout>:[2025-10-12 02:04:01 DP1 TP8] Decode batch. #running-req: 16, #token: 8885, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 465.95, #queue-req: 653, 
[1,1]<stdout>:[2025-10-12 02:04:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 652, 
[1,1]<stdout>:[2025-10-12 02:04:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1021, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 651, 
[1,0]<stdout>:[2025-10-12 02:04:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 15, #queue-req: 616, 
[1,0]<stdout>:[2025-10-12 02:04:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 4, token usage: 0.10, #running-req: 15, #queue-req: 615, 
[1,0]<stdout>:[2025-10-12 02:04:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 2, token usage: 0.10, #running-req: 15, #queue-req: 614, 
[1,0]<stdout>:[2025-10-12 02:04:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 2, token usage: 0.11, #running-req: 15, #queue-req: 613, 
[1,1]<stdout>:[2025-10-12 02:04:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 650, 
[1,0]<stdout>:[2025-10-12 02:04:03 DP0 TP0] Decode batch. #running-req: 16, #token: 16659, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 307.23, #queue-req: 613, 
[1,1]<stdout>:[2025-10-12 02:04:03 DP1 TP8] Decode batch. #running-req: 16, #token: 9110, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 307.69, #queue-req: 650, 
[1,0]<stdout>:[2025-10-12 02:04:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 391, #cached-token: 3, token usage: 0.11, #running-req: 15, #queue-req: 612, 
[1,1]<stdout>:[2025-10-12 02:04:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 649, 
[1,0]<stdout>:[2025-10-12 02:04:04 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 791, #cached-token: 3, token usage: 0.10, #running-req: 14, #queue-req: 610, 
[1,0]<stdout>:[2025-10-12 02:04:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 2, token usage: 0.10, #running-req: 15, #queue-req: 609, 
[1,1]<stdout>:[2025-10-12 02:04:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 648, 
[1,0]<stdout>:[2025-10-12 02:04:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.11, #running-req: 15, #queue-req: 608, 
[1,1]<stdout>:[2025-10-12 02:04:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 647, 
[1,0]<stdout>:[2025-10-12 02:04:05 DP0 TP0] Decode batch. #running-req: 16, #token: 16197, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 328.45, #queue-req: 608, 
[1,1]<stdout>:[2025-10-12 02:04:05 DP1 TP8] Decode batch. #running-req: 16, #token: 7432, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 329.54, #queue-req: 647, 
[1,0]<stdout>:[2025-10-12 02:04:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.10, #running-req: 15, #queue-req: 607, 
[1,1]<stdout>:[2025-10-12 02:04:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 646, 
[1,0]<stdout>:[2025-10-12 02:04:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.11, #running-req: 15, #queue-req: 606, 
[1,0]<stdout>:[2025-10-12 02:04:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 2, token usage: 0.10, #running-req: 15, #queue-req: 605, 
[1,0]<stdout>:[2025-10-12 02:04:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.11, #running-req: 15, #queue-req: 604, 
[1,0]<stdout>:[2025-10-12 02:04:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 772, #cached-token: 2, token usage: 0.10, #running-req: 15, #queue-req: 603, 
[1,0]<stdout>:[2025-10-12 02:04:07 DP0 TP0] Decode batch. #running-req: 16, #token: 16879, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 331.79, #queue-req: 603, 
[1,1]<stdout>:[2025-10-12 02:04:07 DP1 TP8] Decode batch. #running-req: 16, #token: 8068, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 333.85, #queue-req: 646, 
[1,0]<stdout>:[2025-10-12 02:04:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 1, token usage: 0.11, #running-req: 15, #queue-req: 602, 
[1,0]<stdout>:[2025-10-12 02:04:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.11, #running-req: 15, #queue-req: 601, 
[1,0]<stdout>:[2025-10-12 02:04:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 1, token usage: 0.09, #running-req: 15, #queue-req: 600, 
[1,1]<stdout>:[2025-10-12 02:04:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1386, #cached-token: 5, token usage: 0.05, #running-req: 15, #queue-req: 645, 
[1,0]<stdout>:[2025-10-12 02:04:08 DP0 TP0] Decode batch. #running-req: 16, #token: 14597, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 388.26, #queue-req: 600, 
[1,1]<stdout>:[2025-10-12 02:04:08 DP1 TP8] Decode batch. #running-req: 16, #token: 9741, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.49, #queue-req: 645, 
[1,1]<stdout>:[2025-10-12 02:04:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 644, 
[1,1]<stdout>:[2025-10-12 02:04:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 643, 
[1,1]<stdout>:[2025-10-12 02:04:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 708, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 642, 
[1,1]<stdout>:[2025-10-12 02:04:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 641, 
[1,1]<stdout>:[2025-10-12 02:04:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 640, 
[1,0]<stdout>:[2025-10-12 02:04:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.09, #running-req: 15, #queue-req: 599, 
[1,1]<stdout>:[2025-10-12 02:04:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 639, 
[1,1]<stdout>:[2025-10-12 02:04:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 638, 
[1,1]<stdout>:[2025-10-12 02:04:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 637, 
[1,1]<stdout>:[2025-10-12 02:04:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 636, 
[1,0]<stdout>:[2025-10-12 02:04:11 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 320, #cached-token: 11, token usage: 0.05, #running-req: 14, #queue-req: 597, 
[1,0]<stdout>:[2025-10-12 02:04:11 DP0 TP0] Decode batch. #running-req: 16, #token: 7477, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 236.74, #queue-req: 597, 
[1,1]<stdout>:[2025-10-12 02:04:11 DP1 TP8] Decode batch. #running-req: 16, #token: 7530, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 234.48, #queue-req: 636, 
[1,1]<stdout>:[2025-10-12 02:04:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 635, 
[1,0]<stdout>:[2025-10-12 02:04:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 596, 
[1,1]<stdout>:[2025-10-12 02:04:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 634, 
[1,1]<stdout>:[2025-10-12 02:04:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 633, 
[1,1]<stdout>:[2025-10-12 02:04:12 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 409, #cached-token: 7, token usage: 0.04, #running-req: 14, #queue-req: 631, 
[1,0]<stdout>:[2025-10-12 02:04:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1119, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 595, 
[1,1]<stdout>:[2025-10-12 02:04:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 630, 
[1,0]<stdout>:[2025-10-12 02:04:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 594, 
[1,1]<stdout>:[2025-10-12 02:04:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 629, 
[1,1]<stdout>:[2025-10-12 02:04:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 628, 
[1,0]<stdout>:[2025-10-12 02:04:14 DP0 TP0] Decode batch. #running-req: 16, #token: 8895, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 267.71, #queue-req: 594, 
[1,1]<stdout>:[2025-10-12 02:04:14 DP1 TP8] Decode batch. #running-req: 16, #token: 6711, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 265.59, #queue-req: 628, 
[1,0]<stdout>:[2025-10-12 02:04:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 593, 
[1,1]<stdout>:[2025-10-12 02:04:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 627, 
[1,1]<stdout>:[2025-10-12 02:04:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 749, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 626, 
[1,1]<stdout>:[2025-10-12 02:04:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 781, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 625, 
[1,0]<stdout>:[2025-10-12 02:04:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1538, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 592, 
[1,0]<stdout>:[2025-10-12 02:04:15 DP0 TP0] Decode batch. #running-req: 16, #token: 10747, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.26, #queue-req: 592, 
[1,1]<stdout>:[2025-10-12 02:04:15 DP1 TP8] Decode batch. #running-req: 15, #token: 7551, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.23, #queue-req: 625, 
[1,1]<stdout>:[2025-10-12 02:04:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 624, 
[1,1]<stdout>:[2025-10-12 02:04:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 623, 
[1,1]<stdout>:[2025-10-12 02:04:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 622, 
[1,0]<stdout>:[2025-10-12 02:04:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 11, token usage: 0.07, #running-req: 15, #queue-req: 591, 
[1,1]<stdout>:[2025-10-12 02:04:17 DP1 TP8] Decode batch. #running-req: 16, #token: 7374, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 391.68, #queue-req: 622, 
[1,0]<stdout>:[2025-10-12 02:04:17 DP0 TP0] Decode batch. #running-req: 16, #token: 10696, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.23, #queue-req: 591, 
[1,0]<stdout>:[2025-10-12 02:04:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 590, 
[1,1]<stdout>:[2025-10-12 02:04:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 621, 
[1,1]<stdout>:[2025-10-12 02:04:18 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 65, #cached-token: 4, token usage: 0.05, #running-req: 14, #queue-req: 619, 
[1,1]<stdout>:[2025-10-12 02:04:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 618, 
[1,1]<stdout>:[2025-10-12 02:04:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 617, 
[1,0]<stdout>:[2025-10-12 02:04:19 DP0 TP0] Decode batch. #running-req: 16, #token: 11352, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 359.15, #queue-req: 590, 
[1,1]<stdout>:[2025-10-12 02:04:19 DP1 TP8] Decode batch. #running-req: 16, #token: 7171, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.86, #queue-req: 617, 
[1,1]<stdout>:[2025-10-12 02:04:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 616, 
[1,0]<stdout>:[2025-10-12 02:04:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1474, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 589, 
[1,1]<stdout>:[2025-10-12 02:04:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 615, 
[1,0]<stdout>:[2025-10-12 02:04:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 8, token usage: 0.08, #running-req: 15, #queue-req: 588, 
[1,0]<stdout>:[2025-10-12 02:04:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 587, 
[1,1]<stdout>:[2025-10-12 02:04:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 5, token usage: 0.04, #running-req: 15, #queue-req: 614, 
[1,0]<stdout>:[2025-10-12 02:04:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.07, #running-req: 15, #queue-req: 586, 
[1,0]<stdout>:[2025-10-12 02:04:21 DP0 TP0] Decode batch. #running-req: 16, #token: 11394, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 304.02, #queue-req: 586, 
[1,1]<stdout>:[2025-10-12 02:04:21 DP1 TP8] Decode batch. #running-req: 16, #token: 6310, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 304.49, #queue-req: 614, 
[1,1]<stdout>:[2025-10-12 02:04:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 820, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 613, 
[1,0]<stdout>:[2025-10-12 02:04:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 585, 
[1,1]<stdout>:[2025-10-12 02:04:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1894, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 612, 
[1,1]<stdout>:[2025-10-12 02:04:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 611, 
[1,0]<stdout>:[2025-10-12 02:04:22 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 736, #cached-token: 7, token usage: 0.07, #running-req: 14, #queue-req: 583, 
[1,0]<stdout>:[2025-10-12 02:04:23 DP0 TP0] Decode batch. #running-req: 16, #token: 11647, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.39, #queue-req: 583, 
[1,1]<stdout>:[2025-10-12 02:04:23 DP1 TP8] Decode batch. #running-req: 16, #token: 8155, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.40, #queue-req: 611, 
[1,1]<stdout>:[2025-10-12 02:04:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 610, 
[1,0]<stdout>:[2025-10-12 02:04:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 582, 
[1,0]<stdout>:[2025-10-12 02:04:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 581, 
[1,0]<stdout>:[2025-10-12 02:04:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 580, 
[1,0]<stdout>:[2025-10-12 02:04:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 0, token usage: 0.08, #running-req: 15, #queue-req: 580, 
[1,0]<stdout>:[2025-10-12 02:04:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 4, token usage: 0.08, #running-req: 15, #queue-req: 579, 
[1,0]<stdout>:[2025-10-12 02:04:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 578, 
[1,0]<stdout>:[2025-10-12 02:04:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 8, token usage: 0.06, #running-req: 15, #queue-req: 577, 
[1,0]<stdout>:[2025-10-12 02:04:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 576, 
[1,1]<stdout>:[2025-10-12 02:04:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 609, 
[1,0]<stdout>:[2025-10-12 02:04:25 DP0 TP0] Decode batch. #running-req: 16, #token: 10087, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 249.55, #queue-req: 576, 
[1,1]<stdout>:[2025-10-12 02:04:25 DP1 TP8] Decode batch. #running-req: 16, #token: 8700, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 251.51, #queue-req: 609, 
[1,0]<stdout>:[2025-10-12 02:04:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 575, 
[1,1]<stdout>:[2025-10-12 02:04:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 608, 
[1,1]<stdout>:[2025-10-12 02:04:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 607, 
[1,0]<stdout>:[2025-10-12 02:04:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 10, token usage: 0.06, #running-req: 15, #queue-req: 574, 
[1,0]<stdout>:[2025-10-12 02:04:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1734, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 573, 
[1,1]<stdout>:[2025-10-12 02:04:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 606, 
[1,0]<stdout>:[2025-10-12 02:04:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 6, token usage: 0.08, #running-req: 15, #queue-req: 572, 
[1,0]<stdout>:[2025-10-12 02:04:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 571, 
[1,1]<stdout>:[2025-10-12 02:04:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2044, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 605, 
[1,0]<stdout>:[2025-10-12 02:04:28 DP0 TP0] Decode batch. #running-req: 16, #token: 12190, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 263.71, #queue-req: 571, 
[1,1]<stdout>:[2025-10-12 02:04:28 DP1 TP8] Decode batch. #running-req: 16, #token: 10322, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 264.15, #queue-req: 605, 
[1,1]<stdout>:[2025-10-12 02:04:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 604, 
[1,0]<stdout>:[2025-10-12 02:04:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 570, 
[1,0]<stdout>:[2025-10-12 02:04:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 569, 
[1,1]<stdout>:[2025-10-12 02:04:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 637, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 603, 
[1,0]<stdout>:[2025-10-12 02:04:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 568, 
[1,1]<stdout>:[2025-10-12 02:04:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 8, token usage: 0.07, #running-req: 15, #queue-req: 602, 
[1,0]<stdout>:[2025-10-12 02:04:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 567, 
[1,0]<stdout>:[2025-10-12 02:04:30 DP0 TP0] Decode batch. #running-req: 16, #token: 11349, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 305.94, #queue-req: 567, 
[1,1]<stdout>:[2025-10-12 02:04:30 DP1 TP8] Decode batch. #running-req: 16, #token: 8982, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 306.39, #queue-req: 602, 
[1,1]<stdout>:[2025-10-12 02:04:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 737, #cached-token: 7, token usage: 0.06, #running-req: 15, #queue-req: 601, 
[1,1]<stdout>:[2025-10-12 02:04:30 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 405, #cached-token: 10, token usage: 0.05, #running-req: 14, #queue-req: 599, 
[1,0]<stdout>:[2025-10-12 02:04:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 566, 
[1,1]<stdout>:[2025-10-12 02:04:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 598, 
[1,0]<stdout>:[2025-10-12 02:04:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 565, 
[1,1]<stdout>:[2025-10-12 02:04:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 597, 
[1,1]<stdout>:[2025-10-12 02:04:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 596, 
[1,1]<stdout>:[2025-10-12 02:04:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 595, 
[1,1]<stdout>:[2025-10-12 02:04:32 DP1 TP8] Decode batch. #running-req: 16, #token: 9119, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 282.00, #queue-req: 595, 
[1,0]<stdout>:[2025-10-12 02:04:32 DP0 TP0] Decode batch. #running-req: 16, #token: 11557, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.22, #queue-req: 565, 
[1,1]<stdout>:[2025-10-12 02:04:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 594, 
[1,1]<stdout>:[2025-10-12 02:04:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 593, 
[1,1]<stdout>:[2025-10-12 02:04:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 592, 
[1,0]<stdout>:[2025-10-12 02:04:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 564, 
[1,1]<stdout>:[2025-10-12 02:04:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 591, 
[1,1]<stdout>:[2025-10-12 02:04:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 590, 
[1,1]<stdout>:[2025-10-12 02:04:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 589, 
[1,1]<stdout>:[2025-10-12 02:04:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 588, 
[1,0]<stdout>:[2025-10-12 02:04:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 563, 
[1,0]<stdout>:[2025-10-12 02:04:34 DP0 TP0] Decode batch. #running-req: 16, #token: 8104, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 271.62, #queue-req: 563, 
[1,1]<stdout>:[2025-10-12 02:04:34 DP1 TP8] Decode batch. #running-req: 16, #token: 7649, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 269.49, #queue-req: 588, 
[1,1]<stdout>:[2025-10-12 02:04:35 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 138, #cached-token: 3, token usage: 0.05, #running-req: 14, #queue-req: 586, 
[1,1]<stdout>:[2025-10-12 02:04:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 585, 
[1,0]<stdout>:[2025-10-12 02:04:36 DP0 TP0] Decode batch. #running-req: 16, #token: 8744, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 478.31, #queue-req: 563, 
[1,1]<stdout>:[2025-10-12 02:04:36 DP1 TP8] Decode batch. #running-req: 16, #token: 5957, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 476.01, #queue-req: 585, 
[1,1]<stdout>:[2025-10-12 02:04:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 584, 
[1,1]<stdout>:[2025-10-12 02:04:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 583, 
[1,1]<stdout>:[2025-10-12 02:04:37 DP1 TP8] Decode batch. #running-req: 16, #token: 5665, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 479.95, #queue-req: 583, 
[1,0]<stdout>:[2025-10-12 02:04:37 DP0 TP0] Decode batch. #running-req: 16, #token: 9384, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 481.34, #queue-req: 563, 
[1,0]<stdout>:[2025-10-12 02:04:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 562, 
[1,0]<stdout>:[2025-10-12 02:04:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 561, 
[1,0]<stdout>:[2025-10-12 02:04:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 560, 
[1,1]<stdout>:[2025-10-12 02:04:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 582, 
[1,0]<stdout>:[2025-10-12 02:04:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 559, 
[1,0]<stdout>:[2025-10-12 02:04:39 DP0 TP0] Decode batch. #running-req: 15, #token: 7417, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 359.80, #queue-req: 559, 
[1,1]<stdout>:[2025-10-12 02:04:39 DP1 TP8] Decode batch. #running-req: 16, #token: 6476, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 361.99, #queue-req: 582, 
[1,0]<stdout>:[2025-10-12 02:04:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 6, token usage: 0.05, #running-req: 15, #queue-req: 558, 
[1,0]<stdout>:[2025-10-12 02:04:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 5, token usage: 0.05, #running-req: 15, #queue-req: 557, 
[1,0]<stdout>:[2025-10-12 02:04:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 556, 
[1,1]<stdout>:[2025-10-12 02:04:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 581, 
[1,0]<stdout>:[2025-10-12 02:04:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 555, 
[1,1]<stdout>:[2025-10-12 02:04:40 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 47, #cached-token: 5, token usage: 0.04, #running-req: 14, #queue-req: 579, 
[1,0]<stdout>:[2025-10-12 02:04:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 554, 
[1,1]<stdout>:[2025-10-12 02:04:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 578, 
[1,0]<stdout>:[2025-10-12 02:04:41 DP0 TP0] Decode batch. #running-req: 16, #token: 8231, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 306.19, #queue-req: 554, 
[1,1]<stdout>:[2025-10-12 02:04:41 DP1 TP8] Decode batch. #running-req: 16, #token: 4730, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 306.23, #queue-req: 578, 
[1,1]<stdout>:[2025-10-12 02:04:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 844, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 577, 
[1,1]<stdout>:[2025-10-12 02:04:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 576, 
[1,0]<stdout>:[2025-10-12 02:04:42 DP0 TP0] Decode batch. #running-req: 16, #token: 8871, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 476.91, #queue-req: 554, 
[1,1]<stdout>:[2025-10-12 02:04:42 DP1 TP8] Decode batch. #running-req: 16, #token: 5715, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 475.36, #queue-req: 576, 
[1,1]<stdout>:[2025-10-12 02:04:42 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 706, #cached-token: 3, token usage: 0.03, #running-req: 14, #queue-req: 574, 
[1,0]<stdout>:[2025-10-12 02:04:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 553, 
[1,1]<stdout>:[2025-10-12 02:04:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 573, 
[1,1]<stdout>:[2025-10-12 02:04:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 572, 
[1,1]<stdout>:[2025-10-12 02:04:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 571, 
[1,1]<stdout>:[2025-10-12 02:04:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 570, 
[1,0]<stdout>:[2025-10-12 02:04:44 DP0 TP0] Decode batch. #running-req: 15, #token: 8751, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 332.00, #queue-req: 553, 
[1,1]<stdout>:[2025-10-12 02:04:44 DP1 TP8] Decode batch. #running-req: 16, #token: 4540, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 329.93, #queue-req: 570, 
[1,0]<stdout>:[2025-10-12 02:04:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 552, 
[1,1]<stdout>:[2025-10-12 02:04:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 569, 
[1,0]<stdout>:[2025-10-12 02:04:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 551, 
[1,1]<stdout>:[2025-10-12 02:04:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 568, 
[1,0]<stdout>:[2025-10-12 02:04:46 DP0 TP0] Decode batch. #running-req: 16, #token: 8506, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 393.81, #queue-req: 551, 
[1,1]<stdout>:[2025-10-12 02:04:46 DP1 TP8] Decode batch. #running-req: 16, #token: 5440, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 393.17, #queue-req: 568, 
[1,0]<stdout>:[2025-10-12 02:04:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 550, 
[1,0]<stdout>:[2025-10-12 02:04:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 549, 
[1,1]<stdout>:[2025-10-12 02:04:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 567, 
[1,1]<stdout>:[2025-10-12 02:04:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 566, 
[1,1]<stdout>:[2025-10-12 02:04:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 565, 
[1,1]<stdout>:[2025-10-12 02:04:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 564, 
[1,0]<stdout>:[2025-10-12 02:04:48 DP0 TP0] Decode batch. #running-req: 16, #token: 8065, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 331.22, #queue-req: 549, 
[1,1]<stdout>:[2025-10-12 02:04:48 DP1 TP8] Decode batch. #running-req: 16, #token: 5025, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 330.16, #queue-req: 564, 
[1,1]<stdout>:[2025-10-12 02:04:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 563, 
[1,0]<stdout>:[2025-10-12 02:04:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 548, 
[1,0]<stdout>:[2025-10-12 02:04:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 547, 
[1,0]<stdout>:[2025-10-12 02:04:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 546, 
[1,1]<stdout>:[2025-10-12 02:04:49 DP1 TP8] Decode batch. #running-req: 16, #token: 5333, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 394.53, #queue-req: 563, 
[1,0]<stdout>:[2025-10-12 02:04:49 DP0 TP0] Decode batch. #running-req: 16, #token: 7584, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 393.18, #queue-req: 546, 
[1,0]<stdout>:[2025-10-12 02:04:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 545, 
[1,0]<stdout>:[2025-10-12 02:04:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 14, token usage: 0.05, #running-req: 15, #queue-req: 544, 
[1,0]<stdout>:[2025-10-12 02:04:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 543, 
[1,1]<stdout>:[2025-10-12 02:04:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 562, 
[1,0]<stdout>:[2025-10-12 02:04:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 542, 
[1,1]<stdout>:[2025-10-12 02:04:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 561, 
[1,1]<stdout>:[2025-10-12 02:04:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 560, 
[1,1]<stdout>:[2025-10-12 02:04:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 559, 
[1,1]<stdout>:[2025-10-12 02:04:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 558, 
[1,0]<stdout>:[2025-10-12 02:04:51 DP0 TP0] Decode batch. #running-req: 16, #token: 6204, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.02, #queue-req: 542, 
[1,1]<stdout>:[2025-10-12 02:04:51 DP1 TP8] Decode batch. #running-req: 16, #token: 5008, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 285.51, #queue-req: 558, 
[1,0]<stdout>:[2025-10-12 02:04:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 541, 
[1,0]<stdout>:[2025-10-12 02:04:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 10, token usage: 0.03, #running-req: 15, #queue-req: 540, 
[1,0]<stdout>:[2025-10-12 02:04:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 539, 
[1,1]<stdout>:[2025-10-12 02:04:53 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 1549, #cached-token: 8, token usage: 0.03, #running-req: 14, #queue-req: 556, 
[1,0]<stdout>:[2025-10-12 02:04:53 DP0 TP0] Decode batch. #running-req: 16, #token: 5872, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.66, #queue-req: 539, 
[1,1]<stdout>:[2025-10-12 02:04:53 DP1 TP8] Decode batch. #running-req: 16, #token: 6469, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 393.25, #queue-req: 556, 
[1,1]<stdout>:[2025-10-12 02:04:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 739, #cached-token: 7, token usage: 0.04, #running-req: 15, #queue-req: 555, 
[1,1]<stdout>:[2025-10-12 02:04:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 554, 
[1,0]<stdout>:[2025-10-12 02:04:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 538, 
[1,1]<stdout>:[2025-10-12 02:04:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 553, 
[1,1]<stdout>:[2025-10-12 02:04:54 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 138, #cached-token: 7, token usage: 0.04, #running-req: 14, #queue-req: 551, 
[1,0]<stdout>:[2025-10-12 02:04:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 537, 
[1,0]<stdout>:[2025-10-12 02:04:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1427, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 536, 
[1,0]<stdout>:[2025-10-12 02:04:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 535, 
[1,0]<stdout>:[2025-10-12 02:04:55 DP0 TP0] Decode batch. #running-req: 16, #token: 7187, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.75, #queue-req: 535, 
[1,1]<stdout>:[2025-10-12 02:04:55 DP1 TP8] Decode batch. #running-req: 16, #token: 6079, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.31, #queue-req: 551, 
[1,0]<stdout>:[2025-10-12 02:04:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 534, 
[1,0]<stdout>:[2025-10-12 02:04:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 533, 
[1,1]<stdout>:[2025-10-12 02:04:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 550, 
[1,0]<stdout>:[2025-10-12 02:04:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 532, 
[1,1]<stdout>:[2025-10-12 02:04:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 549, 
[1,1]<stdout>:[2025-10-12 02:04:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 548, 
[1,0]<stdout>:[2025-10-12 02:04:57 DP0 TP0] Decode batch. #running-req: 16, #token: 8077, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 323.38, #queue-req: 532, 
[1,1]<stdout>:[2025-10-12 02:04:57 DP1 TP8] Decode batch. #running-req: 16, #token: 5941, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 323.41, #queue-req: 548, 
[1,0]<stdout>:[2025-10-12 02:04:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 531, 
[1,1]<stdout>:[2025-10-12 02:04:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 376, token usage: 0.04, #running-req: 15, #queue-req: 547, 
[1,1]<stdout>:[2025-10-12 02:04:59 DP1 TP8] Decode batch. #running-req: 16, #token: 6472, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 473.40, #queue-req: 547, 
[1,0]<stdout>:[2025-10-12 02:04:59 DP0 TP0] Decode batch. #running-req: 16, #token: 8429, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 473.30, #queue-req: 531, 
[1,0]<stdout>:[2025-10-12 02:04:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 530, 
[1,0]<stdout>:[2025-10-12 02:04:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 5, token usage: 0.05, #running-req: 15, #queue-req: 529, 
[1,0]<stdout>:[2025-10-12 02:04:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 528, 
[1,0]<stdout>:[2025-10-12 02:04:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 527, 
[1,1]<stdout>:[2025-10-12 02:05:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 546, 
[1,1]<stdout>:[2025-10-12 02:05:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1399, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 545, 
[1,0]<stdout>:[2025-10-12 02:05:01 DP0 TP0] Decode batch. #running-req: 16, #token: 6979, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 320.81, #queue-req: 527, 
[1,1]<stdout>:[2025-10-12 02:05:01 DP1 TP8] Decode batch. #running-req: 16, #token: 8040, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 321.74, #queue-req: 545, 
[1,1]<stdout>:[2025-10-12 02:05:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 544, 
[1,1]<stdout>:[2025-10-12 02:05:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 543, 
[1,1]<stdout>:[2025-10-12 02:05:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 8, token usage: 0.05, #running-req: 15, #queue-req: 542, 
[1,0]<stdout>:[2025-10-12 02:05:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 526, 
[1,0]<stdout>:[2025-10-12 02:05:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 829, #cached-token: 10, token usage: 0.05, #running-req: 15, #queue-req: 525, 
[1,0]<stdout>:[2025-10-12 02:05:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 524, 
[1,0]<stdout>:[2025-10-12 02:05:03 DP0 TP0] Decode batch. #running-req: 16, #token: 7800, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 322.41, #queue-req: 524, 
[1,1]<stdout>:[2025-10-12 02:05:03 DP1 TP8] Decode batch. #running-req: 16, #token: 8490, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 322.46, #queue-req: 542, 
[1,1]<stdout>:[2025-10-12 02:05:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 541, 
[1,0]<stdout>:[2025-10-12 02:05:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 523, 
[1,0]<stdout>:[2025-10-12 02:05:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 522, 
[1,1]<stdout>:[2025-10-12 02:05:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 238, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 540, 
[1,0]<stdout>:[2025-10-12 02:05:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 521, 
[1,0]<stdout>:[2025-10-12 02:05:04 DP0 TP0] Decode batch. #running-req: 16, #token: 7385, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 354.91, #queue-req: 521, 
[1,1]<stdout>:[2025-10-12 02:05:04 DP1 TP8] Decode batch. #running-req: 16, #token: 8391, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.42, #queue-req: 540, 
[1,1]<stdout>:[2025-10-12 02:05:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 539, 
[1,0]<stdout>:[2025-10-12 02:05:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 520, 
[1,0]<stdout>:[2025-10-12 02:05:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 519, 
[1,1]<stdout>:[2025-10-12 02:05:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 538, 
[1,0]<stdout>:[2025-10-12 02:05:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 518, 
[1,0]<stdout>:[2025-10-12 02:05:06 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 995, #cached-token: 4, token usage: 0.04, #running-req: 14, #queue-req: 516, 
[1,1]<stdout>:[2025-10-12 02:05:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 537, 
[1,1]<stdout>:[2025-10-12 02:05:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 536, 
[1,0]<stdout>:[2025-10-12 02:05:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.05, #running-req: 15, #queue-req: 515, 
[1,0]<stdout>:[2025-10-12 02:05:07 DP0 TP0] Decode batch. #running-req: 16, #token: 7431, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 281.80, #queue-req: 515, 
[1,1]<stdout>:[2025-10-12 02:05:07 DP1 TP8] Decode batch. #running-req: 16, #token: 9466, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 282.71, #queue-req: 536, 
[1,0]<stdout>:[2025-10-12 02:05:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 514, 
[1,1]<stdout>:[2025-10-12 02:05:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 535, 
[1,0]<stdout>:[2025-10-12 02:05:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 513, 
[1,0]<stdout>:[2025-10-12 02:05:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1167, #cached-token: 0, token usage: 0.06, #running-req: 15, #queue-req: 513, 
[1,0]<stdout>:[2025-10-12 02:05:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 5, token usage: 0.07, #running-req: 15, #queue-req: 512, 
[1,0]<stdout>:[2025-10-12 02:05:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 511, 
[1,1]<stdout>:[2025-10-12 02:05:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 534, 
[1,0]<stdout>:[2025-10-12 02:05:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 510, 
[1,1]<stdout>:[2025-10-12 02:05:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 533, 
[1,0]<stdout>:[2025-10-12 02:05:09 DP0 TP0] Decode batch. #running-req: 16, #token: 10065, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 266.64, #queue-req: 510, 
[1,1]<stdout>:[2025-10-12 02:05:09 DP1 TP8] Decode batch. #running-req: 16, #token: 9176, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 267.48, #queue-req: 533, 
[1,0]<stdout>:[2025-10-12 02:05:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 509, 
[1,0]<stdout>:[2025-10-12 02:05:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 508, 
[1,0]<stdout>:[2025-10-12 02:05:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 507, 
[1,1]<stdout>:[2025-10-12 02:05:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 451, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 532, 
[1,0]<stdout>:[2025-10-12 02:05:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 506, 
[1,1]<stdout>:[2025-10-12 02:05:10 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 16, #cached-token: 5, token usage: 0.05, #running-req: 14, #queue-req: 530, 
[1,1]<stdout>:[2025-10-12 02:05:10 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 587, #cached-token: 2, token usage: 0.05, #running-req: 14, #queue-req: 528, 
[1,1]<stdout>:[2025-10-12 02:05:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 527, 
[1,0]<stdout>:[2025-10-12 02:05:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 505, 
[1,0]<stdout>:[2025-10-12 02:05:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1951, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 504, 
[1,1]<stdout>:[2025-10-12 02:05:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 9, token usage: 0.05, #running-req: 15, #queue-req: 526, 
[1,0]<stdout>:[2025-10-12 02:05:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 503, 
[1,0]<stdout>:[2025-10-12 02:05:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 502, 
[1,0]<stdout>:[2025-10-12 02:05:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 501, 
[1,1]<stdout>:[2025-10-12 02:05:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 525, 
[1,0]<stdout>:[2025-10-12 02:05:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 500, 
[1,0]<stdout>:[2025-10-12 02:05:12 DP0 TP0] Decode batch. #running-req: 16, #token: 10153, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 212.19, #queue-req: 500, 
[1,1]<stdout>:[2025-10-12 02:05:12 DP1 TP8] Decode batch. #running-req: 16, #token: 8499, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 212.85, #queue-req: 525, 
[1,0]<stdout>:[2025-10-12 02:05:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 499, 
[1,1]<stdout>:[2025-10-12 02:05:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 524, 
[1,1]<stdout>:[2025-10-12 02:05:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 386, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 523, 
[1,0]<stdout>:[2025-10-12 02:05:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 498, 
[1,1]<stdout>:[2025-10-12 02:05:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 522, 
[1,0]<stdout>:[2025-10-12 02:05:14 DP0 TP0] Decode batch. #running-req: 16, #token: 10466, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.40, #queue-req: 498, 
[1,1]<stdout>:[2025-10-12 02:05:14 DP1 TP8] Decode batch. #running-req: 16, #token: 8543, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 354.90, #queue-req: 522, 
[1,1]<stdout>:[2025-10-12 02:05:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 521, 
[1,1]<stdout>:[2025-10-12 02:05:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 520, 
[1,0]<stdout>:[2025-10-12 02:05:15 DP0 TP0] Decode batch. #running-req: 16, #token: 11106, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 477.53, #queue-req: 498, 
[1,1]<stdout>:[2025-10-12 02:05:15 DP1 TP8] Decode batch. #running-req: 16, #token: 9322, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 476.09, #queue-req: 520, 
[1,1]<stdout>:[2025-10-12 02:05:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 519, 
[1,1]<stdout>:[2025-10-12 02:05:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 518, 
[1,1]<stdout>:[2025-10-12 02:05:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 517, 
[1,0]<stdout>:[2025-10-12 02:05:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 497, 
[1,1]<stdout>:[2025-10-12 02:05:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 516, 
[1,0]<stdout>:[2025-10-12 02:05:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 496, 
[1,1]<stdout>:[2025-10-12 02:05:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 515, 
[1,0]<stdout>:[2025-10-12 02:05:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 0, token usage: 0.08, #running-req: 15, #queue-req: 496, 
[1,1]<stdout>:[2025-10-12 02:05:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 514, 
[1,0]<stdout>:[2025-10-12 02:05:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 495, 
[1,0]<stdout>:[2025-10-12 02:05:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 494, 
[1,1]<stdout>:[2025-10-12 02:05:18 DP1 TP8] Decode batch. #running-req: 16, #token: 7030, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 250.19, #queue-req: 514, 
[1,0]<stdout>:[2025-10-12 02:05:18 DP0 TP0] Decode batch. #running-req: 16, #token: 11518, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 250.97, #queue-req: 494, 
[1,1]<stdout>:[2025-10-12 02:05:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 513, 
[1,1]<stdout>:[2025-10-12 02:05:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 512, 
[1,0]<stdout>:[2025-10-12 02:05:19 DP0 TP0] Decode batch. #running-req: 16, #token: 12158, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 477.39, #queue-req: 494, 
[1,1]<stdout>:[2025-10-12 02:05:19 DP1 TP8] Decode batch. #running-req: 15, #token: 7571, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 474.95, #queue-req: 512, 
[1,1]<stdout>:[2025-10-12 02:05:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 511, 
[1,0]<stdout>:[2025-10-12 02:05:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 493, 
[1,0]<stdout>:[2025-10-12 02:05:20 DP0 TP0] Decode batch. #running-req: 16, #token: 12598, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 477.57, #queue-req: 493, 
[1,1]<stdout>:[2025-10-12 02:05:20 DP1 TP8] Decode batch. #running-req: 16, #token: 8952, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 478.42, #queue-req: 511, 
[1,0]<stdout>:[2025-10-12 02:05:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 492, 
[1,0]<stdout>:[2025-10-12 02:05:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 491, 
[1,1]<stdout>:[2025-10-12 02:05:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 510, 
[1,1]<stdout>:[2025-10-12 02:05:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1016, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 509, 
[1,0]<stdout>:[2025-10-12 02:05:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 490, 
[1,0]<stdout>:[2025-10-12 02:05:22 DP0 TP0] Decode batch. #running-req: 16, #token: 12635, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 357.63, #queue-req: 490, 
[1,1]<stdout>:[2025-10-12 02:05:22 DP1 TP8] Decode batch. #running-req: 16, #token: 10405, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.14, #queue-req: 509, 
[1,0]<stdout>:[2025-10-12 02:05:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.08, #running-req: 15, #queue-req: 489, 
[1,1]<stdout>:[2025-10-12 02:05:23 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 468, #cached-token: 6, token usage: 0.06, #running-req: 14, #queue-req: 507, 
[1,0]<stdout>:[2025-10-12 02:05:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 488, 
[1,0]<stdout>:[2025-10-12 02:05:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 487, 
[1,1]<stdout>:[2025-10-12 02:05:23 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 614, #cached-token: 3, token usage: 0.06, #running-req: 14, #queue-req: 505, 
[1,0]<stdout>:[2025-10-12 02:05:24 DP0 TP0] Decode batch. #running-req: 16, #token: 13392, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 385.31, #queue-req: 487, 
[1,1]<stdout>:[2025-10-12 02:05:24 DP1 TP8] Decode batch. #running-req: 16, #token: 10728, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 384.74, #queue-req: 505, 
[1,1]<stdout>:[2025-10-12 02:05:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 504, 
[1,0]<stdout>:[2025-10-12 02:05:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 486, 
[1,0]<stdout>:[2025-10-12 02:05:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 485, 
[1,0]<stdout>:[2025-10-12 02:05:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 484, 
[1,0]<stdout>:[2025-10-12 02:05:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.08, #running-req: 15, #queue-req: 483, 
[1,0]<stdout>:[2025-10-12 02:05:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 482, 
[1,1]<stdout>:[2025-10-12 02:05:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 503, 
[1,1]<stdout>:[2025-10-12 02:05:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 502, 
[1,0]<stdout>:[2025-10-12 02:05:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2032, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 481, 
[1,0]<stdout>:[2025-10-12 02:05:26 DP0 TP0] Decode batch. #running-req: 16, #token: 14686, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 267.49, #queue-req: 481, 
[1,1]<stdout>:[2025-10-12 02:05:26 DP1 TP8] Decode batch. #running-req: 15, #token: 9928, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 268.33, #queue-req: 502, 
[1,1]<stdout>:[2025-10-12 02:05:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 501, 
[1,1]<stdout>:[2025-10-12 02:05:27 DP1 TP8] Prefill batch. #new-seq: 3, #new-token: 1514, #cached-token: 7, token usage: 0.06, #running-req: 13, #queue-req: 498, 
[1,0]<stdout>:[2025-10-12 02:05:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 619, #cached-token: 8, token usage: 0.07, #running-req: 15, #queue-req: 480, 
[1,0]<stdout>:[2025-10-12 02:05:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1101, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 479, 
[1,1]<stdout>:[2025-10-12 02:05:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 793, #cached-token: 7, token usage: 0.06, #running-req: 15, #queue-req: 497, 
[1,1]<stdout>:[2025-10-12 02:05:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 496, 
[1,1]<stdout>:[2025-10-12 02:05:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 495, 
[1,0]<stdout>:[2025-10-12 02:05:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 478, 
[1,1]<stdout>:[2025-10-12 02:05:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 494, 
[1,0]<stdout>:[2025-10-12 02:05:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 4, token usage: 0.07, #running-req: 15, #queue-req: 477, 
[1,0]<stdout>:[2025-10-12 02:05:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 476, 
[1,1]<stdout>:[2025-10-12 02:05:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 493, 
[1,0]<stdout>:[2025-10-12 02:05:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 475, 
[1,0]<stdout>:[2025-10-12 02:05:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 474, 
[1,0]<stdout>:[2025-10-12 02:05:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 473, 
[1,0]<stdout>:[2025-10-12 02:05:29 DP0 TP0] Decode batch. #running-req: 16, #token: 12127, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 473, 
[1,1]<stdout>:[2025-10-12 02:05:29 DP1 TP8] Decode batch. #running-req: 16, #token: 8581, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 493, 
[1,0]<stdout>:[2025-10-12 02:05:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 472, 
[1,0]<stdout>:[2025-10-12 02:05:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 4, token usage: 0.08, #running-req: 15, #queue-req: 471, 
[1,0]<stdout>:[2025-10-12 02:05:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 470, 
[1,0]<stdout>:[2025-10-12 02:05:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 565, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 469, 
[1,0]<stdout>:[2025-10-12 02:05:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 468, 
[1,1]<stdout>:[2025-10-12 02:05:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 492, 
[1,0]<stdout>:[2025-10-12 02:05:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1117, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 467, 
[1,0]<stdout>:[2025-10-12 02:05:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 466, 
[1,0]<stdout>:[2025-10-12 02:05:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 465, 
[1,1]<stdout>:[2025-10-12 02:05:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 661, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 491, 
[1,1]<stdout>:[2025-10-12 02:05:31 DP1 TP8] Decode batch. #running-req: 15, #token: 7815, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 253.90, #queue-req: 491, 
[1,0]<stdout>:[2025-10-12 02:05:31 DP0 TP0] Decode batch. #running-req: 16, #token: 13260, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 251.89, #queue-req: 465, 
[1,1]<stdout>:[2025-10-12 02:05:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 490, 
[1,1]<stdout>:[2025-10-12 02:05:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 489, 
[1,1]<stdout>:[2025-10-12 02:05:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 488, 
[1,1]<stdout>:[2025-10-12 02:05:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 0, token usage: 0.06, #running-req: 15, #queue-req: 488, 
[1,0]<stdout>:[2025-10-12 02:05:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 464, 
[1,0]<stdout>:[2025-10-12 02:05:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 463, 
[1,0]<stdout>:[2025-10-12 02:05:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1335, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 462, 
[1,0]<stdout>:[2025-10-12 02:05:34 DP0 TP0] Decode batch. #running-req: 16, #token: 12377, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 306.20, #queue-req: 462, 
[1,1]<stdout>:[2025-10-12 02:05:34 DP1 TP8] Decode batch. #running-req: 16, #token: 10223, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 306.66, #queue-req: 488, 
[1,0]<stdout>:[2025-10-12 02:05:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 461, 
[1,0]<stdout>:[2025-10-12 02:05:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 460, 
[1,0]<stdout>:[2025-10-12 02:05:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 459, 
[1,0]<stdout>:[2025-10-12 02:05:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1558, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 458, 
[1,0]<stdout>:[2025-10-12 02:05:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 5, token usage: 0.06, #running-req: 15, #queue-req: 457, 
[1,0]<stdout>:[2025-10-12 02:05:35 DP0 TP0] Decode batch. #running-req: 16, #token: 8714, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.43, #queue-req: 457, 
[1,1]<stdout>:[2025-10-12 02:05:35 DP1 TP8] Decode batch. #running-req: 16, #token: 10863, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 361.25, #queue-req: 488, 
[1,1]<stdout>:[2025-10-12 02:05:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 480, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 487, 
[1,0]<stdout>:[2025-10-12 02:05:36 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 15, #cached-token: 4, token usage: 0.05, #running-req: 14, #queue-req: 455, 
[1,1]<stdout>:[2025-10-12 02:05:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 8, token usage: 0.07, #running-req: 15, #queue-req: 486, 
[1,0]<stdout>:[2025-10-12 02:05:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 454, 
[1,0]<stdout>:[2025-10-12 02:05:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 453, 
[1,0]<stdout>:[2025-10-12 02:05:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 452, 
[1,1]<stdout>:[2025-10-12 02:05:37 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 865, #cached-token: 6, token usage: 0.06, #running-req: 14, #queue-req: 484, 
[1,1]<stdout>:[2025-10-12 02:05:37 DP1 TP8] Decode batch. #running-req: 16, #token: 10171, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 328.55, #queue-req: 484, 
[1,0]<stdout>:[2025-10-12 02:05:37 DP0 TP0] Decode batch. #running-req: 16, #token: 7750, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 328.00, #queue-req: 452, 
[1,1]<stdout>:[2025-10-12 02:05:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 483, 
[1,0]<stdout>:[2025-10-12 02:05:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 451, 
[1,1]<stdout>:[2025-10-12 02:05:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 482, 
[1,0]<stdout>:[2025-10-12 02:05:38 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 242, #cached-token: 7, token usage: 0.05, #running-req: 14, #queue-req: 449, 
[1,0]<stdout>:[2025-10-12 02:05:38 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 341, #cached-token: 3, token usage: 0.05, #running-req: 14, #queue-req: 447, 
[1,0]<stdout>:[2025-10-12 02:05:39 DP0 TP0] Decode batch. #running-req: 16, #token: 8742, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.11, #queue-req: 447, 
[1,1]<stdout>:[2025-10-12 02:05:39 DP1 TP8] Decode batch. #running-req: 16, #token: 9965, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 390.87, #queue-req: 482, 
[1,0]<stdout>:[2025-10-12 02:05:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 567, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 446, 
[1,0]<stdout>:[2025-10-12 02:05:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 8, token usage: 0.06, #running-req: 15, #queue-req: 445, 
[1,0]<stdout>:[2025-10-12 02:05:40 DP0 TP0] Decode batch. #running-req: 15, #token: 8626, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 474.08, #queue-req: 445, 
[1,1]<stdout>:[2025-10-12 02:05:40 DP1 TP8] Decode batch. #running-req: 16, #token: 10605, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 476.36, #queue-req: 482, 
[1,0]<stdout>:[2025-10-12 02:05:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 4, token usage: 0.06, #running-req: 15, #queue-req: 444, 
[1,1]<stdout>:[2025-10-12 02:05:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 481, 
[1,0]<stdout>:[2025-10-12 02:05:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 443, 
[1,0]<stdout>:[2025-10-12 02:05:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 442, 
[1,0]<stdout>:[2025-10-12 02:05:42 DP0 TP0] Decode batch. #running-req: 16, #token: 9018, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.25, #queue-req: 442, 
[1,1]<stdout>:[2025-10-12 02:05:42 DP1 TP8] Decode batch. #running-req: 16, #token: 8960, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.81, #queue-req: 481, 
[1,1]<stdout>:[2025-10-12 02:05:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 480, 
[1,0]<stdout>:[2025-10-12 02:05:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 441, 
[1,1]<stdout>:[2025-10-12 02:05:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 479, 
[1,1]<stdout>:[2025-10-12 02:05:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 478, 
[1,1]<stdout>:[2025-10-12 02:05:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 477, 
[1,1]<stdout>:[2025-10-12 02:05:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 474, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 476, 
[1,0]<stdout>:[2025-10-12 02:05:44 DP0 TP0] Decode batch. #running-req: 16, #token: 7934, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 332.82, #queue-req: 441, 
[1,1]<stdout>:[2025-10-12 02:05:44 DP1 TP8] Decode batch. #running-req: 16, #token: 7593, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 330.75, #queue-req: 476, 
[1,1]<stdout>:[2025-10-12 02:05:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 475, 
[1,1]<stdout>:[2025-10-12 02:05:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1424, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 474, 
[1,1]<stdout>:[2025-10-12 02:05:45 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 208, #cached-token: 2, token usage: 0.04, #running-req: 14, #queue-req: 472, 
[1,0]<stdout>:[2025-10-12 02:05:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 6, token usage: 0.05, #running-req: 15, #queue-req: 440, 
[1,0]<stdout>:[2025-10-12 02:05:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 439, 
[1,0]<stdout>:[2025-10-12 02:05:46 DP0 TP0] Decode batch. #running-req: 16, #token: 8762, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 357.24, #queue-req: 439, 
[1,1]<stdout>:[2025-10-12 02:05:46 DP1 TP8] Decode batch. #running-req: 16, #token: 7312, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.12, #queue-req: 472, 
[1,1]<stdout>:[2025-10-12 02:05:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 19, token usage: 0.05, #running-req: 15, #queue-req: 471, 
[1,0]<stdout>:[2025-10-12 02:05:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 438, 
[1,0]<stdout>:[2025-10-12 02:05:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 437, 
[1,1]<stdout>:[2025-10-12 02:05:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 470, 
[1,1]<stdout>:[2025-10-12 02:05:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 469, 
[1,0]<stdout>:[2025-10-12 02:05:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 436, 
[1,0]<stdout>:[2025-10-12 02:05:47 DP0 TP0] Decode batch. #running-req: 16, #token: 6921, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.71, #queue-req: 436, 
[1,1]<stdout>:[2025-10-12 02:05:47 DP1 TP8] Decode batch. #running-req: 16, #token: 7697, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.71, #queue-req: 469, 
[1,1]<stdout>:[2025-10-12 02:05:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 468, 
[1,0]<stdout>:[2025-10-12 02:05:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 435, 
[1,1]<stdout>:[2025-10-12 02:05:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 467, 
[1,0]<stdout>:[2025-10-12 02:05:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 434, 
[1,1]<stdout>:[2025-10-12 02:05:49 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 441, #cached-token: 8, token usage: 0.05, #running-req: 14, #queue-req: 465, 
[1,0]<stdout>:[2025-10-12 02:05:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 433, 
[1,0]<stdout>:[2025-10-12 02:05:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 432, 
[1,0]<stdout>:[2025-10-12 02:05:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 431, 
[1,1]<stdout>:[2025-10-12 02:05:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 464, 
[1,0]<stdout>:[2025-10-12 02:05:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 430, 
[1,0]<stdout>:[2025-10-12 02:05:50 DP0 TP0] Decode batch. #running-req: 16, #token: 4754, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 252.71, #queue-req: 430, 
[1,1]<stdout>:[2025-10-12 02:05:50 DP1 TP8] Decode batch. #running-req: 16, #token: 7874, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 253.11, #queue-req: 464, 
[1,0]<stdout>:[2025-10-12 02:05:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 429, 
[1,0]<stdout>:[2025-10-12 02:05:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 428, 
[1,1]<stdout>:[2025-10-12 02:05:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 463, 
[1,1]<stdout>:[2025-10-12 02:05:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 462, 
[1,0]<stdout>:[2025-10-12 02:05:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 427, 
[1,0]<stdout>:[2025-10-12 02:05:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 426, 
[1,1]<stdout>:[2025-10-12 02:05:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 461, 
[1,0]<stdout>:[2025-10-12 02:05:52 DP0 TP0] Decode batch. #running-req: 16, #token: 5201, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 328.07, #queue-req: 426, 
[1,1]<stdout>:[2025-10-12 02:05:52 DP1 TP8] Decode batch. #running-req: 16, #token: 8608, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 328.54, #queue-req: 461, 
[1,0]<stdout>:[2025-10-12 02:05:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 425, 
[1,0]<stdout>:[2025-10-12 02:05:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 424, 
[1,0]<stdout>:[2025-10-12 02:05:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 423, 
[1,1]<stdout>:[2025-10-12 02:05:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.05, #running-req: 15, #queue-req: 460, 
[1,0]<stdout>:[2025-10-12 02:05:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 674, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 422, 
[1,0]<stdout>:[2025-10-12 02:05:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 421, 
[1,0]<stdout>:[2025-10-12 02:05:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 420, 
[1,1]<stdout>:[2025-10-12 02:05:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1779, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 459, 
[1,0]<stdout>:[2025-10-12 02:05:54 DP0 TP0] Decode batch. #running-req: 16, #token: 5585, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 278.53, #queue-req: 420, 
[1,1]<stdout>:[2025-10-12 02:05:54 DP1 TP8] Decode batch. #running-req: 16, #token: 9913, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 280.33, #queue-req: 459, 
[1,0]<stdout>:[2025-10-12 02:05:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 419, 
[1,1]<stdout>:[2025-10-12 02:05:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 4, token usage: 0.05, #running-req: 15, #queue-req: 458, 
[1,0]<stdout>:[2025-10-12 02:05:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 418, 
[1,1]<stdout>:[2025-10-12 02:05:55 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 2048, #cached-token: 6, token usage: 0.05, #running-req: 14, #queue-req: 456, 
[1,1]<stdout>:[2025-10-12 02:05:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.06, #running-req: 15, #queue-req: 456, 
[1,1]<stdout>:[2025-10-12 02:05:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 0, token usage: 0.07, #running-req: 15, #queue-req: 456, 
[1,0]<stdout>:[2025-10-12 02:05:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 8, token usage: 0.03, #running-req: 15, #queue-req: 417, 
[1,1]<stdout>:[2025-10-12 02:05:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 455, 
[1,0]<stdout>:[2025-10-12 02:05:56 DP0 TP0] Decode batch. #running-req: 16, #token: 5176, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.89, #queue-req: 417, 
[1,1]<stdout>:[2025-10-12 02:05:56 DP1 TP8] Decode batch. #running-req: 16, #token: 11621, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 286.41, #queue-req: 455, 
[1,1]<stdout>:[2025-10-12 02:05:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 727, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 454, 
[1,1]<stdout>:[2025-10-12 02:05:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 453, 
[1,1]<stdout>:[2025-10-12 02:05:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 452, 
[1,0]<stdout>:[2025-10-12 02:05:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 4, token usage: 0.03, #running-req: 15, #queue-req: 416, 
[1,0]<stdout>:[2025-10-12 02:05:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 415, 
[1,0]<stdout>:[2025-10-12 02:05:58 DP0 TP0] Decode batch. #running-req: 16, #token: 4702, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 360.17, #queue-req: 415, 
[1,1]<stdout>:[2025-10-12 02:05:58 DP1 TP8] Decode batch. #running-req: 16, #token: 10877, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 359.61, #queue-req: 452, 
[1,0]<stdout>:[2025-10-12 02:05:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 414, 
[1,1]<stdout>:[2025-10-12 02:05:59 DP1 TP8] Decode batch. #running-req: 16, #token: 11517, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 536.39, #queue-req: 452, 
[1,0]<stdout>:[2025-10-12 02:05:59 DP0 TP0] Decode batch. #running-req: 16, #token: 5366, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 535.37, #queue-req: 414, 
[1,1]<stdout>:[2025-10-12 02:05:59 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 323, #cached-token: 3, token usage: 0.07, #running-req: 14, #queue-req: 450, 
[1,1]<stdout>:[2025-10-12 02:06:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 449, 
[1,0]<stdout>:[2025-10-12 02:06:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 413, 
[1,1]<stdout>:[2025-10-12 02:06:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 448, 
[1,0]<stdout>:[2025-10-12 02:06:01 DP0 TP0] Decode batch. #running-req: 16, #token: 5938, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 391.17, #queue-req: 413, 
[1,1]<stdout>:[2025-10-12 02:06:01 DP1 TP8] Decode batch. #running-req: 16, #token: 10507, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.24, #queue-req: 448, 
[1,1]<stdout>:[2025-10-12 02:06:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 447, 
[1,1]<stdout>:[2025-10-12 02:06:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 446, 
[1,0]<stdout>:[2025-10-12 02:06:02 DP0 TP0] Decode batch. #running-req: 16, #token: 6578, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 476.66, #queue-req: 413, 
[1,1]<stdout>:[2025-10-12 02:06:02 DP1 TP8] Decode batch. #running-req: 16, #token: 9140, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 475.10, #queue-req: 446, 
[1,1]<stdout>:[2025-10-12 02:06:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.06, #running-req: 15, #queue-req: 445, 
[1,1]<stdout>:[2025-10-12 02:06:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 3, token usage: 0.05, #running-req: 15, #queue-req: 444, 
[1,0]<stdout>:[2025-10-12 02:06:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 412, 
[1,0]<stdout>:[2025-10-12 02:06:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 411, 
[1,0]<stdout>:[2025-10-12 02:06:04 DP0 TP0] Decode batch. #running-req: 16, #token: 7218, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.72, #queue-req: 411, 
[1,1]<stdout>:[2025-10-12 02:06:04 DP1 TP8] Decode batch. #running-req: 16, #token: 8616, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.61, #queue-req: 444, 
[1,1]<stdout>:[2025-10-12 02:06:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 443, 
[1,0]<stdout>:[2025-10-12 02:06:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 840, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 410, 
[1,1]<stdout>:[2025-10-12 02:06:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 691, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 442, 
[1,0]<stdout>:[2025-10-12 02:06:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.05, #running-req: 15, #queue-req: 409, 
[1,0]<stdout>:[2025-10-12 02:06:06 DP0 TP0] Decode batch. #running-req: 16, #token: 7542, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 385.57, #queue-req: 409, 
[1,1]<stdout>:[2025-10-12 02:06:06 DP1 TP8] Decode batch. #running-req: 16, #token: 9894, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 385.69, #queue-req: 442, 
[1,0]<stdout>:[2025-10-12 02:06:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 408, 
[1,0]<stdout>:[2025-10-12 02:06:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 407, 
[1,0]<stdout>:[2025-10-12 02:06:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 406, 
[1,0]<stdout>:[2025-10-12 02:06:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 405, 
[1,0]<stdout>:[2025-10-12 02:06:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 404, 
[1,0]<stdout>:[2025-10-12 02:06:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 403, 
[1,1]<stdout>:[2025-10-12 02:06:08 DP1 TP8] Decode batch. #running-req: 16, #token: 10534, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 319.99, #queue-req: 442, 
[1,0]<stdout>:[2025-10-12 02:06:08 DP0 TP0] Decode batch. #running-req: 16, #token: 6763, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 316.91, #queue-req: 403, 
[1,0]<stdout>:[2025-10-12 02:06:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 402, 
[1,0]<stdout>:[2025-10-12 02:06:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 401, 
[1,0]<stdout>:[2025-10-12 02:06:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 400, 
[1,0]<stdout>:[2025-10-12 02:06:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 633, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 399, 
[1,0]<stdout>:[2025-10-12 02:06:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 462, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 398, 
[1,1]<stdout>:[2025-10-12 02:06:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 6, token usage: 0.07, #running-req: 15, #queue-req: 441, 
[1,0]<stdout>:[2025-10-12 02:06:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 3, token usage: 0.04, #running-req: 15, #queue-req: 397, 
[1,0]<stdout>:[2025-10-12 02:06:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 396, 
[1,0]<stdout>:[2025-10-12 02:06:10 DP0 TP0] Decode batch. #running-req: 16, #token: 6518, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 282.92, #queue-req: 396, 
[1,1]<stdout>:[2025-10-12 02:06:10 DP1 TP8] Decode batch. #running-req: 16, #token: 10580, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 285.58, #queue-req: 441, 
[1,0]<stdout>:[2025-10-12 02:06:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 395, 
[1,1]<stdout>:[2025-10-12 02:06:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 440, 
[1,1]<stdout>:[2025-10-12 02:06:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.06, #running-req: 15, #queue-req: 439, 
[1,0]<stdout>:[2025-10-12 02:06:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 394, 
[1,1]<stdout>:[2025-10-12 02:06:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1080, #cached-token: 1, token usage: 0.06, #running-req: 15, #queue-req: 438, 
[1,0]<stdout>:[2025-10-12 02:06:11 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 60, #cached-token: 7, token usage: 0.04, #running-req: 14, #queue-req: 392, 
[1,0]<stdout>:[2025-10-12 02:06:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 391, 
[1,0]<stdout>:[2025-10-12 02:06:12 DP0 TP0] Decode batch. #running-req: 16, #token: 5620, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 316.33, #queue-req: 391, 
[1,1]<stdout>:[2025-10-12 02:06:12 DP1 TP8] Decode batch. #running-req: 16, #token: 11302, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 317.28, #queue-req: 438, 
[1,1]<stdout>:[2025-10-12 02:06:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 437, 
[1,0]<stdout>:[2025-10-12 02:06:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 390, 
[1,1]<stdout>:[2025-10-12 02:06:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 3, token usage: 0.07, #running-req: 15, #queue-req: 436, 
[1,1]<stdout>:[2025-10-12 02:06:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1444, #cached-token: 0, token usage: 0.08, #running-req: 15, #queue-req: 436, 
[1,0]<stdout>:[2025-10-12 02:06:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 389, 
[1,0]<stdout>:[2025-10-12 02:06:14 DP0 TP0] Decode batch. #running-req: 16, #token: 6057, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 350.36, #queue-req: 389, 
[1,1]<stdout>:[2025-10-12 02:06:14 DP1 TP8] Decode batch. #running-req: 15, #token: 13991, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 349.80, #queue-req: 436, 
[1,1]<stdout>:[2025-10-12 02:06:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 3, token usage: 0.09, #running-req: 15, #queue-req: 435, 
[1,0]<stdout>:[2025-10-12 02:06:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 388, 
[1,0]<stdout>:[2025-10-12 02:06:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 387, 
[1,1]<stdout>:[2025-10-12 02:06:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 3, token usage: 0.09, #running-req: 15, #queue-req: 434, 
[1,0]<stdout>:[2025-10-12 02:06:15 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 243, #cached-token: 3, token usage: 0.03, #running-req: 14, #queue-req: 385, 
[1,1]<stdout>:[2025-10-12 02:06:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 2, token usage: 0.09, #running-req: 15, #queue-req: 433, 
[1,0]<stdout>:[2025-10-12 02:06:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 5, token usage: 0.03, #running-req: 15, #queue-req: 384, 
[1,0]<stdout>:[2025-10-12 02:06:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 8, token usage: 0.03, #running-req: 15, #queue-req: 383, 
[1,0]<stdout>:[2025-10-12 02:06:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 382, 
[1,0]<stdout>:[2025-10-12 02:06:16 DP0 TP0] Decode batch. #running-req: 16, #token: 4575, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 267.88, #queue-req: 382, 
[1,1]<stdout>:[2025-10-12 02:06:16 DP1 TP8] Decode batch. #running-req: 16, #token: 13995, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 270.06, #queue-req: 433, 
[1,1]<stdout>:[2025-10-12 02:06:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 1, token usage: 0.09, #running-req: 15, #queue-req: 432, 
[1,0]<stdout>:[2025-10-12 02:06:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 381, 
[1,0]<stdout>:[2025-10-12 02:06:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 380, 
[1,0]<stdout>:[2025-10-12 02:06:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 379, 
[1,1]<stdout>:[2025-10-12 02:06:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 424, #cached-token: 9, token usage: 0.08, #running-req: 15, #queue-req: 431, 
[1,1]<stdout>:[2025-10-12 02:06:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 430, 
[1,1]<stdout>:[2025-10-12 02:06:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 429, 
[1,0]<stdout>:[2025-10-12 02:06:18 DP0 TP0] Decode batch. #running-req: 16, #token: 4861, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 307.26, #queue-req: 379, 
[1,1]<stdout>:[2025-10-12 02:06:18 DP1 TP8] Decode batch. #running-req: 16, #token: 12894, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 306.74, #queue-req: 429, 
[1,0]<stdout>:[2025-10-12 02:06:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 378, 
[1,1]<stdout>:[2025-10-12 02:06:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 5, token usage: 0.08, #running-req: 15, #queue-req: 428, 
[1,1]<stdout>:[2025-10-12 02:06:19 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 577, #cached-token: 2, token usage: 0.08, #running-req: 14, #queue-req: 426, 
[1,1]<stdout>:[2025-10-12 02:06:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 425, 
[1,1]<stdout>:[2025-10-12 02:06:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 1, token usage: 0.07, #running-req: 15, #queue-req: 424, 
[1,1]<stdout>:[2025-10-12 02:06:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 423, 
[1,1]<stdout>:[2025-10-12 02:06:20 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 462, #cached-token: 7, token usage: 0.07, #running-req: 14, #queue-req: 421, 
[1,1]<stdout>:[2025-10-12 02:06:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 871, #cached-token: 7, token usage: 0.07, #running-req: 15, #queue-req: 420, 
[1,1]<stdout>:[2025-10-12 02:06:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 4, token usage: 0.07, #running-req: 15, #queue-req: 419, 
[1,0]<stdout>:[2025-10-12 02:06:20 DP0 TP0] Decode batch. #running-req: 16, #token: 4924, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 269.14, #queue-req: 378, 
[1,1]<stdout>:[2025-10-12 02:06:20 DP1 TP8] Decode batch. #running-req: 16, #token: 11658, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 265.34, #queue-req: 419, 
[1,0]<stdout>:[2025-10-12 02:06:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 377, 
[1,0]<stdout>:[2025-10-12 02:06:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 376, 
[1,1]<stdout>:[2025-10-12 02:06:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.07, #running-req: 15, #queue-req: 418, 
[1,1]<stdout>:[2025-10-12 02:06:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 984, #cached-token: 2, token usage: 0.07, #running-req: 15, #queue-req: 417, 
[1,0]<stdout>:[2025-10-12 02:06:22 DP0 TP0] Decode batch. #running-req: 16, #token: 4449, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 426.10, #queue-req: 376, 
[1,1]<stdout>:[2025-10-12 02:06:22 DP1 TP8] Decode batch. #running-req: 16, #token: 12480, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 426.20, #queue-req: 417, 
[1,1]<stdout>:[2025-10-12 02:06:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 416, 
[1,1]<stdout>:[2025-10-12 02:06:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 415, 
[1,0]<stdout>:[2025-10-12 02:06:23 DP0 TP0] Decode batch. #running-req: 16, #token: 5089, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 476.30, #queue-req: 376, 
[1,1]<stdout>:[2025-10-12 02:06:23 DP1 TP8] Decode batch. #running-req: 16, #token: 13206, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 474.65, #queue-req: 415, 
[1,1]<stdout>:[2025-10-12 02:06:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 414, 
[1,1]<stdout>:[2025-10-12 02:06:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 413, 
[1,0]<stdout>:[2025-10-12 02:06:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 651, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 375, 
[1,0]<stdout>:[2025-10-12 02:06:25 DP0 TP0] Decode batch. #running-req: 16, #token: 6263, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 426.21, #queue-req: 375, 
[1,1]<stdout>:[2025-10-12 02:06:25 DP1 TP8] Decode batch. #running-req: 16, #token: 13065, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 425.66, #queue-req: 413, 
[1,0]<stdout>:[2025-10-12 02:06:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 655, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 374, 
[1,0]<stdout>:[2025-10-12 02:06:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 373, 
[1,0]<stdout>:[2025-10-12 02:06:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 3, token usage: 0.03, #running-req: 15, #queue-req: 372, 
[1,0]<stdout>:[2025-10-12 02:06:26 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 652, #cached-token: 6, token usage: 0.03, #running-req: 14, #queue-req: 370, 
[1,1]<stdout>:[2025-10-12 02:06:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 2, token usage: 0.08, #running-req: 15, #queue-req: 412, 
[1,0]<stdout>:[2025-10-12 02:06:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 369, 
[1,1]<stdout>:[2025-10-12 02:06:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 411, 
[1,0]<stdout>:[2025-10-12 02:06:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 368, 
[1,0]<stdout>:[2025-10-12 02:06:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 2, token usage: 0.03, #running-req: 15, #queue-req: 367, 
[1,0]<stdout>:[2025-10-12 02:06:27 DP0 TP0] Decode batch. #running-req: 16, #token: 5238, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 302.95, #queue-req: 367, 
[1,1]<stdout>:[2025-10-12 02:06:27 DP1 TP8] Decode batch. #running-req: 16, #token: 12345, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 305.80, #queue-req: 411, 
[1,0]<stdout>:[2025-10-12 02:06:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1156, #cached-token: 1, token usage: 0.03, #running-req: 15, #queue-req: 366, 
[1,0]<stdout>:[2025-10-12 02:06:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.04, #running-req: 15, #queue-req: 365, 
[1,1]<stdout>:[2025-10-12 02:06:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 410, 
[1,0]<stdout>:[2025-10-12 02:06:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 364, 
[1,0]<stdout>:[2025-10-12 02:06:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 689, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 363, 
[1,0]<stdout>:[2025-10-12 02:06:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 6, token usage: 0.04, #running-req: 15, #queue-req: 362, 
[1,1]<stdout>:[2025-10-12 02:06:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 764, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 409, 
[1,1]<stdout>:[2025-10-12 02:06:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 1, token usage: 0.08, #running-req: 15, #queue-req: 408, 
[1,0]<stdout>:[2025-10-12 02:06:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 361, 
[1,1]<stdout>:[2025-10-12 02:06:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 798, #cached-token: 3, token usage: 0.08, #running-req: 15, #queue-req: 407, 
[1,0]<stdout>:[2025-10-12 02:06:29 DP0 TP0] Decode batch. #running-req: 16, #token: 6610, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 266.24, #queue-req: 361, 
[1,1]<stdout>:[2025-10-12 02:06:29 DP1 TP8] Decode batch. #running-req: 16, #token: 13260, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 267.12, #queue-req: 407, 
[1,1]<stdout>:[2025-10-12 02:06:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 793, #cached-token: 5, token usage: 0.09, #running-req: 15, #queue-req: 406, 
[1,1]<stdout>:[2025-10-12 02:06:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 4, token usage: 0.09, #running-req: 15, #queue-req: 405, 
[1,0]<stdout>:[2025-10-12 02:06:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 4, token usage: 0.04, #running-req: 15, #queue-req: 360, 
[1,1]<stdout>:[2025-10-12 02:06:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 15, #queue-req: 404, 
[1,0]<stdout>:[2025-10-12 02:06:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 2, token usage: 0.04, #running-req: 15, #queue-req: 359, 
[1,0]<stdout>:[2025-10-12 02:06:31 DP0 TP0] Decode batch. #running-req: 16, #token: 6587, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.81, #queue-req: 359, 
[1,1]<stdout>:[2025-10-12 02:06:31 DP1 TP8] Decode batch. #running-req: 16, #token: 13643, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.22, #queue-req: 404, 
[1,0]<stdout>:[2025-10-12 02:06:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 387, #cached-token: 12, token usage: 0.04, #running-req: 15, #queue-req: 358, 
[1,1]<stdout>:[2025-10-12 02:06:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.09, #running-req: 15, #queue-req: 403, 
[1,1]<stdout>:[2025-10-12 02:06:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 6, token usage: 0.06, #running-req: 15, #queue-req: 402, 
=>> PBS: job killed: walltime 603 exceeded limit 600
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-12 02:06:53.566693:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 97115.pbs111
	Project: 50000128
	Exit Status: -29
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 02:11:30
	Memory: Requested(3760gb), Used(52310792kb)
	Vmem Used: 80607208400kb
	Walltime: Requested(00:10:00), Used(00:10:17)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx007:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx010:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 10.47mins
	GPU Power Consumed: 357.87W
	GPU Max GPU Memory Used: 1.24TB
	Memory Throughput Rate (Average): a2ap-dgx007:(gpu1:4%+gpu0:4%+gpu2:4%+gpu3:4%+gpu5:4%+gpu4:4%+gpu6:4%+gpu7:4%)+a2ap-dgx010:(gpu1:5%+gpu0:4%+gpu2:4%+gpu3:4%+gpu5:4%+gpu4:4%+gpu6:4%+gpu7:4%)
	Memory Throughput Rate (Max): a2ap-dgx007:(gpu1:23%+gpu0:16%+gpu2:16%+gpu3:17%+gpu5:21%+gpu4:13%+gpu6:16%+gpu7:14%)+a2ap-dgx010:(gpu1:15%+gpu0:13%+gpu2:11%+gpu3:13%+gpu5:10%+gpu4:16%+gpu6:30%+gpu7:28%)
	Memory Throughput Rate (Min): a2ap-dgx007:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx010:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx007:(gpu1:60%+gpu0:50%+gpu2:57%+gpu3:62%+gpu5:60%+gpu4:57%+gpu6:61%+gpu7:54%)+a2ap-dgx010:(gpu1:64%+gpu0:60%+gpu2:57%+gpu3:67%+gpu5:67%+gpu4:67%+gpu6:62%+gpu7:65%)
	GPU SM Utilization (Max): a2ap-dgx007:(gpu1:96%+gpu0:97%+gpu2:97%+gpu3:97%+gpu5:97%+gpu4:97%+gpu6:96%+gpu7:96%)+a2ap-dgx010:(gpu1:97%+gpu0:97%+gpu2:100%+gpu3:98%+gpu5:96%+gpu4:97%+gpu6:96%+gpu7:96%)
	GPU SM Utilization (Min): a2ap-dgx007:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx010:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: None
GPU application profile: Medium
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

