========== FA3 OPTIMIZED BENCHMARK ==========
Target: <15min | Est. SU: 238.934 | Balance: 38996.698
N/A
Job ID: 97125.pbs111 | GPUs: 16 | Master: a2ap-dgx010.asp2p.nscc.sg:5000
Config: TP16+DP2 | Attention: FlashAttention-3
=============================================
[04:10:31] Launching FA3-optimized benchmark...
Warning: Permanently added 'a2ap-dgx015' (ED25519) to the list of known hosts.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 4096 to avoid MoE kernel issues. 
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,0]<stdout>:[2025-10-12 04:10:53] Using default HuggingFace chat template with detected content format: string
[1,1]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 4096 to avoid MoE kernel issues. 
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,0]<stdout>:[2025-10-12 04:11:38 DP0 TP0] MLA optimization is turned on. Use fa3 backend.
[1,0]<stdout>:[2025-10-12 04:11:38 DP0 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-12 04:11:38 DP0 TP0] Init torch distributed begin.
[1,0]<stdout>:[W1012 04:11:39.565723716 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 04:11:40.646175666 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 04:11:40.875166841 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 04:11:40.019043604 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 04:11:40.252953285 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 04:11:40.252959597 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 04:11:40.253170548 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 04:11:49.857240785 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 04:11:53.174987925 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 04:11:53.184662028 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 04:11:53.191188010 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 04:11:53.214476998 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 04:11:53.214490079 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 04:11:53.370841863 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 04:11:53.401744912 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 04:11:53.524507989 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 04:11:54 DP0 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 04:12:01 DP0 TP1] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 04:12:01 DP0 TP2] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 04:12:01 DP0 TP3] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 04:12:01 DP0 TP0] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 04:12:01 DP0 TP4] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 04:12:01 DP0 TP5] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 04:12:01 DP0 TP6] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 04:12:01 DP1 TP15] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 04:12:01 DP1 TP14] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 04:12:01 DP1 TP13] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 04:12:01 DP1 TP12] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 04:12:01 DP1 TP11] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 04:12:01 DP1 TP10] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 04:12:01 DP0 TP7] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 04:12:01 DP1 TP8] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 04:12:01 DP1 TP9] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 04:12:01 DP0 TP0] sglang is using nccl==2.27.3
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,1]<stdout>:[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1,0]<stdout>:[2025-10-12 04:12:03 DP0 TP0] Init torch distributed ends. mem usage=1.75 GB
[1,0]<stdout>:[2025-10-12 04:12:04 DP0 TP5] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 04:12:04 DP0 TP2] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 04:12:04 DP0 TP7] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 04:12:04 DP0 TP4] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 04:12:04 DP0 TP1] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 04:12:04 DP0 TP3] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 04:12:04 DP0 TP6] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 04:12:04 DP0 TP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 04:12:04 DP1 TP8] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 04:12:04 DP1 TP10] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 04:12:04 DP1 TP13] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 04:12:04 DP1 TP11] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 04:12:04 DP1 TP15] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 04:12:04 DP1 TP9] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 04:12:04 DP1 TP12] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 04:12:04 DP1 TP14] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 04:12:05 DP0 TP0] Load weight begin. avail mem=76.79 GB
[1,0]<stdout>:[2025-10-12 04:12:05 DP0 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-12 04:12:23 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=32.73 GB, mem usage=44.05 GB.
[1,1]<stdout>:[2025-10-12 04:12:28 DP1 TP12] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,1]<stdout>:[2025-10-12 04:12:28 DP1 TP8] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,1]<stdout>:[2025-10-12 04:12:28 DP1 TP11] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,1]<stdout>:[2025-10-12 04:12:28 DP1 TP13] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,1]<stdout>:[2025-10-12 04:12:28 DP1 TP9] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,1]<stdout>:[2025-10-12 04:12:28 DP1 TP15] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,1]<stdout>:[2025-10-12 04:12:28 DP1 TP10] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,0]<stdout>:[2025-10-12 04:12:28 DP0 TP5] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,1]<stdout>:[2025-10-12 04:12:28 DP1 TP14] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,0]<stdout>:[2025-10-12 04:12:28 DP0 TP3] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,0]<stdout>:[2025-10-12 04:12:28 DP0 TP0] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,0]<stdout>:[2025-10-12 04:12:28 DP0 TP0] Memory pool end. avail mem=22.23 GB
[1,0]<stdout>:[2025-10-12 04:12:28 DP0 TP1] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,0]<stdout>:[2025-10-12 04:12:29 DP0 TP2] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,0]<stdout>:[2025-10-12 04:12:29 DP0 TP6] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,0]<stdout>:[2025-10-12 04:12:29 DP0 TP4] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,0]<stdout>:[2025-10-12 04:12:29 DP0 TP7] KV Cache is allocated. #tokens: 153767, KV size: 10.06 GB
[1,0]<stdout>:[2025-10-12 04:12:29 DP0 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=22.16 GB
[1,0]<stdout>:[2025-10-12 04:12:30 DP0 TP0] Capture cuda graph bs [8, 16, 24, 32, 40, 48]
[1,0]<stdout>:  0% 0/6 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=21.98 GB):   0% 0/6 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-12 04:12:31 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:31 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:31 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:31 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:31 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:31 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:31 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:31 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:31 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:31 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 04:12:31 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:31 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:31 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:31 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:31 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 04:12:31 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:31 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:31 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 4366.59it/s]
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5658.02it/s]
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][A[1,1]<stdout>:100% 33/33 [00:00<00:00, 1870.48it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 2255.15it/s][1,1]<stdout>:
[1,1]<stdout>:100% 33/33 [00:00<00:00, 3364.25it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 2558.26it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 5602.82it/s]
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 5692.22it/s]
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 4900.93it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 5289.16it/s]
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-12 04:12:32 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 33/33 [00:00<00:00, 5322.52it/s]
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5611.91it/s]
[1,0]<stdout>:[2025-10-12 04:12:32 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 04:12:32 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 33/33 [00:00<00:00, 4909.27it/s]
[1,0]<stdout>:[2025-10-12 04:12:32 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 33/33 [00:00<00:00, 5481.45it/s]
[1,0]<stdout>:[2025-10-12 04:12:32 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:32 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:32 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:32 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:32 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:32 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 04:12:32 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:32 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:32 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:32 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:32 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:32 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5646.94it/s]
[1,0]<stdout>:[2025-10-12 04:12:32 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 5991.60it/s]
[1,0]<stdout>:[2025-10-12 04:12:32 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:[A[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:100% 29/29 [00:00<00:00, 11896.99it/s]
[1,0]<stdout>:100% 29/29 [00:00<00:00, 14415.12it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 7641.82it/s]
[1,1]<stdout>:100% 29/29 [00:00<00:00, 15102.41it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 14630.12it/s][1,1]<stdout>:
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 11795.46it/s]
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:100% 29/29 [00:00<00:00, 15979.35it/s]
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s]  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:100% 29/29 [00:00<00:00, 16072.25it/s]
[1,0]<stdout>:100% 29/29 [00:00<00:00, 15933.30it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 15568.26it/s]
[1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s]100% 29/29 [00:00<00:00, 14399.77it/s]
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,1]<stdout>:100% 29/29 [00:00<00:00, 13593.52it/s]
[1,0]<stdout>:100% 29/29 [00:00<00:00, 14759.72it/s]
[1,1]<stdout>:100% 29/29 [00:00<00:00, 12243.06it/s]
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:100% 29/29 [00:00<00:00, 13845.74it/s]
[1,0]<stdout>:  0% 0/29 [00:00<?, ?it/s][1,0]<stdout>:100% 29/29 [00:00<00:00, 13476.05it/s]
[1,0]<stdout>:[2025-10-12 04:12:33 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:33 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 04:12:33 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:33 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:33 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:33 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:33 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:33 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 04:12:33 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:33 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:33 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:33 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:33 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:33 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:33 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:33 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:33 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:33 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:[A[1,0]<stdout>:100% 16/16 [00:00<00:00, 10642.07it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15399.01it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15427.33it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 19070.44it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 16492.72it/s][1,0]<stdout>:
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 6830.42it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 15377.83it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 13028.32it/s][1,1]<stdout>:
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 16561.91it/s][1,1]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 17618.50it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s]  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 17485.37it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 11035.83it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 18507.68it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 17814.94it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 16264.87it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 14713.63it/s]
[1,0]<stdout>:[2025-10-12 04:12:36 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:36 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:36 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:36 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:36 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 04:12:36 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:36 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:36 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:36 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:36 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:36 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 04:12:36 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:36 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:36 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:36 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:36 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:36 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:36 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s]  0% 0/32 [00:00<?, ?it/s][A[1,0]<stdout>:100% 32/32 [00:00<00:00, 10329.21it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 9730.15it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 6783.81it/s]
[1,1]<stdout>:100% 32/32 [00:00<00:00, 18523.01it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-12 04:12:37 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 04:12:37 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:37 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 32/32 [00:00<00:00, 14293.69it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 13934.56it/s]
[1,0]<stdout>:[2025-10-12 04:12:37 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:[2025-10-12 04:12:37 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 04:12:37 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:37 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:[2025-10-12 04:12:37 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 32/32 [00:00<00:00, 14177.43it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 13818.36it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 14166.95it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 13780.05it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 15323.41it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 14557.24it/s]
[1,0]<stdout>:[2025-10-12 04:12:37 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:37 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:37 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:37 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:37 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:12:37 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 15987.82it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 15650.39it/s]
[1,1]<stdout>:[2025-10-12 04:12:37 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:37 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 15097.61it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 13000.55it/s]
[1,1]<stdout>:[2025-10-12 04:12:37 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:12:37 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 10837.99it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 16882.73it/s]
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][A[1,0]<stdout>:100% 16/16 [00:00<00:00, 18957.31it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 9210.66it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 5305.05it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 14906.46it/s][1,1]<stdout>:
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 15635.80it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 17613.88it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 14544.62it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 17508.18it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15982.11it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 15097.61it/s][1,0]<stdout>:
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 15087.42it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 19328.59it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 14617.48it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 13519.11it/s]
[1,0]<stdout>:[2025-10-12 04:12:40 DP0 TP5] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 04:12:40 DP0 TP4] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 04:12:40 DP0 TP6] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 04:12:40 DP0 TP1] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 04:12:40 DP0 TP7] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 04:12:40 DP0 TP2] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 04:12:40 DP0 TP3] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 04:12:40 DP0 TP0] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 04:12:40 DP1 TP11] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 04:12:40 DP1 TP12] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 04:12:40 DP1 TP15] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 04:12:40 DP1 TP13] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 04:12:40 DP1 TP10] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 04:12:40 DP1 TP9] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 04:12:40 DP1 TP14] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 04:12:40 DP1 TP8] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:Capturing batches (bs=48 avail_mem=21.98 GB):  17% 1/6 [00:09<00:47,  9.51s/it]Capturing batches (bs=40 avail_mem=20.13 GB):  17% 1/6 [00:09<00:47,  9.51s/it][1,0]<stdout>:Capturing batches (bs=40 avail_mem=20.13 GB):  33% 2/6 [00:10<00:17,  4.30s/it][1,0]<stdout>:Capturing batches (bs=32 avail_mem=20.09 GB):  33% 2/6 [00:10<00:17,  4.30s/it][1,0]<stdout>:Capturing batches (bs=32 avail_mem=20.09 GB):  50% 3/6 [00:11<00:08,  2.82s/it][1,0]<stdout>:Capturing batches (bs=24 avail_mem=20.05 GB):  50% 3/6 [00:11<00:08,  2.82s/it][1,0]<stdout>:Capturing batches (bs=24 avail_mem=20.05 GB):  67% 4/6 [00:12<00:04,  2.02s/it][1,0]<stdout>:Capturing batches (bs=16 avail_mem=20.01 GB):  67% 4/6 [00:12<00:04,  2.02s/it][1,0]<stdout>:Capturing batches (bs=16 avail_mem=20.01 GB):  83% 5/6 [00:12<00:01,  1.61s/it][1,0]<stdout>:Capturing batches (bs=8 avail_mem=19.97 GB):  83% 5/6 [00:12<00:01,  1.61s/it] [1,0]<stdout>:Capturing batches (bs=8 avail_mem=19.97 GB): 100% 6/6 [00:13<00:00,  1.35s/it]Capturing batches (bs=8 avail_mem=19.97 GB): 100% 6/6 [00:13<00:00,  2.29s/it]
[1,0]<stdout>:[2025-10-12 04:12:44 DP0 TP0] Capture cuda graph end. Time elapsed: 15.40 s. mem usage=2.22 GB. avail mem=19.94 GB.
[1,0]<stdout>:[2025-10-12 04:12:45 DP0 TP0] MLA optimization is turned on. Use fa3 backend.
[1,0]<stdout>:[2025-10-12 04:12:45 DP0 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-12 04:12:45 DP0 TP0] Init torch distributed begin.
[1,0]<stdout>:[2025-10-12 04:12:45 DP0 TP0] Init torch distributed ends. mem usage=0.00 GB
[1,0]<stdout>:[2025-10-12 04:12:45 DP0 TP0] Load weight begin. avail mem=19.94 GB
[1,0]<stdout>:[2025-10-12 04:12:45 DP0 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=17.05 GB, mem usage=2.89 GB.
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP3] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP1] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,1]<stdout>:[2025-10-12 04:12:46 DP1 TP14] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,1]<stdout>:[2025-10-12 04:12:46 DP1 TP10] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,1]<stdout>:[2025-10-12 04:12:46 DP1 TP15] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP0] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP6] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP0] Memory pool end. avail mem=16.87 GB
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP5] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP4] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP7] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,1]<stdout>:[2025-10-12 04:12:46 DP1 TP8] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,0]<stdout>:[2025-10-12 04:12:46 DP0 TP2] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,1]<stdout>:[2025-10-12 04:12:46 DP1 TP11] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,1]<stdout>:[2025-10-12 04:12:46 DP1 TP9] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,1]<stdout>:[2025-10-12 04:12:46 DP1 TP13] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,1]<stdout>:[2025-10-12 04:12:46 DP1 TP12] KV Cache is allocated. #tokens: 153767, KV size: 0.16 GB
[1,0]<stdout>:[2025-10-12 04:12:47 DP0 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.78 GB
[1,1]<stdout>:[2025-10-12 04:12:47 DP1 TP12] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.73 GB
[1,1]<stdout>:[2025-10-12 04:12:47 DP1 TP8] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.78 GB
[1,1]<stdout>:[2025-10-12 04:12:47 DP1 TP13] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.78 GB
[1,1]<stdout>:[2025-10-12 04:12:47 DP1 TP11] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.78 GB
[1,1]<stdout>:[2025-10-12 04:12:47 DP1 TP14] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.73 GB
[1,1]<stdout>:[2025-10-12 04:12:47 DP1 TP10] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.73 GB
[1,1]<stdout>:[2025-10-12 04:12:47 DP1 TP9] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.78 GB
[1,0]<stdout>:[2025-10-12 04:12:47 DP0 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.73 GB
[1,0]<stdout>:[2025-10-12 04:12:47 DP0 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.73 GB
[1,0]<stdout>:[2025-10-12 04:12:47 DP0 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.78 GB
[1,0]<stdout>:[2025-10-12 04:12:47 DP0 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.82 GB
[1,0]<stdout>:[2025-10-12 04:12:47 DP0 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.96 GB
[1,0]<stdout>:[2025-10-12 04:12:47 DP0 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.73 GB
[1,0]<stdout>:[2025-10-12 04:12:47 DP0 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=18.78 GB
[1,1]<stdout>:[2025-10-12 04:12:47 DP1 TP15] Capture draft cuda graph begin. This can take up to several minutes. avail mem=19.01 GB
[1,0]<stdout>:  0% 0/6 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=18.67 GB):   0% 0/6 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=18.67 GB):  17% 1/6 [00:00<00:03,  1.38it/s][1,0]<stdout>:Capturing batches (bs=40 avail_mem=18.67 GB):  17% 1/6 [00:00<00:03,  1.38it/s][1,0]<stdout>:Capturing batches (bs=40 avail_mem=18.67 GB):  33% 2/6 [00:00<00:01,  2.20it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=18.67 GB):  33% 2/6 [00:00<00:01,  2.20it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=18.67 GB):  33% 2/6 [00:01<00:01,  2.20it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=18.67 GB):  67% 4/6 [00:01<00:00,  4.80it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=18.67 GB):  67% 4/6 [00:01<00:00,  4.80it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.67 GB):  67% 4/6 [00:01<00:00,  4.80it/s] [1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.67 GB): 100% 6/6 [00:01<00:00,  7.26it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.67 GB): 100% 6/6 [00:01<00:00,  4.87it/s]
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP2] Capture draft cuda graph end. Time elapsed: 2.84 s. mem usage=0.16 GB. avail mem=18.62 GB.
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.62 GB
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP0] Capture draft cuda graph end. Time elapsed: 2.82 s. mem usage=0.16 GB. avail mem=18.67 GB.
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.67 GB
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP8] Capture draft cuda graph end. Time elapsed: 3.03 s. mem usage=0.16 GB. avail mem=18.62 GB.
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP11] Capture draft cuda graph end. Time elapsed: 3.02 s. mem usage=0.16 GB. avail mem=18.62 GB.
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP8] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.62 GB
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP11] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.62 GB
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP14] Capture draft cuda graph end. Time elapsed: 3.01 s. mem usage=0.16 GB. avail mem=18.57 GB.
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP9] Capture draft cuda graph end. Time elapsed: 2.98 s. mem usage=0.16 GB. avail mem=18.62 GB.
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP15] Capture draft cuda graph end. Time elapsed: 2.40 s. mem usage=0.16 GB. avail mem=18.85 GB.
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP14] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.57 GB
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP9] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.62 GB
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP15] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.85 GB
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP4] Capture draft cuda graph end. Time elapsed: 3.06 s. mem usage=0.16 GB. avail mem=18.62 GB.
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP12] Capture draft cuda graph end. Time elapsed: 3.04 s. mem usage=0.16 GB. avail mem=18.57 GB.
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.62 GB
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP12] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.57 GB
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP10] Capture draft cuda graph end. Time elapsed: 3.00 s. mem usage=0.16 GB. avail mem=18.57 GB.
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP10] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.57 GB
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP3] Capture draft cuda graph end. Time elapsed: 2.96 s. mem usage=0.16 GB. avail mem=18.57 GB.
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP6] Capture draft cuda graph end. Time elapsed: 2.80 s. mem usage=0.16 GB. avail mem=18.62 GB.
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.57 GB
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.62 GB
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP5] Capture draft cuda graph end. Time elapsed: 2.90 s. mem usage=0.16 GB. avail mem=18.57 GB.
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.57 GB
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP7] Capture draft cuda graph end. Time elapsed: 2.81 s. mem usage=0.16 GB. avail mem=18.81 GB.
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP1] Capture draft cuda graph end. Time elapsed: 2.81 s. mem usage=0.16 GB. avail mem=18.57 GB.
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.57 GB
[1,0]<stdout>:[2025-10-12 04:12:50 DP0 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.81 GB
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP13] Capture draft cuda graph end. Time elapsed: 3.03 s. mem usage=0.16 GB. avail mem=18.62 GB.
[1,1]<stdout>:[2025-10-12 04:12:50 DP1 TP13] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=18.62 GB
[1,0]<stdout>:  0% 0/6 [00:00<?, ?it/s]Capturing batches (bs=48 avail_mem=18.49 GB):   0% 0/6 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=18.49 GB):  17% 1/6 [00:00<00:02,  2.47it/s][1,0]<stdout>:Capturing batches (bs=40 avail_mem=18.09 GB):  17% 1/6 [00:00<00:02,  2.47it/s][1,0]<stdout>:Capturing batches (bs=40 avail_mem=18.09 GB):  33% 2/6 [00:00<00:01,  2.72it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=18.09 GB):  33% 2/6 [00:00<00:01,  2.72it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=18.09 GB):  50% 3/6 [00:00<00:00,  3.54it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=18.09 GB):  50% 3/6 [00:00<00:00,  3.54it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=18.09 GB):  67% 4/6 [00:01<00:00,  4.51it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=18.08 GB):  67% 4/6 [00:01<00:00,  4.51it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.08 GB):  67% 4/6 [00:01<00:00,  4.51it/s] [1,1]<stdout>:[2025-10-12 04:12:53 DP1 TP8] Capture draft extend cuda graph end. Time elapsed: 2.95 s. mem usage=0.59 GB. avail mem=18.03 GB.
[1,0]<stdout>:Capturing batches (bs=8 avail_mem=18.08 GB): 100% 6/6 [00:01<00:00,  7.06it/s]Capturing batches (bs=8 avail_mem=18.08 GB): 100% 6/6 [00:01<00:00,  5.01it/s]
[1,0]<stdout>:[2025-10-12 04:12:53 DP0 TP0] Capture draft extend cuda graph end. Time elapsed: 2.96 s. mem usage=0.59 GB. avail mem=18.08 GB.
[1,1]<stdout>:[2025-10-12 04:12:53 DP1 TP15] Capture draft extend cuda graph end. Time elapsed: 2.96 s. mem usage=0.59 GB. avail mem=18.27 GB.
[1,1]<stdout>:[2025-10-12 04:12:53 DP1 TP12] Capture draft extend cuda graph end. Time elapsed: 2.96 s. mem usage=0.59 GB. avail mem=17.99 GB.
[1,1]<stdout>:[2025-10-12 04:12:53 DP1 TP14] Capture draft extend cuda graph end. Time elapsed: 2.96 s. mem usage=0.59 GB. avail mem=17.99 GB.
[1,1]<stdout>:[2025-10-12 04:12:53 DP1 TP11] Capture draft extend cuda graph end. Time elapsed: 2.96 s. mem usage=0.59 GB. avail mem=18.03 GB.
[1,1]<stdout>:[2025-10-12 04:12:53 DP1 TP10] Capture draft extend cuda graph end. Time elapsed: 2.96 s. mem usage=0.59 GB. avail mem=17.99 GB.
[1,1]<stdout>:[2025-10-12 04:12:53 DP1 TP9] Capture draft extend cuda graph end. Time elapsed: 2.96 s. mem usage=0.59 GB. avail mem=18.03 GB.
[1,1]<stdout>:[2025-10-12 04:12:53 DP1 TP13] Capture draft extend cuda graph end. Time elapsed: 2.96 s. mem usage=0.59 GB. avail mem=18.03 GB.
[1,0]<stdout>:[2025-10-12 04:12:53 DP0 TP0] max_total_num_tokens=153767, chunked_prefill_size=2048, max_prefill_tokens=16384, max_running_requests=24, context_len=163840, available_gpu_mem=18.08 GB
[1,0]<stdout>:[2025-10-12 04:12:53 DP0 TP5] Capture draft extend cuda graph end. Time elapsed: 2.97 s. mem usage=0.59 GB. avail mem=17.99 GB.
[1,0]<stdout>:[2025-10-12 04:12:53 DP0 TP6] Capture draft extend cuda graph end. Time elapsed: 2.97 s. mem usage=0.59 GB. avail mem=18.03 GB.
[1,0]<stdout>:[2025-10-12 04:12:53 DP0 TP4] Capture draft extend cuda graph end. Time elapsed: 2.97 s. mem usage=0.59 GB. avail mem=18.03 GB.
[1,0]<stdout>:[2025-10-12 04:12:53 DP0 TP3] Capture draft extend cuda graph end. Time elapsed: 2.97 s. mem usage=0.59 GB. avail mem=17.99 GB.
[1,0]<stdout>:[2025-10-12 04:12:53 DP0 TP1] Capture draft extend cuda graph end. Time elapsed: 2.97 s. mem usage=0.59 GB. avail mem=17.99 GB.
[1,0]<stdout>:[2025-10-12 04:12:53 DP0 TP7] Capture draft extend cuda graph end. Time elapsed: 2.99 s. mem usage=0.59 GB. avail mem=18.22 GB.
[1,0]<stdout>:[2025-10-12 04:12:53 DP0 TP2] Capture draft extend cuda graph end. Time elapsed: 2.99 s. mem usage=0.59 GB. avail mem=18.03 GB.
[1,1]<stdout>:[2025-10-12 04:12:53] Starting dummy health check server at 127.0.0.1:30000
[1,0]<stdout>:#Input tokens: 626729
[1,0]<stdout>:#Output tokens: 388685
[1,0]<stdout>:#Input tokens: 4096
[1,0]<stdout>:#Output tokens: 256
[1,0]<stdout>:[2025-10-12 04:13:07] 
[1,0]<stdout>:Warmup...
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP0] Prefill batch. #new-seq: 3, #new-token: 771, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 04:13:07 DP1 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 04:13:07 DP0 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 6765.46it/s]
[1,1]<stdout>:100% 24/24 [00:00<00:00, 14280.51it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 16139.70it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 6508.68it/s]100% 24/24 [00:00<00:00, 9442.20it/s][1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 11849.71it/s]
[1,0]<stdout>:100% 24/24 [00:00<00:00, 10520.83it/s]
[1,0]<stdout>:100% 24/24 [00:00<00:00, 10530.74it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 10243.54it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s]  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 15247.39it/s]
[1,1]<stdout>:100% 24/24 [00:00<00:00, 15058.08it/s]
[1,1]<stdout>:100% 24/24 [00:00<00:00, 14532.02it/s]
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 15162.42it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,0]<stdout>:100% 24/24 [00:00<00:00, 13103.79it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 13528.19it/s]
[1,1]<stdout>:  0% 0/24 [00:00<?, ?it/s][1,1]<stdout>:100% 24/24 [00:00<00:00, 13213.87it/s]
[1,0]<stdout>:[2025-10-12 04:13:08 DP0 TP0] Prefill batch. #new-seq: 5, #new-token: 1275, #cached-token: 10, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:13:08 DP1 TP8] Prefill batch. #new-seq: 7, #new-token: 1785, #cached-token: 14, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 04:13:09] 
[1,0]<stdout>:Benchmark...
[1,0]<stdout>:[2025-10-12 04:13:09 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 515, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:13:09 DP1 TP8] Prefill batch. #new-seq: 13, #new-token: 2048, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 232, 
[1,0]<stdout>:[2025-10-12 04:13:09 DP0 TP0] Prefill batch. #new-seq: 13, #new-token: 2048, #cached-token: 18, token usage: 0.00, #running-req: 2, #queue-req: 232, 
[1,1]<stdout>:[2025-10-12 04:13:10 DP1 TP8] Prefill batch. #new-seq: 3, #new-token: 2048, #cached-token: 2, token usage: 0.01, #running-req: 12, #queue-req: 442, 
[1,0]<stdout>:[2025-10-12 04:13:10 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 2048, #cached-token: 1, token usage: 0.02, #running-req: 14, #queue-req: 443, 
[1,1]<stdout>:[2025-10-12 04:13:10 DP1 TP8] Prefill batch. #new-seq: 7, #new-token: 2048, #cached-token: 7, token usage: 0.03, #running-req: 14, #queue-req: 493, 
[1,0]<stdout>:[2025-10-12 04:13:10 DP0 TP0] Prefill batch. #new-seq: 9, #new-token: 2048, #cached-token: 10, token usage: 0.03, #running-req: 15, #queue-req: 491, 
[1,1]<stdout>:[2025-10-12 04:13:10 DP1 TP8] Prefill batch. #new-seq: 4, #new-token: 1033, #cached-token: 3, token usage: 0.04, #running-req: 20, #queue-req: 519, 
[1,0]<stdout>:[2025-10-12 04:13:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 478, #cached-token: 0, token usage: 0.04, #running-req: 23, #queue-req: 521, 
[1,1]<stdout>:[2025-10-12 04:13:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 743, 
[1,1]<stdout>:[2025-10-12 04:13:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 974, 
[1,0]<stdout>:[2025-10-12 04:13:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1904, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 975, 
[1,1]<stdout>:[2025-10-12 04:13:12 DP1 TP8] Prefill batch. #new-seq: 3, #new-token: 750, #cached-token: 5, token usage: 0.04, #running-req: 21, #queue-req: 971, 
[1,0]<stdout>:[2025-10-12 04:13:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 974, 
[1,1]<stdout>:[2025-10-12 04:13:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 970, 
[1,1]<stdout>:[2025-10-12 04:13:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.03, #running-req: 23, #queue-req: 969, 
[1,1]<stdout>:[2025-10-12 04:13:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 2, token usage: 0.03, #running-req: 23, #queue-req: 968, 
[1,0]<stdout>:[2025-10-12 04:13:13 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 380, #cached-token: 5, token usage: 0.05, #running-req: 22, #queue-req: 972, 
[1,0]<stdout>:[2025-10-12 04:13:13 DP0 TP0] Decode batch. #running-req: 24, #token: 8632, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 34.28, #queue-req: 972, 
[1,1]<stdout>:[2025-10-12 04:13:13 DP1 TP8] Decode batch. #running-req: 24, #token: 5574, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 34.06, #queue-req: 968, 
[1,0]<stdout>:[2025-10-12 04:13:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 971, 
[1,1]<stdout>:[2025-10-12 04:13:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 967, 
[1,0]<stdout>:[2025-10-12 04:13:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 970, 
[1,0]<stdout>:[2025-10-12 04:13:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 969, 
[1,0]<stdout>:[2025-10-12 04:13:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 968, 
[1,0]<stdout>:[2025-10-12 04:13:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 967, 
[1,0]<stdout>:[2025-10-12 04:13:16 DP0 TP0] Decode batch. #running-req: 24, #token: 7852, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 454.31, #queue-req: 967, 
[1,1]<stdout>:[2025-10-12 04:13:16 DP1 TP8] Decode batch. #running-req: 24, #token: 6574, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 456.22, #queue-req: 967, 
[1,0]<stdout>:[2025-10-12 04:13:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 966, 
[1,1]<stdout>:[2025-10-12 04:13:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 966, 
[1,1]<stdout>:[2025-10-12 04:13:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 965, 
[1,1]<stdout>:[2025-10-12 04:13:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 964, 
[1,1]<stdout>:[2025-10-12 04:13:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 963, 
[1,0]<stdout>:[2025-10-12 04:13:18 DP0 TP0] Decode batch. #running-req: 24, #token: 8991, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 483.61, #queue-req: 966, 
[1,1]<stdout>:[2025-10-12 04:13:18 DP1 TP8] Decode batch. #running-req: 24, #token: 7595, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 482.10, #queue-req: 963, 
[1,0]<stdout>:[2025-10-12 04:13:18 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 469, #cached-token: 4, token usage: 0.05, #running-req: 22, #queue-req: 964, 
[1,1]<stdout>:[2025-10-12 04:13:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 962, 
[1,0]<stdout>:[2025-10-12 04:13:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 774, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 963, 
[1,0]<stdout>:[2025-10-12 04:13:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 962, 
[1,1]<stdout>:[2025-10-12 04:13:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 961, 
[1,1]<stdout>:[2025-10-12 04:13:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 411, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 960, 
[1,0]<stdout>:[2025-10-12 04:13:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 961, 
[1,0]<stdout>:[2025-10-12 04:13:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 960, 
[1,0]<stdout>:[2025-10-12 04:13:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 959, 
[1,0]<stdout>:[2025-10-12 04:13:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1381, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 958, 
[1,1]<stdout>:[2025-10-12 04:13:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 959, 
[1,1]<stdout>:[2025-10-12 04:13:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1818, #cached-token: 0, token usage: 0.07, #running-req: 23, #queue-req: 959, 
[1,0]<stdout>:[2025-10-12 04:13:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 957, 
[1,1]<stdout>:[2025-10-12 04:13:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 958, 
[1,0]<stdout>:[2025-10-12 04:13:21 DP0 TP0] Decode batch. #running-req: 24, #token: 8679, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 271.33, #queue-req: 957, 
[1,1]<stdout>:[2025-10-12 04:13:21 DP1 TP8] Decode batch. #running-req: 24, #token: 9031, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 272.47, #queue-req: 958, 
[1,0]<stdout>:[2025-10-12 04:13:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 460, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 956, 
[1,1]<stdout>:[2025-10-12 04:13:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 957, 
[1,1]<stdout>:[2025-10-12 04:13:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 956, 
[1,0]<stdout>:[2025-10-12 04:13:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 955, 
[1,0]<stdout>:[2025-10-12 04:13:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 773, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 954, 
[1,0]<stdout>:[2025-10-12 04:13:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 953, 
[1,1]<stdout>:[2025-10-12 04:13:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 955, 
[1,0]<stdout>:[2025-10-12 04:13:23 DP0 TP0] Decode batch. #running-req: 24, #token: 7958, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 471.59, #queue-req: 953, 
[1,1]<stdout>:[2025-10-12 04:13:23 DP1 TP8] Decode batch. #running-req: 24, #token: 9012, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 472.14, #queue-req: 955, 
[1,0]<stdout>:[2025-10-12 04:13:23 DP0 TP0] Prefill batch. #new-seq: 3, #new-token: 560, #cached-token: 3, token usage: 0.05, #running-req: 21, #queue-req: 950, 
[1,0]<stdout>:[2025-10-12 04:13:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 949, 
[1,0]<stdout>:[2025-10-12 04:13:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 948, 
[1,0]<stdout>:[2025-10-12 04:13:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 947, 
[1,0]<stdout>:[2025-10-12 04:13:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 946, 
[1,0]<stdout>:[2025-10-12 04:13:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 1, token usage: 0.03, #running-req: 23, #queue-req: 945, 
[1,0]<stdout>:[2025-10-12 04:13:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.03, #running-req: 23, #queue-req: 944, 
[1,1]<stdout>:[2025-10-12 04:13:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 954, 
[1,0]<stdout>:[2025-10-12 04:13:25 DP0 TP0] Decode batch. #running-req: 24, #token: 5746, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 403.38, #queue-req: 944, 
[1,1]<stdout>:[2025-10-12 04:13:25 DP1 TP8] Decode batch. #running-req: 24, #token: 9719, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 406.73, #queue-req: 954, 
[1,0]<stdout>:[2025-10-12 04:13:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 943, 
[1,1]<stdout>:[2025-10-12 04:13:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 953, 
[1,1]<stdout>:[2025-10-12 04:13:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 952, 
[1,0]<stdout>:[2025-10-12 04:13:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 11, token usage: 0.04, #running-req: 23, #queue-req: 942, 
[1,1]<stdout>:[2025-10-12 04:13:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 951, 
[1,0]<stdout>:[2025-10-12 04:13:27 DP0 TP0] Decode batch. #running-req: 24, #token: 6593, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 528.68, #queue-req: 942, 
[1,1]<stdout>:[2025-10-12 04:13:27 DP1 TP8] Decode batch. #running-req: 24, #token: 10496, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 528.19, #queue-req: 951, 
[1,0]<stdout>:[2025-10-12 04:13:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 941, 
[1,1]<stdout>:[2025-10-12 04:13:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 950, 
[1,1]<stdout>:[2025-10-12 04:13:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 949, 
[1,1]<stdout>:[2025-10-12 04:13:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 575, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 948, 
[1,1]<stdout>:[2025-10-12 04:13:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 947, 
[1,1]<stdout>:[2025-10-12 04:13:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 946, 
[1,1]<stdout>:[2025-10-12 04:13:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 945, 
[1,1]<stdout>:[2025-10-12 04:13:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 944, 
[1,1]<stdout>:[2025-10-12 04:13:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 0, token usage: 0.07, #running-req: 23, #queue-req: 944, 
[1,0]<stdout>:[2025-10-12 04:13:30 DP0 TP0] Decode batch. #running-req: 23, #token: 7203, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 397.72, #queue-req: 941, 
[1,1]<stdout>:[2025-10-12 04:13:30 DP1 TP8] Decode batch. #running-req: 24, #token: 10834, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 395.60, #queue-req: 944, 
[1,0]<stdout>:[2025-10-12 04:13:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 940, 
[1,0]<stdout>:[2025-10-12 04:13:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 5, token usage: 0.05, #running-req: 23, #queue-req: 939, 
[1,1]<stdout>:[2025-10-12 04:13:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 943, 
[1,1]<stdout>:[2025-10-12 04:13:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 942, 
[1,0]<stdout>:[2025-10-12 04:13:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 938, 
[1,1]<stdout>:[2025-10-12 04:13:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 941, 
[1,1]<stdout>:[2025-10-12 04:13:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 940, 
[1,0]<stdout>:[2025-10-12 04:13:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 937, 
[1,0]<stdout>:[2025-10-12 04:13:32 DP0 TP0] Decode batch. #running-req: 24, #token: 7611, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 413.56, #queue-req: 937, 
[1,1]<stdout>:[2025-10-12 04:13:32 DP1 TP8] Decode batch. #running-req: 24, #token: 6613, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 413.13, #queue-req: 940, 
[1,0]<stdout>:[2025-10-12 04:13:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 936, 
[1,0]<stdout>:[2025-10-12 04:13:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 935, 
[1,0]<stdout>:[2025-10-12 04:13:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 934, 
[1,1]<stdout>:[2025-10-12 04:13:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 939, 
[1,0]<stdout>:[2025-10-12 04:13:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 933, 
[1,0]<stdout>:[2025-10-12 04:13:34 DP0 TP0] Decode batch. #running-req: 24, #token: 8256, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 519.02, #queue-req: 933, 
[1,1]<stdout>:[2025-10-12 04:13:34 DP1 TP8] Decode batch. #running-req: 24, #token: 7637, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 520.69, #queue-req: 939, 
[1,0]<stdout>:[2025-10-12 04:13:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 932, 
[1,0]<stdout>:[2025-10-12 04:13:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 806, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 931, 
[1,0]<stdout>:[2025-10-12 04:13:34 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 404, #cached-token: 2, token usage: 0.05, #running-req: 22, #queue-req: 929, 
[1,0]<stdout>:[2025-10-12 04:13:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 617, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 928, 
[1,1]<stdout>:[2025-10-12 04:13:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 938, 
[1,0]<stdout>:[2025-10-12 04:13:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 927, 
[1,1]<stdout>:[2025-10-12 04:13:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 429, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 937, 
[1,0]<stdout>:[2025-10-12 04:13:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 926, 
[1,0]<stdout>:[2025-10-12 04:13:35 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 1399, #cached-token: 4, token usage: 0.04, #running-req: 22, #queue-req: 924, 
[1,0]<stdout>:[2025-10-12 04:13:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 699, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 923, 
[1,1]<stdout>:[2025-10-12 04:13:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 936, 
[1,1]<stdout>:[2025-10-12 04:13:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 935, 
[1,0]<stdout>:[2025-10-12 04:13:36 DP0 TP0] Decode batch. #running-req: 24, #token: 8849, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 360.67, #queue-req: 923, 
[1,1]<stdout>:[2025-10-12 04:13:36 DP1 TP8] Decode batch. #running-req: 24, #token: 8691, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 362.92, #queue-req: 935, 
[1,1]<stdout>:[2025-10-12 04:13:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 934, 
[1,1]<stdout>:[2025-10-12 04:13:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 933, 
[1,0]<stdout>:[2025-10-12 04:13:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 922, 
[1,0]<stdout>:[2025-10-12 04:13:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 921, 
[1,0]<stdout>:[2025-10-12 04:13:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 920, 
[1,1]<stdout>:[2025-10-12 04:13:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1978, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 932, 
[1,0]<stdout>:[2025-10-12 04:13:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 919, 
[1,0]<stdout>:[2025-10-12 04:13:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 918, 
[1,1]<stdout>:[2025-10-12 04:13:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 931, 
[1,0]<stdout>:[2025-10-12 04:13:39 DP0 TP0] Decode batch. #running-req: 24, #token: 8152, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 391.17, #queue-req: 918, 
[1,1]<stdout>:[2025-10-12 04:13:39 DP1 TP8] Decode batch. #running-req: 23, #token: 10712, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 391.20, #queue-req: 931, 
[1,1]<stdout>:[2025-10-12 04:13:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 930, 
[1,0]<stdout>:[2025-10-12 04:13:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 917, 
[1,1]<stdout>:[2025-10-12 04:13:40 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 376, #cached-token: 4, token usage: 0.07, #running-req: 22, #queue-req: 928, 
[1,0]<stdout>:[2025-10-12 04:13:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 916, 
[1,1]<stdout>:[2025-10-12 04:13:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 927, 
[1,1]<stdout>:[2025-10-12 04:13:40 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 804, #cached-token: 4, token usage: 0.06, #running-req: 22, #queue-req: 925, 
[1,1]<stdout>:[2025-10-12 04:13:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 924, 
[1,1]<stdout>:[2025-10-12 04:13:41 DP1 TP8] Decode batch. #running-req: 24, #token: 10682, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 442.96, #queue-req: 924, 
[1,0]<stdout>:[2025-10-12 04:13:41 DP0 TP0] Decode batch. #running-req: 23, #token: 8838, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 444.38, #queue-req: 916, 
[1,0]<stdout>:[2025-10-12 04:13:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 915, 
[1,1]<stdout>:[2025-10-12 04:13:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 923, 
[1,1]<stdout>:[2025-10-12 04:13:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 922, 
[1,1]<stdout>:[2025-10-12 04:13:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 810, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 921, 
[1,0]<stdout>:[2025-10-12 04:13:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 914, 
[1,1]<stdout>:[2025-10-12 04:13:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 920, 
[1,1]<stdout>:[2025-10-12 04:13:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 919, 
[1,1]<stdout>:[2025-10-12 04:13:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 918, 
[1,1]<stdout>:[2025-10-12 04:13:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 917, 
[1,0]<stdout>:[2025-10-12 04:13:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 913, 
[1,0]<stdout>:[2025-10-12 04:13:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 385, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 912, 
[1,0]<stdout>:[2025-10-12 04:13:44 DP0 TP0] Decode batch. #running-req: 23, #token: 8912, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 346.59, #queue-req: 912, 
[1,1]<stdout>:[2025-10-12 04:13:44 DP1 TP8] Decode batch. #running-req: 24, #token: 9508, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 345.52, #queue-req: 917, 
[1,0]<stdout>:[2025-10-12 04:13:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1066, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 911, 
[1,0]<stdout>:[2025-10-12 04:13:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 910, 
[1,0]<stdout>:[2025-10-12 04:13:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 909, 
[1,1]<stdout>:[2025-10-12 04:13:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 916, 
[1,1]<stdout>:[2025-10-12 04:13:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 494, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 915, 
[1,0]<stdout>:[2025-10-12 04:13:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 908, 
[1,1]<stdout>:[2025-10-12 04:13:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 914, 
[1,1]<stdout>:[2025-10-12 04:13:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 913, 
[1,0]<stdout>:[2025-10-12 04:13:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 907, 
[1,0]<stdout>:[2025-10-12 04:13:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 906, 
[1,1]<stdout>:[2025-10-12 04:13:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 912, 
[1,0]<stdout>:[2025-10-12 04:13:46 DP0 TP0] Decode batch. #running-req: 24, #token: 10184, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 384.06, #queue-req: 906, 
[1,1]<stdout>:[2025-10-12 04:13:46 DP1 TP8] Decode batch. #running-req: 24, #token: 9464, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 384.06, #queue-req: 912, 
[1,0]<stdout>:[2025-10-12 04:13:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 905, 
[1,1]<stdout>:[2025-10-12 04:13:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 911, 
[1,0]<stdout>:[2025-10-12 04:13:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 904, 
[1,0]<stdout>:[2025-10-12 04:13:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 903, 
[1,0]<stdout>:[2025-10-12 04:13:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 902, 
[1,0]<stdout>:[2025-10-12 04:13:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 901, 
[1,0]<stdout>:[2025-10-12 04:13:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 900, 
[1,0]<stdout>:[2025-10-12 04:13:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 899, 
[1,1]<stdout>:[2025-10-12 04:13:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 910, 
[1,0]<stdout>:[2025-10-12 04:13:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 898, 
[1,0]<stdout>:[2025-10-12 04:13:49 DP0 TP0] Decode batch. #running-req: 23, #token: 9642, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 388.21, #queue-req: 898, 
[1,1]<stdout>:[2025-10-12 04:13:49 DP1 TP8] Decode batch. #running-req: 24, #token: 9594, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 391.02, #queue-req: 910, 
[1,0]<stdout>:[2025-10-12 04:13:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 897, 
[1,1]<stdout>:[2025-10-12 04:13:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 909, 
[1,0]<stdout>:[2025-10-12 04:13:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 896, 
[1,1]<stdout>:[2025-10-12 04:13:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 765, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 908, 
[1,0]<stdout>:[2025-10-12 04:13:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 895, 
[1,1]<stdout>:[2025-10-12 04:13:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1228, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 907, 
[1,1]<stdout>:[2025-10-12 04:13:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 906, 
[1,0]<stdout>:[2025-10-12 04:13:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 894, 
[1,1]<stdout>:[2025-10-12 04:13:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 905, 
[1,0]<stdout>:[2025-10-12 04:13:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 893, 
[1,0]<stdout>:[2025-10-12 04:13:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 892, 
[1,0]<stdout>:[2025-10-12 04:13:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 891, 
[1,0]<stdout>:[2025-10-12 04:13:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 890, 
[1,1]<stdout>:[2025-10-12 04:13:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 904, 
[1,0]<stdout>:[2025-10-12 04:13:52 DP0 TP0] Decode batch. #running-req: 23, #token: 9701, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 299.02, #queue-req: 890, 
[1,1]<stdout>:[2025-10-12 04:13:52 DP1 TP8] Decode batch. #running-req: 24, #token: 10286, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 299.65, #queue-req: 904, 
[1,0]<stdout>:[2025-10-12 04:13:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 7, token usage: 0.06, #running-req: 23, #queue-req: 889, 
[1,1]<stdout>:[2025-10-12 04:13:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 903, 
[1,1]<stdout>:[2025-10-12 04:13:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 902, 
[1,0]<stdout>:[2025-10-12 04:13:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 888, 
[1,1]<stdout>:[2025-10-12 04:13:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 901, 
[1,0]<stdout>:[2025-10-12 04:13:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 8, token usage: 0.07, #running-req: 23, #queue-req: 887, 
[1,1]<stdout>:[2025-10-12 04:13:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 900, 
[1,0]<stdout>:[2025-10-12 04:13:54 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 533, #cached-token: 2, token usage: 0.07, #running-req: 22, #queue-req: 885, 
[1,1]<stdout>:[2025-10-12 04:13:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 899, 
[1,0]<stdout>:[2025-10-12 04:13:54 DP0 TP0] Decode batch. #running-req: 24, #token: 10937, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 422.17, #queue-req: 885, 
[1,1]<stdout>:[2025-10-12 04:13:54 DP1 TP8] Decode batch. #running-req: 24, #token: 8875, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 421.74, #queue-req: 899, 
[1,0]<stdout>:[2025-10-12 04:13:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 884, 
[1,0]<stdout>:[2025-10-12 04:13:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 883, 
[1,0]<stdout>:[2025-10-12 04:13:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 882, 
[1,0]<stdout>:[2025-10-12 04:13:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 881, 
[1,1]<stdout>:[2025-10-12 04:13:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 898, 
[1,0]<stdout>:[2025-10-12 04:13:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 880, 
[1,1]<stdout>:[2025-10-12 04:13:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 897, 
[1,0]<stdout>:[2025-10-12 04:13:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 879, 
[1,1]<stdout>:[2025-10-12 04:13:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 896, 
[1,1]<stdout>:[2025-10-12 04:13:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 895, 
[1,0]<stdout>:[2025-10-12 04:13:57 DP0 TP0] Decode batch. #running-req: 24, #token: 9667, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 394.63, #queue-req: 879, 
[1,1]<stdout>:[2025-10-12 04:13:57 DP1 TP8] Decode batch. #running-req: 24, #token: 8393, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 395.49, #queue-req: 895, 
[1,0]<stdout>:[2025-10-12 04:13:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 878, 
[1,1]<stdout>:[2025-10-12 04:13:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 894, 
[1,0]<stdout>:[2025-10-12 04:13:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 877, 
[1,0]<stdout>:[2025-10-12 04:13:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 876, 
[1,1]<stdout>:[2025-10-12 04:13:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 893, 
[1,0]<stdout>:[2025-10-12 04:13:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 430, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 875, 
[1,0]<stdout>:[2025-10-12 04:13:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 874, 
[1,0]<stdout>:[2025-10-12 04:13:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 873, 
[1,0]<stdout>:[2025-10-12 04:13:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 872, 
[1,0]<stdout>:[2025-10-12 04:13:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 871, 
[1,0]<stdout>:[2025-10-12 04:13:59 DP0 TP0] Decode batch. #running-req: 24, #token: 9574, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 369.83, #queue-req: 871, 
[1,1]<stdout>:[2025-10-12 04:13:59 DP1 TP8] Decode batch. #running-req: 23, #token: 8053, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 371.77, #queue-req: 893, 
[1,1]<stdout>:[2025-10-12 04:13:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 892, 
[1,0]<stdout>:[2025-10-12 04:13:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 870, 
[1,0]<stdout>:[2025-10-12 04:14:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 869, 
[1,0]<stdout>:[2025-10-12 04:14:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 868, 
[1,0]<stdout>:[2025-10-12 04:14:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 867, 
[1,1]<stdout>:[2025-10-12 04:14:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 891, 
[1,0]<stdout>:[2025-10-12 04:14:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 866, 
[1,1]<stdout>:[2025-10-12 04:14:01 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 134, #cached-token: 4, token usage: 0.04, #running-req: 22, #queue-req: 889, 
[1,0]<stdout>:[2025-10-12 04:14:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 868, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 865, 
[1,1]<stdout>:[2025-10-12 04:14:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 888, 
[1,1]<stdout>:[2025-10-12 04:14:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 4, token usage: 0.04, #running-req: 23, #queue-req: 887, 
[1,0]<stdout>:[2025-10-12 04:14:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 864, 
[1,1]<stdout>:[2025-10-12 04:14:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 886, 
[1,1]<stdout>:[2025-10-12 04:14:02 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 544, #cached-token: 4, token usage: 0.04, #running-req: 22, #queue-req: 884, 
[1,0]<stdout>:[2025-10-12 04:14:02 DP0 TP0] Decode batch. #running-req: 24, #token: 8814, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 319.21, #queue-req: 864, 
[1,1]<stdout>:[2025-10-12 04:14:02 DP1 TP8] Decode batch. #running-req: 24, #token: 6667, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 318.86, #queue-req: 884, 
[1,1]<stdout>:[2025-10-12 04:14:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 883, 
[1,1]<stdout>:[2025-10-12 04:14:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 882, 
[1,0]<stdout>:[2025-10-12 04:14:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 863, 
[1,1]<stdout>:[2025-10-12 04:14:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 881, 
[1,0]<stdout>:[2025-10-12 04:14:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 862, 
[1,0]<stdout>:[2025-10-12 04:14:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 493, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 861, 
[1,0]<stdout>:[2025-10-12 04:14:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 860, 
[1,1]<stdout>:[2025-10-12 04:14:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 880, 
[1,1]<stdout>:[2025-10-12 04:14:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 879, 
[1,0]<stdout>:[2025-10-12 04:14:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 859, 
[1,1]<stdout>:[2025-10-12 04:14:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 878, 
[1,0]<stdout>:[2025-10-12 04:14:05 DP0 TP0] Decode batch. #running-req: 24, #token: 8561, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 352.33, #queue-req: 859, 
[1,1]<stdout>:[2025-10-12 04:14:05 DP1 TP8] Decode batch. #running-req: 24, #token: 6076, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 351.97, #queue-req: 878, 
[1,1]<stdout>:[2025-10-12 04:14:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 877, 
[1,0]<stdout>:[2025-10-12 04:14:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 858, 
[1,1]<stdout>:[2025-10-12 04:14:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 876, 
[1,0]<stdout>:[2025-10-12 04:14:06 DP0 TP0] Decode batch. #running-req: 24, #token: 9211, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 616.39, #queue-req: 858, 
[1,1]<stdout>:[2025-10-12 04:14:06 DP1 TP8] Decode batch. #running-req: 24, #token: 6919, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 615.75, #queue-req: 876, 
[1,1]<stdout>:[2025-10-12 04:14:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 875, 
[1,0]<stdout>:[2025-10-12 04:14:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 857, 
[1,0]<stdout>:[2025-10-12 04:14:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 856, 
[1,1]<stdout>:[2025-10-12 04:14:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 734, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 874, 
[1,1]<stdout>:[2025-10-12 04:14:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 873, 
[1,1]<stdout>:[2025-10-12 04:14:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 872, 
[1,1]<stdout>:[2025-10-12 04:14:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 871, 
[1,1]<stdout>:[2025-10-12 04:14:08 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 1316, #cached-token: 2, token usage: 0.04, #running-req: 22, #queue-req: 869, 
[1,0]<stdout>:[2025-10-12 04:14:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 855, 
[1,0]<stdout>:[2025-10-12 04:14:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 854, 
[1,1]<stdout>:[2025-10-12 04:14:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 868, 
[1,0]<stdout>:[2025-10-12 04:14:09 DP0 TP0] Decode batch. #running-req: 24, #token: 10039, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 371.96, #queue-req: 854, 
[1,1]<stdout>:[2025-10-12 04:14:09 DP1 TP8] Decode batch. #running-req: 24, #token: 7578, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 370.41, #queue-req: 868, 
[1,1]<stdout>:[2025-10-12 04:14:09 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 190, #cached-token: 3, token usage: 0.05, #running-req: 22, #queue-req: 866, 
[1,0]<stdout>:[2025-10-12 04:14:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 853, 
[1,1]<stdout>:[2025-10-12 04:14:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 673, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 865, 
[1,1]<stdout>:[2025-10-12 04:14:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 864, 
[1,1]<stdout>:[2025-10-12 04:14:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 660, #cached-token: 4, token usage: 0.04, #running-req: 23, #queue-req: 863, 
[1,1]<stdout>:[2025-10-12 04:14:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 862, 
[1,0]<stdout>:[2025-10-12 04:14:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 852, 
[1,0]<stdout>:[2025-10-12 04:14:11 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 17, #cached-token: 4, token usage: 0.07, #running-req: 22, #queue-req: 850, 
[1,0]<stdout>:[2025-10-12 04:14:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 849, 
[1,0]<stdout>:[2025-10-12 04:14:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 848, 
[1,1]<stdout>:[2025-10-12 04:14:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 861, 
[1,1]<stdout>:[2025-10-12 04:14:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 860, 
[1,1]<stdout>:[2025-10-12 04:14:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 859, 
[1,0]<stdout>:[2025-10-12 04:14:12 DP0 TP0] Decode batch. #running-req: 24, #token: 10168, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 323.28, #queue-req: 848, 
[1,1]<stdout>:[2025-10-12 04:14:12 DP1 TP8] Decode batch. #running-req: 24, #token: 6479, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 322.27, #queue-req: 859, 
[1,0]<stdout>:[2025-10-12 04:14:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 847, 
[1,1]<stdout>:[2025-10-12 04:14:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 858, 
[1,1]<stdout>:[2025-10-12 04:14:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 669, #cached-token: 4, token usage: 0.04, #running-req: 23, #queue-req: 857, 
[1,1]<stdout>:[2025-10-12 04:14:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 856, 
[1,0]<stdout>:[2025-10-12 04:14:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 452, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 846, 
[1,0]<stdout>:[2025-10-12 04:14:14 DP0 TP0] Decode batch. #running-req: 24, #token: 11308, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 521.13, #queue-req: 846, 
[1,1]<stdout>:[2025-10-12 04:14:14 DP1 TP8] Decode batch. #running-req: 24, #token: 7803, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 520.58, #queue-req: 856, 
[1,1]<stdout>:[2025-10-12 04:14:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 855, 
[1,0]<stdout>:[2025-10-12 04:14:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 845, 
[1,0]<stdout>:[2025-10-12 04:14:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 844, 
[1,1]<stdout>:[2025-10-12 04:14:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 854, 
[1,1]<stdout>:[2025-10-12 04:14:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 853, 
[1,1]<stdout>:[2025-10-12 04:14:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 852, 
[1,1]<stdout>:[2025-10-12 04:14:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 851, 
[1,0]<stdout>:[2025-10-12 04:14:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 843, 
[1,1]<stdout>:[2025-10-12 04:14:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 850, 
[1,1]<stdout>:[2025-10-12 04:14:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 849, 
[1,0]<stdout>:[2025-10-12 04:14:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 842, 
[1,1]<stdout>:[2025-10-12 04:14:16 DP1 TP8] Decode batch. #running-req: 24, #token: 8212, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 374.86, #queue-req: 849, 
[1,0]<stdout>:[2025-10-12 04:14:16 DP0 TP0] Decode batch. #running-req: 24, #token: 11359, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 376.02, #queue-req: 842, 
[1,0]<stdout>:[2025-10-12 04:14:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 841, 
[1,1]<stdout>:[2025-10-12 04:14:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 224, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 848, 
[1,1]<stdout>:[2025-10-12 04:14:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 847, 
[1,1]<stdout>:[2025-10-12 04:14:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 5, token usage: 0.05, #running-req: 23, #queue-req: 846, 
[1,0]<stdout>:[2025-10-12 04:14:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 840, 
[1,0]<stdout>:[2025-10-12 04:14:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 839, 
[1,1]<stdout>:[2025-10-12 04:14:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 845, 
[1,1]<stdout>:[2025-10-12 04:14:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 844, 
[1,0]<stdout>:[2025-10-12 04:14:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 903, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 838, 
[1,1]<stdout>:[2025-10-12 04:14:19 DP1 TP8] Decode batch. #running-req: 24, #token: 8552, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 397.28, #queue-req: 844, 
[1,0]<stdout>:[2025-10-12 04:14:19 DP0 TP0] Decode batch. #running-req: 24, #token: 11527, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 397.70, #queue-req: 838, 
[1,0]<stdout>:[2025-10-12 04:14:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 837, 
[1,1]<stdout>:[2025-10-12 04:14:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 843, 
[1,0]<stdout>:[2025-10-12 04:14:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 836, 
[1,0]<stdout>:[2025-10-12 04:14:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 835, 
[1,1]<stdout>:[2025-10-12 04:14:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 842, 
[1,0]<stdout>:[2025-10-12 04:14:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 834, 
[1,1]<stdout>:[2025-10-12 04:14:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 841, 
[1,1]<stdout>:[2025-10-12 04:14:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 840, 
[1,1]<stdout>:[2025-10-12 04:14:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 839, 
[1,1]<stdout>:[2025-10-12 04:14:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 838, 
[1,0]<stdout>:[2025-10-12 04:14:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 833, 
[1,1]<stdout>:[2025-10-12 04:14:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 837, 
[1,0]<stdout>:[2025-10-12 04:14:22 DP0 TP0] Decode batch. #running-req: 24, #token: 10989, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 335.57, #queue-req: 833, 
[1,1]<stdout>:[2025-10-12 04:14:22 DP1 TP8] Decode batch. #running-req: 24, #token: 7396, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 334.86, #queue-req: 837, 
[1,1]<stdout>:[2025-10-12 04:14:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 836, 
[1,0]<stdout>:[2025-10-12 04:14:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 832, 
[1,0]<stdout>:[2025-10-12 04:14:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 831, 
[1,0]<stdout>:[2025-10-12 04:14:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 830, 
[1,0]<stdout>:[2025-10-12 04:14:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 829, 
[1,1]<stdout>:[2025-10-12 04:14:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 835, 
[1,0]<stdout>:[2025-10-12 04:14:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 463, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 828, 
[1,0]<stdout>:[2025-10-12 04:14:24 DP0 TP0] Decode batch. #running-req: 24, #token: 11323, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 453.80, #queue-req: 828, 
[1,1]<stdout>:[2025-10-12 04:14:24 DP1 TP8] Decode batch. #running-req: 24, #token: 7692, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 455.21, #queue-req: 835, 
[1,1]<stdout>:[2025-10-12 04:14:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 834, 
[1,1]<stdout>:[2025-10-12 04:14:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 833, 
[1,0]<stdout>:[2025-10-12 04:14:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 827, 
[1,1]<stdout>:[2025-10-12 04:14:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 832, 
[1,0]<stdout>:[2025-10-12 04:14:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 822, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 826, 
[1,1]<stdout>:[2025-10-12 04:14:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 831, 
[1,1]<stdout>:[2025-10-12 04:14:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 670, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 830, 
[1,0]<stdout>:[2025-10-12 04:14:26 DP0 TP0] Decode batch. #running-req: 24, #token: 12757, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 445.96, #queue-req: 826, 
[1,1]<stdout>:[2025-10-12 04:14:26 DP1 TP8] Decode batch. #running-req: 24, #token: 7984, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 444.57, #queue-req: 830, 
[1,0]<stdout>:[2025-10-12 04:14:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 825, 
[1,0]<stdout>:[2025-10-12 04:14:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 824, 
[1,1]<stdout>:[2025-10-12 04:14:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 829, 
[1,1]<stdout>:[2025-10-12 04:14:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 828, 
[1,0]<stdout>:[2025-10-12 04:14:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1132, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 823, 
[1,0]<stdout>:[2025-10-12 04:14:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 735, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 822, 
[1,0]<stdout>:[2025-10-12 04:14:28 DP0 TP0] Decode batch. #running-req: 24, #token: 13940, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 479.53, #queue-req: 822, 
[1,1]<stdout>:[2025-10-12 04:14:28 DP1 TP8] Decode batch. #running-req: 24, #token: 8341, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 480.51, #queue-req: 828, 
[1,1]<stdout>:[2025-10-12 04:14:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 827, 
[1,0]<stdout>:[2025-10-12 04:14:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 821, 
[1,0]<stdout>:[2025-10-12 04:14:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 820, 
[1,1]<stdout>:[2025-10-12 04:14:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 826, 
[1,0]<stdout>:[2025-10-12 04:14:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 819, 
[1,1]<stdout>:[2025-10-12 04:14:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 825, 
[1,1]<stdout>:[2025-10-12 04:14:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 824, 
[1,0]<stdout>:[2025-10-12 04:14:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 818, 
[1,1]<stdout>:[2025-10-12 04:14:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 823, 
[1,0]<stdout>:[2025-10-12 04:14:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1231, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 817, 
[1,1]<stdout>:[2025-10-12 04:14:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 822, 
[1,1]<stdout>:[2025-10-12 04:14:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 821, 
[1,0]<stdout>:[2025-10-12 04:14:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 816, 
[1,0]<stdout>:[2025-10-12 04:14:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 7, token usage: 0.09, #running-req: 23, #queue-req: 815, 
[1,0]<stdout>:[2025-10-12 04:14:31 DP0 TP0] Decode batch. #running-req: 23, #token: 14940, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 331.51, #queue-req: 815, 
[1,1]<stdout>:[2025-10-12 04:14:31 DP1 TP8] Decode batch. #running-req: 23, #token: 7084, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 331.52, #queue-req: 821, 
[1,0]<stdout>:[2025-10-12 04:14:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 814, 
[1,1]<stdout>:[2025-10-12 04:14:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 820, 
[1,1]<stdout>:[2025-10-12 04:14:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 0, token usage: 0.06, #running-req: 23, #queue-req: 820, 
[1,0]<stdout>:[2025-10-12 04:14:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 813, 
[1,1]<stdout>:[2025-10-12 04:14:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 819, 
[1,0]<stdout>:[2025-10-12 04:14:32 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 1394, #cached-token: 3, token usage: 0.09, #running-req: 22, #queue-req: 811, 
[1,1]<stdout>:[2025-10-12 04:14:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 818, 
[1,1]<stdout>:[2025-10-12 04:14:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 817, 
[1,0]<stdout>:[2025-10-12 04:14:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 992, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 810, 
[1,0]<stdout>:[2025-10-12 04:14:33 DP0 TP0] Decode batch. #running-req: 24, #token: 15507, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 410.40, #queue-req: 810, 
[1,1]<stdout>:[2025-10-12 04:14:33 DP1 TP8] Decode batch. #running-req: 24, #token: 9374, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 410.84, #queue-req: 817, 
[1,1]<stdout>:[2025-10-12 04:14:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 816, 
[1,0]<stdout>:[2025-10-12 04:14:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 809, 
[1,0]<stdout>:[2025-10-12 04:14:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1940, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 808, 
[1,0]<stdout>:[2025-10-12 04:14:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 770, #cached-token: 5, token usage: 0.11, #running-req: 23, #queue-req: 807, 
[1,1]<stdout>:[2025-10-12 04:14:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 815, 
[1,1]<stdout>:[2025-10-12 04:14:35 DP1 TP8] Decode batch. #running-req: 24, #token: 9539, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 513.27, #queue-req: 815, 
[1,0]<stdout>:[2025-10-12 04:14:35 DP0 TP0] Decode batch. #running-req: 24, #token: 17042, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 512.74, #queue-req: 807, 
[1,1]<stdout>:[2025-10-12 04:14:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 724, #cached-token: 9, token usage: 0.06, #running-req: 23, #queue-req: 814, 
[1,1]<stdout>:[2025-10-12 04:14:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 905, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 813, 
[1,0]<stdout>:[2025-10-12 04:14:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 806, 
[1,0]<stdout>:[2025-10-12 04:14:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 805, 
[1,0]<stdout>:[2025-10-12 04:14:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 04:14:37 DP0 TP0] Decode batch. #running-req: 24, #token: 15909, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 515.15, #queue-req: 804, 
[1,1]<stdout>:[2025-10-12 04:14:37 DP1 TP8] Decode batch. #running-req: 24, #token: 11607, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 515.67, #queue-req: 813, 
[1,1]<stdout>:[2025-10-12 04:14:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 812, 
[1,0]<stdout>:[2025-10-12 04:14:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 803, 
[1,0]<stdout>:[2025-10-12 04:14:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 802, 
[1,1]<stdout>:[2025-10-12 04:14:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 811, 
[1,0]<stdout>:[2025-10-12 04:14:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 801, 
[1,0]<stdout>:[2025-10-12 04:14:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 800, 
[1,1]<stdout>:[2025-10-12 04:14:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 810, 
[1,1]<stdout>:[2025-10-12 04:14:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 809, 
[1,0]<stdout>:[2025-10-12 04:14:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 447, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 799, 
[1,0]<stdout>:[2025-10-12 04:14:39 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 501, #cached-token: 5, token usage: 0.09, #running-req: 22, #queue-req: 797, 
[1,0]<stdout>:[2025-10-12 04:14:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 796, 
[1,0]<stdout>:[2025-10-12 04:14:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 759, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 795, 
[1,0]<stdout>:[2025-10-12 04:14:39 DP0 TP0] Decode batch. #running-req: 23, #token: 14092, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 354.06, #queue-req: 795, 
[1,1]<stdout>:[2025-10-12 04:14:39 DP1 TP8] Decode batch. #running-req: 24, #token: 11420, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.29, #queue-req: 809, 
[1,0]<stdout>:[2025-10-12 04:14:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 794, 
[1,1]<stdout>:[2025-10-12 04:14:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 712, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 808, 
[1,0]<stdout>:[2025-10-12 04:14:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 793, 
[1,0]<stdout>:[2025-10-12 04:14:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 792, 
[1,0]<stdout>:[2025-10-12 04:14:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 791, 
[1,1]<stdout>:[2025-10-12 04:14:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 834, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 807, 
[1,1]<stdout>:[2025-10-12 04:14:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 755, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 806, 
[1,1]<stdout>:[2025-10-12 04:14:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 805, 
[1,0]<stdout>:[2025-10-12 04:14:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 790, 
[1,0]<stdout>:[2025-10-12 04:14:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 789, 
[1,0]<stdout>:[2025-10-12 04:14:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 788, 
[1,0]<stdout>:[2025-10-12 04:14:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 787, 
[1,1]<stdout>:[2025-10-12 04:14:42 DP1 TP8] Decode batch. #running-req: 24, #token: 12549, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 336.06, #queue-req: 805, 
[1,0]<stdout>:[2025-10-12 04:14:42 DP0 TP0] Decode batch. #running-req: 24, #token: 11709, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 334.98, #queue-req: 787, 
[1,1]<stdout>:[2025-10-12 04:14:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 04:14:42 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 307, #cached-token: 8, token usage: 0.07, #running-req: 22, #queue-req: 785, 
[1,0]<stdout>:[2025-10-12 04:14:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 784, 
[1,0]<stdout>:[2025-10-12 04:14:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 783, 
[1,0]<stdout>:[2025-10-12 04:14:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 775, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 782, 
[1,0]<stdout>:[2025-10-12 04:14:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 781, 
[1,0]<stdout>:[2025-10-12 04:14:44 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 836, #cached-token: 9, token usage: 0.07, #running-req: 22, #queue-req: 779, 
[1,0]<stdout>:[2025-10-12 04:14:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 8, token usage: 0.07, #running-req: 23, #queue-req: 778, 
[1,0]<stdout>:[2025-10-12 04:14:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 777, 
[1,1]<stdout>:[2025-10-12 04:14:45 DP1 TP8] Decode batch. #running-req: 23, #token: 13462, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 429.98, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 04:14:45 DP0 TP0] Decode batch. #running-req: 24, #token: 11547, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 426.41, #queue-req: 777, 
[1,1]<stdout>:[2025-10-12 04:14:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 803, 
[1,0]<stdout>:[2025-10-12 04:14:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 7, token usage: 0.07, #running-req: 23, #queue-req: 776, 
[1,0]<stdout>:[2025-10-12 04:14:45 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 36, #cached-token: 2, token usage: 0.06, #running-req: 22, #queue-req: 774, 
[1,1]<stdout>:[2025-10-12 04:14:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 802, 
[1,0]<stdout>:[2025-10-12 04:14:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 773, 
[1,1]<stdout>:[2025-10-12 04:14:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 801, 
[1,0]<stdout>:[2025-10-12 04:14:46 DP0 TP0] Decode batch. #running-req: 24, #token: 9863, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 483.70, #queue-req: 773, 
[1,1]<stdout>:[2025-10-12 04:14:46 DP1 TP8] Decode batch. #running-req: 24, #token: 14841, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 484.71, #queue-req: 801, 
[1,1]<stdout>:[2025-10-12 04:14:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 800, 
[1,0]<stdout>:[2025-10-12 04:14:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 772, 
[1,1]<stdout>:[2025-10-12 04:14:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 799, 
[1,0]<stdout>:[2025-10-12 04:14:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 771, 
[1,0]<stdout>:[2025-10-12 04:14:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 770, 
[1,1]<stdout>:[2025-10-12 04:14:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1044, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 798, 
[1,1]<stdout>:[2025-10-12 04:14:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1051, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 797, 
[1,0]<stdout>:[2025-10-12 04:14:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 769, 
[1,1]<stdout>:[2025-10-12 04:14:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 796, 
[1,0]<stdout>:[2025-10-12 04:14:49 DP0 TP0] Decode batch. #running-req: 24, #token: 9778, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 399.78, #queue-req: 769, 
[1,1]<stdout>:[2025-10-12 04:14:49 DP1 TP8] Decode batch. #running-req: 23, #token: 13818, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 398.95, #queue-req: 796, 
[1,1]<stdout>:[2025-10-12 04:14:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 795, 
[1,1]<stdout>:[2025-10-12 04:14:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 794, 
[1,1]<stdout>:[2025-10-12 04:14:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 793, 
[1,0]<stdout>:[2025-10-12 04:14:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 768, 
[1,1]<stdout>:[2025-10-12 04:14:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 792, 
[1,0]<stdout>:[2025-10-12 04:14:51 DP0 TP0] Decode batch. #running-req: 24, #token: 10803, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 519.85, #queue-req: 768, 
[1,1]<stdout>:[2025-10-12 04:14:51 DP1 TP8] Decode batch. #running-req: 24, #token: 12118, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 518.75, #queue-req: 792, 
[1,1]<stdout>:[2025-10-12 04:14:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 7, token usage: 0.08, #running-req: 23, #queue-req: 791, 
[1,1]<stdout>:[2025-10-12 04:14:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 790, 
[1,1]<stdout>:[2025-10-12 04:14:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 789, 
[1,1]<stdout>:[2025-10-12 04:14:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 788, 
[1,1]<stdout>:[2025-10-12 04:14:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 787, 
[1,0]<stdout>:[2025-10-12 04:14:53 DP0 TP0] Decode batch. #running-req: 24, #token: 11763, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 526.67, #queue-req: 768, 
[1,1]<stdout>:[2025-10-12 04:14:53 DP1 TP8] Decode batch. #running-req: 24, #token: 12662, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 523.95, #queue-req: 787, 
[1,1]<stdout>:[2025-10-12 04:14:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 786, 
[1,0]<stdout>:[2025-10-12 04:14:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 767, 
[1,1]<stdout>:[2025-10-12 04:14:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 785, 
[1,0]<stdout>:[2025-10-12 04:14:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 766, 
[1,0]<stdout>:[2025-10-12 04:14:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 765, 
[1,1]<stdout>:[2025-10-12 04:14:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 784, 
[1,1]<stdout>:[2025-10-12 04:14:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 783, 
[1,0]<stdout>:[2025-10-12 04:14:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 764, 
[1,0]<stdout>:[2025-10-12 04:14:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 763, 
[1,1]<stdout>:[2025-10-12 04:14:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 782, 
[1,1]<stdout>:[2025-10-12 04:14:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 781, 
[1,0]<stdout>:[2025-10-12 04:14:55 DP0 TP0] Decode batch. #running-req: 24, #token: 9969, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 359.85, #queue-req: 763, 
[1,1]<stdout>:[2025-10-12 04:14:55 DP1 TP8] Decode batch. #running-req: 24, #token: 11128, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 359.47, #queue-req: 781, 
[1,1]<stdout>:[2025-10-12 04:14:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 780, 
[1,1]<stdout>:[2025-10-12 04:14:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 779, 
[1,1]<stdout>:[2025-10-12 04:14:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1414, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 778, 
[1,1]<stdout>:[2025-10-12 04:14:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 777, 
[1,0]<stdout>:[2025-10-12 04:14:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 762, 
[1,0]<stdout>:[2025-10-12 04:14:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 761, 
[1,1]<stdout>:[2025-10-12 04:14:57 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 879, #cached-token: 3, token usage: 0.07, #running-req: 22, #queue-req: 775, 
[1,0]<stdout>:[2025-10-12 04:14:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 760, 
[1,0]<stdout>:[2025-10-12 04:14:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 759, 
[1,1]<stdout>:[2025-10-12 04:14:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 774, 
[1,1]<stdout>:[2025-10-12 04:14:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 773, 
[1,0]<stdout>:[2025-10-12 04:14:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 758, 
[1,0]<stdout>:[2025-10-12 04:14:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1019, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 757, 
[1,0]<stdout>:[2025-10-12 04:14:58 DP0 TP0] Decode batch. #running-req: 24, #token: 11239, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 321.22, #queue-req: 757, 
[1,1]<stdout>:[2025-10-12 04:14:58 DP1 TP8] Decode batch. #running-req: 24, #token: 10756, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 320.55, #queue-req: 773, 
[1,0]<stdout>:[2025-10-12 04:14:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 756, 
[1,0]<stdout>:[2025-10-12 04:14:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 755, 
[1,1]<stdout>:[2025-10-12 04:14:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 772, 
[1,1]<stdout>:[2025-10-12 04:14:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 0, token usage: 0.09, #running-req: 23, #queue-req: 772, 
[1,1]<stdout>:[2025-10-12 04:15:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 771, 
[1,0]<stdout>:[2025-10-12 04:15:00 DP0 TP0] Decode batch. #running-req: 24, #token: 10893, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 529.63, #queue-req: 755, 
[1,1]<stdout>:[2025-10-12 04:15:00 DP1 TP8] Decode batch. #running-req: 24, #token: 14041, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 529.61, #queue-req: 771, 
[1,0]<stdout>:[2025-10-12 04:15:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 754, 
[1,0]<stdout>:[2025-10-12 04:15:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 6, token usage: 0.07, #running-req: 23, #queue-req: 753, 
[1,1]<stdout>:[2025-10-12 04:15:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 770, 
[1,1]<stdout>:[2025-10-12 04:15:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 769, 
[1,0]<stdout>:[2025-10-12 04:15:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 752, 
[1,0]<stdout>:[2025-10-12 04:15:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 751, 
[1,0]<stdout>:[2025-10-12 04:15:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 750, 
[1,0]<stdout>:[2025-10-12 04:15:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 749, 
[1,1]<stdout>:[2025-10-12 04:15:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 768, 
[1,0]<stdout>:[2025-10-12 04:15:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 748, 
[1,1]<stdout>:[2025-10-12 04:15:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 767, 
[1,0]<stdout>:[2025-10-12 04:15:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 747, 
[1,0]<stdout>:[2025-10-12 04:15:03 DP0 TP0] Decode batch. #running-req: 24, #token: 9952, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 337.01, #queue-req: 747, 
[1,1]<stdout>:[2025-10-12 04:15:03 DP1 TP8] Decode batch. #running-req: 24, #token: 11195, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 338.42, #queue-req: 767, 
[1,0]<stdout>:[2025-10-12 04:15:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 746, 
[1,1]<stdout>:[2025-10-12 04:15:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 766, 
[1,0]<stdout>:[2025-10-12 04:15:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 819, #cached-token: 8, token usage: 0.06, #running-req: 23, #queue-req: 745, 
[1,0]<stdout>:[2025-10-12 04:15:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 744, 
[1,1]<stdout>:[2025-10-12 04:15:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 765, 
[1,1]<stdout>:[2025-10-12 04:15:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 764, 
[1,1]<stdout>:[2025-10-12 04:15:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1532, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 763, 
[1,0]<stdout>:[2025-10-12 04:15:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 743, 
[1,1]<stdout>:[2025-10-12 04:15:05 DP1 TP8] Decode batch. #running-req: 24, #token: 11442, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 421.20, #queue-req: 763, 
[1,0]<stdout>:[2025-10-12 04:15:05 DP0 TP0] Decode batch. #running-req: 24, #token: 10588, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 421.16, #queue-req: 743, 
[1,0]<stdout>:[2025-10-12 04:15:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 742, 
[1,1]<stdout>:[2025-10-12 04:15:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 762, 
[1,1]<stdout>:[2025-10-12 04:15:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 761, 
[1,0]<stdout>:[2025-10-12 04:15:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 881, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 741, 
[1,0]<stdout>:[2025-10-12 04:15:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 740, 
[1,0]<stdout>:[2025-10-12 04:15:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 739, 
[1,0]<stdout>:[2025-10-12 04:15:07 DP0 TP0] Decode batch. #running-req: 24, #token: 12261, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 515.88, #queue-req: 739, 
[1,1]<stdout>:[2025-10-12 04:15:07 DP1 TP8] Decode batch. #running-req: 24, #token: 12200, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 516.92, #queue-req: 761, 
[1,0]<stdout>:[2025-10-12 04:15:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 738, 
[1,1]<stdout>:[2025-10-12 04:15:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 760, 
[1,1]<stdout>:[2025-10-12 04:15:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 759, 
[1,0]<stdout>:[2025-10-12 04:15:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 737, 
[1,0]<stdout>:[2025-10-12 04:15:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 736, 
[1,0]<stdout>:[2025-10-12 04:15:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 735, 
[1,0]<stdout>:[2025-10-12 04:15:09 DP0 TP0] Decode batch. #running-req: 23, #token: 9796, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 482.41, #queue-req: 735, 
[1,1]<stdout>:[2025-10-12 04:15:09 DP1 TP8] Decode batch. #running-req: 24, #token: 12115, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 483.92, #queue-req: 759, 
[1,0]<stdout>:[2025-10-12 04:15:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 734, 
[1,0]<stdout>:[2025-10-12 04:15:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 733, 
[1,1]<stdout>:[2025-10-12 04:15:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 758, 
[1,0]<stdout>:[2025-10-12 04:15:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 7, token usage: 0.06, #running-req: 23, #queue-req: 732, 
[1,1]<stdout>:[2025-10-12 04:15:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 757, 
[1,1]<stdout>:[2025-10-12 04:15:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 849, #cached-token: 6, token usage: 0.07, #running-req: 23, #queue-req: 756, 
[1,1]<stdout>:[2025-10-12 04:15:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 755, 
[1,0]<stdout>:[2025-10-12 04:15:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 514, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 731, 
[1,1]<stdout>:[2025-10-12 04:15:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 754, 
[1,1]<stdout>:[2025-10-12 04:15:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 753, 
[1,0]<stdout>:[2025-10-12 04:15:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 730, 
[1,1]<stdout>:[2025-10-12 04:15:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 752, 
[1,0]<stdout>:[2025-10-12 04:15:11 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 31, #cached-token: 5, token usage: 0.06, #running-req: 22, #queue-req: 728, 
[1,0]<stdout>:[2025-10-12 04:15:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 727, 
[1,0]<stdout>:[2025-10-12 04:15:12 DP0 TP0] Decode batch. #running-req: 24, #token: 10195, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 336.19, #queue-req: 727, 
[1,1]<stdout>:[2025-10-12 04:15:12 DP1 TP8] Decode batch. #running-req: 24, #token: 11392, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 336.19, #queue-req: 752, 
[1,0]<stdout>:[2025-10-12 04:15:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 726, 
[1,1]<stdout>:[2025-10-12 04:15:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 581, #cached-token: 6, token usage: 0.07, #running-req: 23, #queue-req: 751, 
[1,1]<stdout>:[2025-10-12 04:15:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 750, 
[1,0]<stdout>:[2025-10-12 04:15:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 725, 
[1,1]<stdout>:[2025-10-12 04:15:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 749, 
[1,1]<stdout>:[2025-10-12 04:15:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 571, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 748, 
[1,1]<stdout>:[2025-10-12 04:15:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 486, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 747, 
[1,1]<stdout>:[2025-10-12 04:15:14 DP1 TP8] Decode batch. #running-req: 24, #token: 12533, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 443.45, #queue-req: 747, 
[1,0]<stdout>:[2025-10-12 04:15:14 DP0 TP0] Decode batch. #running-req: 24, #token: 10942, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 444.82, #queue-req: 725, 
[1,0]<stdout>:[2025-10-12 04:15:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 724, 
[1,1]<stdout>:[2025-10-12 04:15:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 746, 
[1,1]<stdout>:[2025-10-12 04:15:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 745, 
[1,1]<stdout>:[2025-10-12 04:15:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 744, 
[1,0]<stdout>:[2025-10-12 04:15:15 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 803, #cached-token: 5, token usage: 0.07, #running-req: 22, #queue-req: 722, 
[1,0]<stdout>:[2025-10-12 04:15:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 721, 
[1,0]<stdout>:[2025-10-12 04:15:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 720, 
[1,0]<stdout>:[2025-10-12 04:15:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 479, #cached-token: 7, token usage: 0.07, #running-req: 23, #queue-req: 719, 
[1,1]<stdout>:[2025-10-12 04:15:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 743, 
[1,0]<stdout>:[2025-10-12 04:15:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 718, 
[1,1]<stdout>:[2025-10-12 04:15:16 DP1 TP8] Decode batch. #running-req: 24, #token: 11610, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 393.35, #queue-req: 743, 
[1,0]<stdout>:[2025-10-12 04:15:16 DP0 TP0] Decode batch. #running-req: 24, #token: 9663, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.12, #queue-req: 718, 
[1,0]<stdout>:[2025-10-12 04:15:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1595, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 717, 
[1,1]<stdout>:[2025-10-12 04:15:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 742, 
[1,0]<stdout>:[2025-10-12 04:15:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 716, 
[1,1]<stdout>:[2025-10-12 04:15:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 741, 
[1,1]<stdout>:[2025-10-12 04:15:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 740, 
[1,0]<stdout>:[2025-10-12 04:15:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 715, 
[1,1]<stdout>:[2025-10-12 04:15:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 739, 
[1,1]<stdout>:[2025-10-12 04:15:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 738, 
[1,0]<stdout>:[2025-10-12 04:15:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 714, 
[1,0]<stdout>:[2025-10-12 04:15:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1146, #cached-token: 0, token usage: 0.09, #running-req: 23, #queue-req: 714, 
[1,0]<stdout>:[2025-10-12 04:15:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 713, 
[1,0]<stdout>:[2025-10-12 04:15:19 DP0 TP0] Decode batch. #running-req: 24, #token: 14109, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 382.20, #queue-req: 713, 
[1,1]<stdout>:[2025-10-12 04:15:19 DP1 TP8] Decode batch. #running-req: 24, #token: 8991, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 382.22, #queue-req: 738, 
[1,0]<stdout>:[2025-10-12 04:15:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 8, token usage: 0.09, #running-req: 23, #queue-req: 712, 
[1,0]<stdout>:[2025-10-12 04:15:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 711, 
[1,1]<stdout>:[2025-10-12 04:15:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 737, 
[1,1]<stdout>:[2025-10-12 04:15:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 736, 
[1,1]<stdout>:[2025-10-12 04:15:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 735, 
[1,1]<stdout>:[2025-10-12 04:15:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 734, 
[1,1]<stdout>:[2025-10-12 04:15:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 733, 
[1,1]<stdout>:[2025-10-12 04:15:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 732, 
[1,1]<stdout>:[2025-10-12 04:15:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 731, 
[1,0]<stdout>:[2025-10-12 04:15:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 710, 
[1,0]<stdout>:[2025-10-12 04:15:21 DP0 TP0] Decode batch. #running-req: 24, #token: 14414, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.93, #queue-req: 710, 
[1,1]<stdout>:[2025-10-12 04:15:21 DP1 TP8] Decode batch. #running-req: 24, #token: 9149, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 391.28, #queue-req: 731, 
[1,0]<stdout>:[2025-10-12 04:15:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 7, token usage: 0.08, #running-req: 23, #queue-req: 709, 
[1,1]<stdout>:[2025-10-12 04:15:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 730, 
[1,1]<stdout>:[2025-10-12 04:15:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 729, 
[1,0]<stdout>:[2025-10-12 04:15:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 6, token usage: 0.09, #running-req: 23, #queue-req: 708, 
[1,1]<stdout>:[2025-10-12 04:15:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 728, 
[1,1]<stdout>:[2025-10-12 04:15:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 727, 
[1,1]<stdout>:[2025-10-12 04:15:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 726, 
[1,1]<stdout>:[2025-10-12 04:15:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 725, 
[1,0]<stdout>:[2025-10-12 04:15:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 707, 
[1,0]<stdout>:[2025-10-12 04:15:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 706, 
[1,0]<stdout>:[2025-10-12 04:15:24 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 795, #cached-token: 9, token usage: 0.08, #running-req: 22, #queue-req: 704, 
[1,1]<stdout>:[2025-10-12 04:15:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 720, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 724, 
[1,0]<stdout>:[2025-10-12 04:15:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 703, 
[1,0]<stdout>:[2025-10-12 04:15:24 DP0 TP0] Decode batch. #running-req: 23, #token: 13289, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 335.11, #queue-req: 703, 
[1,1]<stdout>:[2025-10-12 04:15:24 DP1 TP8] Decode batch. #running-req: 24, #token: 10232, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 335.44, #queue-req: 724, 
[1,0]<stdout>:[2025-10-12 04:15:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 14, token usage: 0.09, #running-req: 23, #queue-req: 702, 
[1,1]<stdout>:[2025-10-12 04:15:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1255, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 723, 
[1,1]<stdout>:[2025-10-12 04:15:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 7, token usage: 0.07, #running-req: 23, #queue-req: 722, 
[1,0]<stdout>:[2025-10-12 04:15:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 701, 
[1,0]<stdout>:[2025-10-12 04:15:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 700, 
[1,1]<stdout>:[2025-10-12 04:15:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 405, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 721, 
[1,0]<stdout>:[2025-10-12 04:15:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 699, 
[1,1]<stdout>:[2025-10-12 04:15:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 720, 
[1,1]<stdout>:[2025-10-12 04:15:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 719, 
[1,0]<stdout>:[2025-10-12 04:15:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 930, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 698, 
[1,1]<stdout>:[2025-10-12 04:15:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 718, 
[1,0]<stdout>:[2025-10-12 04:15:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 697, 
[1,0]<stdout>:[2025-10-12 04:15:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 825, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 696, 
[1,0]<stdout>:[2025-10-12 04:15:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 695, 
[1,0]<stdout>:[2025-10-12 04:15:27 DP0 TP0] Decode batch. #running-req: 23, #token: 13478, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 305.29, #queue-req: 695, 
[1,1]<stdout>:[2025-10-12 04:15:27 DP1 TP8] Decode batch. #running-req: 24, #token: 12129, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 305.93, #queue-req: 718, 
[1,0]<stdout>:[2025-10-12 04:15:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 694, 
[1,0]<stdout>:[2025-10-12 04:15:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 693, 
[1,0]<stdout>:[2025-10-12 04:15:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 692, 
[1,0]<stdout>:[2025-10-12 04:15:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 691, 
[1,0]<stdout>:[2025-10-12 04:15:28 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 1203, #cached-token: 6, token usage: 0.08, #running-req: 22, #queue-req: 689, 
[1,1]<stdout>:[2025-10-12 04:15:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1292, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 717, 
[1,0]<stdout>:[2025-10-12 04:15:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 688, 
[1,0]<stdout>:[2025-10-12 04:15:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 687, 
[1,1]<stdout>:[2025-10-12 04:15:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 716, 
[1,0]<stdout>:[2025-10-12 04:15:29 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 56, #cached-token: 5, token usage: 0.08, #running-req: 22, #queue-req: 685, 
[1,0]<stdout>:[2025-10-12 04:15:30 DP0 TP0] Decode batch. #running-req: 24, #token: 12900, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 374.10, #queue-req: 685, 
[1,1]<stdout>:[2025-10-12 04:15:30 DP1 TP8] Decode batch. #running-req: 23, #token: 12520, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 376.47, #queue-req: 716, 
[1,1]<stdout>:[2025-10-12 04:15:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 715, 
[1,0]<stdout>:[2025-10-12 04:15:30 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 1028, #cached-token: 7, token usage: 0.08, #running-req: 22, #queue-req: 683, 
[1,0]<stdout>:[2025-10-12 04:15:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 682, 
[1,0]<stdout>:[2025-10-12 04:15:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 681, 
[1,1]<stdout>:[2025-10-12 04:15:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 714, 
[1,0]<stdout>:[2025-10-12 04:15:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 680, 
[1,0]<stdout>:[2025-10-12 04:15:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 679, 
[1,1]<stdout>:[2025-10-12 04:15:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 808, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 713, 
[1,0]<stdout>:[2025-10-12 04:15:32 DP0 TP0] Decode batch. #running-req: 24, #token: 13181, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 419.15, #queue-req: 679, 
[1,1]<stdout>:[2025-10-12 04:15:32 DP1 TP8] Decode batch. #running-req: 24, #token: 13997, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 420.89, #queue-req: 713, 
[1,1]<stdout>:[2025-10-12 04:15:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 712, 
[1,1]<stdout>:[2025-10-12 04:15:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 694, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 711, 
[1,1]<stdout>:[2025-10-12 04:15:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 710, 
[1,1]<stdout>:[2025-10-12 04:15:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 709, 
[1,1]<stdout>:[2025-10-12 04:15:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 708, 
[1,0]<stdout>:[2025-10-12 04:15:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 678, 
[1,1]<stdout>:[2025-10-12 04:15:34 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 335, #cached-token: 6, token usage: 0.07, #running-req: 22, #queue-req: 706, 
[1,0]<stdout>:[2025-10-12 04:15:34 DP0 TP0] Decode batch. #running-req: 24, #token: 14186, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 446.63, #queue-req: 678, 
[1,1]<stdout>:[2025-10-12 04:15:34 DP1 TP8] Decode batch. #running-req: 24, #token: 11009, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 443.86, #queue-req: 706, 
[1,1]<stdout>:[2025-10-12 04:15:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 705, 
[1,1]<stdout>:[2025-10-12 04:15:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 704, 
[1,0]<stdout>:[2025-10-12 04:15:35 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 1242, #cached-token: 8, token usage: 0.09, #running-req: 22, #queue-req: 676, 
[1,1]<stdout>:[2025-10-12 04:15:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 703, 
[1,0]<stdout>:[2025-10-12 04:15:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 675, 
[1,1]<stdout>:[2025-10-12 04:15:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 702, 
[1,0]<stdout>:[2025-10-12 04:15:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 674, 
[1,0]<stdout>:[2025-10-12 04:15:36 DP0 TP0] Decode batch. #running-req: 24, #token: 14129, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 452.18, #queue-req: 674, 
[1,1]<stdout>:[2025-10-12 04:15:36 DP1 TP8] Decode batch. #running-req: 23, #token: 10001, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 451.65, #queue-req: 702, 
[1,1]<stdout>:[2025-10-12 04:15:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 805, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 701, 
[1,1]<stdout>:[2025-10-12 04:15:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 700, 
[1,0]<stdout>:[2025-10-12 04:15:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 673, 
[1,1]<stdout>:[2025-10-12 04:15:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 6, token usage: 0.07, #running-req: 23, #queue-req: 699, 
[1,0]<stdout>:[2025-10-12 04:15:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 672, 
[1,1]<stdout>:[2025-10-12 04:15:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 698, 
[1,0]<stdout>:[2025-10-12 04:15:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 7, token usage: 0.09, #running-req: 23, #queue-req: 671, 
[1,0]<stdout>:[2025-10-12 04:15:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 765, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 670, 
[1,1]<stdout>:[2025-10-12 04:15:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 697, 
[1,1]<stdout>:[2025-10-12 04:15:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 696, 
[1,0]<stdout>:[2025-10-12 04:15:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 669, 
[1,0]<stdout>:[2025-10-12 04:15:38 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 219, #cached-token: 6, token usage: 0.09, #running-req: 22, #queue-req: 667, 
[1,1]<stdout>:[2025-10-12 04:15:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 695, 
[1,0]<stdout>:[2025-10-12 04:15:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 666, 
[1,0]<stdout>:[2025-10-12 04:15:39 DP0 TP0] Decode batch. #running-req: 24, #token: 14117, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 321.07, #queue-req: 666, 
[1,1]<stdout>:[2025-10-12 04:15:39 DP1 TP8] Decode batch. #running-req: 24, #token: 11330, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 321.75, #queue-req: 695, 
[1,1]<stdout>:[2025-10-12 04:15:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 694, 
[1,1]<stdout>:[2025-10-12 04:15:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 693, 
[1,0]<stdout>:[2025-10-12 04:15:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 665, 
[1,1]<stdout>:[2025-10-12 04:15:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 692, 
[1,1]<stdout>:[2025-10-12 04:15:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 691, 
[1,0]<stdout>:[2025-10-12 04:15:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 664, 
[1,1]<stdout>:[2025-10-12 04:15:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 690, 
[1,0]<stdout>:[2025-10-12 04:15:41 DP0 TP0] Decode batch. #running-req: 24, #token: 13343, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 450.39, #queue-req: 664, 
[1,1]<stdout>:[2025-10-12 04:15:41 DP1 TP8] Decode batch. #running-req: 24, #token: 11034, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.05, #queue-req: 690, 
[1,0]<stdout>:[2025-10-12 04:15:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 663, 
[1,0]<stdout>:[2025-10-12 04:15:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 662, 
[1,0]<stdout>:[2025-10-12 04:15:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 661, 
[1,0]<stdout>:[2025-10-12 04:15:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 660, 
[1,0]<stdout>:[2025-10-12 04:15:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 659, 
[1,0]<stdout>:[2025-10-12 04:15:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 794, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 658, 
[1,1]<stdout>:[2025-10-12 04:15:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 689, 
[1,1]<stdout>:[2025-10-12 04:15:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 6, token usage: 0.07, #running-req: 23, #queue-req: 688, 
[1,1]<stdout>:[2025-10-12 04:15:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 687, 
[1,1]<stdout>:[2025-10-12 04:15:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 686, 
[1,0]<stdout>:[2025-10-12 04:15:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 657, 
[1,0]<stdout>:[2025-10-12 04:15:44 DP0 TP0] Decode batch. #running-req: 24, #token: 12390, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 351.97, #queue-req: 657, 
[1,1]<stdout>:[2025-10-12 04:15:44 DP1 TP8] Decode batch. #running-req: 24, #token: 10838, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 353.07, #queue-req: 686, 
[1,0]<stdout>:[2025-10-12 04:15:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 656, 
[1,0]<stdout>:[2025-10-12 04:15:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 655, 
[1,0]<stdout>:[2025-10-12 04:15:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 654, 
[1,1]<stdout>:[2025-10-12 04:15:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 685, 
[1,0]<stdout>:[2025-10-12 04:15:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 653, 
[1,0]<stdout>:[2025-10-12 04:15:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 652, 
[1,1]<stdout>:[2025-10-12 04:15:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 885, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 684, 
[1,1]<stdout>:[2025-10-12 04:15:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 683, 
[1,0]<stdout>:[2025-10-12 04:15:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 651, 
[1,1]<stdout>:[2025-10-12 04:15:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 682, 
[1,0]<stdout>:[2025-10-12 04:15:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 650, 
[1,0]<stdout>:[2025-10-12 04:15:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 754, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 649, 
[1,1]<stdout>:[2025-10-12 04:15:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 681, 
[1,1]<stdout>:[2025-10-12 04:15:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 680, 
[1,1]<stdout>:[2025-10-12 04:15:47 DP1 TP8] Decode batch. #running-req: 24, #token: 9267, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 321.48, #queue-req: 680, 
[1,0]<stdout>:[2025-10-12 04:15:47 DP0 TP0] Decode batch. #running-req: 24, #token: 13276, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 320.81, #queue-req: 649, 
[1,0]<stdout>:[2025-10-12 04:15:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 648, 
[1,0]<stdout>:[2025-10-12 04:15:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 647, 
[1,1]<stdout>:[2025-10-12 04:15:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 679, 
[1,0]<stdout>:[2025-10-12 04:15:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 788, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 646, 
[1,1]<stdout>:[2025-10-12 04:15:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 678, 
[1,1]<stdout>:[2025-10-12 04:15:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 677, 
[1,0]<stdout>:[2025-10-12 04:15:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 645, 
[1,0]<stdout>:[2025-10-12 04:15:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 644, 
[1,1]<stdout>:[2025-10-12 04:15:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 676, 
[1,0]<stdout>:[2025-10-12 04:15:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 643, 
[1,1]<stdout>:[2025-10-12 04:15:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 675, 
[1,1]<stdout>:[2025-10-12 04:15:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 674, 
[1,0]<stdout>:[2025-10-12 04:15:50 DP0 TP0] Decode batch. #running-req: 23, #token: 11879, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 354.60, #queue-req: 643, 
[1,1]<stdout>:[2025-10-12 04:15:50 DP1 TP8] Decode batch. #running-req: 24, #token: 10020, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 354.96, #queue-req: 674, 
[1,0]<stdout>:[2025-10-12 04:15:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 642, 
[1,0]<stdout>:[2025-10-12 04:15:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 641, 
[1,1]<stdout>:[2025-10-12 04:15:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 673, 
[1,1]<stdout>:[2025-10-12 04:15:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 672, 
[1,0]<stdout>:[2025-10-12 04:15:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 694, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 640, 
[1,0]<stdout>:[2025-10-12 04:15:51 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 397, #cached-token: 3, token usage: 0.08, #running-req: 22, #queue-req: 638, 
[1,0]<stdout>:[2025-10-12 04:15:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 862, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 637, 
[1,0]<stdout>:[2025-10-12 04:15:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 636, 
[1,1]<stdout>:[2025-10-12 04:15:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 671, 
[1,0]<stdout>:[2025-10-12 04:15:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 635, 
[1,0]<stdout>:[2025-10-12 04:15:52 DP0 TP0] Decode batch. #running-req: 24, #token: 12166, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.23, #queue-req: 635, 
[1,1]<stdout>:[2025-10-12 04:15:52 DP1 TP8] Decode batch. #running-req: 23, #token: 10354, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 393.46, #queue-req: 671, 
[1,1]<stdout>:[2025-10-12 04:15:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 670, 
[1,0]<stdout>:[2025-10-12 04:15:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 634, 
[1,0]<stdout>:[2025-10-12 04:15:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 633, 
[1,0]<stdout>:[2025-10-12 04:15:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.09, #running-req: 23, #queue-req: 633, 
[1,0]<stdout>:[2025-10-12 04:15:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.10, #running-req: 23, #queue-req: 633, 
[1,0]<stdout>:[2025-10-12 04:15:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 0, token usage: 0.12, #running-req: 23, #queue-req: 633, 
[1,1]<stdout>:[2025-10-12 04:15:53 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 270, #cached-token: 10, token usage: 0.07, #running-req: 22, #queue-req: 668, 
[1,1]<stdout>:[2025-10-12 04:15:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 7, token usage: 0.06, #running-req: 23, #queue-req: 667, 
[1,1]<stdout>:[2025-10-12 04:15:54 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 722, #cached-token: 6, token usage: 0.06, #running-req: 22, #queue-req: 665, 
[1,1]<stdout>:[2025-10-12 04:15:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 664, 
[1,0]<stdout>:[2025-10-12 04:15:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 632, 
[1,0]<stdout>:[2025-10-12 04:15:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 631, 
[1,0]<stdout>:[2025-10-12 04:15:55 DP0 TP0] Decode batch. #running-req: 24, #token: 19062, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 336.39, #queue-req: 631, 
[1,1]<stdout>:[2025-10-12 04:15:55 DP1 TP8] Decode batch. #running-req: 24, #token: 10612, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 335.70, #queue-req: 664, 
[1,0]<stdout>:[2025-10-12 04:15:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 630, 
[1,0]<stdout>:[2025-10-12 04:15:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 629, 
[1,0]<stdout>:[2025-10-12 04:15:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 628, 
[1,1]<stdout>:[2025-10-12 04:15:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 663, 
[1,1]<stdout>:[2025-10-12 04:15:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 662, 
[1,0]<stdout>:[2025-10-12 04:15:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1966, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 627, 
[1,1]<stdout>:[2025-10-12 04:15:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 661, 
[1,0]<stdout>:[2025-10-12 04:15:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 626, 
[1,0]<stdout>:[2025-10-12 04:15:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 625, 
[1,1]<stdout>:[2025-10-12 04:15:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 407, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 660, 
[1,0]<stdout>:[2025-10-12 04:15:57 DP0 TP0] Decode batch. #running-req: 24, #token: 16741, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.38, #queue-req: 625, 
[1,1]<stdout>:[2025-10-12 04:15:57 DP1 TP8] Decode batch. #running-req: 23, #token: 10814, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.77, #queue-req: 660, 
[1,1]<stdout>:[2025-10-12 04:15:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 353, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 659, 
[1,1]<stdout>:[2025-10-12 04:15:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 658, 
[1,1]<stdout>:[2025-10-12 04:15:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 657, 
[1,0]<stdout>:[2025-10-12 04:15:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 624, 
[1,0]<stdout>:[2025-10-12 04:15:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 6, token usage: 0.11, #running-req: 23, #queue-req: 623, 
[1,1]<stdout>:[2025-10-12 04:15:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 656, 
[1,0]<stdout>:[2025-10-12 04:15:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 622, 
[1,1]<stdout>:[2025-10-12 04:15:59 DP1 TP8] Prefill batch. #new-seq: 3, #new-token: 1185, #cached-token: 5, token usage: 0.05, #running-req: 21, #queue-req: 653, 
[1,0]<stdout>:[2025-10-12 04:15:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 621, 
[1,1]<stdout>:[2025-10-12 04:15:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 652, 
[1,0]<stdout>:[2025-10-12 04:15:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 0, token usage: 0.12, #running-req: 23, #queue-req: 621, 
[1,1]<stdout>:[2025-10-12 04:15:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1021, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 651, 
[1,0]<stdout>:[2025-10-12 04:16:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1012, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 620, 
[1,1]<stdout>:[2025-10-12 04:16:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 650, 
[1,1]<stdout>:[2025-10-12 04:16:00 DP1 TP8] Decode batch. #running-req: 23, #token: 10061, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 344.53, #queue-req: 650, 
[1,0]<stdout>:[2025-10-12 04:16:00 DP0 TP0] Decode batch. #running-req: 24, #token: 19976, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 346.32, #queue-req: 620, 
[1,1]<stdout>:[2025-10-12 04:16:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 649, 
[1,0]<stdout>:[2025-10-12 04:16:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.13, #running-req: 23, #queue-req: 619, 
[1,1]<stdout>:[2025-10-12 04:16:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 648, 
[1,0]<stdout>:[2025-10-12 04:16:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.13, #running-req: 23, #queue-req: 618, 
[1,1]<stdout>:[2025-10-12 04:16:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 647, 
[1,0]<stdout>:[2025-10-12 04:16:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 617, 
[1,1]<stdout>:[2025-10-12 04:16:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 646, 
[1,0]<stdout>:[2025-10-12 04:16:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 616, 
[1,1]<stdout>:[2025-10-12 04:16:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1386, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 645, 
[1,0]<stdout>:[2025-10-12 04:16:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 4, token usage: 0.12, #running-req: 23, #queue-req: 615, 
[1,1]<stdout>:[2025-10-12 04:16:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 644, 
[1,0]<stdout>:[2025-10-12 04:16:03 DP0 TP0] Decode batch. #running-req: 24, #token: 19414, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 391.29, #queue-req: 615, 
[1,1]<stdout>:[2025-10-12 04:16:03 DP1 TP8] Decode batch. #running-req: 24, #token: 11094, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 391.29, #queue-req: 644, 
[1,0]<stdout>:[2025-10-12 04:16:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 2, token usage: 0.12, #running-req: 23, #queue-req: 614, 
[1,0]<stdout>:[2025-10-12 04:16:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 2, token usage: 0.12, #running-req: 23, #queue-req: 613, 
[1,0]<stdout>:[2025-10-12 04:16:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 391, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 612, 
[1,0]<stdout>:[2025-10-12 04:16:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.13, #running-req: 23, #queue-req: 611, 
[1,0]<stdout>:[2025-10-12 04:16:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.13, #running-req: 23, #queue-req: 610, 
[1,0]<stdout>:[2025-10-12 04:16:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 2, token usage: 0.12, #running-req: 23, #queue-req: 609, 
[1,0]<stdout>:[2025-10-12 04:16:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.13, #running-req: 23, #queue-req: 608, 
[1,1]<stdout>:[2025-10-12 04:16:05 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 733, #cached-token: 7, token usage: 0.07, #running-req: 22, #queue-req: 642, 
[1,0]<stdout>:[2025-10-12 04:16:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.12, #running-req: 23, #queue-req: 607, 
[1,0]<stdout>:[2025-10-12 04:16:05 DP0 TP0] Decode batch. #running-req: 24, #token: 18546, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 390.09, #queue-req: 607, 
[1,1]<stdout>:[2025-10-12 04:16:05 DP1 TP8] Decode batch. #running-req: 24, #token: 12244, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.54, #queue-req: 642, 
[1,0]<stdout>:[2025-10-12 04:16:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 606, 
[1,1]<stdout>:[2025-10-12 04:16:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 641, 
[1,0]<stdout>:[2025-10-12 04:16:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 605, 
[1,0]<stdout>:[2025-10-12 04:16:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 604, 
[1,1]<stdout>:[2025-10-12 04:16:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 640, 
[1,0]<stdout>:[2025-10-12 04:16:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 772, #cached-token: 2, token usage: 0.12, #running-req: 23, #queue-req: 603, 
[1,0]<stdout>:[2025-10-12 04:16:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 602, 
[1,0]<stdout>:[2025-10-12 04:16:07 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 357, #cached-token: 4, token usage: 0.12, #running-req: 22, #queue-req: 600, 
[1,1]<stdout>:[2025-10-12 04:16:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 639, 
[1,1]<stdout>:[2025-10-12 04:16:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 638, 
[1,0]<stdout>:[2025-10-12 04:16:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 599, 
[1,1]<stdout>:[2025-10-12 04:16:08 DP1 TP8] Decode batch. #running-req: 24, #token: 12888, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 351.13, #queue-req: 638, 
[1,0]<stdout>:[2025-10-12 04:16:08 DP0 TP0] Decode batch. #running-req: 24, #token: 18173, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 349.65, #queue-req: 599, 
[1,0]<stdout>:[2025-10-12 04:16:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 8, token usage: 0.11, #running-req: 23, #queue-req: 598, 
[1,0]<stdout>:[2025-10-12 04:16:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 597, 
[1,1]<stdout>:[2025-10-12 04:16:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 637, 
[1,1]<stdout>:[2025-10-12 04:16:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 636, 
[1,0]<stdout>:[2025-10-12 04:16:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 596, 
[1,0]<stdout>:[2025-10-12 04:16:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1119, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 595, 
[1,0]<stdout>:[2025-10-12 04:16:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.12, #running-req: 23, #queue-req: 594, 
[1,1]<stdout>:[2025-10-12 04:16:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 635, 
[1,0]<stdout>:[2025-10-12 04:16:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 593, 
[1,1]<stdout>:[2025-10-12 04:16:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 634, 
[1,1]<stdout>:[2025-10-12 04:16:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 633, 
[1,0]<stdout>:[2025-10-12 04:16:11 DP0 TP0] Decode batch. #running-req: 24, #token: 19380, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 347.56, #queue-req: 593, 
[1,1]<stdout>:[2025-10-12 04:16:11 DP1 TP8] Decode batch. #running-req: 24, #token: 13091, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 347.91, #queue-req: 633, 
[1,1]<stdout>:[2025-10-12 04:16:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 371, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 632, 
[1,1]<stdout>:[2025-10-12 04:16:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 631, 
[1,0]<stdout>:[2025-10-12 04:16:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1538, #cached-token: 1, token usage: 0.13, #running-req: 23, #queue-req: 592, 
[1,1]<stdout>:[2025-10-12 04:16:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 630, 
[1,1]<stdout>:[2025-10-12 04:16:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 629, 
[1,1]<stdout>:[2025-10-12 04:16:12 DP1 TP8] Decode batch. #running-req: 24, #token: 13875, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 519.88, #queue-req: 629, 
[1,0]<stdout>:[2025-10-12 04:16:12 DP0 TP0] Decode batch. #running-req: 24, #token: 21473, token usage: 0.14, accept len: 1.00, cuda graph: True, gen throughput (token/s): 521.47, #queue-req: 592, 
[1,0]<stdout>:[2025-10-12 04:16:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 11, token usage: 0.14, #running-req: 23, #queue-req: 591, 
[1,1]<stdout>:[2025-10-12 04:16:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 628, 
[1,0]<stdout>:[2025-10-12 04:16:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.14, #running-req: 23, #queue-req: 590, 
[1,0]<stdout>:[2025-10-12 04:16:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1474, #cached-token: 1, token usage: 0.14, #running-req: 23, #queue-req: 589, 
[1,1]<stdout>:[2025-10-12 04:16:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 627, 
[1,0]<stdout>:[2025-10-12 04:16:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 8, token usage: 0.13, #running-req: 23, #queue-req: 588, 
[1,1]<stdout>:[2025-10-12 04:16:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 749, #cached-token: 6, token usage: 0.09, #running-req: 23, #queue-req: 626, 
[1,1]<stdout>:[2025-10-12 04:16:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 781, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 625, 
[1,1]<stdout>:[2025-10-12 04:16:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 624, 
[1,0]<stdout>:[2025-10-12 04:16:15 DP0 TP0] Decode batch. #running-req: 24, #token: 20804, token usage: 0.14, accept len: 1.00, cuda graph: True, gen throughput (token/s): 412.92, #queue-req: 588, 
[1,1]<stdout>:[2025-10-12 04:16:15 DP1 TP8] Decode batch. #running-req: 24, #token: 13905, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 412.49, #queue-req: 624, 
[1,0]<stdout>:[2025-10-12 04:16:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.14, #running-req: 23, #queue-req: 587, 
[1,1]<stdout>:[2025-10-12 04:16:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 623, 
[1,0]<stdout>:[2025-10-12 04:16:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.13, #running-req: 23, #queue-req: 586, 
[1,1]<stdout>:[2025-10-12 04:16:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 622, 
[1,1]<stdout>:[2025-10-12 04:16:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 621, 
[1,1]<stdout>:[2025-10-12 04:16:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 620, 
[1,1]<stdout>:[2025-10-12 04:16:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 619, 
[1,0]<stdout>:[2025-10-12 04:16:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.13, #running-req: 23, #queue-req: 585, 
[1,1]<stdout>:[2025-10-12 04:16:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 618, 
[1,0]<stdout>:[2025-10-12 04:16:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.13, #running-req: 23, #queue-req: 584, 
[1,1]<stdout>:[2025-10-12 04:16:17 DP1 TP8] Decode batch. #running-req: 24, #token: 12539, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 389.80, #queue-req: 618, 
[1,0]<stdout>:[2025-10-12 04:16:17 DP0 TP0] Decode batch. #running-req: 24, #token: 19267, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 390.60, #queue-req: 584, 
[1,0]<stdout>:[2025-10-12 04:16:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 691, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 583, 
[1,0]<stdout>:[2025-10-12 04:16:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 582, 
[1,1]<stdout>:[2025-10-12 04:16:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 617, 
[1,0]<stdout>:[2025-10-12 04:16:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 581, 
[1,1]<stdout>:[2025-10-12 04:16:18 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 314, #cached-token: 2, token usage: 0.08, #running-req: 22, #queue-req: 615, 
[1,1]<stdout>:[2025-10-12 04:16:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 614, 
[1,1]<stdout>:[2025-10-12 04:16:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 820, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 613, 
[1,0]<stdout>:[2025-10-12 04:16:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 580, 
[1,0]<stdout>:[2025-10-12 04:16:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 0, token usage: 0.11, #running-req: 23, #queue-req: 580, 
[1,1]<stdout>:[2025-10-12 04:16:20 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 1904, #cached-token: 10, token usage: 0.07, #running-req: 22, #queue-req: 611, 
[1,1]<stdout>:[2025-10-12 04:16:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 610, 
[1,0]<stdout>:[2025-10-12 04:16:20 DP0 TP0] Decode batch. #running-req: 24, #token: 16242, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 348.10, #queue-req: 580, 
[1,1]<stdout>:[2025-10-12 04:16:20 DP1 TP8] Decode batch. #running-req: 24, #token: 12288, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 346.65, #queue-req: 610, 
[1,0]<stdout>:[2025-10-12 04:16:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 579, 
[1,0]<stdout>:[2025-10-12 04:16:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 578, 
[1,1]<stdout>:[2025-10-12 04:16:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 609, 
[1,0]<stdout>:[2025-10-12 04:16:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 8, token usage: 0.10, #running-req: 23, #queue-req: 577, 
[1,0]<stdout>:[2025-10-12 04:16:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 576, 
[1,1]<stdout>:[2025-10-12 04:16:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 608, 
[1,1]<stdout>:[2025-10-12 04:16:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 607, 
[1,1]<stdout>:[2025-10-12 04:16:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 606, 
[1,0]<stdout>:[2025-10-12 04:16:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 575, 
[1,0]<stdout>:[2025-10-12 04:16:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 10, token usage: 0.11, #running-req: 23, #queue-req: 574, 
[1,0]<stdout>:[2025-10-12 04:16:23 DP0 TP0] Decode batch. #running-req: 24, #token: 16793, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 370.98, #queue-req: 574, 
[1,1]<stdout>:[2025-10-12 04:16:23 DP1 TP8] Decode batch. #running-req: 24, #token: 11253, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 371.73, #queue-req: 606, 
[1,1]<stdout>:[2025-10-12 04:16:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2044, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 605, 
[1,0]<stdout>:[2025-10-12 04:16:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1734, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 573, 
[1,0]<stdout>:[2025-10-12 04:16:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 6, token usage: 0.11, #running-req: 23, #queue-req: 572, 
[1,0]<stdout>:[2025-10-12 04:16:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 571, 
[1,1]<stdout>:[2025-10-12 04:16:23 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 651, #cached-token: 6, token usage: 0.08, #running-req: 22, #queue-req: 603, 
[1,1]<stdout>:[2025-10-12 04:16:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 8, token usage: 0.08, #running-req: 23, #queue-req: 602, 
[1,1]<stdout>:[2025-10-12 04:16:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 737, #cached-token: 7, token usage: 0.08, #running-req: 23, #queue-req: 601, 
[1,0]<stdout>:[2025-10-12 04:16:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 570, 
[1,1]<stdout>:[2025-10-12 04:16:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 600, 
[1,0]<stdout>:[2025-10-12 04:16:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 569, 
[1,1]<stdout>:[2025-10-12 04:16:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 7, token usage: 0.08, #running-req: 23, #queue-req: 599, 
[1,0]<stdout>:[2025-10-12 04:16:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 3, token usage: 0.11, #running-req: 23, #queue-req: 568, 
[1,1]<stdout>:[2025-10-12 04:16:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 598, 
[1,0]<stdout>:[2025-10-12 04:16:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 567, 
[1,0]<stdout>:[2025-10-12 04:16:25 DP0 TP0] Decode batch. #running-req: 24, #token: 17716, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 347.26, #queue-req: 567, 
[1,1]<stdout>:[2025-10-12 04:16:25 DP1 TP8] Decode batch. #running-req: 24, #token: 12489, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 346.91, #queue-req: 598, 
[1,1]<stdout>:[2025-10-12 04:16:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 597, 
[1,1]<stdout>:[2025-10-12 04:16:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 596, 
[1,0]<stdout>:[2025-10-12 04:16:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 566, 
[1,0]<stdout>:[2025-10-12 04:16:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 565, 
[1,1]<stdout>:[2025-10-12 04:16:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 595, 
[1,0]<stdout>:[2025-10-12 04:16:27 DP0 TP0] Decode batch. #running-req: 24, #token: 18048, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 520.27, #queue-req: 565, 
[1,1]<stdout>:[2025-10-12 04:16:27 DP1 TP8] Decode batch. #running-req: 24, #token: 13202, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 519.68, #queue-req: 595, 
[1,1]<stdout>:[2025-10-12 04:16:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 594, 
[1,1]<stdout>:[2025-10-12 04:16:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 593, 
[1,0]<stdout>:[2025-10-12 04:16:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 4, token usage: 0.12, #running-req: 23, #queue-req: 564, 
[1,0]<stdout>:[2025-10-12 04:16:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 563, 
[1,0]<stdout>:[2025-10-12 04:16:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 3, token usage: 0.11, #running-req: 23, #queue-req: 562, 
[1,1]<stdout>:[2025-10-12 04:16:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 592, 
[1,1]<stdout>:[2025-10-12 04:16:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 591, 
[1,0]<stdout>:[2025-10-12 04:16:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 561, 
[1,1]<stdout>:[2025-10-12 04:16:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 590, 
[1,1]<stdout>:[2025-10-12 04:16:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 589, 
[1,0]<stdout>:[2025-10-12 04:16:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 560, 
[1,1]<stdout>:[2025-10-12 04:16:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 588, 
[1,1]<stdout>:[2025-10-12 04:16:30 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 138, #cached-token: 3, token usage: 0.06, #running-req: 22, #queue-req: 586, 
[1,0]<stdout>:[2025-10-12 04:16:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 559, 
[1,0]<stdout>:[2025-10-12 04:16:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 558, 
[1,0]<stdout>:[2025-10-12 04:16:30 DP0 TP0] Decode batch. #running-req: 24, #token: 13607, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 293.99, #queue-req: 558, 
[1,1]<stdout>:[2025-10-12 04:16:30 DP1 TP8] Decode batch. #running-req: 24, #token: 10368, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 293.39, #queue-req: 586, 
[1,0]<stdout>:[2025-10-12 04:16:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 557, 
[1,0]<stdout>:[2025-10-12 04:16:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 556, 
[1,1]<stdout>:[2025-10-12 04:16:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 585, 
[1,0]<stdout>:[2025-10-12 04:16:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 555, 
[1,0]<stdout>:[2025-10-12 04:16:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 554, 
[1,1]<stdout>:[2025-10-12 04:16:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 584, 
[1,0]<stdout>:[2025-10-12 04:16:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 553, 
[1,0]<stdout>:[2025-10-12 04:16:32 DP0 TP0] Decode batch. #running-req: 24, #token: 13684, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 450.71, #queue-req: 553, 
[1,1]<stdout>:[2025-10-12 04:16:32 DP1 TP8] Decode batch. #running-req: 24, #token: 11127, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 452.14, #queue-req: 584, 
[1,1]<stdout>:[2025-10-12 04:16:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 583, 
[1,0]<stdout>:[2025-10-12 04:16:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 552, 
[1,1]<stdout>:[2025-10-12 04:16:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 582, 
[1,1]<stdout>:[2025-10-12 04:16:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 581, 
[1,1]<stdout>:[2025-10-12 04:16:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 580, 
[1,1]<stdout>:[2025-10-12 04:16:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 579, 
[1,1]<stdout>:[2025-10-12 04:16:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 578, 
[1,0]<stdout>:[2025-10-12 04:16:35 DP0 TP0] Decode batch. #running-req: 24, #token: 14220, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 454.60, #queue-req: 552, 
[1,1]<stdout>:[2025-10-12 04:16:35 DP1 TP8] Decode batch. #running-req: 24, #token: 9769, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 452.20, #queue-req: 578, 
[1,1]<stdout>:[2025-10-12 04:16:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 844, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 577, 
[1,0]<stdout>:[2025-10-12 04:16:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 551, 
[1,1]<stdout>:[2025-10-12 04:16:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 576, 
[1,1]<stdout>:[2025-10-12 04:16:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 313, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 575, 
[1,1]<stdout>:[2025-10-12 04:16:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 574, 
[1,0]<stdout>:[2025-10-12 04:16:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 550, 
[1,1]<stdout>:[2025-10-12 04:16:36 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 107, #cached-token: 6, token usage: 0.06, #running-req: 22, #queue-req: 572, 
[1,1]<stdout>:[2025-10-12 04:16:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 571, 
[1,1]<stdout>:[2025-10-12 04:16:37 DP1 TP8] Decode batch. #running-req: 23, #token: 7938, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 423.02, #queue-req: 571, 
[1,0]<stdout>:[2025-10-12 04:16:37 DP0 TP0] Decode batch. #running-req: 24, #token: 12634, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 425.67, #queue-req: 550, 
[1,1]<stdout>:[2025-10-12 04:16:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 570, 
[1,0]<stdout>:[2025-10-12 04:16:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 549, 
[1,0]<stdout>:[2025-10-12 04:16:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 548, 
[1,0]<stdout>:[2025-10-12 04:16:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 547, 
[1,1]<stdout>:[2025-10-12 04:16:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 569, 
[1,1]<stdout>:[2025-10-12 04:16:38 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 1208, #cached-token: 4, token usage: 0.05, #running-req: 22, #queue-req: 567, 
[1,1]<stdout>:[2025-10-12 04:16:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 566, 
[1,1]<stdout>:[2025-10-12 04:16:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 565, 
[1,1]<stdout>:[2025-10-12 04:16:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 564, 
[1,0]<stdout>:[2025-10-12 04:16:39 DP0 TP0] Decode batch. #running-req: 24, #token: 9657, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 401.67, #queue-req: 547, 
[1,1]<stdout>:[2025-10-12 04:16:39 DP1 TP8] Decode batch. #running-req: 24, #token: 6699, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 400.41, #queue-req: 564, 
[1,1]<stdout>:[2025-10-12 04:16:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 563, 
[1,0]<stdout>:[2025-10-12 04:16:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 546, 
[1,0]<stdout>:[2025-10-12 04:16:40 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 348, #cached-token: 17, token usage: 0.06, #running-req: 22, #queue-req: 544, 
[1,1]<stdout>:[2025-10-12 04:16:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 562, 
[1,1]<stdout>:[2025-10-12 04:16:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 561, 
[1,0]<stdout>:[2025-10-12 04:16:41 DP0 TP0] Decode batch. #running-req: 24, #token: 10185, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 562.48, #queue-req: 544, 
[1,1]<stdout>:[2025-10-12 04:16:41 DP1 TP8] Decode batch. #running-req: 24, #token: 7269, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 562.49, #queue-req: 561, 
[1,0]<stdout>:[2025-10-12 04:16:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 543, 
[1,1]<stdout>:[2025-10-12 04:16:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 560, 
[1,0]<stdout>:[2025-10-12 04:16:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 542, 
[1,0]<stdout>:[2025-10-12 04:16:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 541, 
[1,0]<stdout>:[2025-10-12 04:16:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 10, token usage: 0.06, #running-req: 23, #queue-req: 540, 
[1,1]<stdout>:[2025-10-12 04:16:42 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 253, #cached-token: 5, token usage: 0.05, #running-req: 22, #queue-req: 558, 
[1,0]<stdout>:[2025-10-12 04:16:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 539, 
[1,1]<stdout>:[2025-10-12 04:16:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 563, #cached-token: 7, token usage: 0.05, #running-req: 23, #queue-req: 557, 
[1,1]<stdout>:[2025-10-12 04:16:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 986, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 556, 
[1,1]<stdout>:[2025-10-12 04:16:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 739, #cached-token: 7, token usage: 0.06, #running-req: 23, #queue-req: 555, 
[1,0]<stdout>:[2025-10-12 04:16:43 DP0 TP0] Decode batch. #running-req: 23, #token: 9421, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 376.22, #queue-req: 539, 
[1,1]<stdout>:[2025-10-12 04:16:43 DP1 TP8] Decode batch. #running-req: 24, #token: 9532, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 376.23, #queue-req: 555, 
[1,0]<stdout>:[2025-10-12 04:16:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 538, 
[1,1]<stdout>:[2025-10-12 04:16:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 554, 
[1,0]<stdout>:[2025-10-12 04:16:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 537, 
[1,1]<stdout>:[2025-10-12 04:16:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 553, 
[1,0]<stdout>:[2025-10-12 04:16:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1427, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 536, 
[1,1]<stdout>:[2025-10-12 04:16:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 552, 
[1,0]<stdout>:[2025-10-12 04:16:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 535, 
[1,0]<stdout>:[2025-10-12 04:16:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 534, 
[1,1]<stdout>:[2025-10-12 04:16:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 551, 
[1,0]<stdout>:[2025-10-12 04:16:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 533, 
[1,0]<stdout>:[2025-10-12 04:16:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 532, 
[1,0]<stdout>:[2025-10-12 04:16:46 DP0 TP0] Decode batch. #running-req: 24, #token: 11413, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 365.97, #queue-req: 532, 
[1,1]<stdout>:[2025-10-12 04:16:46 DP1 TP8] Decode batch. #running-req: 24, #token: 8831, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 366.73, #queue-req: 551, 
[1,0]<stdout>:[2025-10-12 04:16:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 531, 
[1,1]<stdout>:[2025-10-12 04:16:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 550, 
[1,0]<stdout>:[2025-10-12 04:16:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 530, 
[1,1]<stdout>:[2025-10-12 04:16:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 549, 
[1,0]<stdout>:[2025-10-12 04:16:48 DP0 TP0] Decode batch. #running-req: 24, #token: 12039, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 563.26, #queue-req: 530, 
[1,1]<stdout>:[2025-10-12 04:16:48 DP1 TP8] Decode batch. #running-req: 24, #token: 8803, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 563.26, #queue-req: 549, 
[1,0]<stdout>:[2025-10-12 04:16:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 529, 
[1,0]<stdout>:[2025-10-12 04:16:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 528, 
[1,0]<stdout>:[2025-10-12 04:16:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 527, 
[1,1]<stdout>:[2025-10-12 04:16:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 548, 
[1,0]<stdout>:[2025-10-12 04:16:49 DP0 TP0] Decode batch. #running-req: 24, #token: 11998, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 567.24, #queue-req: 527, 
[1,1]<stdout>:[2025-10-12 04:16:49 DP1 TP8] Decode batch. #running-req: 24, #token: 9275, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 568.43, #queue-req: 548, 
[1,1]<stdout>:[2025-10-12 04:16:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 376, token usage: 0.06, #running-req: 23, #queue-req: 547, 
[1,1]<stdout>:[2025-10-12 04:16:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 546, 
[1,1]<stdout>:[2025-10-12 04:16:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1399, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 545, 
[1,0]<stdout>:[2025-10-12 04:16:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 526, 
[1,1]<stdout>:[2025-10-12 04:16:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 544, 
[1,0]<stdout>:[2025-10-12 04:16:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 829, #cached-token: 10, token usage: 0.08, #running-req: 23, #queue-req: 525, 
[1,1]<stdout>:[2025-10-12 04:16:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 543, 
[1,0]<stdout>:[2025-10-12 04:16:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 524, 
[1,1]<stdout>:[2025-10-12 04:16:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 8, token usage: 0.06, #running-req: 23, #queue-req: 542, 
[1,0]<stdout>:[2025-10-12 04:16:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 523, 
[1,0]<stdout>:[2025-10-12 04:16:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 522, 
[1,0]<stdout>:[2025-10-12 04:16:52 DP0 TP0] Decode batch. #running-req: 24, #token: 11696, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 352.94, #queue-req: 522, 
[1,1]<stdout>:[2025-10-12 04:16:52 DP1 TP8] Decode batch. #running-req: 23, #token: 10175, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 352.20, #queue-req: 542, 
[1,1]<stdout>:[2025-10-12 04:16:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 541, 
[1,1]<stdout>:[2025-10-12 04:16:52 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 500, #cached-token: 5, token usage: 0.06, #running-req: 22, #queue-req: 539, 
[1,0]<stdout>:[2025-10-12 04:16:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 521, 
[1,1]<stdout>:[2025-10-12 04:16:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 538, 
[1,0]<stdout>:[2025-10-12 04:16:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 520, 
[1,1]<stdout>:[2025-10-12 04:16:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 537, 
[1,1]<stdout>:[2025-10-12 04:16:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 536, 
[1,0]<stdout>:[2025-10-12 04:16:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 519, 
[1,1]<stdout>:[2025-10-12 04:16:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 535, 
[1,0]<stdout>:[2025-10-12 04:16:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 518, 
[1,1]<stdout>:[2025-10-12 04:16:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 534, 
[1,0]<stdout>:[2025-10-12 04:16:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 684, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 517, 
[1,0]<stdout>:[2025-10-12 04:16:55 DP0 TP0] Decode batch. #running-req: 24, #token: 12380, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 353.34, #queue-req: 517, 
[1,1]<stdout>:[2025-10-12 04:16:55 DP1 TP8] Decode batch. #running-req: 24, #token: 11301, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 352.60, #queue-req: 534, 
[1,0]<stdout>:[2025-10-12 04:16:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 516, 
[1,0]<stdout>:[2025-10-12 04:16:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.07, #running-req: 23, #queue-req: 515, 
[1,0]<stdout>:[2025-10-12 04:16:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 514, 
[1,0]<stdout>:[2025-10-12 04:16:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 513, 
[1,0]<stdout>:[2025-10-12 04:16:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1167, #cached-token: 0, token usage: 0.08, #running-req: 23, #queue-req: 513, 
[1,1]<stdout>:[2025-10-12 04:16:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 533, 
[1,0]<stdout>:[2025-10-12 04:16:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 512, 
[1,1]<stdout>:[2025-10-12 04:16:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 451, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 532, 
[1,1]<stdout>:[2025-10-12 04:16:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 531, 
[1,1]<stdout>:[2025-10-12 04:16:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 530, 
[1,1]<stdout>:[2025-10-12 04:16:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 529, 
[1,0]<stdout>:[2025-10-12 04:16:58 DP0 TP0] Decode batch. #running-req: 24, #token: 14118, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.75, #queue-req: 512, 
[1,1]<stdout>:[2025-10-12 04:16:58 DP1 TP8] Decode batch. #running-req: 24, #token: 11393, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.75, #queue-req: 529, 
[1,0]<stdout>:[2025-10-12 04:16:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 511, 
[1,0]<stdout>:[2025-10-12 04:16:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 510, 
[1,0]<stdout>:[2025-10-12 04:16:58 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 391, #cached-token: 3, token usage: 0.09, #running-req: 22, #queue-req: 508, 
[1,1]<stdout>:[2025-10-12 04:16:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 528, 
[1,0]<stdout>:[2025-10-12 04:16:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 507, 
[1,1]<stdout>:[2025-10-12 04:16:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 527, 
[1,0]<stdout>:[2025-10-12 04:16:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 506, 
[1,1]<stdout>:[2025-10-12 04:16:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 9, token usage: 0.07, #running-req: 23, #queue-req: 526, 
[1,0]<stdout>:[2025-10-12 04:16:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 505, 
[1,0]<stdout>:[2025-10-12 04:17:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1951, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 504, 
[1,1]<stdout>:[2025-10-12 04:17:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 525, 
[1,1]<stdout>:[2025-10-12 04:17:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 524, 
[1,0]<stdout>:[2025-10-12 04:17:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 503, 
[1,0]<stdout>:[2025-10-12 04:17:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 5, token usage: 0.10, #running-req: 23, #queue-req: 502, 
[1,0]<stdout>:[2025-10-12 04:17:01 DP0 TP0] Decode batch. #running-req: 24, #token: 15636, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 316.74, #queue-req: 502, 
[1,1]<stdout>:[2025-10-12 04:17:01 DP1 TP8] Decode batch. #running-req: 24, #token: 11844, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 318.40, #queue-req: 524, 
[1,0]<stdout>:[2025-10-12 04:17:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 501, 
[1,0]<stdout>:[2025-10-12 04:17:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 500, 
[1,0]<stdout>:[2025-10-12 04:17:01 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 46, #cached-token: 3, token usage: 0.09, #running-req: 22, #queue-req: 498, 
[1,0]<stdout>:[2025-10-12 04:17:01 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 2048, #cached-token: 5, token usage: 0.09, #running-req: 22, #queue-req: 496, 
[1,0]<stdout>:[2025-10-12 04:17:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 0, token usage: 0.10, #running-req: 23, #queue-req: 496, 
[1,1]<stdout>:[2025-10-12 04:17:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 386, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 523, 
[1,0]<stdout>:[2025-10-12 04:17:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 495, 
[1,1]<stdout>:[2025-10-12 04:17:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 522, 
[1,0]<stdout>:[2025-10-12 04:17:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 494, 
[1,1]<stdout>:[2025-10-12 04:17:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 521, 
[1,1]<stdout>:[2025-10-12 04:17:03 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 315, #cached-token: 3, token usage: 0.07, #running-req: 22, #queue-req: 519, 
[1,0]<stdout>:[2025-10-12 04:17:03 DP0 TP0] Decode batch. #running-req: 24, #token: 14632, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 353.61, #queue-req: 494, 
[1,1]<stdout>:[2025-10-12 04:17:03 DP1 TP8] Decode batch. #running-req: 23, #token: 10421, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 354.36, #queue-req: 519, 
[1,1]<stdout>:[2025-10-12 04:17:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 518, 
[1,0]<stdout>:[2025-10-12 04:17:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 493, 
[1,1]<stdout>:[2025-10-12 04:17:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 517, 
[1,1]<stdout>:[2025-10-12 04:17:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 516, 
[1,1]<stdout>:[2025-10-12 04:17:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 515, 
[1,1]<stdout>:[2025-10-12 04:17:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 514, 
[1,1]<stdout>:[2025-10-12 04:17:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 513, 
[1,0]<stdout>:[2025-10-12 04:17:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 492, 
[1,0]<stdout>:[2025-10-12 04:17:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 491, 
[1,1]<stdout>:[2025-10-12 04:17:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 512, 
[1,1]<stdout>:[2025-10-12 04:17:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 511, 
[1,0]<stdout>:[2025-10-12 04:17:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 490, 
[1,0]<stdout>:[2025-10-12 04:17:06 DP0 TP0] Decode batch. #running-req: 24, #token: 13305, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 386.11, #queue-req: 490, 
[1,1]<stdout>:[2025-10-12 04:17:06 DP1 TP8] Decode batch. #running-req: 24, #token: 11961, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 384.89, #queue-req: 511, 
[1,1]<stdout>:[2025-10-12 04:17:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 510, 
[1,1]<stdout>:[2025-10-12 04:17:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1016, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 509, 
[1,1]<stdout>:[2025-10-12 04:17:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 508, 
[1,1]<stdout>:[2025-10-12 04:17:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 507, 
[1,0]<stdout>:[2025-10-12 04:17:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 489, 
[1,0]<stdout>:[2025-10-12 04:17:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 488, 
[1,0]<stdout>:[2025-10-12 04:17:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 487, 
[1,1]<stdout>:[2025-10-12 04:17:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 506, 
[1,1]<stdout>:[2025-10-12 04:17:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 505, 
[1,0]<stdout>:[2025-10-12 04:17:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 486, 
[1,0]<stdout>:[2025-10-12 04:17:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 485, 
[1,0]<stdout>:[2025-10-12 04:17:08 DP0 TP0] Decode batch. #running-req: 24, #token: 13805, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 353.86, #queue-req: 485, 
[1,1]<stdout>:[2025-10-12 04:17:08 DP1 TP8] Decode batch. #running-req: 24, #token: 13223, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 353.49, #queue-req: 505, 
[1,0]<stdout>:[2025-10-12 04:17:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 484, 
[1,1]<stdout>:[2025-10-12 04:17:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 504, 
[1,0]<stdout>:[2025-10-12 04:17:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 483, 
[1,0]<stdout>:[2025-10-12 04:17:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 482, 
[1,0]<stdout>:[2025-10-12 04:17:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2032, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 481, 
[1,0]<stdout>:[2025-10-12 04:17:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 619, #cached-token: 8, token usage: 0.10, #running-req: 23, #queue-req: 480, 
[1,0]<stdout>:[2025-10-12 04:17:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1101, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 479, 
[1,1]<stdout>:[2025-10-12 04:17:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 503, 
[1,1]<stdout>:[2025-10-12 04:17:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 502, 
[1,0]<stdout>:[2025-10-12 04:17:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 478, 
[1,0]<stdout>:[2025-10-12 04:17:11 DP0 TP0] Decode batch. #running-req: 24, #token: 15897, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 414.49, #queue-req: 478, 
[1,1]<stdout>:[2025-10-12 04:17:11 DP1 TP8] Decode batch. #running-req: 24, #token: 13316, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 416.23, #queue-req: 502, 
[1,1]<stdout>:[2025-10-12 04:17:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 501, 
[1,1]<stdout>:[2025-10-12 04:17:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 500, 
[1,0]<stdout>:[2025-10-12 04:17:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 477, 
[1,0]<stdout>:[2025-10-12 04:17:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 476, 
[1,1]<stdout>:[2025-10-12 04:17:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 779, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 499, 
[1,1]<stdout>:[2025-10-12 04:17:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 498, 
[1,0]<stdout>:[2025-10-12 04:17:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 475, 
[1,1]<stdout>:[2025-10-12 04:17:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 793, #cached-token: 7, token usage: 0.08, #running-req: 23, #queue-req: 497, 
[1,0]<stdout>:[2025-10-12 04:17:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 474, 
[1,0]<stdout>:[2025-10-12 04:17:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 473, 
[1,1]<stdout>:[2025-10-12 04:17:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 496, 
[1,1]<stdout>:[2025-10-12 04:17:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 495, 
[1,0]<stdout>:[2025-10-12 04:17:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 472, 
[1,1]<stdout>:[2025-10-12 04:17:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 494, 
[1,0]<stdout>:[2025-10-12 04:17:14 DP0 TP0] Decode batch. #running-req: 23, #token: 17603, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 316.31, #queue-req: 472, 
[1,1]<stdout>:[2025-10-12 04:17:14 DP1 TP8] Decode batch. #running-req: 24, #token: 11270, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 315.98, #queue-req: 494, 
[1,0]<stdout>:[2025-10-12 04:17:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 471, 
[1,0]<stdout>:[2025-10-12 04:17:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 470, 
[1,0]<stdout>:[2025-10-12 04:17:14 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 573, #cached-token: 3, token usage: 0.11, #running-req: 22, #queue-req: 468, 
[1,0]<stdout>:[2025-10-12 04:17:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1117, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 467, 
[1,1]<stdout>:[2025-10-12 04:17:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 493, 
[1,1]<stdout>:[2025-10-12 04:17:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 492, 
[1,1]<stdout>:[2025-10-12 04:17:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 661, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 491, 
[1,1]<stdout>:[2025-10-12 04:17:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 490, 
[1,0]<stdout>:[2025-10-12 04:17:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.12, #running-req: 23, #queue-req: 466, 
[1,0]<stdout>:[2025-10-12 04:17:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 465, 
[1,1]<stdout>:[2025-10-12 04:17:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 489, 
[1,1]<stdout>:[2025-10-12 04:17:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 488, 
[1,1]<stdout>:[2025-10-12 04:17:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 0, token usage: 0.09, #running-req: 23, #queue-req: 488, 
[1,0]<stdout>:[2025-10-12 04:17:17 DP0 TP0] Decode batch. #running-req: 24, #token: 19175, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 336.35, #queue-req: 465, 
[1,1]<stdout>:[2025-10-12 04:17:17 DP1 TP8] Decode batch. #running-req: 24, #token: 14560, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 336.36, #queue-req: 488, 
[1,1]<stdout>:[2025-10-12 04:17:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 480, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 487, 
[1,1]<stdout>:[2025-10-12 04:17:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 8, token usage: 0.09, #running-req: 23, #queue-req: 486, 
[1,0]<stdout>:[2025-10-12 04:17:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 464, 
[1,0]<stdout>:[2025-10-12 04:17:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.12, #running-req: 23, #queue-req: 463, 
[1,0]<stdout>:[2025-10-12 04:17:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1335, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 462, 
[1,1]<stdout>:[2025-10-12 04:17:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 313, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 485, 
[1,1]<stdout>:[2025-10-12 04:17:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 552, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 484, 
[1,0]<stdout>:[2025-10-12 04:17:19 DP0 TP0] Decode batch. #running-req: 24, #token: 19362, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.63, #queue-req: 462, 
[1,1]<stdout>:[2025-10-12 04:17:19 DP1 TP8] Decode batch. #running-req: 24, #token: 14513, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.16, #queue-req: 484, 
[1,0]<stdout>:[2025-10-12 04:17:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 2, token usage: 0.13, #running-req: 23, #queue-req: 461, 
[1,1]<stdout>:[2025-10-12 04:17:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 483, 
[1,0]<stdout>:[2025-10-12 04:17:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.13, #running-req: 23, #queue-req: 460, 
[1,0]<stdout>:[2025-10-12 04:17:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 459, 
[1,1]<stdout>:[2025-10-12 04:17:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 482, 
[1,0]<stdout>:[2025-10-12 04:17:20 DP0 TP0] Decode batch. #running-req: 24, #token: 20051, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 557.77, #queue-req: 459, 
[1,1]<stdout>:[2025-10-12 04:17:20 DP1 TP8] Decode batch. #running-req: 24, #token: 14369, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 558.29, #queue-req: 482, 
[1,1]<stdout>:[2025-10-12 04:17:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 481, 
[1,0]<stdout>:[2025-10-12 04:17:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1558, #cached-token: 3, token usage: 0.13, #running-req: 23, #queue-req: 458, 
[1,0]<stdout>:[2025-10-12 04:17:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 5, token usage: 0.14, #running-req: 23, #queue-req: 457, 
[1,0]<stdout>:[2025-10-12 04:17:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.14, #running-req: 23, #queue-req: 456, 
[1,0]<stdout>:[2025-10-12 04:17:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 455, 
[1,0]<stdout>:[2025-10-12 04:17:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 454, 
[1,0]<stdout>:[2025-10-12 04:17:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 453, 
[1,0]<stdout>:[2025-10-12 04:17:22 DP0 TP0] Decode batch. #running-req: 24, #token: 17637, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.23, #queue-req: 453, 
[1,1]<stdout>:[2025-10-12 04:17:22 DP1 TP8] Decode batch. #running-req: 24, #token: 15672, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 451.62, #queue-req: 481, 
[1,0]<stdout>:[2025-10-12 04:17:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 452, 
[1,1]<stdout>:[2025-10-12 04:17:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 480, 
[1,0]<stdout>:[2025-10-12 04:17:23 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 1005, #cached-token: 9, token usage: 0.10, #running-req: 22, #queue-req: 450, 
[1,1]<stdout>:[2025-10-12 04:17:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 479, 
[1,0]<stdout>:[2025-10-12 04:17:23 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 353, #cached-token: 3, token usage: 0.10, #running-req: 22, #queue-req: 448, 
[1,0]<stdout>:[2025-10-12 04:17:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 447, 
[1,0]<stdout>:[2025-10-12 04:17:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 567, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 446, 
[1,0]<stdout>:[2025-10-12 04:17:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 8, token usage: 0.10, #running-req: 23, #queue-req: 445, 
[1,1]<stdout>:[2025-10-12 04:17:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 478, 
[1,0]<stdout>:[2025-10-12 04:17:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 444, 
[1,0]<stdout>:[2025-10-12 04:17:25 DP0 TP0] Decode batch. #running-req: 24, #token: 15812, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 371.33, #queue-req: 444, 
[1,1]<stdout>:[2025-10-12 04:17:25 DP1 TP8] Decode batch. #running-req: 24, #token: 14842, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 373.67, #queue-req: 478, 
[1,0]<stdout>:[2025-10-12 04:17:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 443, 
[1,0]<stdout>:[2025-10-12 04:17:25 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 420, #cached-token: 4, token usage: 0.09, #running-req: 22, #queue-req: 441, 
[1,0]<stdout>:[2025-10-12 04:17:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 6, token usage: 0.09, #running-req: 23, #queue-req: 440, 
[1,0]<stdout>:[2025-10-12 04:17:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 439, 
[1,1]<stdout>:[2025-10-12 04:17:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 477, 
[1,1]<stdout>:[2025-10-12 04:17:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 474, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 476, 
[1,0]<stdout>:[2025-10-12 04:17:27 DP0 TP0] Decode batch. #running-req: 24, #token: 12822, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 518.86, #queue-req: 439, 
[1,1]<stdout>:[2025-10-12 04:17:27 DP1 TP8] Decode batch. #running-req: 24, #token: 12858, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 520.48, #queue-req: 476, 
[1,0]<stdout>:[2025-10-12 04:17:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 438, 
[1,1]<stdout>:[2025-10-12 04:17:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 475, 
[1,0]<stdout>:[2025-10-12 04:17:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 437, 
[1,0]<stdout>:[2025-10-12 04:17:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 436, 
[1,0]<stdout>:[2025-10-12 04:17:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 435, 
[1,1]<stdout>:[2025-10-12 04:17:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1424, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 474, 
[1,0]<stdout>:[2025-10-12 04:17:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 434, 
[1,1]<stdout>:[2025-10-12 04:17:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 473, 
[1,1]<stdout>:[2025-10-12 04:17:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 472, 
[1,0]<stdout>:[2025-10-12 04:17:29 DP0 TP0] Decode batch. #running-req: 24, #token: 12285, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 444.79, #queue-req: 434, 
[1,1]<stdout>:[2025-10-12 04:17:29 DP1 TP8] Decode batch. #running-req: 24, #token: 12650, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 445.26, #queue-req: 472, 
[1,1]<stdout>:[2025-10-12 04:17:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 19, token usage: 0.08, #running-req: 23, #queue-req: 471, 
[1,0]<stdout>:[2025-10-12 04:17:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 433, 
[1,1]<stdout>:[2025-10-12 04:17:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 470, 
[1,1]<stdout>:[2025-10-12 04:17:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 469, 
[1,0]<stdout>:[2025-10-12 04:17:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 432, 
[1,1]<stdout>:[2025-10-12 04:17:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 468, 
[1,1]<stdout>:[2025-10-12 04:17:31 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 804, #cached-token: 4, token usage: 0.07, #running-req: 22, #queue-req: 466, 
[1,1]<stdout>:[2025-10-12 04:17:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 417, #cached-token: 7, token usage: 0.07, #running-req: 23, #queue-req: 465, 
[1,1]<stdout>:[2025-10-12 04:17:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 464, 
[1,0]<stdout>:[2025-10-12 04:17:31 DP0 TP0] Decode batch. #running-req: 24, #token: 10909, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 398.70, #queue-req: 432, 
[1,1]<stdout>:[2025-10-12 04:17:31 DP1 TP8] Decode batch. #running-req: 24, #token: 10908, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 396.23, #queue-req: 464, 
[1,0]<stdout>:[2025-10-12 04:17:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 431, 
[1,1]<stdout>:[2025-10-12 04:17:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 463, 
[1,1]<stdout>:[2025-10-12 04:17:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 462, 
[1,0]<stdout>:[2025-10-12 04:17:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 430, 
[1,1]<stdout>:[2025-10-12 04:17:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 461, 
[1,0]<stdout>:[2025-10-12 04:17:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 429, 
[1,0]<stdout>:[2025-10-12 04:17:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 428, 
[1,1]<stdout>:[2025-10-12 04:17:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 460, 
[1,1]<stdout>:[2025-10-12 04:17:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1779, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 459, 
[1,0]<stdout>:[2025-10-12 04:17:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 427, 
[1,0]<stdout>:[2025-10-12 04:17:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 426, 
[1,1]<stdout>:[2025-10-12 04:17:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 458, 
[1,0]<stdout>:[2025-10-12 04:17:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 425, 
[1,0]<stdout>:[2025-10-12 04:17:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 424, 
[1,0]<stdout>:[2025-10-12 04:17:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 423, 
[1,0]<stdout>:[2025-10-12 04:17:35 DP0 TP0] Decode batch. #running-req: 24, #token: 9488, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 292.76, #queue-req: 423, 
[1,1]<stdout>:[2025-10-12 04:17:35 DP1 TP8] Decode batch. #running-req: 24, #token: 12956, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 293.69, #queue-req: 458, 
[1,0]<stdout>:[2025-10-12 04:17:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 674, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 422, 
[1,0]<stdout>:[2025-10-12 04:17:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 421, 
[1,0]<stdout>:[2025-10-12 04:17:35 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 627, #cached-token: 3, token usage: 0.06, #running-req: 22, #queue-req: 419, 
[1,0]<stdout>:[2025-10-12 04:17:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 418, 
[1,1]<stdout>:[2025-10-12 04:17:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 812, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 457, 
[1,1]<stdout>:[2025-10-12 04:17:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 456, 
[1,1]<stdout>:[2025-10-12 04:17:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1361, #cached-token: 0, token usage: 0.10, #running-req: 23, #queue-req: 456, 
[1,1]<stdout>:[2025-10-12 04:17:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 455, 
[1,0]<stdout>:[2025-10-12 04:17:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 8, token usage: 0.06, #running-req: 23, #queue-req: 417, 
[1,1]<stdout>:[2025-10-12 04:17:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 727, #cached-token: 3, token usage: 0.11, #running-req: 23, #queue-req: 454, 
[1,1]<stdout>:[2025-10-12 04:17:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 453, 
[1,0]<stdout>:[2025-10-12 04:17:37 DP0 TP0] Decode batch. #running-req: 24, #token: 10318, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.03, #queue-req: 417, 
[1,1]<stdout>:[2025-10-12 04:17:37 DP1 TP8] Decode batch. #running-req: 23, #token: 16401, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.01, #queue-req: 453, 
[1,1]<stdout>:[2025-10-12 04:17:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 452, 
[1,0]<stdout>:[2025-10-12 04:17:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 416, 
[1,1]<stdout>:[2025-10-12 04:17:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 451, 
[1,0]<stdout>:[2025-10-12 04:17:38 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 292, #cached-token: 2, token usage: 0.05, #running-req: 22, #queue-req: 414, 
[1,0]<stdout>:[2025-10-12 04:17:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 413, 
[1,1]<stdout>:[2025-10-12 04:17:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 450, 
[1,1]<stdout>:[2025-10-12 04:17:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 449, 
[1,0]<stdout>:[2025-10-12 04:17:39 DP0 TP0] Decode batch. #running-req: 23, #token: 7741, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 484.17, #queue-req: 413, 
[1,1]<stdout>:[2025-10-12 04:17:39 DP1 TP8] Decode batch. #running-req: 24, #token: 16082, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 485.15, #queue-req: 449, 
[1,0]<stdout>:[2025-10-12 04:17:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 412, 
[1,1]<stdout>:[2025-10-12 04:17:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 448, 
[1,1]<stdout>:[2025-10-12 04:17:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 447, 
[1,0]<stdout>:[2025-10-12 04:17:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 411, 
[1,1]<stdout>:[2025-10-12 04:17:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 446, 
[1,0]<stdout>:[2025-10-12 04:17:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 840, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 410, 
[1,1]<stdout>:[2025-10-12 04:17:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 445, 
[1,0]<stdout>:[2025-10-12 04:17:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 409, 
[1,0]<stdout>:[2025-10-12 04:17:42 DP0 TP0] Decode batch. #running-req: 24, #token: 9188, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 423.25, #queue-req: 409, 
[1,1]<stdout>:[2025-10-12 04:17:42 DP1 TP8] Decode batch. #running-req: 24, #token: 14916, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 422.83, #queue-req: 445, 
[1,0]<stdout>:[2025-10-12 04:17:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 408, 
[1,1]<stdout>:[2025-10-12 04:17:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 444, 
[1,1]<stdout>:[2025-10-12 04:17:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 443, 
[1,0]<stdout>:[2025-10-12 04:17:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 407, 
[1,1]<stdout>:[2025-10-12 04:17:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 691, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 442, 
[1,0]<stdout>:[2025-10-12 04:17:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 406, 
[1,1]<stdout>:[2025-10-12 04:17:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 6, token usage: 0.09, #running-req: 23, #queue-req: 441, 
[1,0]<stdout>:[2025-10-12 04:17:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 405, 
[1,0]<stdout>:[2025-10-12 04:17:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 404, 
[1,1]<stdout>:[2025-10-12 04:17:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 440, 
[1,0]<stdout>:[2025-10-12 04:17:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 403, 
[1,0]<stdout>:[2025-10-12 04:17:44 DP0 TP0] Decode batch. #running-req: 24, #token: 9278, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 375.09, #queue-req: 403, 
[1,1]<stdout>:[2025-10-12 04:17:44 DP1 TP8] Decode batch. #running-req: 24, #token: 14770, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 375.47, #queue-req: 440, 
[1,0]<stdout>:[2025-10-12 04:17:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 402, 
[1,0]<stdout>:[2025-10-12 04:17:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 401, 
[1,1]<stdout>:[2025-10-12 04:17:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 439, 
[1,0]<stdout>:[2025-10-12 04:17:45 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 641, #cached-token: 3, token usage: 0.05, #running-req: 22, #queue-req: 399, 
[1,1]<stdout>:[2025-10-12 04:17:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1080, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 438, 
[1,0]<stdout>:[2025-10-12 04:17:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 462, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 398, 
[1,1]<stdout>:[2025-10-12 04:17:46 DP1 TP8] Decode batch. #running-req: 24, #token: 14602, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 484.33, #queue-req: 438, 
[1,0]<stdout>:[2025-10-12 04:17:46 DP0 TP0] Decode batch. #running-req: 24, #token: 8556, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 482.77, #queue-req: 398, 
[1,0]<stdout>:[2025-10-12 04:17:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 397, 
[1,0]<stdout>:[2025-10-12 04:17:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 396, 
[1,0]<stdout>:[2025-10-12 04:17:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 395, 
[1,0]<stdout>:[2025-10-12 04:17:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 394, 
[1,0]<stdout>:[2025-10-12 04:17:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 393, 
[1,1]<stdout>:[2025-10-12 04:17:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 437, 
[1,0]<stdout>:[2025-10-12 04:17:48 DP0 TP0] Decode batch. #running-req: 24, #token: 8531, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 480.26, #queue-req: 393, 
[1,1]<stdout>:[2025-10-12 04:17:48 DP1 TP8] Decode batch. #running-req: 24, #token: 14778, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 482.25, #queue-req: 437, 
[1,0]<stdout>:[2025-10-12 04:17:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 392, 
[1,1]<stdout>:[2025-10-12 04:17:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 436, 
[1,1]<stdout>:[2025-10-12 04:17:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1444, #cached-token: 0, token usage: 0.11, #running-req: 23, #queue-req: 436, 
[1,1]<stdout>:[2025-10-12 04:17:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 3, token usage: 0.11, #running-req: 23, #queue-req: 435, 
[1,0]<stdout>:[2025-10-12 04:17:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 391, 
[1,0]<stdout>:[2025-10-12 04:17:50 DP0 TP0] Decode batch. #running-req: 23, #token: 8394, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 516.47, #queue-req: 391, 
[1,1]<stdout>:[2025-10-12 04:17:50 DP1 TP8] Decode batch. #running-req: 24, #token: 17522, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 517.02, #queue-req: 435, 
[1,0]<stdout>:[2025-10-12 04:17:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 390, 
[1,0]<stdout>:[2025-10-12 04:17:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 389, 
[1,1]<stdout>:[2025-10-12 04:17:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 434, 
[1,0]<stdout>:[2025-10-12 04:17:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 388, 
[1,1]<stdout>:[2025-10-12 04:17:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 433, 
[1,0]<stdout>:[2025-10-12 04:17:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 387, 
[1,1]<stdout>:[2025-10-12 04:17:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 432, 
[1,0]<stdout>:[2025-10-12 04:17:52 DP0 TP0] Decode batch. #running-req: 23, #token: 8971, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 448.37, #queue-req: 387, 
[1,1]<stdout>:[2025-10-12 04:17:52 DP1 TP8] Decode batch. #running-req: 24, #token: 16480, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 448.82, #queue-req: 432, 
[1,0]<stdout>:[2025-10-12 04:17:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 386, 
[1,0]<stdout>:[2025-10-12 04:17:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 385, 
[1,0]<stdout>:[2025-10-12 04:17:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 384, 
[1,0]<stdout>:[2025-10-12 04:17:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 8, token usage: 0.06, #running-req: 23, #queue-req: 383, 
[1,1]<stdout>:[2025-10-12 04:17:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 424, #cached-token: 9, token usage: 0.11, #running-req: 23, #queue-req: 431, 
[1,0]<stdout>:[2025-10-12 04:17:54 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 63, #cached-token: 3, token usage: 0.06, #running-req: 22, #queue-req: 381, 
[1,0]<stdout>:[2025-10-12 04:17:54 DP0 TP0] Decode batch. #running-req: 24, #token: 9521, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 474.71, #queue-req: 381, 
[1,1]<stdout>:[2025-10-12 04:17:54 DP1 TP8] Decode batch. #running-req: 24, #token: 17568, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 476.67, #queue-req: 431, 
[1,0]<stdout>:[2025-10-12 04:17:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 380, 
[1,1]<stdout>:[2025-10-12 04:17:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 430, 
[1,1]<stdout>:[2025-10-12 04:17:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 429, 
[1,1]<stdout>:[2025-10-12 04:17:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 5, token usage: 0.11, #running-req: 23, #queue-req: 428, 
[1,1]<stdout>:[2025-10-12 04:17:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 427, 
[1,1]<stdout>:[2025-10-12 04:17:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 426, 
[1,1]<stdout>:[2025-10-12 04:17:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 425, 
[1,0]<stdout>:[2025-10-12 04:17:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 379, 
[1,1]<stdout>:[2025-10-12 04:17:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 424, 
[1,0]<stdout>:[2025-10-12 04:17:56 DP0 TP0] Decode batch. #running-req: 24, #token: 10120, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 412.50, #queue-req: 379, 
[1,1]<stdout>:[2025-10-12 04:17:56 DP1 TP8] Decode batch. #running-req: 24, #token: 17032, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 410.36, #queue-req: 424, 
[1,1]<stdout>:[2025-10-12 04:17:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 423, 
[1,1]<stdout>:[2025-10-12 04:17:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 422, 
[1,1]<stdout>:[2025-10-12 04:17:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 3, token usage: 0.11, #running-req: 23, #queue-req: 421, 
[1,0]<stdout>:[2025-10-12 04:17:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 378, 
[1,0]<stdout>:[2025-10-12 04:17:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 377, 
[1,0]<stdout>:[2025-10-12 04:17:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 376, 
[1,1]<stdout>:[2025-10-12 04:17:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 871, #cached-token: 7, token usage: 0.11, #running-req: 23, #queue-req: 420, 
[1,1]<stdout>:[2025-10-12 04:17:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 419, 
[1,1]<stdout>:[2025-10-12 04:17:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 418, 
[1,1]<stdout>:[2025-10-12 04:17:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 984, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 417, 
[1,1]<stdout>:[2025-10-12 04:17:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 416, 
[1,0]<stdout>:[2025-10-12 04:17:59 DP0 TP0] Decode batch. #running-req: 24, #token: 9307, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 368.83, #queue-req: 376, 
[1,1]<stdout>:[2025-10-12 04:17:59 DP1 TP8] Decode batch. #running-req: 24, #token: 17223, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 366.91, #queue-req: 416, 
[1,0]<stdout>:[2025-10-12 04:17:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 651, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 375, 
[1,0]<stdout>:[2025-10-12 04:17:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 655, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 374, 
[1,1]<stdout>:[2025-10-12 04:17:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 415, 
[1,0]<stdout>:[2025-10-12 04:18:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 373, 
[1,0]<stdout>:[2025-10-12 04:18:00 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 532, #cached-token: 6, token usage: 0.05, #running-req: 22, #queue-req: 371, 
[1,0]<stdout>:[2025-10-12 04:18:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 456, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 370, 
[1,1]<stdout>:[2025-10-12 04:18:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 414, 
[1,0]<stdout>:[2025-10-12 04:18:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 369, 
[1,1]<stdout>:[2025-10-12 04:18:01 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 66, #cached-token: 4, token usage: 0.11, #running-req: 22, #queue-req: 412, 
[1,0]<stdout>:[2025-10-12 04:18:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 368, 
[1,0]<stdout>:[2025-10-12 04:18:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 367, 
[1,0]<stdout>:[2025-10-12 04:18:02 DP0 TP0] Decode batch. #running-req: 24, #token: 8162, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 372.48, #queue-req: 367, 
[1,1]<stdout>:[2025-10-12 04:18:02 DP1 TP8] Decode batch. #running-req: 24, #token: 17165, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 374.44, #queue-req: 412, 
[1,1]<stdout>:[2025-10-12 04:18:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.11, #running-req: 23, #queue-req: 411, 
[1,0]<stdout>:[2025-10-12 04:18:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1156, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 366, 
[1,0]<stdout>:[2025-10-12 04:18:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 365, 
[1,1]<stdout>:[2025-10-12 04:18:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 410, 
[1,0]<stdout>:[2025-10-12 04:18:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 364, 
[1,0]<stdout>:[2025-10-12 04:18:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 689, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 363, 
[1,0]<stdout>:[2025-10-12 04:18:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 362, 
[1,0]<stdout>:[2025-10-12 04:18:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 361, 
[1,1]<stdout>:[2025-10-12 04:18:04 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 842, #cached-token: 4, token usage: 0.10, #running-req: 22, #queue-req: 408, 
[1,1]<stdout>:[2025-10-12 04:18:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 798, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 407, 
[1,0]<stdout>:[2025-10-12 04:18:04 DP0 TP0] Decode batch. #running-req: 24, #token: 9989, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 373.65, #queue-req: 361, 
[1,1]<stdout>:[2025-10-12 04:18:04 DP1 TP8] Decode batch. #running-req: 24, #token: 16633, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 374.05, #queue-req: 407, 
[1,0]<stdout>:[2025-10-12 04:18:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 360, 
[1,1]<stdout>:[2025-10-12 04:18:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 793, #cached-token: 5, token usage: 0.11, #running-req: 23, #queue-req: 406, 
[1,1]<stdout>:[2025-10-12 04:18:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 405, 
[1,1]<stdout>:[2025-10-12 04:18:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 404, 
[1,0]<stdout>:[2025-10-12 04:18:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 359, 
[1,1]<stdout>:[2025-10-12 04:18:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 403, 
[1,1]<stdout>:[2025-10-12 04:18:06 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 933, #cached-token: 14, token usage: 0.10, #running-req: 22, #queue-req: 401, 
[1,1]<stdout>:[2025-10-12 04:18:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 804, #cached-token: 5, token usage: 0.10, #running-req: 23, #queue-req: 400, 
[1,1]<stdout>:[2025-10-12 04:18:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 8, token usage: 0.10, #running-req: 23, #queue-req: 399, 
[1,0]<stdout>:[2025-10-12 04:18:07 DP0 TP0] Decode batch. #running-req: 23, #token: 8659, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 398.43, #queue-req: 359, 
[1,1]<stdout>:[2025-10-12 04:18:07 DP1 TP8] Decode batch. #running-req: 24, #token: 16470, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 396.33, #queue-req: 399, 
[1,0]<stdout>:[2025-10-12 04:18:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 387, #cached-token: 12, token usage: 0.06, #running-req: 23, #queue-req: 358, 
[1,0]<stdout>:[2025-10-12 04:18:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 357, 
[1,1]<stdout>:[2025-10-12 04:18:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 398, 
[1,0]<stdout>:[2025-10-12 04:18:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 356, 
[1,0]<stdout>:[2025-10-12 04:18:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 355, 
[1,1]<stdout>:[2025-10-12 04:18:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 397, 
[1,0]<stdout>:[2025-10-12 04:18:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 354, 
[1,0]<stdout>:[2025-10-12 04:18:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 353, 
[1,1]<stdout>:[2025-10-12 04:18:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 396, 
[1,1]<stdout>:[2025-10-12 04:18:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 395, 
[1,1]<stdout>:[2025-10-12 04:18:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 394, 
[1,0]<stdout>:[2025-10-12 04:18:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 352, 
[1,1]<stdout>:[2025-10-12 04:18:09 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 988, #cached-token: 5, token usage: 0.10, #running-req: 22, #queue-req: 392, 
[1,0]<stdout>:[2025-10-12 04:18:09 DP0 TP0] Decode batch. #running-req: 24, #token: 8890, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 339.26, #queue-req: 352, 
[1,1]<stdout>:[2025-10-12 04:18:09 DP1 TP8] Decode batch. #running-req: 23, #token: 15986, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 338.55, #queue-req: 392, 
[1,1]<stdout>:[2025-10-12 04:18:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 538, #cached-token: 5, token usage: 0.10, #running-req: 23, #queue-req: 391, 
[1,1]<stdout>:[2025-10-12 04:18:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 390, 
[1,0]<stdout>:[2025-10-12 04:18:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 351, 
[1,1]<stdout>:[2025-10-12 04:18:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 389, 
[1,0]<stdout>:[2025-10-12 04:18:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 350, 
[1,1]<stdout>:[2025-10-12 04:18:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 388, 
[1,0]<stdout>:[2025-10-12 04:18:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 349, 
[1,0]<stdout>:[2025-10-12 04:18:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 348, 
[1,1]<stdout>:[2025-10-12 04:18:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 387, 
[1,1]<stdout>:[2025-10-12 04:18:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 640, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 386, 
[1,0]<stdout>:[2025-10-12 04:18:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1543, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 347, 
[1,0]<stdout>:[2025-10-12 04:18:12 DP0 TP0] Decode batch. #running-req: 23, #token: 9633, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 357.50, #queue-req: 347, 
[1,1]<stdout>:[2025-10-12 04:18:12 DP1 TP8] Decode batch. #running-req: 24, #token: 16832, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 357.86, #queue-req: 386, 
[1,0]<stdout>:[2025-10-12 04:18:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 346, 
[1,0]<stdout>:[2025-10-12 04:18:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.08, #running-req: 23, #queue-req: 346, 
[1,0]<stdout>:[2025-10-12 04:18:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 0, token usage: 0.09, #running-req: 23, #queue-req: 346, 
[1,0]<stdout>:[2025-10-12 04:18:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 345, 
[1,0]<stdout>:[2025-10-12 04:18:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1098, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 344, 
[1,1]<stdout>:[2025-10-12 04:18:13 DP1 TP8] Prefill batch. #new-seq: 3, #new-token: 599, #cached-token: 12, token usage: 0.10, #running-req: 21, #queue-req: 383, 
[1,1]<stdout>:[2025-10-12 04:18:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 749, #cached-token: 6, token usage: 0.10, #running-req: 23, #queue-req: 382, 
[1,0]<stdout>:[2025-10-12 04:18:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 343, 
[1,1]<stdout>:[2025-10-12 04:18:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 381, 
[1,0]<stdout>:[2025-10-12 04:18:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 456, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 342, 
[1,0]<stdout>:[2025-10-12 04:18:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 341, 
[1,1]<stdout>:[2025-10-12 04:18:14 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 628, #cached-token: 3, token usage: 0.10, #running-req: 22, #queue-req: 379, 
[1,0]<stdout>:[2025-10-12 04:18:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 340, 
[1,0]<stdout>:[2025-10-12 04:18:15 DP0 TP0] Decode batch. #running-req: 24, #token: 10973, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 339.37, #queue-req: 340, 
[1,1]<stdout>:[2025-10-12 04:18:15 DP1 TP8] Decode batch. #running-req: 24, #token: 16391, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 339.03, #queue-req: 379, 
[1,0]<stdout>:[2025-10-12 04:18:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 339, 
[1,1]<stdout>:[2025-10-12 04:18:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 3, token usage: 0.11, #running-req: 23, #queue-req: 378, 
[1,1]<stdout>:[2025-10-12 04:18:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 377, 
[1,1]<stdout>:[2025-10-12 04:18:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 376, 
[1,0]<stdout>:[2025-10-12 04:18:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 338, 
[1,0]<stdout>:[2025-10-12 04:18:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 337, 
[1,0]<stdout>:[2025-10-12 04:18:17 DP0 TP0] Decode batch. #running-req: 24, #token: 11870, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 480.33, #queue-req: 337, 
[1,1]<stdout>:[2025-10-12 04:18:17 DP1 TP8] Decode batch. #running-req: 24, #token: 16412, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 480.32, #queue-req: 376, 
[1,1]<stdout>:[2025-10-12 04:18:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 375, 
[1,1]<stdout>:[2025-10-12 04:18:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 617, #cached-token: 9, token usage: 0.11, #running-req: 23, #queue-req: 374, 
[1,1]<stdout>:[2025-10-12 04:18:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 373, 
[1,0]<stdout>:[2025-10-12 04:18:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 401, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 336, 
[1,1]<stdout>:[2025-10-12 04:18:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 372, 
[1,1]<stdout>:[2025-10-12 04:18:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 371, 
[1,0]<stdout>:[2025-10-12 04:18:19 DP0 TP0] Decode batch. #running-req: 24, #token: 12197, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 480.81, #queue-req: 336, 
[1,1]<stdout>:[2025-10-12 04:18:19 DP1 TP8] Decode batch. #running-req: 24, #token: 17270, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 478.85, #queue-req: 371, 
[1,0]<stdout>:[2025-10-12 04:18:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 551, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 335, 
[1,0]<stdout>:[2025-10-12 04:18:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 334, 
[1,0]<stdout>:[2025-10-12 04:18:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 333, 
[1,0]<stdout>:[2025-10-12 04:18:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 332, 
[1,0]<stdout>:[2025-10-12 04:18:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 331, 
[1,0]<stdout>:[2025-10-12 04:18:21 DP0 TP0] Decode batch. #running-req: 23, #token: 12430, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 519.77, #queue-req: 331, 
[1,1]<stdout>:[2025-10-12 04:18:21 DP1 TP8] Decode batch. #running-req: 24, #token: 18230, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 522.98, #queue-req: 371, 
[1,0]<stdout>:[2025-10-12 04:18:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1200, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 330, 
[1,0]<stdout>:[2025-10-12 04:18:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 329, 
[1,1]<stdout>:[2025-10-12 04:18:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 370, 
[1,1]<stdout>:[2025-10-12 04:18:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 3, token usage: 0.11, #running-req: 23, #queue-req: 369, 
[1,1]<stdout>:[2025-10-12 04:18:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 368, 
[1,1]<stdout>:[2025-10-12 04:18:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 367, 
[1,1]<stdout>:[2025-10-12 04:18:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 366, 
[1,1]<stdout>:[2025-10-12 04:18:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 365, 
[1,1]<stdout>:[2025-10-12 04:18:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 364, 
[1,0]<stdout>:[2025-10-12 04:18:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 328, 
[1,1]<stdout>:[2025-10-12 04:18:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 363, 
[1,0]<stdout>:[2025-10-12 04:18:23 DP0 TP0] Decode batch. #running-req: 24, #token: 13024, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 357.09, #queue-req: 328, 
[1,1]<stdout>:[2025-10-12 04:18:23 DP1 TP8] Decode batch. #running-req: 23, #token: 12862, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 354.49, #queue-req: 363, 
[1,1]<stdout>:[2025-10-12 04:18:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 903, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 362, 
[1,1]<stdout>:[2025-10-12 04:18:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 361, 
[1,1]<stdout>:[2025-10-12 04:18:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 360, 
[1,1]<stdout>:[2025-10-12 04:18:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 359, 
[1,0]<stdout>:[2025-10-12 04:18:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 327, 
[1,1]<stdout>:[2025-10-12 04:18:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 358, 
[1,1]<stdout>:[2025-10-12 04:18:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 357, 
[1,0]<stdout>:[2025-10-12 04:18:25 DP0 TP0] Decode batch. #running-req: 24, #token: 12731, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 451.01, #queue-req: 327, 
[1,1]<stdout>:[2025-10-12 04:18:25 DP1 TP8] Decode batch. #running-req: 24, #token: 14686, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.12, #queue-req: 357, 
[1,0]<stdout>:[2025-10-12 04:18:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 326, 
[1,0]<stdout>:[2025-10-12 04:18:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 325, 
[1,1]<stdout>:[2025-10-12 04:18:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 356, 
[1,1]<stdout>:[2025-10-12 04:18:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 355, 
[1,0]<stdout>:[2025-10-12 04:18:27 DP0 TP0] Decode batch. #running-req: 24, #token: 12618, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 562.84, #queue-req: 325, 
[1,1]<stdout>:[2025-10-12 04:18:27 DP1 TP8] Decode batch. #running-req: 24, #token: 15362, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 562.87, #queue-req: 355, 
[1,0]<stdout>:[2025-10-12 04:18:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 324, 
[1,1]<stdout>:[2025-10-12 04:18:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 354, 
[1,0]<stdout>:[2025-10-12 04:18:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 2, token usage: 0.08, #running-req: 22, #queue-req: 323, 
[1,1]<stdout>:[2025-10-12 04:18:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 353, 
[1,0]<stdout>:[2025-10-12 04:18:28 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 365, #cached-token: 1, token usage: 0.09, #running-req: 22, #queue-req: 322, 
[1,1]<stdout>:[2025-10-12 04:18:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 830, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 352, 
[1,1]<stdout>:[2025-10-12 04:18:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 351, 
[1,1]<stdout>:[2025-10-12 04:18:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 350, 
[1,0]<stdout>:[2025-10-12 04:18:29 DP0 TP0] Decode batch. #running-req: 24, #token: 15288, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 444.10, #queue-req: 322, 
[1,1]<stdout>:[2025-10-12 04:18:29 DP1 TP8] Decode batch. #running-req: 24, #token: 14369, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 443.16, #queue-req: 350, 
[1,1]<stdout>:[2025-10-12 04:18:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 349, 
[1,1]<stdout>:[2025-10-12 04:18:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 348, 
[1,1]<stdout>:[2025-10-12 04:18:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 347, 
[1,1]<stdout>:[2025-10-12 04:18:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1811, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 346, 
[1,1]<stdout>:[2025-10-12 04:18:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 345, 
[1,0]<stdout>:[2025-10-12 04:18:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 321, 
[1,1]<stdout>:[2025-10-12 04:18:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 344, 
[1,0]<stdout>:[2025-10-12 04:18:31 DP0 TP0] Decode batch. #running-req: 23, #token: 14587, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 442.84, #queue-req: 321, 
[1,1]<stdout>:[2025-10-12 04:18:31 DP1 TP8] Decode batch. #running-req: 24, #token: 11697, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 441.01, #queue-req: 344, 
[1,0]<stdout>:[2025-10-12 04:18:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 245, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 320, 
[1,0]<stdout>:[2025-10-12 04:18:32 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 236, #cached-token: 5, token usage: 0.09, #running-req: 22, #queue-req: 318, 
[1,0]<stdout>:[2025-10-12 04:18:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 317, 
[1,1]<stdout>:[2025-10-12 04:18:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 814, #cached-token: 10, token usage: 0.08, #running-req: 23, #queue-req: 343, 
[1,1]<stdout>:[2025-10-12 04:18:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 342, 
[1,1]<stdout>:[2025-10-12 04:18:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 0, token usage: 0.09, #running-req: 23, #queue-req: 342, 
[1,0]<stdout>:[2025-10-12 04:18:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 316, 
[1,1]<stdout>:[2025-10-12 04:18:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 341, 
[1,0]<stdout>:[2025-10-12 04:18:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 315, 
[1,1]<stdout>:[2025-10-12 04:18:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 340, 
[1,0]<stdout>:[2025-10-12 04:18:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 314, 
[1,0]<stdout>:[2025-10-12 04:18:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 313, 
[1,0]<stdout>:[2025-10-12 04:18:34 DP0 TP0] Decode batch. #running-req: 24, #token: 10801, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 335.89, #queue-req: 313, 
[1,1]<stdout>:[2025-10-12 04:18:34 DP1 TP8] Decode batch. #running-req: 24, #token: 13021, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 336.95, #queue-req: 340, 
[1,1]<stdout>:[2025-10-12 04:18:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 7, token usage: 0.08, #running-req: 23, #queue-req: 339, 
[1,1]<stdout>:[2025-10-12 04:18:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 338, 
[1,0]<stdout>:[2025-10-12 04:18:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 312, 
[1,0]<stdout>:[2025-10-12 04:18:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 311, 
[1,1]<stdout>:[2025-10-12 04:18:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 337, 
[1,0]<stdout>:[2025-10-12 04:18:36 DP0 TP0] Prefill batch. #new-seq: 3, #new-token: 74, #cached-token: 5, token usage: 0.06, #running-req: 21, #queue-req: 308, 
[1,0]<stdout>:[2025-10-12 04:18:36 DP0 TP0] Decode batch. #running-req: 24, #token: 9664, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 480.89, #queue-req: 308, 
[1,1]<stdout>:[2025-10-12 04:18:36 DP1 TP8] Decode batch. #running-req: 24, #token: 12870, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 481.90, #queue-req: 337, 
[1,0]<stdout>:[2025-10-12 04:18:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 307, 
[1,1]<stdout>:[2025-10-12 04:18:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 336, 
[1,1]<stdout>:[2025-10-12 04:18:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 335, 
[1,0]<stdout>:[2025-10-12 04:18:37 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 431, #cached-token: 5, token usage: 0.06, #running-req: 22, #queue-req: 305, 
[1,1]<stdout>:[2025-10-12 04:18:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 8, token usage: 0.08, #running-req: 23, #queue-req: 334, 
[1,0]<stdout>:[2025-10-12 04:18:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 304, 
[1,1]<stdout>:[2025-10-12 04:18:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 349, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 333, 
[1,1]<stdout>:[2025-10-12 04:18:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 332, 
[1,1]<stdout>:[2025-10-12 04:18:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 331, 
[1,0]<stdout>:[2025-10-12 04:18:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 303, 
[1,1]<stdout>:[2025-10-12 04:18:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 330, 
[1,0]<stdout>:[2025-10-12 04:18:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 302, 
[1,0]<stdout>:[2025-10-12 04:18:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 301, 
[1,1]<stdout>:[2025-10-12 04:18:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 329, 
[1,1]<stdout>:[2025-10-12 04:18:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 328, 
[1,0]<stdout>:[2025-10-12 04:18:39 DP0 TP0] Decode batch. #running-req: 23, #token: 9281, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 318.41, #queue-req: 301, 
[1,1]<stdout>:[2025-10-12 04:18:39 DP1 TP8] Decode batch. #running-req: 24, #token: 10598, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 318.08, #queue-req: 328, 
[1,0]<stdout>:[2025-10-12 04:18:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 300, 
[1,0]<stdout>:[2025-10-12 04:18:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 299, 
[1,1]<stdout>:[2025-10-12 04:18:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 327, 
[1,1]<stdout>:[2025-10-12 04:18:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 326, 
[1,1]<stdout>:[2025-10-12 04:18:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 325, 
[1,1]<stdout>:[2025-10-12 04:18:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 324, 
[1,0]<stdout>:[2025-10-12 04:18:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 298, 
[1,0]<stdout>:[2025-10-12 04:18:41 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 77, #cached-token: 4, token usage: 0.06, #running-req: 22, #queue-req: 296, 
[1,1]<stdout>:[2025-10-12 04:18:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 323, 
[1,0]<stdout>:[2025-10-12 04:18:42 DP0 TP0] Decode batch. #running-req: 24, #token: 9996, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 394.46, #queue-req: 296, 
[1,1]<stdout>:[2025-10-12 04:18:42 DP1 TP8] Decode batch. #running-req: 24, #token: 10631, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 394.03, #queue-req: 323, 
[1,0]<stdout>:[2025-10-12 04:18:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 295, 
[1,1]<stdout>:[2025-10-12 04:18:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 322, 
[1,0]<stdout>:[2025-10-12 04:18:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 294, 
[1,0]<stdout>:[2025-10-12 04:18:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 293, 
[1,0]<stdout>:[2025-10-12 04:18:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 292, 
[1,1]<stdout>:[2025-10-12 04:18:43 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 244, #cached-token: 6, token usage: 0.07, #running-req: 22, #queue-req: 320, 
[1,0]<stdout>:[2025-10-12 04:18:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 291, 
[1,0]<stdout>:[2025-10-12 04:18:44 DP0 TP0] Decode batch. #running-req: 24, #token: 9489, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 445.65, #queue-req: 291, 
[1,1]<stdout>:[2025-10-12 04:18:44 DP1 TP8] Decode batch. #running-req: 24, #token: 11155, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 446.59, #queue-req: 320, 
[1,0]<stdout>:[2025-10-12 04:18:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 290, 
[1,1]<stdout>:[2025-10-12 04:18:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 319, 
[1,1]<stdout>:[2025-10-12 04:18:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 782, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 318, 
[1,1]<stdout>:[2025-10-12 04:18:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 317, 
[1,1]<stdout>:[2025-10-12 04:18:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 316, 
[1,1]<stdout>:[2025-10-12 04:18:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 911, #cached-token: 0, token usage: 0.09, #running-req: 23, #queue-req: 316, 
[1,1]<stdout>:[2025-10-12 04:18:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 315, 
[1,1]<stdout>:[2025-10-12 04:18:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 314, 
[1,0]<stdout>:[2025-10-12 04:18:46 DP0 TP0] Decode batch. #running-req: 24, #token: 10225, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 420.24, #queue-req: 290, 
[1,1]<stdout>:[2025-10-12 04:18:46 DP1 TP8] Decode batch. #running-req: 24, #token: 15255, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 418.05, #queue-req: 314, 
[1,0]<stdout>:[2025-10-12 04:18:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 477, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 289, 
[1,1]<stdout>:[2025-10-12 04:18:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 313, 
[1,0]<stdout>:[2025-10-12 04:18:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 288, 
[1,1]<stdout>:[2025-10-12 04:18:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 7, token usage: 0.09, #running-req: 23, #queue-req: 312, 
[1,1]<stdout>:[2025-10-12 04:18:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 311, 
[1,0]<stdout>:[2025-10-12 04:18:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 861, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 287, 
[1,1]<stdout>:[2025-10-12 04:18:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 850, #cached-token: 7, token usage: 0.09, #running-req: 23, #queue-req: 310, 
[1,1]<stdout>:[2025-10-12 04:18:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 309, 
[1,1]<stdout>:[2025-10-12 04:18:48 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 19, #cached-token: 6, token usage: 0.08, #running-req: 22, #queue-req: 307, 
[1,0]<stdout>:[2025-10-12 04:18:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 286, 
[1,1]<stdout>:[2025-10-12 04:18:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 306, 
[1,0]<stdout>:[2025-10-12 04:18:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 6, token usage: 0.07, #running-req: 23, #queue-req: 285, 
[1,0]<stdout>:[2025-10-12 04:18:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 853, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 284, 
[1,0]<stdout>:[2025-10-12 04:18:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 283, 
[1,1]<stdout>:[2025-10-12 04:18:49 DP1 TP8] Decode batch. #running-req: 24, #token: 12893, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 315.46, #queue-req: 306, 
[1,0]<stdout>:[2025-10-12 04:18:49 DP0 TP0] Decode batch. #running-req: 24, #token: 11161, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 315.78, #queue-req: 283, 
[1,0]<stdout>:[2025-10-12 04:18:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 282, 
[1,1]<stdout>:[2025-10-12 04:18:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 305, 
[1,1]<stdout>:[2025-10-12 04:18:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 304, 
[1,1]<stdout>:[2025-10-12 04:18:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 303, 
[1,0]<stdout>:[2025-10-12 04:18:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 281, 
[1,1]<stdout>:[2025-10-12 04:18:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 302, 
[1,1]<stdout>:[2025-10-12 04:18:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 301, 
[1,0]<stdout>:[2025-10-12 04:18:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 280, 
[1,0]<stdout>:[2025-10-12 04:18:51 DP0 TP0] Decode batch. #running-req: 23, #token: 11395, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 419.10, #queue-req: 280, 
[1,1]<stdout>:[2025-10-12 04:18:51 DP1 TP8] Decode batch. #running-req: 24, #token: 11038, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 418.62, #queue-req: 301, 
[1,0]<stdout>:[2025-10-12 04:18:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 279, 
[1,0]<stdout>:[2025-10-12 04:18:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 278, 
[1,1]<stdout>:[2025-10-12 04:18:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 300, 
[1,1]<stdout>:[2025-10-12 04:18:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 299, 
[1,0]<stdout>:[2025-10-12 04:18:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 277, 
[1,1]<stdout>:[2025-10-12 04:18:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 298, 
[1,0]<stdout>:[2025-10-12 04:18:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 276, 
[1,0]<stdout>:[2025-10-12 04:18:54 DP0 TP0] Decode batch. #running-req: 23, #token: 7371, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.83, #queue-req: 276, 
[1,1]<stdout>:[2025-10-12 04:18:54 DP1 TP8] Decode batch. #running-req: 24, #token: 11000, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 450.31, #queue-req: 298, 
[1,0]<stdout>:[2025-10-12 04:18:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 275, 
[1,1]<stdout>:[2025-10-12 04:18:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 7, token usage: 0.07, #running-req: 23, #queue-req: 297, 
[1,1]<stdout>:[2025-10-12 04:18:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 296, 
[1,1]<stdout>:[2025-10-12 04:18:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 295, 
[1,1]<stdout>:[2025-10-12 04:18:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 294, 
[1,1]<stdout>:[2025-10-12 04:18:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1388, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 293, 
[1,0]<stdout>:[2025-10-12 04:18:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 274, 
[1,0]<stdout>:[2025-10-12 04:18:56 DP0 TP0] Decode batch. #running-req: 24, #token: 7984, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.73, #queue-req: 274, 
[1,1]<stdout>:[2025-10-12 04:18:56 DP1 TP8] Decode batch. #running-req: 24, #token: 10510, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 447.86, #queue-req: 293, 
[1,1]<stdout>:[2025-10-12 04:18:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 292, 
[1,0]<stdout>:[2025-10-12 04:18:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 273, 
[1,0]<stdout>:[2025-10-12 04:18:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 272, 
[1,1]<stdout>:[2025-10-12 04:18:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 291, 
[1,0]<stdout>:[2025-10-12 04:18:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 271, 
[1,1]<stdout>:[2025-10-12 04:18:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 877, token usage: 0.07, #running-req: 23, #queue-req: 290, 
[1,1]<stdout>:[2025-10-12 04:18:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 439, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 289, 
[1,1]<stdout>:[2025-10-12 04:18:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 288, 
[1,0]<stdout>:[2025-10-12 04:18:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1117, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 270, 
[1,0]<stdout>:[2025-10-12 04:18:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 269, 
[1,1]<stdout>:[2025-10-12 04:18:58 DP1 TP8] Decode batch. #running-req: 24, #token: 11304, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 376.07, #queue-req: 288, 
[1,0]<stdout>:[2025-10-12 04:18:58 DP0 TP0] Decode batch. #running-req: 24, #token: 8940, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 376.07, #queue-req: 269, 
[1,0]<stdout>:[2025-10-12 04:18:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 268, 
[1,1]<stdout>:[2025-10-12 04:18:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 287, 
[1,1]<stdout>:[2025-10-12 04:18:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 286, 
[1,1]<stdout>:[2025-10-12 04:18:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 285, 
[1,0]<stdout>:[2025-10-12 04:19:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 267, 
[1,0]<stdout>:[2025-10-12 04:19:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 266, 
[1,1]<stdout>:[2025-10-12 04:19:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 284, 
[1,1]<stdout>:[2025-10-12 04:19:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 283, 
[1,0]<stdout>:[2025-10-12 04:19:01 DP0 TP0] Decode batch. #running-req: 24, #token: 8941, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 422.54, #queue-req: 266, 
[1,1]<stdout>:[2025-10-12 04:19:01 DP1 TP8] Decode batch. #running-req: 24, #token: 9207, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 421.66, #queue-req: 283, 
[1,0]<stdout>:[2025-10-12 04:19:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 265, 
[1,1]<stdout>:[2025-10-12 04:19:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 843, #cached-token: 9, token usage: 0.04, #running-req: 23, #queue-req: 282, 
[1,1]<stdout>:[2025-10-12 04:19:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 281, 
[1,1]<stdout>:[2025-10-12 04:19:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 280, 
[1,0]<stdout>:[2025-10-12 04:19:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 264, 
[1,1]<stdout>:[2025-10-12 04:19:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 279, 
[1,1]<stdout>:[2025-10-12 04:19:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 0, token usage: 0.05, #running-req: 23, #queue-req: 279, 
[1,0]<stdout>:[2025-10-12 04:19:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 263, 
[1,0]<stdout>:[2025-10-12 04:19:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 262, 
[1,1]<stdout>:[2025-10-12 04:19:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 278, 
[1,0]<stdout>:[2025-10-12 04:19:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 261, 
[1,1]<stdout>:[2025-10-12 04:19:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.04, #running-req: 23, #queue-req: 277, 
[1,1]<stdout>:[2025-10-12 04:19:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 276, 
[1,0]<stdout>:[2025-10-12 04:19:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 260, 
[1,0]<stdout>:[2025-10-12 04:19:03 DP0 TP0] Decode batch. #running-req: 23, #token: 7442, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 348.01, #queue-req: 260, 
[1,1]<stdout>:[2025-10-12 04:19:03 DP1 TP8] Decode batch. #running-req: 24, #token: 5927, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 347.99, #queue-req: 276, 
[1,0]<stdout>:[2025-10-12 04:19:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 259, 
[1,1]<stdout>:[2025-10-12 04:19:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 275, 
[1,1]<stdout>:[2025-10-12 04:19:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 4, token usage: 0.04, #running-req: 23, #queue-req: 274, 
[1,1]<stdout>:[2025-10-12 04:19:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 273, 
[1,1]<stdout>:[2025-10-12 04:19:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 272, 
[1,0]<stdout>:[2025-10-12 04:19:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 258, 
[1,0]<stdout>:[2025-10-12 04:19:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 257, 
[1,0]<stdout>:[2025-10-12 04:19:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 256, 
[1,1]<stdout>:[2025-10-12 04:19:05 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 452, #cached-token: 7, token usage: 0.04, #running-req: 22, #queue-req: 270, 
[1,0]<stdout>:[2025-10-12 04:19:06 DP0 TP0] Decode batch. #running-req: 24, #token: 5981, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 401.18, #queue-req: 256, 
[1,1]<stdout>:[2025-10-12 04:19:06 DP1 TP8] Decode batch. #running-req: 24, #token: 6097, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 399.96, #queue-req: 270, 
[1,0]<stdout>:[2025-10-12 04:19:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 255, 
[1,0]<stdout>:[2025-10-12 04:19:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 254, 
[1,1]<stdout>:[2025-10-12 04:19:06 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 496, #cached-token: 6, token usage: 0.03, #running-req: 22, #queue-req: 268, 
[1,0]<stdout>:[2025-10-12 04:19:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 253, 
[1,1]<stdout>:[2025-10-12 04:19:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 586, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 267, 
[1,1]<stdout>:[2025-10-12 04:19:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 266, 
[1,1]<stdout>:[2025-10-12 04:19:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 265, 
[1,0]<stdout>:[2025-10-12 04:19:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 252, 
[1,1]<stdout>:[2025-10-12 04:19:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 264, 
[1,0]<stdout>:[2025-10-12 04:19:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 5, token usage: 0.04, #running-req: 23, #queue-req: 251, 
[1,1]<stdout>:[2025-10-12 04:19:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 263, 
[1,0]<stdout>:[2025-10-12 04:19:08 DP0 TP0] Decode batch. #running-req: 24, #token: 6619, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.37, #queue-req: 251, 
[1,1]<stdout>:[2025-10-12 04:19:08 DP1 TP8] Decode batch. #running-req: 24, #token: 5669, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.59, #queue-req: 263, 
[1,1]<stdout>:[2025-10-12 04:19:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 262, 
[1,0]<stdout>:[2025-10-12 04:19:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 250, 
[1,1]<stdout>:[2025-10-12 04:19:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 261, 
[1,0]<stdout>:[2025-10-12 04:19:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 440, #cached-token: 5, token usage: 0.04, #running-req: 23, #queue-req: 249, 
[1,1]<stdout>:[2025-10-12 04:19:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 4, token usage: 0.04, #running-req: 23, #queue-req: 260, 
[1,0]<stdout>:[2025-10-12 04:19:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 248, 
[1,0]<stdout>:[2025-10-12 04:19:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 247, 
[1,1]<stdout>:[2025-10-12 04:19:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 259, 
[1,0]<stdout>:[2025-10-12 04:19:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 246, 
[1,1]<stdout>:[2025-10-12 04:19:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 258, 
[1,0]<stdout>:[2025-10-12 04:19:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 245, 
[1,0]<stdout>:[2025-10-12 04:19:11 DP0 TP0] Decode batch. #running-req: 24, #token: 7937, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 398.76, #queue-req: 245, 
[1,1]<stdout>:[2025-10-12 04:19:11 DP1 TP8] Decode batch. #running-req: 24, #token: 6556, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 399.20, #queue-req: 258, 
[1,0]<stdout>:[2025-10-12 04:19:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 787, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 244, 
[1,0]<stdout>:[2025-10-12 04:19:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 243, 
[1,1]<stdout>:[2025-10-12 04:19:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.04, #running-req: 23, #queue-req: 257, 
[1,0]<stdout>:[2025-10-12 04:19:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 242, 
[1,1]<stdout>:[2025-10-12 04:19:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1771, #cached-token: 1, token usage: 0.04, #running-req: 23, #queue-req: 256, 
[1,1]<stdout>:[2025-10-12 04:19:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 255, 
[1,0]<stdout>:[2025-10-12 04:19:13 DP0 TP0] Decode batch. #running-req: 24, #token: 9467, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 482.59, #queue-req: 242, 
[1,1]<stdout>:[2025-10-12 04:19:13 DP1 TP8] Decode batch. #running-req: 24, #token: 8559, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 482.58, #queue-req: 255, 
[1,1]<stdout>:[2025-10-12 04:19:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 254, 
[1,0]<stdout>:[2025-10-12 04:19:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 241, 
[1,0]<stdout>:[2025-10-12 04:19:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 240, 
[1,0]<stdout>:[2025-10-12 04:19:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 239, 
[1,0]<stdout>:[2025-10-12 04:19:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 238, 
[1,0]<stdout>:[2025-10-12 04:19:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 0, token usage: 0.07, #running-req: 23, #queue-req: 238, 
[1,0]<stdout>:[2025-10-12 04:19:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 504, token usage: 0.08, #running-req: 23, #queue-req: 237, 
[1,0]<stdout>:[2025-10-12 04:19:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 236, 
[1,0]<stdout>:[2025-10-12 04:19:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 235, 
[1,1]<stdout>:[2025-10-12 04:19:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 253, 
[1,1]<stdout>:[2025-10-12 04:19:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 252, 
[1,0]<stdout>:[2025-10-12 04:19:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 234, 
[1,1]<stdout>:[2025-10-12 04:19:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 251, 
[1,0]<stdout>:[2025-10-12 04:19:16 DP0 TP0] Decode batch. #running-req: 24, #token: 11878, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 335.21, #queue-req: 234, 
[1,1]<stdout>:[2025-10-12 04:19:16 DP1 TP8] Decode batch. #running-req: 24, #token: 9182, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 336.62, #queue-req: 251, 
[1,0]<stdout>:[2025-10-12 04:19:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 233, 
[1,0]<stdout>:[2025-10-12 04:19:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 232, 
[1,1]<stdout>:[2025-10-12 04:19:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 250, 
[1,0]<stdout>:[2025-10-12 04:19:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 231, 
[1,0]<stdout>:[2025-10-12 04:19:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 12, token usage: 0.07, #running-req: 23, #queue-req: 230, 
[1,1]<stdout>:[2025-10-12 04:19:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1051, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 249, 
[1,0]<stdout>:[2025-10-12 04:19:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 229, 
[1,0]<stdout>:[2025-10-12 04:19:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 228, 
[1,1]<stdout>:[2025-10-12 04:19:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 248, 
[1,0]<stdout>:[2025-10-12 04:19:18 DP0 TP0] Decode batch. #running-req: 24, #token: 11136, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 393.16, #queue-req: 228, 
[1,1]<stdout>:[2025-10-12 04:19:18 DP1 TP8] Decode batch. #running-req: 24, #token: 10359, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 394.41, #queue-req: 248, 
[1,1]<stdout>:[2025-10-12 04:19:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 247, 
[1,0]<stdout>:[2025-10-12 04:19:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1958, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 227, 
[1,0]<stdout>:[2025-10-12 04:19:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 226, 
[1,0]<stdout>:[2025-10-12 04:19:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 225, 
[1,1]<stdout>:[2025-10-12 04:19:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 246, 
[1,0]<stdout>:[2025-10-12 04:19:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 224, 
[1,0]<stdout>:[2025-10-12 04:19:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 223, 
[1,0]<stdout>:[2025-10-12 04:19:20 DP0 TP0] Decode batch. #running-req: 24, #token: 10070, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.97, #queue-req: 223, 
[1,1]<stdout>:[2025-10-12 04:19:20 DP1 TP8] Decode batch. #running-req: 23, #token: 9799, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 450.91, #queue-req: 246, 
[1,1]<stdout>:[2025-10-12 04:19:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 245, 
[1,0]<stdout>:[2025-10-12 04:19:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 222, 
[1,1]<stdout>:[2025-10-12 04:19:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 244, 
[1,0]<stdout>:[2025-10-12 04:19:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 783, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 221, 
[1,0]<stdout>:[2025-10-12 04:19:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 220, 
[1,1]<stdout>:[2025-10-12 04:19:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 243, 
[1,0]<stdout>:[2025-10-12 04:19:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 219, 
[1,0]<stdout>:[2025-10-12 04:19:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 218, 
[1,0]<stdout>:[2025-10-12 04:19:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 217, 
[1,1]<stdout>:[2025-10-12 04:19:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 242, 
[1,0]<stdout>:[2025-10-12 04:19:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 216, 
[1,0]<stdout>:[2025-10-12 04:19:23 DP0 TP0] Decode batch. #running-req: 24, #token: 9740, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 374.68, #queue-req: 216, 
[1,1]<stdout>:[2025-10-12 04:19:23 DP1 TP8] Decode batch. #running-req: 24, #token: 9488, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 376.23, #queue-req: 242, 
[1,1]<stdout>:[2025-10-12 04:19:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 241, 
[1,1]<stdout>:[2025-10-12 04:19:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 240, 
[1,0]<stdout>:[2025-10-12 04:19:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 402, token usage: 0.06, #running-req: 23, #queue-req: 215, 
[1,1]<stdout>:[2025-10-12 04:19:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 239, 
[1,0]<stdout>:[2025-10-12 04:19:23 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 214, 
[1,0]<stdout>:[2025-10-12 04:19:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 213, 
[1,1]<stdout>:[2025-10-12 04:19:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 238, 
[1,0]<stdout>:[2025-10-12 04:19:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 212, 
[1,0]<stdout>:[2025-10-12 04:19:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 211, 
[1,0]<stdout>:[2025-10-12 04:19:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 627, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 210, 
[1,0]<stdout>:[2025-10-12 04:19:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 209, 
[1,1]<stdout>:[2025-10-12 04:19:25 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 237, 
[1,0]<stdout>:[2025-10-12 04:19:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 208, 
[1,0]<stdout>:[2025-10-12 04:19:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 452, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 207, 
[1,0]<stdout>:[2025-10-12 04:19:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 206, 
[1,0]<stdout>:[2025-10-12 04:19:26 DP0 TP0] Decode batch. #running-req: 24, #token: 9725, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 288.34, #queue-req: 206, 
[1,1]<stdout>:[2025-10-12 04:19:26 DP1 TP8] Decode batch. #running-req: 24, #token: 10293, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 289.87, #queue-req: 237, 
[1,0]<stdout>:[2025-10-12 04:19:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1014, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 205, 
[1,1]<stdout>:[2025-10-12 04:19:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 236, 
[1,0]<stdout>:[2025-10-12 04:19:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 204, 
[1,0]<stdout>:[2025-10-12 04:19:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 203, 
[1,1]<stdout>:[2025-10-12 04:19:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 235, 
[1,1]<stdout>:[2025-10-12 04:19:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 234, 
[1,0]<stdout>:[2025-10-12 04:19:27 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 202, 
[1,0]<stdout>:[2025-10-12 04:19:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 201, 
[1,1]<stdout>:[2025-10-12 04:19:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 233, 
[1,0]<stdout>:[2025-10-12 04:19:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 427, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 200, 
[1,0]<stdout>:[2025-10-12 04:19:28 DP0 TP0] Decode batch. #running-req: 24, #token: 8659, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 443.61, #queue-req: 200, 
[1,1]<stdout>:[2025-10-12 04:19:28 DP1 TP8] Decode batch. #running-req: 24, #token: 9305, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 444.54, #queue-req: 233, 
[1,0]<stdout>:[2025-10-12 04:19:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 826, token usage: 0.06, #running-req: 23, #queue-req: 199, 
[1,0]<stdout>:[2025-10-12 04:19:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 538, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 198, 
[1,1]<stdout>:[2025-10-12 04:19:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 232, 
[1,0]<stdout>:[2025-10-12 04:19:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 197, 
[1,1]<stdout>:[2025-10-12 04:19:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1426, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 231, 
[1,0]<stdout>:[2025-10-12 04:19:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 196, 
[1,1]<stdout>:[2025-10-12 04:19:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 230, 
[1,1]<stdout>:[2025-10-12 04:19:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 229, 
[1,0]<stdout>:[2025-10-12 04:19:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 195, 
[1,0]<stdout>:[2025-10-12 04:19:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 194, 
[1,1]<stdout>:[2025-10-12 04:19:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 228, 
[1,0]<stdout>:[2025-10-12 04:19:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 193, 
[1,0]<stdout>:[2025-10-12 04:19:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 192, 
[1,0]<stdout>:[2025-10-12 04:19:31 DP0 TP0] Decode batch. #running-req: 24, #token: 9771, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 335.80, #queue-req: 192, 
[1,1]<stdout>:[2025-10-12 04:19:31 DP1 TP8] Decode batch. #running-req: 24, #token: 9740, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 336.86, #queue-req: 228, 
[1,0]<stdout>:[2025-10-12 04:19:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 744, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 191, 
[1,0]<stdout>:[2025-10-12 04:19:31 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 382, #cached-token: 8, token usage: 0.06, #running-req: 22, #queue-req: 189, 
[1,0]<stdout>:[2025-10-12 04:19:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 188, 
[1,0]<stdout>:[2025-10-12 04:19:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 833, #cached-token: 7, token usage: 0.06, #running-req: 23, #queue-req: 187, 
[1,0]<stdout>:[2025-10-12 04:19:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 186, 
[1,0]<stdout>:[2025-10-12 04:19:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 656, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 185, 
[1,1]<stdout>:[2025-10-12 04:19:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 227, 
[1,0]<stdout>:[2025-10-12 04:19:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 7, token usage: 0.05, #running-req: 23, #queue-req: 184, 
[1,1]<stdout>:[2025-10-12 04:19:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 226, 
[1,0]<stdout>:[2025-10-12 04:19:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 183, 
[1,0]<stdout>:[2025-10-12 04:19:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 182, 
[1,0]<stdout>:[2025-10-12 04:19:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 181, 
[1,1]<stdout>:[2025-10-12 04:19:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 225, 
[1,0]<stdout>:[2025-10-12 04:19:34 DP0 TP0] Decode batch. #running-req: 24, #token: 6715, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 351.20, #queue-req: 181, 
[1,1]<stdout>:[2025-10-12 04:19:34 DP1 TP8] Decode batch. #running-req: 23, #token: 9465, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 353.82, #queue-req: 225, 
[1,1]<stdout>:[2025-10-12 04:19:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 224, 
[1,0]<stdout>:[2025-10-12 04:19:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 554, #cached-token: 2, token usage: 0.04, #running-req: 23, #queue-req: 180, 
[1,1]<stdout>:[2025-10-12 04:19:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 223, 
[1,0]<stdout>:[2025-10-12 04:19:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 179, 
[1,1]<stdout>:[2025-10-12 04:19:35 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 2048, #cached-token: 3, token usage: 0.06, #running-req: 22, #queue-req: 221, 
[1,1]<stdout>:[2025-10-12 04:19:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 0, token usage: 0.07, #running-req: 23, #queue-req: 221, 
[1,0]<stdout>:[2025-10-12 04:19:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 811, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 178, 
[1,0]<stdout>:[2025-10-12 04:19:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 177, 
[1,1]<stdout>:[2025-10-12 04:19:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 8, token usage: 0.07, #running-req: 23, #queue-req: 220, 
[1,0]<stdout>:[2025-10-12 04:19:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 176, 
[1,0]<stdout>:[2025-10-12 04:19:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 175, 
[1,0]<stdout>:[2025-10-12 04:19:36 DP0 TP0] Decode batch. #running-req: 24, #token: 7704, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 351.13, #queue-req: 175, 
[1,1]<stdout>:[2025-10-12 04:19:36 DP1 TP8] Decode batch. #running-req: 24, #token: 11877, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 351.84, #queue-req: 220, 
[1,0]<stdout>:[2025-10-12 04:19:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 174, 
[1,1]<stdout>:[2025-10-12 04:19:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 219, 
[1,1]<stdout>:[2025-10-12 04:19:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 218, 
[1,0]<stdout>:[2025-10-12 04:19:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 173, 
[1,1]<stdout>:[2025-10-12 04:19:37 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 236, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 217, 
[1,0]<stdout>:[2025-10-12 04:19:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 172, 
[1,1]<stdout>:[2025-10-12 04:19:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 216, 
[1,1]<stdout>:[2025-10-12 04:19:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 215, 
[1,1]<stdout>:[2025-10-12 04:19:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 494, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 214, 
[1,0]<stdout>:[2025-10-12 04:19:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 484, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 171, 
[1,1]<stdout>:[2025-10-12 04:19:39 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 39, #cached-token: 6, token usage: 0.07, #running-req: 22, #queue-req: 212, 
[1,0]<stdout>:[2025-10-12 04:19:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 170, 
[1,0]<stdout>:[2025-10-12 04:19:39 DP0 TP0] Decode batch. #running-req: 24, #token: 8419, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 333.86, #queue-req: 170, 
[1,1]<stdout>:[2025-10-12 04:19:39 DP1 TP8] Decode batch. #running-req: 24, #token: 10721, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 332.81, #queue-req: 212, 
[1,0]<stdout>:[2025-10-12 04:19:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1833, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 169, 
[1,0]<stdout>:[2025-10-12 04:19:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 168, 
[1,0]<stdout>:[2025-10-12 04:19:40 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 743, #cached-token: 9, token usage: 0.05, #running-req: 22, #queue-req: 166, 
[1,0]<stdout>:[2025-10-12 04:19:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 165, 
[1,1]<stdout>:[2025-10-12 04:19:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 211, 
[1,0]<stdout>:[2025-10-12 04:19:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 739, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 164, 
[1,0]<stdout>:[2025-10-12 04:19:41 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 857, #cached-token: 12, token usage: 0.05, #running-req: 22, #queue-req: 162, 
[1,0]<stdout>:[2025-10-12 04:19:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 161, 
[1,0]<stdout>:[2025-10-12 04:19:41 DP0 TP0] Decode batch. #running-req: 23, #token: 8750, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 418.64, #queue-req: 161, 
[1,1]<stdout>:[2025-10-12 04:19:41 DP1 TP8] Decode batch. #running-req: 24, #token: 11557, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 422.61, #queue-req: 211, 
[1,0]<stdout>:[2025-10-12 04:19:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 160, 
[1,0]<stdout>:[2025-10-12 04:19:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 781, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 159, 
[1,0]<stdout>:[2025-10-12 04:19:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 158, 
[1,1]<stdout>:[2025-10-12 04:19:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 210, 
[1,1]<stdout>:[2025-10-12 04:19:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 209, 
[1,1]<stdout>:[2025-10-12 04:19:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 208, 
[1,0]<stdout>:[2025-10-12 04:19:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 157, 
[1,0]<stdout>:[2025-10-12 04:19:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1811, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 156, 
[1,1]<stdout>:[2025-10-12 04:19:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 207, 
[1,0]<stdout>:[2025-10-12 04:19:44 DP0 TP0] Decode batch. #running-req: 23, #token: 10091, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.41, #queue-req: 156, 
[1,1]<stdout>:[2025-10-12 04:19:44 DP1 TP8] Decode batch. #running-req: 23, #token: 11677, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 392.41, #queue-req: 207, 
[1,0]<stdout>:[2025-10-12 04:19:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 155, 
[1,1]<stdout>:[2025-10-12 04:19:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 206, 
[1,0]<stdout>:[2025-10-12 04:19:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 154, 
[1,0]<stdout>:[2025-10-12 04:19:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 153, 
[1,1]<stdout>:[2025-10-12 04:19:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 205, 
[1,0]<stdout>:[2025-10-12 04:19:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 152, 
[1,0]<stdout>:[2025-10-12 04:19:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 415, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 151, 
[1,0]<stdout>:[2025-10-12 04:19:46 DP0 TP0] Decode batch. #running-req: 23, #token: 9256, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 478.97, #queue-req: 151, 
[1,1]<stdout>:[2025-10-12 04:19:46 DP1 TP8] Decode batch. #running-req: 24, #token: 12778, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 481.01, #queue-req: 205, 
[1,0]<stdout>:[2025-10-12 04:19:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 756, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 150, 
[1,0]<stdout>:[2025-10-12 04:19:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 149, 
[1,1]<stdout>:[2025-10-12 04:19:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 204, 
[1,0]<stdout>:[2025-10-12 04:19:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 148, 
[1,0]<stdout>:[2025-10-12 04:19:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 147, 
[1,0]<stdout>:[2025-10-12 04:19:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 550, #cached-token: 8, token usage: 0.06, #running-req: 23, #queue-req: 146, 
[1,0]<stdout>:[2025-10-12 04:19:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 145, 
[1,0]<stdout>:[2025-10-12 04:19:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 144, 
[1,1]<stdout>:[2025-10-12 04:19:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 203, 
[1,1]<stdout>:[2025-10-12 04:19:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 698, #cached-token: 0, token usage: 0.10, #running-req: 23, #queue-req: 203, 
[1,0]<stdout>:[2025-10-12 04:19:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 143, 
[1,0]<stdout>:[2025-10-12 04:19:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 142, 
[1,0]<stdout>:[2025-10-12 04:19:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 141, 
[1,0]<stdout>:[2025-10-12 04:19:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1343, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 140, 
[1,0]<stdout>:[2025-10-12 04:19:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 139, 
[1,1]<stdout>:[2025-10-12 04:19:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 202, 
[1,0]<stdout>:[2025-10-12 04:19:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 138, 
[1,0]<stdout>:[2025-10-12 04:19:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 137, 
[1,0]<stdout>:[2025-10-12 04:19:49 DP0 TP0] Decode batch. #running-req: 24, #token: 10340, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 266.23, #queue-req: 137, 
[1,1]<stdout>:[2025-10-12 04:19:49 DP1 TP8] Decode batch. #running-req: 24, #token: 15694, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 269.03, #queue-req: 202, 
[1,0]<stdout>:[2025-10-12 04:19:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 136, 
[1,0]<stdout>:[2025-10-12 04:19:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 135, 
[1,1]<stdout>:[2025-10-12 04:19:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 851, #cached-token: 5, token usage: 0.10, #running-req: 23, #queue-req: 201, 
[1,0]<stdout>:[2025-10-12 04:19:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 134, 
[1,0]<stdout>:[2025-10-12 04:19:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1438, #cached-token: 0, token usage: 0.08, #running-req: 23, #queue-req: 134, 
[1,1]<stdout>:[2025-10-12 04:19:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 200, 
[1,0]<stdout>:[2025-10-12 04:19:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 133, 
[1,1]<stdout>:[2025-10-12 04:19:52 DP1 TP8] Decode batch. #running-req: 24, #token: 15866, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 452.20, #queue-req: 200, 
[1,0]<stdout>:[2025-10-12 04:19:52 DP0 TP0] Decode batch. #running-req: 24, #token: 12887, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 451.22, #queue-req: 133, 
[1,0]<stdout>:[2025-10-12 04:19:52 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 4, token usage: 0.08, #running-req: 22, #queue-req: 131, 
[1,0]<stdout>:[2025-10-12 04:19:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 130, 
[1,1]<stdout>:[2025-10-12 04:19:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 199, 
[1,0]<stdout>:[2025-10-12 04:19:53 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 129, 
[1,1]<stdout>:[2025-10-12 04:19:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 198, 
[1,1]<stdout>:[2025-10-12 04:19:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 197, 
[1,0]<stdout>:[2025-10-12 04:19:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 128, 
[1,0]<stdout>:[2025-10-12 04:19:54 DP0 TP0] Decode batch. #running-req: 24, #token: 11706, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 448.60, #queue-req: 128, 
[1,1]<stdout>:[2025-10-12 04:19:54 DP1 TP8] Decode batch. #running-req: 24, #token: 16152, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.52, #queue-req: 197, 
[1,1]<stdout>:[2025-10-12 04:19:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 196, 
[1,1]<stdout>:[2025-10-12 04:19:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 195, 
[1,0]<stdout>:[2025-10-12 04:19:54 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 8, token usage: 0.08, #running-req: 23, #queue-req: 127, 
[1,1]<stdout>:[2025-10-12 04:19:55 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 1501, #cached-token: 6, token usage: 0.08, #running-req: 22, #queue-req: 193, 
[1,0]<stdout>:[2025-10-12 04:19:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 345, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 126, 
[1,0]<stdout>:[2025-10-12 04:19:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 125, 
[1,0]<stdout>:[2025-10-12 04:19:55 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 591, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 124, 
[1,1]<stdout>:[2025-10-12 04:19:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 192, 
[1,0]<stdout>:[2025-10-12 04:19:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 123, 
[1,0]<stdout>:[2025-10-12 04:19:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 122, 
[1,1]<stdout>:[2025-10-12 04:19:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 5, token usage: 0.10, #running-req: 23, #queue-req: 191, 
[1,0]<stdout>:[2025-10-12 04:19:56 DP0 TP0] Decode batch. #running-req: 24, #token: 12328, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 369.09, #queue-req: 122, 
[1,1]<stdout>:[2025-10-12 04:19:56 DP1 TP8] Decode batch. #running-req: 24, #token: 15001, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 369.08, #queue-req: 191, 
[1,0]<stdout>:[2025-10-12 04:19:56 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 121, 
[1,1]<stdout>:[2025-10-12 04:19:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 794, #cached-token: 7, token usage: 0.09, #running-req: 23, #queue-req: 190, 
[1,0]<stdout>:[2025-10-12 04:19:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 120, 
[1,0]<stdout>:[2025-10-12 04:19:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 119, 
[1,1]<stdout>:[2025-10-12 04:19:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 189, 
[1,0]<stdout>:[2025-10-12 04:19:57 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.05, #running-req: 23, #queue-req: 118, 
[1,0]<stdout>:[2025-10-12 04:19:58 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 480, #cached-token: 6, token usage: 0.05, #running-req: 23, #queue-req: 117, 
[1,1]<stdout>:[2025-10-12 04:19:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 188, 
[1,1]<stdout>:[2025-10-12 04:19:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 187, 
[1,0]<stdout>:[2025-10-12 04:19:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 837, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 116, 
[1,1]<stdout>:[2025-10-12 04:19:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 666, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 186, 
[1,0]<stdout>:[2025-10-12 04:19:59 DP0 TP0] Decode batch. #running-req: 24, #token: 9459, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 356.68, #queue-req: 116, 
[1,1]<stdout>:[2025-10-12 04:19:59 DP1 TP8] Decode batch. #running-req: 24, #token: 13328, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 357.05, #queue-req: 186, 
[1,1]<stdout>:[2025-10-12 04:19:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 185, 
[1,0]<stdout>:[2025-10-12 04:19:59 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 115, 
[1,0]<stdout>:[2025-10-12 04:20:00 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 114, 
[1,1]<stdout>:[2025-10-12 04:20:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 184, 
[1,0]<stdout>:[2025-10-12 04:20:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 4, token usage: 0.05, #running-req: 23, #queue-req: 113, 
[1,0]<stdout>:[2025-10-12 04:20:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 8, token usage: 0.05, #running-req: 23, #queue-req: 112, 
[1,0]<stdout>:[2025-10-12 04:20:01 DP0 TP0] Decode batch. #running-req: 23, #token: 8516, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 478.10, #queue-req: 112, 
[1,1]<stdout>:[2025-10-12 04:20:01 DP1 TP8] Decode batch. #running-req: 24, #token: 13773, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 479.60, #queue-req: 184, 
[1,0]<stdout>:[2025-10-12 04:20:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 111, 
[1,0]<stdout>:[2025-10-12 04:20:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 110, 
[1,0]<stdout>:[2025-10-12 04:20:01 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 2, token usage: 0.05, #running-req: 23, #queue-req: 109, 
[1,0]<stdout>:[2025-10-12 04:20:02 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 108, 
[1,1]<stdout>:[2025-10-12 04:20:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 183, 
[1,1]<stdout>:[2025-10-12 04:20:02 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 606, #cached-token: 7, token usage: 0.09, #running-req: 22, #queue-req: 181, 
[1,0]<stdout>:[2025-10-12 04:20:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 107, 
[1,1]<stdout>:[2025-10-12 04:20:03 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 137, #cached-token: 3, token usage: 0.09, #running-req: 22, #queue-req: 179, 
[1,1]<stdout>:[2025-10-12 04:20:03 DP1 TP8] Decode batch. #running-req: 24, #token: 14355, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 422.18, #queue-req: 179, 
[1,0]<stdout>:[2025-10-12 04:20:03 DP0 TP0] Decode batch. #running-req: 24, #token: 9146, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 422.61, #queue-req: 107, 
[1,0]<stdout>:[2025-10-12 04:20:03 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 106, 
[1,1]<stdout>:[2025-10-12 04:20:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 178, 
[1,0]<stdout>:[2025-10-12 04:20:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 105, 
[1,0]<stdout>:[2025-10-12 04:20:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 497, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 104, 
[1,1]<stdout>:[2025-10-12 04:20:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 177, 
[1,0]<stdout>:[2025-10-12 04:20:04 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 103, 
[1,1]<stdout>:[2025-10-12 04:20:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 176, 
[1,1]<stdout>:[2025-10-12 04:20:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 175, 
[1,1]<stdout>:[2025-10-12 04:20:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 174, 
[1,1]<stdout>:[2025-10-12 04:20:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 173, 
[1,0]<stdout>:[2025-10-12 04:20:05 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 102, 
[1,1]<stdout>:[2025-10-12 04:20:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 172, 
[1,1]<stdout>:[2025-10-12 04:20:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 6, token usage: 0.07, #running-req: 23, #queue-req: 171, 
[1,1]<stdout>:[2025-10-12 04:20:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 170, 
[1,0]<stdout>:[2025-10-12 04:20:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 101, 
[1,1]<stdout>:[2025-10-12 04:20:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 169, 
[1,0]<stdout>:[2025-10-12 04:20:06 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 100, 
[1,1]<stdout>:[2025-10-12 04:20:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 168, 
[1,0]<stdout>:[2025-10-12 04:20:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 99, 
[1,0]<stdout>:[2025-10-12 04:20:07 DP0 TP0] Decode batch. #running-req: 24, #token: 8737, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 258.02, #queue-req: 99, 
[1,1]<stdout>:[2025-10-12 04:20:07 DP1 TP8] Decode batch. #running-req: 24, #token: 10685, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 257.20, #queue-req: 168, 
[1,1]<stdout>:[2025-10-12 04:20:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 167, 
[1,0]<stdout>:[2025-10-12 04:20:07 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 98, 
[1,0]<stdout>:[2025-10-12 04:20:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 97, 
[1,1]<stdout>:[2025-10-12 04:20:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 166, 
[1,0]<stdout>:[2025-10-12 04:20:08 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 96, 
[1,0]<stdout>:[2025-10-12 04:20:09 DP0 TP0] Decode batch. #running-req: 24, #token: 9689, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 520.13, #queue-req: 96, 
[1,1]<stdout>:[2025-10-12 04:20:09 DP1 TP8] Decode batch. #running-req: 24, #token: 11657, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 520.68, #queue-req: 166, 
[1,0]<stdout>:[2025-10-12 04:20:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 95, 
[1,1]<stdout>:[2025-10-12 04:20:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 165, 
[1,0]<stdout>:[2025-10-12 04:20:09 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 94, 
[1,0]<stdout>:[2025-10-12 04:20:10 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 409, #cached-token: 4, token usage: 0.06, #running-req: 22, #queue-req: 92, 
[1,0]<stdout>:[2025-10-12 04:20:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 4, token usage: 0.06, #running-req: 23, #queue-req: 91, 
[1,1]<stdout>:[2025-10-12 04:20:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 412, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 164, 
[1,0]<stdout>:[2025-10-12 04:20:10 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 90, 
[1,0]<stdout>:[2025-10-12 04:20:11 DP0 TP0] Prefill batch. #new-seq: 3, #new-token: 558, #cached-token: 8, token usage: 0.06, #running-req: 21, #queue-req: 87, 
[1,1]<stdout>:[2025-10-12 04:20:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 163, 
[1,0]<stdout>:[2025-10-12 04:20:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 866, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 86, 
[1,0]<stdout>:[2025-10-12 04:20:11 DP0 TP0] Decode batch. #running-req: 23, #token: 9065, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 375.04, #queue-req: 86, 
[1,1]<stdout>:[2025-10-12 04:20:11 DP1 TP8] Decode batch. #running-req: 24, #token: 11883, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 378.20, #queue-req: 163, 
[1,0]<stdout>:[2025-10-12 04:20:11 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 85, 
[1,1]<stdout>:[2025-10-12 04:20:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 162, 
[1,0]<stdout>:[2025-10-12 04:20:12 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 84, 
[1,1]<stdout>:[2025-10-12 04:20:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 161, 
[1,1]<stdout>:[2025-10-12 04:20:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 160, 
[1,0]<stdout>:[2025-10-12 04:20:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 83, 
[1,0]<stdout>:[2025-10-12 04:20:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 82, 
[1,0]<stdout>:[2025-10-12 04:20:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 81, 
[1,0]<stdout>:[2025-10-12 04:20:13 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 80, 
[1,0]<stdout>:[2025-10-12 04:20:14 DP0 TP0] Decode batch. #running-req: 24, #token: 9258, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 397.77, #queue-req: 80, 
[1,1]<stdout>:[2025-10-12 04:20:14 DP1 TP8] Decode batch. #running-req: 24, #token: 11601, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 398.60, #queue-req: 160, 
[1,0]<stdout>:[2025-10-12 04:20:14 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 79, 
[1,1]<stdout>:[2025-10-12 04:20:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 159, 
[1,0]<stdout>:[2025-10-12 04:20:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 78, 
[1,1]<stdout>:[2025-10-12 04:20:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 158, 
[1,0]<stdout>:[2025-10-12 04:20:15 DP0 TP0] Decode batch. #running-req: 23, #token: 9055, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 563.66, #queue-req: 78, 
[1,1]<stdout>:[2025-10-12 04:20:15 DP1 TP8] Decode batch. #running-req: 24, #token: 11692, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 564.27, #queue-req: 158, 
[1,0]<stdout>:[2025-10-12 04:20:15 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 77, 
[1,1]<stdout>:[2025-10-12 04:20:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 157, 
[1,0]<stdout>:[2025-10-12 04:20:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1234, #cached-token: 3, token usage: 0.05, #running-req: 23, #queue-req: 76, 
[1,0]<stdout>:[2025-10-12 04:20:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 75, 
[1,0]<stdout>:[2025-10-12 04:20:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 688, #cached-token: 0, token usage: 0.07, #running-req: 23, #queue-req: 75, 
[1,0]<stdout>:[2025-10-12 04:20:16 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 74, 
[1,1]<stdout>:[2025-10-12 04:20:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 156, 
[1,0]<stdout>:[2025-10-12 04:20:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 73, 
[1,1]<stdout>:[2025-10-12 04:20:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 155, 
[1,0]<stdout>:[2025-10-12 04:20:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 72, 
[1,0]<stdout>:[2025-10-12 04:20:17 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 71, 
[1,1]<stdout>:[2025-10-12 04:20:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 349, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 154, 
[1,1]<stdout>:[2025-10-12 04:20:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 153, 
[1,0]<stdout>:[2025-10-12 04:20:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 687, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 70, 
[1,0]<stdout>:[2025-10-12 04:20:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 69, 
[1,1]<stdout>:[2025-10-12 04:20:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 739, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 152, 
[1,0]<stdout>:[2025-10-12 04:20:18 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 638, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 68, 
[1,0]<stdout>:[2025-10-12 04:20:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 67, 
[1,0]<stdout>:[2025-10-12 04:20:19 DP0 TP0] Decode batch. #running-req: 24, #token: 12772, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 277.83, #queue-req: 67, 
[1,1]<stdout>:[2025-10-12 04:20:19 DP1 TP8] Decode batch. #running-req: 24, #token: 9984, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 278.99, #queue-req: 152, 
[1,1]<stdout>:[2025-10-12 04:20:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 151, 
[1,0]<stdout>:[2025-10-12 04:20:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 602, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 66, 
[1,0]<stdout>:[2025-10-12 04:20:19 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 65, 
[1,1]<stdout>:[2025-10-12 04:20:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 150, 
[1,1]<stdout>:[2025-10-12 04:20:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 149, 
[1,0]<stdout>:[2025-10-12 04:20:20 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 725, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 64, 
[1,1]<stdout>:[2025-10-12 04:20:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 785, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 148, 
[1,1]<stdout>:[2025-10-12 04:20:20 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 147, 
[1,1]<stdout>:[2025-10-12 04:20:21 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 146, 
[1,0]<stdout>:[2025-10-12 04:20:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 63, 
[1,0]<stdout>:[2025-10-12 04:20:21 DP0 TP0] Decode batch. #running-req: 24, #token: 12142, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 396.31, #queue-req: 63, 
[1,1]<stdout>:[2025-10-12 04:20:21 DP1 TP8] Decode batch. #running-req: 24, #token: 10265, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 395.49, #queue-req: 146, 
[1,0]<stdout>:[2025-10-12 04:20:21 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 62, 
[1,0]<stdout>:[2025-10-12 04:20:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 61, 
[1,1]<stdout>:[2025-10-12 04:20:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 145, 
[1,0]<stdout>:[2025-10-12 04:20:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 1227, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 60, 
[1,0]<stdout>:[2025-10-12 04:20:22 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 59, 
[1,1]<stdout>:[2025-10-12 04:20:22 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 144, 
[1,0]<stdout>:[2025-10-12 04:20:23 DP0 TP0] Prefill batch. #new-seq: 2, #new-token: 451, #cached-token: 4, token usage: 0.08, #running-req: 22, #queue-req: 57, 
[1,1]<stdout>:[2025-10-12 04:20:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 143, 
[1,1]<stdout>:[2025-10-12 04:20:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 142, 
[1,1]<stdout>:[2025-10-12 04:20:23 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 341, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 141, 
[1,0]<stdout>:[2025-10-12 04:20:24 DP0 TP0] Decode batch. #running-req: 23, #token: 12086, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 395.09, #queue-req: 57, 
[1,1]<stdout>:[2025-10-12 04:20:24 DP1 TP8] Decode batch. #running-req: 24, #token: 9770, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 395.92, #queue-req: 141, 
[1,0]<stdout>:[2025-10-12 04:20:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 56, 
[1,0]<stdout>:[2025-10-12 04:20:24 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 55, 
[1,1]<stdout>:[2025-10-12 04:20:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 140, 
[1,1]<stdout>:[2025-10-12 04:20:24 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 752, #cached-token: 0, token usage: 0.08, #running-req: 23, #queue-req: 140, 
[1,0]<stdout>:[2025-10-12 04:20:25 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 54, 
[1,1]<stdout>:[2025-10-12 04:20:25 DP1 TP8] Decode batch. #running-req: 24, #token: 13172, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 517.47, #queue-req: 140, 
[1,0]<stdout>:[2025-10-12 04:20:25 DP0 TP0] Decode batch. #running-req: 24, #token: 13110, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 516.92, #queue-req: 54, 
[1,0]<stdout>:[2025-10-12 04:20:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 53, 
[1,0]<stdout>:[2025-10-12 04:20:26 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 52, 
[1,1]<stdout>:[2025-10-12 04:20:26 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 595, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 139, 
[1,1]<stdout>:[2025-10-12 04:20:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 795, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 138, 
[1,1]<stdout>:[2025-10-12 04:20:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 137, 
[1,1]<stdout>:[2025-10-12 04:20:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 136, 
[1,1]<stdout>:[2025-10-12 04:20:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 135, 
[1,1]<stdout>:[2025-10-12 04:20:27 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 134, 
[1,0]<stdout>:[2025-10-12 04:20:28 DP0 TP0] Decode batch. #running-req: 24, #token: 13540, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 416.17, #queue-req: 52, 
[1,1]<stdout>:[2025-10-12 04:20:28 DP1 TP8] Decode batch. #running-req: 23, #token: 10541, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 414.01, #queue-req: 134, 
[1,1]<stdout>:[2025-10-12 04:20:28 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 133, 
[1,0]<stdout>:[2025-10-12 04:20:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 51, 
[1,0]<stdout>:[2025-10-12 04:20:28 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 50, 
[1,0]<stdout>:[2025-10-12 04:20:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 326, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 49, 
[1,1]<stdout>:[2025-10-12 04:20:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 132, 
[1,0]<stdout>:[2025-10-12 04:20:29 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 48, 
[1,1]<stdout>:[2025-10-12 04:20:29 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 131, 
[1,0]<stdout>:[2025-10-12 04:20:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 47, 
[1,0]<stdout>:[2025-10-12 04:20:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 46, 
[1,1]<stdout>:[2025-10-12 04:20:30 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 130, 
[1,0]<stdout>:[2025-10-12 04:20:30 DP0 TP0] Decode batch. #running-req: 24, #token: 11954, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 373.24, #queue-req: 46, 
[1,1]<stdout>:[2025-10-12 04:20:30 DP1 TP8] Decode batch. #running-req: 24, #token: 10697, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 374.40, #queue-req: 130, 
[1,0]<stdout>:[2025-10-12 04:20:30 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 45, 
[1,1]<stdout>:[2025-10-12 04:20:31 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 129, 
[1,0]<stdout>:[2025-10-12 04:20:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 44, 
[1,0]<stdout>:[2025-10-12 04:20:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 43, 
[1,0]<stdout>:[2025-10-12 04:20:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 42, 
[1,0]<stdout>:[2025-10-12 04:20:31 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 41, 
[1,1]<stdout>:[2025-10-12 04:20:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2036, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 128, 
[1,1]<stdout>:[2025-10-12 04:20:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 127, 
[1,1]<stdout>:[2025-10-12 04:20:32 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 746, #cached-token: 0, token usage: 0.10, #running-req: 23, #queue-req: 127, 
[1,0]<stdout>:[2025-10-12 04:20:32 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 40, 
[1,0]<stdout>:[2025-10-12 04:20:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 39, 
[1,1]<stdout>:[2025-10-12 04:20:33 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 126, 
[1,0]<stdout>:[2025-10-12 04:20:33 DP0 TP0] Decode batch. #running-req: 24, #token: 11717, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 347.46, #queue-req: 39, 
[1,1]<stdout>:[2025-10-12 04:20:33 DP1 TP8] Decode batch. #running-req: 24, #token: 15655, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 348.56, #queue-req: 126, 
[1,0]<stdout>:[2025-10-12 04:20:33 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 38, 
[1,0]<stdout>:[2025-10-12 04:20:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 37, 
[1,1]<stdout>:[2025-10-12 04:20:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 125, 
[1,0]<stdout>:[2025-10-12 04:20:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 36, 
[1,0]<stdout>:[2025-10-12 04:20:34 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 35, 
[1,1]<stdout>:[2025-10-12 04:20:34 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 5, token usage: 0.10, #running-req: 23, #queue-req: 124, 
[1,0]<stdout>:[2025-10-12 04:20:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 34, 
[1,1]<stdout>:[2025-10-12 04:20:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 123, 
[1,0]<stdout>:[2025-10-12 04:20:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 33, 
[1,1]<stdout>:[2025-10-12 04:20:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 122, 
[1,0]<stdout>:[2025-10-12 04:20:35 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 32, 
[1,1]<stdout>:[2025-10-12 04:20:35 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 121, 
[1,0]<stdout>:[2025-10-12 04:20:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 483, #cached-token: 6, token usage: 0.06, #running-req: 23, #queue-req: 31, 
[1,0]<stdout>:[2025-10-12 04:20:36 DP0 TP0] Decode batch. #running-req: 24, #token: 9380, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 352.12, #queue-req: 31, 
[1,1]<stdout>:[2025-10-12 04:20:36 DP1 TP8] Decode batch. #running-req: 24, #token: 13953, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 353.22, #queue-req: 121, 
[1,0]<stdout>:[2025-10-12 04:20:36 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 30, 
[1,1]<stdout>:[2025-10-12 04:20:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 120, 
[1,1]<stdout>:[2025-10-12 04:20:36 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 119, 
[1,0]<stdout>:[2025-10-12 04:20:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 823, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 29, 
[1,0]<stdout>:[2025-10-12 04:20:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 28, 
[1,0]<stdout>:[2025-10-12 04:20:37 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 0, token usage: 0.08, #running-req: 23, #queue-req: 28, 
[1,0]<stdout>:[2025-10-12 04:20:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 27, 
[1,0]<stdout>:[2025-10-12 04:20:38 DP0 TP0] Decode batch. #running-req: 24, #token: 12314, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 483.61, #queue-req: 27, 
[1,1]<stdout>:[2025-10-12 04:20:38 DP1 TP8] Decode batch. #running-req: 23, #token: 13947, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 484.12, #queue-req: 119, 
[1,1]<stdout>:[2025-10-12 04:20:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 118, 
[1,0]<stdout>:[2025-10-12 04:20:38 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 26, 
[1,1]<stdout>:[2025-10-12 04:20:38 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 6, token usage: 0.09, #running-req: 23, #queue-req: 117, 
[1,0]<stdout>:[2025-10-12 04:20:39 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 25, 
[1,1]<stdout>:[2025-10-12 04:20:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 116, 
[1,1]<stdout>:[2025-10-12 04:20:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 1, token usage: 0.09, #running-req: 23, #queue-req: 115, 
[1,1]<stdout>:[2025-10-12 04:20:39 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 627, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 114, 
[1,0]<stdout>:[2025-10-12 04:20:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 24, 
[1,1]<stdout>:[2025-10-12 04:20:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 113, 
[1,0]<stdout>:[2025-10-12 04:20:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 23, 
[1,1]<stdout>:[2025-10-12 04:20:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 112, 
[1,0]<stdout>:[2025-10-12 04:20:40 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 22, 
[1,1]<stdout>:[2025-10-12 04:20:40 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 111, 
[1,0]<stdout>:[2025-10-12 04:20:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 21, 
[1,0]<stdout>:[2025-10-12 04:20:41 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 20, 
[1,0]<stdout>:[2025-10-12 04:20:41 DP0 TP0] Decode batch. #running-req: 24, #token: 11757, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 292.14, #queue-req: 20, 
[1,1]<stdout>:[2025-10-12 04:20:41 DP1 TP8] Decode batch. #running-req: 24, #token: 13038, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 292.14, #queue-req: 111, 
[1,1]<stdout>:[2025-10-12 04:20:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 110, 
[1,1]<stdout>:[2025-10-12 04:20:41 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 454, #cached-token: 0, token usage: 0.09, #running-req: 23, #queue-req: 110, 
[1,0]<stdout>:[2025-10-12 04:20:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 19, 
[1,0]<stdout>:[2025-10-12 04:20:42 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 770, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 18, 
[1,1]<stdout>:[2025-10-12 04:20:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 109, 
[1,1]<stdout>:[2025-10-12 04:20:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 108, 
[1,1]<stdout>:[2025-10-12 04:20:42 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 107, 
[1,0]<stdout>:[2025-10-12 04:20:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 17, 
[1,0]<stdout>:[2025-10-12 04:20:43 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 16, 
[1,1]<stdout>:[2025-10-12 04:20:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 817, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 106, 
[1,1]<stdout>:[2025-10-12 04:20:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 601, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 105, 
[1,1]<stdout>:[2025-10-12 04:20:43 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.09, #running-req: 23, #queue-req: 104, 
[1,1]<stdout>:[2025-10-12 04:20:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 103, 
[1,0]<stdout>:[2025-10-12 04:20:44 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 426, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 15, 
[1,1]<stdout>:[2025-10-12 04:20:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 792, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 102, 
[1,0]<stdout>:[2025-10-12 04:20:44 DP0 TP0] Decode batch. #running-req: 24, #token: 13041, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 289.13, #queue-req: 15, 
[1,1]<stdout>:[2025-10-12 04:20:44 DP1 TP8] Decode batch. #running-req: 24, #token: 12396, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 287.90, #queue-req: 102, 
[1,1]<stdout>:[2025-10-12 04:20:44 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 101, 
[1,0]<stdout>:[2025-10-12 04:20:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 14, 
[1,1]<stdout>:[2025-10-12 04:20:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 100, 
[1,0]<stdout>:[2025-10-12 04:20:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 13, 
[1,1]<stdout>:[2025-10-12 04:20:45 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 8, token usage: 0.08, #running-req: 23, #queue-req: 99, 
[1,0]<stdout>:[2025-10-12 04:20:45 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 12, 
[1,1]<stdout>:[2025-10-12 04:20:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 98, 
[1,1]<stdout>:[2025-10-12 04:20:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 785, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 97, 
[1,0]<stdout>:[2025-10-12 04:20:46 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 11, 
[1,1]<stdout>:[2025-10-12 04:20:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 96, 
[1,1]<stdout>:[2025-10-12 04:20:46 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 95, 
[1,0]<stdout>:[2025-10-12 04:20:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 10, 
[1,0]<stdout>:[2025-10-12 04:20:47 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 9, 
[1,1]<stdout>:[2025-10-12 04:20:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 94, 
[1,1]<stdout>:[2025-10-12 04:20:47 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 529, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 93, 
[1,0]<stdout>:[2025-10-12 04:20:48 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 8, 
[1,0]<stdout>:[2025-10-12 04:20:48 DP0 TP0] Decode batch. #running-req: 24, #token: 12194, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 282.81, #queue-req: 8, 
[1,1]<stdout>:[2025-10-12 04:20:48 DP1 TP8] Decode batch. #running-req: 23, #token: 12783, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 281.93, #queue-req: 93, 
[1,1]<stdout>:[2025-10-12 04:20:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 302, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 92, 
[1,1]<stdout>:[2025-10-12 04:20:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 325, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 91, 
[1,1]<stdout>:[2025-10-12 04:20:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 620, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 90, 
[1,1]<stdout>:[2025-10-12 04:20:48 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 2, token usage: 0.08, #running-req: 23, #queue-req: 89, 
[1,1]<stdout>:[2025-10-12 04:20:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 5, token usage: 0.08, #running-req: 23, #queue-req: 88, 
[1,1]<stdout>:[2025-10-12 04:20:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 637, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 87, 
[1,0]<stdout>:[2025-10-12 04:20:49 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 282, #cached-token: 6, token usage: 0.08, #running-req: 23, #queue-req: 7, 
[1,1]<stdout>:[2025-10-12 04:20:49 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 86, 
[1,1]<stdout>:[2025-10-12 04:20:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 85, 
[1,1]<stdout>:[2025-10-12 04:20:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 84, 
[1,0]<stdout>:[2025-10-12 04:20:50 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 6, 
[1,1]<stdout>:[2025-10-12 04:20:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 83, 
[1,0]<stdout>:[2025-10-12 04:20:50 DP0 TP0] Decode batch. #running-req: 24, #token: 12884, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.90, #queue-req: 6, 
[1,1]<stdout>:[2025-10-12 04:20:50 DP1 TP8] Decode batch. #running-req: 23, #token: 9890, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 355.91, #queue-req: 83, 
[1,1]<stdout>:[2025-10-12 04:20:50 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 82, 
[1,0]<stdout>:[2025-10-12 04:20:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 830, #cached-token: 4, token usage: 0.08, #running-req: 23, #queue-req: 5, 
[1,0]<stdout>:[2025-10-12 04:20:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 4, 
[1,0]<stdout>:[2025-10-12 04:20:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 3, 
[1,0]<stdout>:[2025-10-12 04:20:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 345, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 2, 
[1,1]<stdout>:[2025-10-12 04:20:51 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 81, 
[1,0]<stdout>:[2025-10-12 04:20:51 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 1, 
[1,0]<stdout>:[2025-10-12 04:20:52 DP0 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:20:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 80, 
[1,1]<stdout>:[2025-10-12 04:20:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 381, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 79, 
[1,1]<stdout>:[2025-10-12 04:20:52 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 770, #cached-token: 5, token usage: 0.06, #running-req: 23, #queue-req: 78, 
[1,1]<stdout>:[2025-10-12 04:20:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 77, 
[1,1]<stdout>:[2025-10-12 04:20:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 5, token usage: 0.07, #running-req: 23, #queue-req: 76, 
[1,1]<stdout>:[2025-10-12 04:20:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 75, 
[1,0]<stdout>:[2025-10-12 04:20:53 DP0 TP0] Decode batch. #running-req: 19, #token: 10867, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 287.94, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:20:53 DP1 TP8] Decode batch. #running-req: 24, #token: 10102, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 309.00, #queue-req: 75, 
[1,1]<stdout>:[2025-10-12 04:20:53 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 74, 
[1,1]<stdout>:[2025-10-12 04:20:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 73, 
[1,1]<stdout>:[2025-10-12 04:20:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 72, 
[1,1]<stdout>:[2025-10-12 04:20:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 665, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 71, 
[1,1]<stdout>:[2025-10-12 04:20:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 573, #cached-token: 7, token usage: 0.07, #running-req: 23, #queue-req: 70, 
[1,1]<stdout>:[2025-10-12 04:20:54 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.07, #running-req: 23, #queue-req: 69, 
[1,1]<stdout>:[2025-10-12 04:20:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 68, 
[1,1]<stdout>:[2025-10-12 04:20:55 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 20, #cached-token: 3, token usage: 0.07, #running-req: 22, #queue-req: 66, 
[1,1]<stdout>:[2025-10-12 04:20:55 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 65, 
[1,1]<stdout>:[2025-10-12 04:20:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 685, #cached-token: 8, token usage: 0.07, #running-req: 23, #queue-req: 64, 
[1,1]<stdout>:[2025-10-12 04:20:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1170, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 63, 
[1,0]<stdout>:[2025-10-12 04:20:56 DP0 TP0] Decode batch. #running-req: 19, #token: 11627, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 284.48, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:20:56 DP1 TP8] Decode batch. #running-req: 24, #token: 11839, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 354.87, #queue-req: 63, 
[1,1]<stdout>:[2025-10-12 04:20:56 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 62, 
[1,1]<stdout>:[2025-10-12 04:20:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 61, 
[1,1]<stdout>:[2025-10-12 04:20:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1543, #cached-token: 0, token usage: 0.09, #running-req: 23, #queue-req: 61, 
[1,1]<stdout>:[2025-10-12 04:20:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 391, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 60, 
[1,1]<stdout>:[2025-10-12 04:20:57 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 236, #cached-token: 2, token usage: 0.09, #running-req: 23, #queue-req: 59, 
[1,0]<stdout>:[2025-10-12 04:20:58 DP0 TP0] Decode batch. #running-req: 17, #token: 11936, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 403.77, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:20:58 DP1 TP8] Decode batch. #running-req: 24, #token: 14889, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 522.31, #queue-req: 59, 
[1,1]<stdout>:[2025-10-12 04:20:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 58, 
[1,1]<stdout>:[2025-10-12 04:20:58 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1097, #cached-token: 0, token usage: 0.11, #running-req: 23, #queue-req: 58, 
[1,1]<stdout>:[2025-10-12 04:20:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1347, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 57, 
[1,1]<stdout>:[2025-10-12 04:20:59 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 451, #cached-token: 4, token usage: 0.12, #running-req: 23, #queue-req: 56, 
[1,1]<stdout>:[2025-10-12 04:21:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 55, 
[1,1]<stdout>:[2025-10-12 04:21:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 54, 
[1,0]<stdout>:[2025-10-12 04:21:00 DP0 TP0] Decode batch. #running-req: 16, #token: 12102, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 322.17, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:00 DP1 TP8] Decode batch. #running-req: 24, #token: 18695, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 469.02, #queue-req: 54, 
[1,1]<stdout>:[2025-10-12 04:21:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 53, 
[1,1]<stdout>:[2025-10-12 04:21:00 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 52, 
[1,1]<stdout>:[2025-10-12 04:21:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 432, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 51, 
[1,1]<stdout>:[2025-10-12 04:21:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.10, #running-req: 23, #queue-req: 50, 
[1,1]<stdout>:[2025-10-12 04:21:01 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 49, 
[1,1]<stdout>:[2025-10-12 04:21:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 4, token usage: 0.10, #running-req: 23, #queue-req: 48, 
[1,0]<stdout>:[2025-10-12 04:21:02 DP0 TP0] Decode batch. #running-req: 13, #token: 10541, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 304.85, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:02 DP1 TP8] Decode batch. #running-req: 24, #token: 15012, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 475.22, #queue-req: 48, 
[1,1]<stdout>:[2025-10-12 04:21:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 784, #cached-token: 3, token usage: 0.10, #running-req: 23, #queue-req: 47, 
[1,1]<stdout>:[2025-10-12 04:21:02 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 1, token usage: 0.10, #running-req: 23, #queue-req: 46, 
[1,1]<stdout>:[2025-10-12 04:21:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 0, token usage: 0.11, #running-req: 23, #queue-req: 46, 
[1,1]<stdout>:[2025-10-12 04:21:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.11, #running-req: 23, #queue-req: 45, 
[1,1]<stdout>:[2025-10-12 04:21:03 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 2, token usage: 0.11, #running-req: 23, #queue-req: 44, 
[1,1]<stdout>:[2025-10-12 04:21:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.11, #running-req: 23, #queue-req: 43, 
[1,1]<stdout>:[2025-10-12 04:21:04 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1236, #cached-token: 4, token usage: 0.11, #running-req: 23, #queue-req: 42, 
[1,0]<stdout>:[2025-10-12 04:21:04 DP0 TP0] Decode batch. #running-req: 11, #token: 7162, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 225.55, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:04 DP1 TP8] Decode batch. #running-req: 24, #token: 17590, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 439.12, #queue-req: 42, 
[1,1]<stdout>:[2025-10-12 04:21:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 752, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 41, 
[1,1]<stdout>:[2025-10-12 04:21:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 1, token usage: 0.12, #running-req: 23, #queue-req: 40, 
[1,1]<stdout>:[2025-10-12 04:21:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.12, #running-req: 23, #queue-req: 39, 
[1,1]<stdout>:[2025-10-12 04:21:05 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 4, token usage: 0.12, #running-req: 23, #queue-req: 38, 
[1,0]<stdout>:[2025-10-12 04:21:06 DP0 TP0] Decode batch. #running-req: 11, #token: 7602, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 258.39, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:06 DP1 TP8] Decode batch. #running-req: 24, #token: 18455, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 561.44, #queue-req: 38, 
[1,1]<stdout>:[2025-10-12 04:21:06 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 37, 
[1,1]<stdout>:[2025-10-12 04:21:06 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 70, #cached-token: 4, token usage: 0.09, #running-req: 22, #queue-req: 35, 
[1,1]<stdout>:[2025-10-12 04:21:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 34, 
[1,1]<stdout>:[2025-10-12 04:21:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 309, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 33, 
[1,1]<stdout>:[2025-10-12 04:21:07 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 32, 
[1,0]<stdout>:[2025-10-12 04:21:08 DP0 TP0] Decode batch. #running-req: 11, #token: 8042, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 239.30, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:08 DP1 TP8] Decode batch. #running-req: 24, #token: 14845, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 518.84, #queue-req: 32, 
[1,1]<stdout>:[2025-10-12 04:21:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 4, token usage: 0.09, #running-req: 23, #queue-req: 31, 
[1,1]<stdout>:[2025-10-12 04:21:08 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 30, 
[1,1]<stdout>:[2025-10-12 04:21:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 6, token usage: 0.09, #running-req: 23, #queue-req: 29, 
[1,1]<stdout>:[2025-10-12 04:21:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 451, #cached-token: 3, token usage: 0.09, #running-req: 23, #queue-req: 28, 
[1,0]<stdout>:[2025-10-12 04:21:09 DP0 TP0] Decode batch. #running-req: 11, #token: 8482, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 258.11, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:09 DP1 TP8] Decode batch. #running-req: 24, #token: 13303, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 560.76, #queue-req: 28, 
[1,1]<stdout>:[2025-10-12 04:21:09 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 5, token usage: 0.09, #running-req: 23, #queue-req: 27, 
[1,1]<stdout>:[2025-10-12 04:21:10 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 26, 
[1,1]<stdout>:[2025-10-12 04:21:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 1, token usage: 0.08, #running-req: 23, #queue-req: 25, 
[1,1]<stdout>:[2025-10-12 04:21:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 24, 
[1,0]<stdout>:[2025-10-12 04:21:11 DP0 TP0] Decode batch. #running-req: 9, #token: 5697, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 235.32, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:11 DP1 TP8] Decode batch. #running-req: 24, #token: 11451, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 561.08, #queue-req: 24, 
[1,1]<stdout>:[2025-10-12 04:21:11 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 3, token usage: 0.08, #running-req: 23, #queue-req: 23, 
[1,1]<stdout>:[2025-10-12 04:21:12 DP1 TP8] Prefill batch. #new-seq: 2, #new-token: 32, #cached-token: 8, token usage: 0.05, #running-req: 22, #queue-req: 21, 
[1,1]<stdout>:[2025-10-12 04:21:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1049, #cached-token: 9, token usage: 0.05, #running-req: 23, #queue-req: 20, 
[1,1]<stdout>:[2025-10-12 04:21:12 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1885, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 19, 
[1,1]<stdout>:[2025-10-12 04:21:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.07, #running-req: 23, #queue-req: 18, 
[1,1]<stdout>:[2025-10-12 04:21:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 17, 
[1,1]<stdout>:[2025-10-12 04:21:13 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 16, 
[1,0]<stdout>:[2025-10-12 04:21:13 DP0 TP0] Decode batch. #running-req: 7, #token: 4836, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 140.61, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:13 DP1 TP8] Decode batch. #running-req: 24, #token: 8609, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 408.10, #queue-req: 16, 
[1,1]<stdout>:[2025-10-12 04:21:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 358, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 15, 
[1,1]<stdout>:[2025-10-12 04:21:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 14, 
[1,1]<stdout>:[2025-10-12 04:21:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1560, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 13, 
[1,1]<stdout>:[2025-10-12 04:21:14 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1197, #cached-token: 1, token usage: 0.07, #running-req: 23, #queue-req: 12, 
[1,1]<stdout>:[2025-10-12 04:21:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 11, 
[1,1]<stdout>:[2025-10-12 04:21:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 865, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 10, 
[1,1]<stdout>:[2025-10-12 04:21:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.07, #running-req: 23, #queue-req: 9, 
[1,1]<stdout>:[2025-10-12 04:21:15 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 8, 
[1,1]<stdout>:[2025-10-12 04:21:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 483, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 7, 
[1,1]<stdout>:[2025-10-12 04:21:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 6, 
[1,0]<stdout>:[2025-10-12 04:21:16 DP0 TP0] Decode batch. #running-req: 7, #token: 5116, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 108.41, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:16 DP1 TP8] Decode batch. #running-req: 24, #token: 8957, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 367.82, #queue-req: 6, 
[1,1]<stdout>:[2025-10-12 04:21:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 5, 
[1,1]<stdout>:[2025-10-12 04:21:16 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 1220, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 4, 
[1,1]<stdout>:[2025-10-12 04:21:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 2, token usage: 0.06, #running-req: 23, #queue-req: 3, 
[1,1]<stdout>:[2025-10-12 04:21:17 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 2, 
[1,0]<stdout>:[2025-10-12 04:21:18 DP0 TP0] Decode batch. #running-req: 7, #token: 5396, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 164.61, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:18 DP1 TP8] Decode batch. #running-req: 24, #token: 9560, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 562.03, #queue-req: 2, 
[1,1]<stdout>:[2025-10-12 04:21:18 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.06, #running-req: 23, #queue-req: 1, 
[1,1]<stdout>:[2025-10-12 04:21:19 DP1 TP8] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.06, #running-req: 23, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 04:21:19 DP0 TP0] Decode batch. #running-req: 6, #token: 4838, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 174.98, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:19 DP1 TP8] Decode batch. #running-req: 24, #token: 10258, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 673.18, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 04:21:20 DP0 TP0] Decode batch. #running-req: 5, #token: 4414, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 187.25, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:20 DP1 TP8] Decode batch. #running-req: 19, #token: 10173, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 743.75, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 04:21:22 DP0 TP0] Decode batch. #running-req: 4, #token: 3931, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 92.99, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:22 DP1 TP8] Decode batch. #running-req: 17, #token: 9683, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 390.67, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 04:21:23 DP0 TP0] Decode batch. #running-req: 3, #token: 2532, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:23 DP1 TP8] Decode batch. #running-req: 16, #token: 10143, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 583.85, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 04:21:25 DP0 TP0] Decode batch. #running-req: 2, #token: 1633, token usage: 0.01, accept len: 1.00, cuda graph: True, gen throughput (token/s): 60.52, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:25 DP1 TP8] Decode batch. #running-req: 15, #token: 10459, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 351.01, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:26 DP1 TP8] Decode batch. #running-req: 12, #token: 9973, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 404.04, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:27 DP1 TP8] Decode batch. #running-req: 11, #token: 10105, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 453.35, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:28 DP1 TP8] Decode batch. #running-req: 8, #token: 7905, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 368.05, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:29 DP1 TP8] Decode batch. #running-req: 5, #token: 5460, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 285.98, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:30 DP1 TP8] Decode batch. #running-req: 5, #token: 4782, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 208.62, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:31 DP1 TP8] Decode batch. #running-req: 4, #token: 4942, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 161.47, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:32 DP1 TP8] Decode batch. #running-req: 2, #token: 2676, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 115.71, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:33 DP1 TP8] Decode batch. #running-req: 2, #token: 2756, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 85.57, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:34 DP1 TP8] Decode batch. #running-req: 2, #token: 2836, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 85.72, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:35 DP1 TP8] Decode batch. #running-req: 2, #token: 2916, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 85.89, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:36 DP1 TP8] Decode batch. #running-req: 1, #token: 2262, token usage: 0.01, accept len: 1.00, cuda graph: True, gen throughput (token/s): 47.63, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:37 DP1 TP8] Decode batch. #running-req: 1, #token: 2302, token usage: 0.01, accept len: 1.00, cuda graph: True, gen throughput (token/s): 42.81, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 04:21:38 DP1 TP8] Decode batch. #running-req: 1, #token: 2342, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 42.87, #queue-req: 0, 
[1,0]<stdout>:
[1,0]<stdout>:====== Offline Throughput Benchmark Result =======
[1,0]<stdout>:Backend:                                 engine    
[1,0]<stdout>:Successful requests:                     2000      
[1,0]<stdout>:Benchmark duration (s):                  509.60    
[1,0]<stdout>:Total input tokens:                      626729    
[1,0]<stdout>:Total generated tokens:                  388685    
[1,0]<stdout>:Last generation throughput (tok/s):      60.52     
[1,0]<stdout>:Request throughput (req/s):              3.92      
[1,0]<stdout>:Input token throughput (tok/s):          1229.85   
[1,0]<stdout>:Output token throughput (tok/s):         762.73    
[1,0]<stdout>:Total token throughput (tok/s):          1992.58   
[1,0]<stdout>:==================================================
[1,1]<stdout>:[2025-10-12 04:21:40 DP1 TP12] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1032, in recv_requests
[1,1]<stdout>:    control_reqs = broadcast_pyobj(
[1,1]<stdout>:                   ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.84]:18325
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 04:21:40 DP1 TP10] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1032, in recv_requests
[1,1]<stdout>:    control_reqs = broadcast_pyobj(
[1,1]<stdout>:                   ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.84]:3973
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 04:21:40 DP1 TP15] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1032, in recv_requests
[1,1]<stdout>:    control_reqs = broadcast_pyobj(
[1,1]<stdout>:                   ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.84]:63878
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 04:21:40 DP1 TP13] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1032, in recv_requests
[1,1]<stdout>:    control_reqs = broadcast_pyobj(
[1,1]<stdout>:                   ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.84]:63879
[1,1]<stdout>:
[1,1]<stdout>:[rank11]:[W1012 04:21:40.871248207 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx015.asp2p.nscc.sg]:50634, remote=[a2ap-dgx010.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank14]:[W1012 04:21:40.871233701 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=98, addr=[a2ap-dgx015.asp2p.nscc.sg]:38400, remote=[a2ap-dgx010.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank8]:[W1012 04:21:40.871258594 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=113, addr=[a2ap-dgx015.asp2p.nscc.sg]:50606, remote=[a2ap-[1,1]<stdout>:dgx010.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank15]:[W1012 04:21:40.871246998 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=98, addr=[a2ap-dgx015.asp2p.nscc.sg]:50622, remote=[a2ap-dgx010.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank12]:[W1012 04:21:40.871226050 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx015.asp2p.nscc.sg]:50618, remote=[a2ap-dgx010.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most rece[1,1]<stdout>:nt call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank9]:[W1012 04:21:40.871242532 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx015.asp2p.nscc.sg]:38430, remote=[a2ap-dgx010.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank13]:[W1012 04:21:40.871224465 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=98, addr=[a2ap-dgx015.asp2p.nscc.sg]:38410, remote=[a2ap-dgx010.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank10]:[W1012 04:21:40.871237091 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx015.asp2p.nscc.sg]:38426, remote=[a2ap-dgx010.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank15]:[W1012 04:21:40.877529793 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 15] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank8]:[W1012 04:21:40.877532511 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 8] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank13]:[W1012 04:21:40.877541837 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 13] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank10]:[W1012 04:21:40.877552383 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 10] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank9]:[W1012 04:21:40.877555498 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 9] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank14]:[W1012 04:21:40.877567069 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 14] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank11]:[W1012 04:21:40.877570194 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 11] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank12]:[W1012 04:21:40.877547056 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 12] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[2025-10-12 04:21:40 DP1 TP14] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1032, in recv_requests
[1,1]<stdout>:    control_reqs = broadcast_pyobj(
[1,1]<stdout>:                   ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.84]:41908
[1,1]<stdout>:
[1,0]<stdout>:[RANK 0] ? Benchmark completed
=>> PBS: job killed: walltime 1224 exceeded limit 1200
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-12 04:31:12.253580:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 97125.pbs111
	Project: 50000128
	Exit Status: -29
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 02:29:31
	Memory: Requested(3760gb), Used(32095800kb)
	Vmem Used: 82097057056kb
	Walltime: Requested(00:20:00), Used(00:20:38)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx010:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx015:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 20.74mins
	GPU Power Consumed: 291.19W
	GPU Max GPU Memory Used: 1.24TB
	Memory Throughput Rate (Average): a2ap-dgx010:(gpu1:3%+gpu0:3%+gpu2:3%+gpu3:3%+gpu5:3%+gpu4:3%+gpu6:3%+gpu7:3%)+a2ap-dgx015:(gpu1:4%+gpu0:3%+gpu2:3%+gpu3:3%+gpu5:3%+gpu4:3%+gpu6:3%+gpu7:3%)
	Memory Throughput Rate (Max): a2ap-dgx010:(gpu1:26%+gpu0:17%+gpu2:13%+gpu3:16%+gpu5:12%+gpu4:14%+gpu6:20%+gpu7:21%)+a2ap-dgx015:(gpu1:38%+gpu0:30%+gpu2:23%+gpu3:13%+gpu5:13%+gpu4:15%+gpu6:19%+gpu7:18%)
	Memory Throughput Rate (Min): a2ap-dgx010:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx015:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx010:(gpu1:38%+gpu0:38%+gpu2:33%+gpu3:39%+gpu5:38%+gpu4:39%+gpu6:39%+gpu7:38%)+a2ap-dgx015:(gpu1:34%+gpu0:40%+gpu2:37%+gpu3:40%+gpu5:39%+gpu4:40%+gpu6:36%+gpu7:38%)
	GPU SM Utilization (Max): a2ap-dgx010:(gpu1:99%+gpu0:97%+gpu2:99%+gpu3:97%+gpu5:96%+gpu4:100%+gpu6:97%+gpu7:100%)+a2ap-dgx015:(gpu1:97%+gpu0:97%+gpu2:98%+gpu3:98%+gpu5:97%+gpu4:99%+gpu6:97%+gpu7:99%)
	GPU SM Utilization (Min): a2ap-dgx010:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx015:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: None
GPU application profile: Medium
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

