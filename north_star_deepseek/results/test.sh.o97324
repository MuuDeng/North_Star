?? 2-NODE TP16+DP2 - OPTIMIZED PRODUCTION VERSION
========== OPTIMIZED 2-NODE TP16+DP2 ==========
Target: ~5min | Est. SU: 170.666 | Balance: 37733.765
N/A
Job ID: 97324.pbs111 | GPUs: 16 | Master: a2ap-dgx002.asp2p.nscc.sg:5000
Config: TP16+DP2+FA3+EAGLE | Model: DeepSeek-R1 671B
================================================
[20:37:05] Validating setup...
[20:37:05] ? Validation passed
[20:37:05] Launching optimized 2-node benchmark...
Warning: Permanently added 'a2ap-dgx013' (ED25519) to the list of known hosts.
[1,1]<stdout>:[RANK 1] Starting optimized benchmark...
[1,1]<stdout>:[RANK 1] DIST_INIT_ADDR: a2ap-dgx002.asp2p.nscc.sg:5000
[1,0]<stdout>:[RANK 0] Starting optimized benchmark...
[1,0]<stdout>:[RANK 0] DIST_INIT_ADDR: a2ap-dgx002.asp2p.nscc.sg:5000
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,0]<stdout>:[2025-10-12 20:38:21] Using default HuggingFace chat template with detected content format: string
[1,0]<stdout>:[2025-10-12 20:38:45 TP0] MLA optimization is turned on. Use fa3 backend.
[1,0]<stdout>:[2025-10-12 20:38:45 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-12 20:38:45 TP0] Init torch distributed begin.
[1,1]<stdout>:[W1012 20:38:46.214644695 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 20:38:46.697605462 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 20:38:47.946964045 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 20:38:47.677162724 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 20:38:48.721687157 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 20:38:49.566177408 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 20:38:49.669337725 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 20:38:49.680460379 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 20:38:49.693093163 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 20:38:52.790132007 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 20:38:53.841953429 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 20:38:54.420566852 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 20:38:55.387016806 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 20:38:59.610071580 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 20:39:02.943743669 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 20:39:02.395571968 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 20:39:02 TP0] sglang is using nccl==2.27.3
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 20:39:09 TP0] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 20:39:09 TP5] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 20:39:09 TP7] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 20:39:09 TP1] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 20:39:09 TP12] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 20:39:09 TP13] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 20:39:09 TP11] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 20:39:09 TP8] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 20:39:09 TP14] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 20:39:09 TP15] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 20:39:09 TP6] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 20:39:09 TP10] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 20:39:09 TP9] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 20:39:09 TP2] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 20:39:09 TP4] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 20:39:09 TP3] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 20:39:09 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 20:39:12 TP0] Init torch distributed ends. mem usage=1.75 GB
[1,1]<stdout>:[2025-10-12 20:39:13 TP9] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 20:39:13 TP8] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 20:39:13 TP10] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 20:39:13 TP12] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 20:39:13 TP15] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 20:39:13 TP14] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 20:39:13 TP13] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 20:39:13 TP11] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 20:39:14 TP5] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 20:39:14 TP7] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 20:39:14 TP6] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 20:39:14 TP4] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 20:39:14 TP3] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 20:39:14 TP1] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 20:39:14 TP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 20:39:14 TP2] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 20:39:16 TP0] Load weight begin. avail mem=76.79 GB
[1,0]<stdout>:[2025-10-12 20:39:16 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-12 20:39:26 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=35.23 GB, mem usage=41.56 GB.
[1,1]<stdout>:[2025-10-12 20:39:34 TP14] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 20:39:34 TP10] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 20:39:35 TP13] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 20:39:35 TP8] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 20:39:35 TP15] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 20:39:35 TP9] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 20:39:35 TP11] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 20:39:35 TP12] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 20:39:41 TP1] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 20:39:42 TP7] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 20:39:42 TP6] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 20:39:42 TP5] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 20:39:42 TP4] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 20:39:42 TP0] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 20:39:42 TP0] Memory pool end. avail mem=18.04 GB
[1,0]<stdout>:[2025-10-12 20:39:43 TP3] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 20:39:44 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.99 GB
[1,0]<stdout>:[2025-10-12 20:39:44 TP2] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 20:39:45 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 40, 48]
[1,0]<stdout>:  0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=17.78 GB):   0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-12 20:39:48 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:48 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 20:39:48 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:48 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:48 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:48 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:48 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:48 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:48 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:48 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:48 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 20:39:48 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:48 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:48 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:48 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:48 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:48 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][A[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 784.11it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 889.89it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 1044.82it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 1112.99it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 369.60it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 899.74it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 361.65it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 379.93it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 570.33it/s]
[1,1]<stdout>:[2025-10-12 20:39:49 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:49 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:49 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 20:39:49 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:49 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:49 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:49 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:49 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:49 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 20:39:49 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s]100% 33/33 [00:00<00:00, 3756.09it/s]
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 3365.40it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 3767.95it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 3577.46it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 3731.99it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 2157.56it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 2145.29it/s]
[1,0]<stdout>:[2025-10-12 20:39:49 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:49 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:49 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:49 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:49 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:49 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:49 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][A[1,1]<stdout>: 39% 17/44 [00:00<00:00, 167.55it/s][1,1]<stdout>:100% 44/44 [00:00<00:00, 761.74it/s]
[1,1]<stdout>:100% 44/44 [00:00<00:00, 795.43it/s][1,1]<stdout>:
[1,1]<stdout>:100% 44/44 [00:00<00:00, 396.05it/s]
[1,1]<stdout>:100% 44/44 [00:00<00:00, 432.76it/s]100% 44/44 [00:00<00:00, 700.73it/s]100% 44/44 [00:00<00:00, 836.37it/s]
[1,0]<stdout>:100% 44/44 [00:00<00:00, 1255.92it/s]
[1,1]<stdout>:
[1,1]<stdout>:100% 44/44 [00:00<00:00, 822.44it/s]
[1,1]<stdout>:100% 44/44 [00:00<00:00, 432.31it/s]
[1,1]<stdout>:100% 44/44 [00:00<00:00, 406.47it/s][1,1]<stdout>:100% 44/44 [00:00<00:00, 406.14it/s]
[1,1]<stdout>:[2025-10-12 20:39:50 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 20:39:50 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:100% 44/44 [00:00<00:00, 7885.38it/s]
[1,0]<stdout>:[2025-10-12 20:39:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 20:39:50 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-12 20:39:50 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 44/44 [00:00<00:00, 3404.34it/s]
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:100% 44/44 [00:00<00:00, 3164.54it/s]
[1,0]<stdout>:100% 44/44 [00:00<00:00, 4554.41it/s]
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:100% 44/44 [00:00<00:00, 4072.68it/s]
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:100% 44/44 [00:00<00:00, 6368.60it/s]
[1,0]<stdout>:100% 44/44 [00:00<00:00, 5949.18it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 978.41it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 2706.33it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 1173.87it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 20522.59it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 19605.28it/s][1,1]<stdout>:
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 17833.87it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 20880.17it/s][1,1]<stdout>:
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 14155.00it/s]
[1,1]<stdout>:[2025-10-12 20:39:50 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 20:39:50 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:50 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:50 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:50 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:50 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:51 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:51 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:51 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][A[1,0]<stdout>:100% 16/16 [00:00<00:00, 1117.81it/s]
[1,0]<stdout>:[2025-10-12 20:39:51 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 20:39:51 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 1552.51it/s]
[1,1]<stdout>:100% 32/32 [00:00<00:00, 2054.77it/s][1,1]<stdout>:
[1,1]<stdout>:100% 32/32 [00:00<00:00, 437.80it/s]
[1,1]<stdout>:100% 32/32 [00:00<00:00, 9379.95it/s]
[1,1]<stdout>:100% 32/32 [00:00<00:00, 445.10it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 389.49it/s]
[1,1]<stdout>:100% 32/32 [00:00<00:00, 1738.53it/s]
[1,1]<stdout>:100% 32/32 [00:00<00:00, 14374.82it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 4896.67it/s]
[1,0]<stdout>:[2025-10-12 20:39:51 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 6631.31it/s]
[1,0]<stdout>:[2025-10-12 20:39:51 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 8793.09it/s]
[1,0]<stdout>:[2025-10-12 20:39:51 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 6680.16it/s]
[1,0]<stdout>:[2025-10-12 20:39:51 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 7215.23it/s]
[1,0]<stdout>:[2025-10-12 20:39:52 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 3720.83it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 2385.41it/s]
[1,0]<stdout>:[2025-10-12 20:39:52 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:52 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:52 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:52 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:52 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 20:39:52 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:52 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:52 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:52 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:52 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:39:52 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 4336.32it/s]
[1,0]<stdout>:[2025-10-12 20:39:52 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][A[1,0]<stdout>:100% 32/32 [00:00<00:00, 9255.76it/s]
[1,0]<stdout>:[2025-10-12 20:39:52 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 20:39:52 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 742.12it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 1954.93it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 922.18it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 14519.44it/s][1,1]<stdout>:
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 19295.25it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 14242.12it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 16170.81it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 14535.17it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 3799.19it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 7097.34it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 8334.43it/s]
[1,0]<stdout>:[2025-10-12 20:39:52 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:52 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 8244.33it/s]
[1,0]<stdout>:[2025-10-12 20:39:52 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 8594.89it/s]
[1,0]<stdout>:[2025-10-12 20:39:52 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][A[1,0]<stdout>:100% 32/32 [00:00<00:00, 2988.06it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 6030.63it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 3550.17it/s]
[1,0]<stdout>:[2025-10-12 20:39:53 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:39:53 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 5734.82it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 5868.72it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 6320.29it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 6883.67it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 6245.01it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 9769.82it/s]
[1,1]<stdout>:[2025-10-12 20:39:54 TP11] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 20:39:54 TP10] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 20:39:54 TP14] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 20:39:54 TP13] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 20:39:54 TP12] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 20:39:54 TP8] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 20:39:54 TP9] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 20:39:54 TP15] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 20:39:54 TP6] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 20:39:54 TP5] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 20:39:54 TP1] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 20:39:54 TP4] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 20:39:54 TP0] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 20:39:54 TP7] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 20:39:54 TP3] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 20:39:54 TP2] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:Capturing batches (bs=48 avail_mem=17.78 GB):   5% 1/22 [00:09<03:20,  9.54s/it][1,0]<stdout>:Capturing batches (bs=40 avail_mem=17.52 GB):   5% 1/22 [00:09<03:20,  9.54s/it][1,0]<stdout>:Capturing batches (bs=40 avail_mem=17.52 GB):   9% 2/22 [00:10<01:35,  4.77s/it][1,0]<stdout>:Capturing batches (bs=32 avail_mem=17.50 GB):   9% 2/22 [00:10<01:35,  4.77s/it][1,0]<stdout>:Capturing batches (bs=32 avail_mem=17.50 GB):  14% 3/22 [00:12<00:59,  3.14s/it][1,0]<stdout>:Capturing batches (bs=30 avail_mem=17.47 GB):  14% 3/22 [00:12<00:59,  3.14s/it][1,0]<stdout>:Capturing batches (bs=30 avail_mem=17.47 GB):  18% 4/22 [00:13<00:40,  2.24s/it][1,0]<stdout>:Capturing batches (bs=28 avail_mem=17.44 GB):  18% 4/22 [00:13<00:40,  2.24s/it][1,0]<stdout>:Capturing batches (bs=28 avail_mem=17.44 GB):  23% 5/22 [00:13<00:29,  1.76s/it][1,0]<stdout>:Capturing batches (bs=26 avail_mem=17.41 GB):  23% 5/22 [00:13<00:29,  1.76s/it][1,0]<stdout>:Capturing batches (bs=26 avail_mem=17.41 GB):  27% 6/22 [00:15<00:24,  1.56s/it][1,0]<stdout>:Capturing batches (bs=24 avail_mem=17.39 GB):  27% 6/22 [00:15<00:24,  1.56s/it][1,0]<stdout>:Capturing batches (bs=24 avail_mem=17.39 GB):  32% 7/22 [00:15<00:20,  1.34s/it]Capturing batches (bs=22 avail_mem=17.36 GB):  32% 7/22 [00:15<00:20,  1.34s/it][1,0]<stdout>:Capturing batches (bs=22 avail_mem=17.36 GB):  36% 8/22 [00:16<00:17,  1.22s/it]Capturing batches (bs=20 avail_mem=17.33 GB):  36% 8/22 [00:16<00:17,  1.22s/it][1,0]<stdout>:Capturing batches (bs=20 avail_mem=17.33 GB):  41% 9/22 [00:17<00:14,  1.11s/it][1,0]<stdout>:Capturing batches (bs=18 avail_mem=17.30 GB):  41% 9/22 [00:17<00:14,  1.11s/it][1,0]<stdout>:Capturing batches (bs=18 avail_mem=17.30 GB):  45% 10/22 [00:18<00:11,  1.01it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=17.27 GB):  45% 10/22 [00:18<00:11,  1.01it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=17.27 GB):  50% 11/22 [00:19<00:11,  1.04s/it][1,0]<stdout>:Capturing batches (bs=14 avail_mem=17.25 GB):  50% 11/22 [00:19<00:11,  1.04s/it][1,0]<stdout>:Capturing batches (bs=14 avail_mem=17.25 GB):  55% 12/22 [00:20<00:10,  1.01s/it]Capturing batches (bs=12 avail_mem=17.22 GB):  55% 12/22 [00:20<00:10,  1.01s/it][1,0]<stdout>:Capturing batches (bs=12 avail_mem=17.22 GB):  59% 13/22 [00:21<00:08,  1.06it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=17.19 GB):  59% 13/22 [00:21<00:08,  1.06it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=17.19 GB):  64% 14/22 [00:22<00:07,  1.08it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=17.17 GB):  64% 14/22 [00:22<00:07,  1.08it/s] [1,0]<stdout>:Capturing batches (bs=8 avail_mem=17.17 GB):  68% 15/22 [00:23<00:06,  1.09it/s][1,0]<stdout>:Capturing batches (bs=7 avail_mem=17.14 GB):  68% 15/22 [00:23<00:06,  1.09it/s][1,0]<stdout>:Capturing batches (bs=7 avail_mem=17.14 GB):  73% 16/22 [00:23<00:05,  1.19it/s][1,0]<stdout>:Capturing batches (bs=6 avail_mem=17.11 GB):  73% 16/22 [00:23<00:05,  1.19it/s][1,0]<stdout>:Capturing batches (bs=6 avail_mem=17.11 GB):  77% 17/22 [00:24<00:03,  1.26it/s]Capturing batches (bs=5 avail_mem=17.09 GB):  77% 17/22 [00:24<00:03,  1.26it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=17.09 GB):  82% 18/22 [00:25<00:03,  1.31it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=17.06 GB):  82% 18/22 [00:25<00:03,  1.31it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=17.06 GB):  86% 19/22 [00:25<00:02,  1.33it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=17.04 GB):  86% 19/22 [00:25<00:02,  1.33it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=17.04 GB):  91% 20/22 [00:27<00:02,  1.10s/it][1,0]<stdout>:Capturing batches (bs=2 avail_mem=17.01 GB):  91% 20/22 [00:27<00:02,  1.10s/it][1,0]<stdout>:Capturing batches (bs=2 avail_mem=17.01 GB):  95% 21/22 [00:28<00:01,  1.02s/it][1,0]<stdout>:Capturing batches (bs=1 avail_mem=16.98 GB):  95% 21/22 [00:28<00:01,  1.02s/it][1,0]<stdout>:Capturing batches (bs=1 avail_mem=16.98 GB): 100% 22/22 [00:30<00:00,  1.25s/it]Capturing batches (bs=1 avail_mem=16.98 GB): 100% 22/22 [00:30<00:00,  1.39s/it]
[1,0]<stdout>:[2025-10-12 20:40:16 TP0] Capture cuda graph end. Time elapsed: 32.40 s. mem usage=1.04 GB. avail mem=16.96 GB.
[1,0]<stdout>:[2025-10-12 20:40:17 TP0] MLA optimization is turned on. Use fa3 backend.
[1,0]<stdout>:[2025-10-12 20:40:17 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-12 20:40:17 TP0] Init torch distributed begin.
[1,0]<stdout>:[2025-10-12 20:40:17 TP0] Init torch distributed ends. mem usage=0.00 GB
[1,0]<stdout>:[2025-10-12 20:40:17 TP0] Load weight begin. avail mem=16.96 GB
[1,0]<stdout>:[2025-10-12 20:40:17 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-12 20:40:18 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.84 GB, mem usage=1.12 GB.
[1,1]<stdout>:[2025-10-12 20:40:18 TP13] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 20:40:18 TP12] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 20:40:18 TP11] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 20:40:18 TP9] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 20:40:18 TP15] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 20:40:18 TP10] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 20:40:18 TP8] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 20:40:18 TP5] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 20:40:18 TP0] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 20:40:18 TP0] Memory pool end. avail mem=15.56 GB
[1,0]<stdout>:[2025-10-12 20:40:18 TP4] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 20:40:18 TP1] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 20:40:18 TP3] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 20:40:18 TP14] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 20:40:18 TP7] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 20:40:18 TP6] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 20:40:18 TP2] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 20:40:19 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.75 GB
[1,1]<stdout>:[2025-10-12 20:40:19 TP8] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,1]<stdout>:[2025-10-12 20:40:19 TP12] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,0]<stdout>:[2025-10-12 20:40:19 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,0]<stdout>:[2025-10-12 20:40:19 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.72 GB
[1,0]<stdout>:[2025-10-12 20:40:19 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,0]<stdout>:[2025-10-12 20:40:19 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,1]<stdout>:[2025-10-12 20:40:19 TP11] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.74 GB
[1,1]<stdout>:[2025-10-12 20:40:19 TP9] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.74 GB
[1,0]<stdout>:[2025-10-12 20:40:19 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.75 GB
[1,0]<stdout>:[2025-10-12 20:40:19 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.74 GB
[1,0]<stdout>:[2025-10-12 20:40:19 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.74 GB
[1,1]<stdout>:[2025-10-12 20:40:19 TP13] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.75 GB
[1,1]<stdout>:[2025-10-12 20:40:19 TP14] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,1]<stdout>:[2025-10-12 20:40:19 TP15] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.75 GB
[1,1]<stdout>:[2025-10-12 20:40:19 TP10] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,0]<stdout>:  0% 0/22 [00:00<?, ?it/s]Capturing batches (bs=48 avail_mem=15.60 GB):   0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=15.60 GB):   5% 1/22 [00:00<00:11,  1.78it/s][1,0]<stdout>:Capturing batches (bs=40 avail_mem=15.60 GB):   5% 1/22 [00:00<00:11,  1.78it/s][1,0]<stdout>:Capturing batches (bs=40 avail_mem=15.60 GB):   9% 2/22 [00:00<00:08,  2.38it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=15.60 GB):   9% 2/22 [00:00<00:08,  2.38it/s][1,0]<stdout>:Capturing batches (bs=30 avail_mem=15.60 GB):   9% 2/22 [00:00<00:08,  2.38it/s][1,0]<stdout>:Capturing batches (bs=28 avail_mem=15.60 GB):   9% 2/22 [00:00<00:08,  2.38it/s][1,0]<stdout>:Capturing batches (bs=28 avail_mem=15.60 GB):  23% 5/22 [00:01<00:02,  6.58it/s][1,0]<stdout>:Capturing batches (bs=26 avail_mem=15.60 GB):  23% 5/22 [00:01<00:02,  6.58it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=15.60 GB):  23% 5/22 [00:01<00:02,  6.58it/s][1,0]<stdout>:Capturing batches (bs=22 avail_mem=15.60 GB):  23% 5/22 [00:01<00:02,  6.58it/s][1,0]<stdout>:Capturing batches (bs=22 avail_mem=15.60 GB):  36% 8/22 [00:01<00:01, 10.75it/s][1,0]<stdout>:Capturing batches (bs=20 avail_mem=15.60 GB):  36% 8/22 [00:01<00:01, 10.75it/s][1,0]<stdout>:Capturing batches (bs=18 avail_mem=15.60 GB):  36% 8/22 [00:01<00:01, 10.75it/s][1,0]<stdout>:Capturing batches (bs=18 avail_mem=15.60 GB):  45% 10/22 [00:01<00:01, 11.54it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=15.60 GB):  45% 10/22 [00:01<00:01, 11.54it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=15.60 GB):  45% 10/22 [00:01<00:01, 11.54it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=15.60 GB):  55% 12/22 [00:01<00:00, 10.67it/s][1,0]<stdout>:Capturing batches (bs=12 avail_mem=15.60 GB):  55% 12/22 [00:01<00:00, 10.67it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=15.60 GB):  55% 12/22 [00:01<00:00, 10.67it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=15.60 GB):  64% 14/22 [00:01<00:00, 10.53it/s]Capturing batches (bs=8 avail_mem=15.60 GB):  64% 14/22 [00:01<00:00, 10.53it/s] [1,0]<stdout>:Capturing batches (bs=7 avail_mem=15.60 GB):  64% 14/22 [00:01<00:00, 10.53it/s][1,0]<stdout>:Capturing batches (bs=7 avail_mem=15.60 GB):  73% 16/22 [00:01<00:00, 10.56it/s][1,0]<stdout>:Capturing batches (bs=6 avail_mem=15.60 GB):  73% 16/22 [00:01<00:00, 10.56it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=15.60 GB):  73% 16/22 [00:01<00:00, 10.56it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=15.60 GB):  82% 18/22 [00:02<00:00, 10.67it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=15.60 GB):  82% 18/22 [00:02<00:00, 10.67it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=15.60 GB):  82% 18/22 [00:02<00:00, 10.67it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=15.60 GB):  91% 20/22 [00:02<00:00, 10.70it/s][1,0]<stdout>:Capturing batches (bs=2 avail_mem=15.60 GB):  91% 20/22 [00:02<00:00, 10.70it/s][1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.60 GB):  91% 20/22 [00:02<00:00, 10.70it/s][1,1]<stdout>:[2025-10-12 20:40:23 TP15] Capture draft cuda graph end. Time elapsed: 4.69 s. mem usage=0.14 GB. avail mem=15.61 GB.
[1,1]<stdout>:[2025-10-12 20:40:23 TP14] Capture draft cuda graph end. Time elapsed: 4.69 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,1]<stdout>:[2025-10-12 20:40:23 TP10] Capture draft cuda graph end. Time elapsed: 4.62 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,1]<stdout>:[2025-10-12 20:40:23 TP12] Capture draft cuda graph end. Time elapsed: 4.74 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,1]<stdout>:[2025-10-12 20:40:23 TP11] Capture draft cuda graph end. Time elapsed: 4.70 s. mem usage=0.14 GB. avail mem=15.60 GB.
[1,1]<stdout>:[2025-10-12 20:40:23 TP14] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,1]<stdout>:[2025-10-12 20:40:23 TP15] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.61 GB
[1,1]<stdout>:[2025-10-12 20:40:23 TP10] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,1]<stdout>:[2025-10-12 20:40:23 TP12] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,1]<stdout>:[2025-10-12 20:40:23 TP11] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.60 GB
[1,1]<stdout>:[2025-10-12 20:40:23 TP13] Capture draft cuda graph end. Time elapsed: 4.70 s. mem usage=0.14 GB. avail mem=15.61 GB.
[1,1]<stdout>:[2025-10-12 20:40:23 TP9] Capture draft cuda graph end. Time elapsed: 4.70 s. mem usage=0.14 GB. avail mem=15.60 GB.
[1,0]<stdout>:[2025-10-12 20:40:23 TP4] Capture draft cuda graph end. Time elapsed: 4.74 s. mem usage=0.14 GB. avail mem=15.61 GB.
[1,0]<stdout>:[2025-10-12 20:40:23 TP5] Capture draft cuda graph end. Time elapsed: 4.70 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,1]<stdout>:[2025-10-12 20:40:23 TP8] Capture draft cuda graph end. Time elapsed: 4.74 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,0]<stdout>:[2025-10-12 20:40:23 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.61 GB
[1,0]<stdout>:[2025-10-12 20:40:23 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,0]<stdout>:[2025-10-12 20:40:23 TP2] Capture draft cuda graph end. Time elapsed: 4.70 s. mem usage=0.14 GB. avail mem=15.60 GB.
[1,0]<stdout>:[2025-10-12 20:40:23 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.60 GB
[1,0]<stdout>:[2025-10-12 20:40:23 TP6] Capture draft cuda graph end. Time elapsed: 4.70 s. mem usage=0.14 GB. avail mem=15.61 GB.
[1,0]<stdout>:[2025-10-12 20:40:23 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.61 GB
[1,0]<stdout>:[2025-10-12 20:40:23 TP3] Capture draft cuda graph end. Time elapsed: 4.71 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,0]<stdout>:[2025-10-12 20:40:23 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,0]<stdout>:[2025-10-12 20:40:23 TP1] Capture draft cuda graph end. Time elapsed: 4.71 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.60 GB): 100% 22/22 [00:03<00:00,  5.15it/s][1,0]<stdout>:[2025-10-12 20:40:23 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.60 GB): 100% 22/22 [00:03<00:00,  7.11it/s]
[1,0]<stdout>:[2025-10-12 20:40:23 TP7] Capture draft cuda graph end. Time elapsed: 4.71 s. mem usage=0.14 GB. avail mem=15.58 GB.
[1,0]<stdout>:[2025-10-12 20:40:23 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.58 GB
[1,0]<stdout>:[2025-10-12 20:40:23 TP0] Capture draft cuda graph end. Time elapsed: 4.70 s. mem usage=0.14 GB. avail mem=15.60 GB.
[1,0]<stdout>:[2025-10-12 20:40:23 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.60 GB
[1,1]<stdout>:[2025-10-12 20:40:23 TP9] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.60 GB
[1,1]<stdout>:[2025-10-12 20:40:23 TP13] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.61 GB
[1,1]<stdout>:[2025-10-12 20:40:23 TP8] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,0]<stdout>:  0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=15.40 GB):   0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=15.40 GB):   5% 1/22 [00:00<00:15,  1.34it/s]Capturing batches (bs=40 avail_mem=15.18 GB):   5% 1/22 [00:00<00:15,  1.34it/s][1,0]<stdout>:Capturing batches (bs=40 avail_mem=15.18 GB):   9% 2/22 [00:01<00:09,  2.17it/s]Capturing batches (bs=32 avail_mem=15.18 GB):   9% 2/22 [00:01<00:09,  2.17it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=15.18 GB):  14% 3/22 [00:01<00:05,  3.35it/s]Capturing batches (bs=30 avail_mem=15.18 GB):  14% 3/22 [00:01<00:05,  3.35it/s][1,0]<stdout>:Capturing batches (bs=30 avail_mem=15.18 GB):  18% 4/22 [00:01<00:04,  4.46it/s][1,0]<stdout>:Capturing batches (bs=28 avail_mem=15.18 GB):  18% 4/22 [00:01<00:04,  4.46it/s][1,0]<stdout>:Capturing batches (bs=28 avail_mem=15.18 GB):  23% 5/22 [00:01<00:05,  3.29it/s]Capturing batches (bs=26 avail_mem=15.17 GB):  23% 5/22 [00:01<00:05,  3.29it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=15.17 GB):  23% 5/22 [00:01<00:05,  3.29it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=15.17 GB):  32% 7/22 [00:02<00:03,  4.12it/s][1,0]<stdout>:Capturing batches (bs=22 avail_mem=15.17 GB):  32% 7/22 [00:02<00:03,  4.12it/s][1,0]<stdout>:Capturing batches (bs=22 avail_mem=15.17 GB):  36% 8/22 [00:02<00:03,  4.46it/s][1,0]<stdout>:Capturing batches (bs=20 avail_mem=15.17 GB):  36% 8/22 [00:02<00:03,  4.46it/s][1,0]<stdout>:Capturing batches (bs=20 avail_mem=15.17 GB):  41% 9/22 [00:02<00:02,  4.71it/s][1,0]<stdout>:Capturing batches (bs=18 avail_mem=15.17 GB):  41% 9/22 [00:02<00:02,  4.71it/s][1,0]<stdout>:Capturing batches (bs=18 avail_mem=15.17 GB):  45% 10/22 [00:02<00:02,  4.61it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=15.17 GB):  45% 10/22 [00:02<00:02,  4.61it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=15.17 GB):  50% 11/22 [00:02<00:02,  4.75it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=15.17 GB):  50% 11/22 [00:02<00:02,  4.75it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=15.17 GB):  55% 12/22 [00:02<00:01,  5.36it/s][1,0]<stdout>:Capturing batches (bs=12 avail_mem=15.17 GB):  55% 12/22 [00:02<00:01,  5.36it/s][1,0]<stdout>:Capturing batches (bs=12 avail_mem=15.17 GB):  59% 13/22 [00:03<00:01,  5.53it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=15.17 GB):  59% 13/22 [00:03<00:01,  5.53it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=15.16 GB):  59% 13/22 [00:03<00:01,  5.53it/s] [1,0]<stdout>:Capturing batches (bs=8 avail_mem=15.16 GB):  68% 15/22 [00:03<00:00,  8.03it/s][1,0]<stdout>:Capturing batches (bs=7 avail_mem=15.16 GB):  68% 15/22 [00:03<00:00,  8.03it/s][1,0]<stdout>:Capturing batches (bs=6 avail_mem=15.16 GB):  68% 15/22 [00:03<00:00,  8.03it/s][1,0]<stdout>:Capturing batches (bs=6 avail_mem=15.16 GB):  77% 17/22 [00:03<00:00,  9.52it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=15.16 GB):  77% 17/22 [00:03<00:00,  9.52it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=15.16 GB):  77% 17/22 [00:03<00:00,  9.52it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=15.16 GB):  86% 19/22 [00:03<00:00,  9.88it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=15.16 GB):  86% 19/22 [00:03<00:00,  9.88it/s][1,0]<stdout>:Capturing batches (bs=2 avail_mem=15.16 GB):  86% 19/22 [00:03<00:00,  9.88it/s][1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.16 GB):  86% 19/22 [00:03<00:00,  9.88it/s][1,0]<stdout>:[2025-10-12 20:40:29 TP7] Capture draft extend cuda graph end. Time elapsed: 5.30 s. mem usage=0.44 GB. avail mem=15.14 GB.
[1,0]<stdout>:[2025-10-12 20:40:29 TP4] Capture draft extend cuda graph end. Time elapsed: 5.30 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,1]<stdout>:[2025-10-12 20:40:29 TP15] Capture draft extend cuda graph end. Time elapsed: 5.31 s. mem usage=0.44 GB. avail mem=15.17 GB.
[1,1]<stdout>:[2025-10-12 20:40:29 TP14] Capture draft extend cuda graph end. Time elapsed: 5.31 s. mem usage=0.44 GB. avail mem=15.13 GB.
[1,1]<stdout>:[2025-10-12 20:40:29 TP12] Capture draft extend cuda graph end. Time elapsed: 5.31 s. mem usage=0.44 GB. avail mem=15.13 GB.
[1,1]<stdout>:[2025-10-12 20:40:29 TP13] Capture draft extend cuda graph end. Time elapsed: 5.31 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:[2025-10-12 20:40:29 TP6] Capture draft extend cuda graph end. Time elapsed: 5.31 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:[2025-10-12 20:40:29 TP5] Capture draft extend cuda graph end. Time elapsed: 5.31 s. mem usage=0.44 GB. avail mem=15.13 GB.
[1,1]<stdout>:[2025-10-12 20:40:29 TP10] Capture draft extend cuda graph end. Time elapsed: 5.32 s. mem usage=0.44 GB. avail mem=15.12 GB.
[1,1]<stdout>:[2025-10-12 20:40:29 TP11] Capture draft extend cuda graph end. Time elapsed: 5.32 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:[2025-10-12 20:40:29 TP3] Capture draft extend cuda graph end. Time elapsed: 5.32 s. mem usage=0.44 GB. avail mem=15.12 GB.
[1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.16 GB): 100% 22/22 [00:03<00:00, 12.48it/s]Capturing batches (bs=1 avail_mem=15.16 GB): 100% 22/22 [00:03<00:00,  5.91it/s]
[1,1]<stdout>:[2025-10-12 20:40:29 TP8] Capture draft extend cuda graph end. Time elapsed: 5.32 s. mem usage=0.44 GB. avail mem=15.12 GB.
[1,1]<stdout>:[2025-10-12 20:40:29 TP9] Capture draft extend cuda graph end. Time elapsed: 5.32 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:[2025-10-12 20:40:29 TP0] Capture draft extend cuda graph end. Time elapsed: 5.33 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:[2025-10-12 20:40:29 TP0] max_total_num_tokens=250610, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=48, context_len=163840, available_gpu_mem=15.16 GB
[1,0]<stdout>:[2025-10-12 20:40:29 TP2] Capture draft extend cuda graph end. Time elapsed: 5.34 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:[2025-10-12 20:40:29 TP1] Capture draft extend cuda graph end. Time elapsed: 5.34 s. mem usage=0.44 GB. avail mem=15.12 GB.
[1,1]<stdout>:[2025-10-12 20:40:29] Starting dummy health check server at 127.0.0.1:30000
[1,0]<stdout>:#Input tokens: 626729
[1,0]<stdout>:#Output tokens: 388685
[1,0]<stdout>:#Input tokens: 4096
[1,0]<stdout>:#Output tokens: 256
[1,0]<stdout>:[2025-10-12 20:40:44] 
[1,0]<stdout>:Warmup...
[1,0]<stdout>:[2025-10-12 20:40:44 TP0] Prefill batch. #new-seq: 10, #new-token: 2570, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 20:40:48 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:40:48 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:40:48 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:40:48 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:40:48 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:40:48 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:40:48 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 20:40:48 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 20:40:48 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:40:48 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:40:48 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:40:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 20:40:48 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:40:48 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:40:48 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:40:48 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:40:48 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 20:40:48 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s]  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:100% 35/35 [00:00<00:00, 715.11it/s]
[1,1]<stdout>:100% 35/35 [00:00<00:00, 1119.74it/s]
[1,1]<stdout>:100% 35/35 [00:00<00:00, 882.92it/s]
[1,1]<stdout>:100% 35/35 [00:00<00:00, 744.09it/s][1,1]<stdout>:
[1,1]<stdout>:100% 35/35 [00:00<00:00, 627.29it/s]
[1,1]<stdout>:100% 35/35 [00:00<00:00, 3179.98it/s][1,1]<stdout>:
[1,1]<stdout>:100% 35/35 [00:00<00:00, 629.54it/s]
[1,1]<stdout>:100% 35/35 [00:00<00:00, 1284.87it/s]
[1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 3573.10it/s]
[1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 5608.22it/s]
[1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 8825.34it/s]
[1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 7874.73it/s]
[1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 7808.54it/s]
[1,0]<stdout>:100% 35/35 [00:00<00:00, 6601.64it/s]
[1,0]<stdout>:100% 35/35 [00:00<00:00, 3302.60it/s]
[1,0]<stdout>:100% 35/35 [00:00<00:00, 2188.90it/s]
[1,0]<stdout>:[2025-10-12 20:40:51 TP0] Prefill batch. #new-seq: 6, #new-token: 1527, #cached-token: 15, token usage: 0.01, #running-req: 10, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 20:40:52] 
[1,0]<stdout>:Benchmark...
[1,0]<stdout>:[2025-10-12 20:40:52 TP0] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 20:40:53 TP0] Prefill batch. #new-seq: 30, #new-token: 8192, #cached-token: 35, token usage: 0.00, #running-req: 1, #queue-req: 424, 
[1,0]<stdout>:[2025-10-12 20:40:54 TP0] Prefill batch. #new-seq: 18, #new-token: 5613, #cached-token: 22, token usage: 0.03, #running-req: 30, #queue-req: 1921, 
[1,0]<stdout>:[2025-10-12 20:40:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1904, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1951, 
[1,0]<stdout>:[2025-10-12 20:40:57 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1950, 
[1,0]<stdout>:[2025-10-12 20:40:59 TP0] Prefill batch. #new-seq: 3, #new-token: 1140, #cached-token: 8, token usage: 0.06, #running-req: 45, #queue-req: 1947, 
[1,0]<stdout>:[2025-10-12 20:40:59 TP0] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1946, 
[1,0]<stdout>:[2025-10-12 20:41:00 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1945, 
[1,0]<stdout>:[2025-10-12 20:41:00 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1944, 
[1,0]<stdout>:[2025-10-12 20:41:00 TP0] Prefill batch. #new-seq: 2, #new-token: 17, #cached-token: 3, token usage: 0.05, #running-req: 46, #queue-req: 1942, 
[1,0]<stdout>:[2025-10-12 20:41:01 TP0] Prefill batch. #new-seq: 2, #new-token: 61, #cached-token: 2, token usage: 0.05, #running-req: 46, #queue-req: 1940, 
[1,0]<stdout>:[2025-10-12 20:41:01 TP0] Decode batch. #running-req: 48, #token: 13877, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 44.09, #queue-req: 1940, 
[1,0]<stdout>:[2025-10-12 20:41:01 TP0] Prefill batch. #new-seq: 2, #new-token: 51, #cached-token: 3, token usage: 0.05, #running-req: 46, #queue-req: 1938, 
[1,0]<stdout>:[2025-10-12 20:41:02 TP0] Prefill batch. #new-seq: 2, #new-token: 349, #cached-token: 3, token usage: 0.05, #running-req: 46, #queue-req: 1936, 
[1,0]<stdout>:[2025-10-12 20:41:03 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1935, 
[1,0]<stdout>:[2025-10-12 20:41:03 TP0] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1934, 
[1,0]<stdout>:[2025-10-12 20:41:03 TP0] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1933, 
[1,0]<stdout>:[2025-10-12 20:41:04 TP0] Decode batch. #running-req: 48, #token: 14598, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 760.64, #queue-req: 1933, 
[1,0]<stdout>:[2025-10-12 20:41:04 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1932, 
[1,0]<stdout>:[2025-10-12 20:41:04 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1931, 
[1,0]<stdout>:[2025-10-12 20:41:05 TP0] Prefill batch. #new-seq: 2, #new-token: 572, #cached-token: 4, token usage: 0.06, #running-req: 46, #queue-req: 1929, 
[1,0]<stdout>:[2025-10-12 20:41:06 TP0] Decode batch. #running-req: 47, #token: 14800, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 895.19, #queue-req: 1929, 
[1,0]<stdout>:[2025-10-12 20:41:06 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1928, 
[1,0]<stdout>:[2025-10-12 20:41:06 TP0] Prefill batch. #new-seq: 1, #new-token: 771, #cached-token: 7, token usage: 0.06, #running-req: 47, #queue-req: 1927, 
[1,0]<stdout>:[2025-10-12 20:41:07 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1926, 
[1,0]<stdout>:[2025-10-12 20:41:08 TP0] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1925, 
[1,0]<stdout>:[2025-10-12 20:41:09 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1924, 
[1,0]<stdout>:[2025-10-12 20:41:09 TP0] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 6, token usage: 0.06, #running-req: 47, #queue-req: 1923, 
[1,0]<stdout>:[2025-10-12 20:41:09 TP0] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1922, 
[1,0]<stdout>:[2025-10-12 20:41:09 TP0] Prefill batch. #new-seq: 2, #new-token: 884, #cached-token: 3, token usage: 0.06, #running-req: 46, #queue-req: 1920, 
[1,0]<stdout>:[2025-10-12 20:41:10 TP0] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1919, 
[1,0]<stdout>:[2025-10-12 20:41:10 TP0] Prefill batch. #new-seq: 1, #new-token: 3866, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1918, 
[1,0]<stdout>:[2025-10-12 20:41:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1381, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1917, 
[1,0]<stdout>:[2025-10-12 20:41:11 TP0] Prefill batch. #new-seq: 1, #new-token: 621, #cached-token: 9, token usage: 0.07, #running-req: 47, #queue-req: 1916, 
[1,0]<stdout>:[2025-10-12 20:41:11 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1915, 
[1,0]<stdout>:[2025-10-12 20:41:11 TP0] Decode batch. #running-req: 48, #token: 17697, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 339.09, #queue-req: 1915, 
[1,0]<stdout>:[2025-10-12 20:41:12 TP0] Prefill batch. #new-seq: 2, #new-token: 487, #cached-token: 3, token usage: 0.07, #running-req: 46, #queue-req: 1913, 
[1,0]<stdout>:[2025-10-12 20:41:12 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1912, 
[1,0]<stdout>:[2025-10-12 20:41:12 TP0] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 1911, 
[1,0]<stdout>:[2025-10-12 20:41:13 TP0] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1910, 
[1,0]<stdout>:[2025-10-12 20:41:13 TP0] Prefill batch. #new-seq: 1, #new-token: 773, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1909, 
[1,0]<stdout>:[2025-10-12 20:41:14 TP0] Decode batch. #running-req: 47, #token: 17383, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 849.90, #queue-req: 1909, 
[1,0]<stdout>:[2025-10-12 20:41:14 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1908, 
[1,0]<stdout>:[2025-10-12 20:41:14 TP0] Prefill batch. #new-seq: 2, #new-token: 76, #cached-token: 3, token usage: 0.07, #running-req: 46, #queue-req: 1906, 
[1,0]<stdout>:[2025-10-12 20:41:14 TP0] Prefill batch. #new-seq: 2, #new-token: 267, #cached-token: 4, token usage: 0.07, #running-req: 46, #queue-req: 1904, 
[1,0]<stdout>:[2025-10-12 20:41:15 TP0] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1903, 
[1,0]<stdout>:[2025-10-12 20:41:15 TP0] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1902, 
[1,0]<stdout>:[2025-10-12 20:41:15 TP0] Prefill batch. #new-seq: 2, #new-token: 360, #cached-token: 2, token usage: 0.06, #running-req: 46, #queue-req: 1900, 
[1,0]<stdout>:[2025-10-12 20:41:16 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1899, 
[1,0]<stdout>:[2025-10-12 20:41:16 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1898, 
[1,0]<stdout>:[2025-10-12 20:41:17 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1897, 
[1,0]<stdout>:[2025-10-12 20:41:17 TP0] Decode batch. #running-req: 48, #token: 15165, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 596.01, #queue-req: 1897, 
[1,0]<stdout>:[2025-10-12 20:41:17 TP0] Prefill batch. #new-seq: 1, #new-token: 574, #cached-token: 6, token usage: 0.06, #running-req: 47, #queue-req: 1896, 
[1,0]<stdout>:[2025-10-12 20:41:18 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1895, 
[1,0]<stdout>:[2025-10-12 20:41:18 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1894, 
[1,0]<stdout>:[2025-10-12 20:41:19 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1893, 
[1,0]<stdout>:[2025-10-12 20:41:19 TP0] Decode batch. #running-req: 48, #token: 17051, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 930.55, #queue-req: 1893, 
[1,0]<stdout>:[2025-10-12 20:41:19 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1892, 
[1,0]<stdout>:[2025-10-12 20:41:20 TP0] Prefill batch. #new-seq: 2, #new-token: 86, #cached-token: 3, token usage: 0.06, #running-req: 46, #queue-req: 1890, 
[1,0]<stdout>:[2025-10-12 20:41:20 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1889, 
[1,0]<stdout>:[2025-10-12 20:41:20 TP0] Prefill batch. #new-seq: 1, #new-token: 2415, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1888, 
[1,0]<stdout>:[2025-10-12 20:41:21 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1887, 
[1,0]<stdout>:[2025-10-12 20:41:21 TP0] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 7, token usage: 0.06, #running-req: 47, #queue-req: 1886, 
[1,0]<stdout>:[2025-10-12 20:41:21 TP0] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 11, token usage: 0.06, #running-req: 47, #queue-req: 1885, 
[1,0]<stdout>:[2025-10-12 20:41:22 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1884, 
[1,0]<stdout>:[2025-10-12 20:41:22 TP0] Decode batch. #running-req: 48, #token: 16005, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 633.11, #queue-req: 1884, 
[1,0]<stdout>:[2025-10-12 20:41:22 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1883, 
[1,0]<stdout>:[2025-10-12 20:41:23 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1882, 
[1,0]<stdout>:[2025-10-12 20:41:23 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1881, 
[1,0]<stdout>:[2025-10-12 20:41:23 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1880, 
[1,0]<stdout>:[2025-10-12 20:41:24 TP0] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 5, token usage: 0.05, #running-req: 47, #queue-req: 1879, 
[1,0]<stdout>:[2025-10-12 20:41:24 TP0] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1878, 
[1,0]<stdout>:[2025-10-12 20:41:24 TP0] Decode batch. #running-req: 48, #token: 14801, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 778.49, #queue-req: 1878, 
[1,0]<stdout>:[2025-10-12 20:41:25 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1877, 
[1,0]<stdout>:[2025-10-12 20:41:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1876, 
[1,0]<stdout>:[2025-10-12 20:41:26 TP0] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1875, 
[1,0]<stdout>:[2025-10-12 20:41:26 TP0] Prefill batch. #new-seq: 1, #new-token: 429, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1874, 
[1,0]<stdout>:[2025-10-12 20:41:27 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1873, 
[1,0]<stdout>:[2025-10-12 20:41:27 TP0] Decode batch. #running-req: 48, #token: 17169, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 802.40, #queue-req: 1873, 
[1,0]<stdout>:[2025-10-12 20:41:27 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1872, 
[1,0]<stdout>:[2025-10-12 20:41:27 TP0] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1871, 
[1,0]<stdout>:[2025-10-12 20:41:28 TP0] Prefill batch. #new-seq: 2, #new-token: 820, #cached-token: 5, token usage: 0.06, #running-req: 46, #queue-req: 1869, 
[1,0]<stdout>:[2025-10-12 20:41:28 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1868, 
[1,0]<stdout>:[2025-10-12 20:41:28 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1867, 
[1,0]<stdout>:[2025-10-12 20:41:28 TP0] Prefill batch. #new-seq: 2, #new-token: 113, #cached-token: 5, token usage: 0.06, #running-req: 46, #queue-req: 1865, 
[1,0]<stdout>:[2025-10-12 20:41:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1978, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1864, 
[1,0]<stdout>:[2025-10-12 20:41:29 TP0] Prefill batch. #new-seq: 1, #new-token: 804, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1863, 
[1,0]<stdout>:[2025-10-12 20:41:29 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1862, 
[1,0]<stdout>:[2025-10-12 20:41:30 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1861, 
[1,0]<stdout>:[2025-10-12 20:41:30 TP0] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1860, 
[1,0]<stdout>:[2025-10-12 20:41:30 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1859, 
[1,0]<stdout>:[2025-10-12 20:41:31 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1858, 
[1,0]<stdout>:[2025-10-12 20:41:31 TP0] Decode batch. #running-req: 48, #token: 17805, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 444.20, #queue-req: 1858, 
[1,0]<stdout>:[2025-10-12 20:41:31 TP0] Prefill batch. #new-seq: 1, #new-token: 615, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1857, 
[1,0]<stdout>:[2025-10-12 20:41:31 TP0] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1856, 
[1,0]<stdout>:[2025-10-12 20:41:32 TP0] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1855, 
[1,0]<stdout>:[2025-10-12 20:41:32 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1854, 
[1,0]<stdout>:[2025-10-12 20:41:33 TP0] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1853, 
[1,0]<stdout>:[2025-10-12 20:41:33 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1852, 
[1,0]<stdout>:[2025-10-12 20:41:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1389, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1851, 
[1,0]<stdout>:[2025-10-12 20:41:33 TP0] Prefill batch. #new-seq: 1, #new-token: 703, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1850, 
[1,0]<stdout>:[2025-10-12 20:41:34 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1849, 
[1,0]<stdout>:[2025-10-12 20:41:34 TP0] Decode batch. #running-req: 47, #token: 17947, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 604.73, #queue-req: 1849, 
[1,0]<stdout>:[2025-10-12 20:41:34 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1848, 
[1,0]<stdout>:[2025-10-12 20:41:35 TP0] Prefill batch. #new-seq: 1, #new-token: 699, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1847, 
[1,0]<stdout>:[2025-10-12 20:41:35 TP0] Prefill batch. #new-seq: 2, #new-token: 314, #cached-token: 9, token usage: 0.07, #running-req: 46, #queue-req: 1845, 
[1,0]<stdout>:[2025-10-12 20:41:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1844, 
[1,0]<stdout>:[2025-10-12 20:41:38 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1843, 
[1,0]<stdout>:[2025-10-12 20:41:38 TP0] Prefill batch. #new-seq: 1, #new-token: 810, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1842, 
[1,0]<stdout>:[2025-10-12 20:41:39 TP0] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1841, 
[1,0]<stdout>:[2025-10-12 20:41:39 TP0] Prefill batch. #new-seq: 1, #new-token: 515, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1840, 
[1,0]<stdout>:[2025-10-12 20:41:39 TP0] Decode batch. #running-req: 48, #token: 19331, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 380.68, #queue-req: 1840, 
[1,0]<stdout>:[2025-10-12 20:41:39 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1839, 
[1,0]<stdout>:[2025-10-12 20:41:40 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1838, 
[1,0]<stdout>:[2025-10-12 20:41:40 TP0] Prefill batch. #new-seq: 2, #new-token: 13, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 1836, 
[1,0]<stdout>:[2025-10-12 20:41:40 TP0] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1835, 
[1,0]<stdout>:[2025-10-12 20:41:41 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1834, 
[1,0]<stdout>:[2025-10-12 20:41:41 TP0] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1833, 
[1,0]<stdout>:[2025-10-12 20:41:41 TP0] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1832, 
[1,0]<stdout>:[2025-10-12 20:41:42 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1831, 
[1,0]<stdout>:[2025-10-12 20:41:42 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1830, 
[1,0]<stdout>:[2025-10-12 20:41:42 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1829, 
[1,0]<stdout>:[2025-10-12 20:41:43 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1828, 
[1,0]<stdout>:[2025-10-12 20:41:43 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1827, 
[1,0]<stdout>:[2025-10-12 20:41:43 TP0] Decode batch. #running-req: 47, #token: 16998, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 504.83, #queue-req: 1827, 
[1,0]<stdout>:[2025-10-12 20:41:43 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1826, 
[1,0]<stdout>:[2025-10-12 20:41:43 TP0] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1825, 
[1,0]<stdout>:[2025-10-12 20:41:44 TP0] Prefill batch. #new-seq: 1, #new-token: 712, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1824, 
[1,0]<stdout>:[2025-10-12 20:41:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1065, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1823, 
[1,0]<stdout>:[2025-10-12 20:41:44 TP0] Prefill batch. #new-seq: 2, #new-token: 517, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 1821, 
[1,0]<stdout>:[2025-10-12 20:41:45 TP0] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1820, 
[1,0]<stdout>:[2025-10-12 20:41:45 TP0] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1819, 
[1,0]<stdout>:[2025-10-12 20:41:46 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1818, 
[1,0]<stdout>:[2025-10-12 20:41:46 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1817, 
[1,0]<stdout>:[2025-10-12 20:41:46 TP0] Decode batch. #running-req: 48, #token: 19556, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 612.20, #queue-req: 1817, 
[1,0]<stdout>:[2025-10-12 20:41:46 TP0] Prefill batch. #new-seq: 1, #new-token: 764, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1816, 
[1,0]<stdout>:[2025-10-12 20:41:47 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1815, 
[1,0]<stdout>:[2025-10-12 20:41:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1228, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1814, 
[1,0]<stdout>:[2025-10-12 20:41:47 TP0] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1813, 
[1,0]<stdout>:[2025-10-12 20:41:48 TP0] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1812, 
[1,0]<stdout>:[2025-10-12 20:41:48 TP0] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1811, 
[1,0]<stdout>:[2025-10-12 20:41:48 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1810, 
[1,0]<stdout>:[2025-10-12 20:41:49 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1809, 
[1,0]<stdout>:[2025-10-12 20:41:49 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1808, 
[1,0]<stdout>:[2025-10-12 20:41:49 TP0] Prefill batch. #new-seq: 1, #new-token: 466, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1807, 
[1,0]<stdout>:[2025-10-12 20:41:51 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1806, 
[1,0]<stdout>:[2025-10-12 20:41:51 TP0] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1805, 
[1,0]<stdout>:[2025-10-12 20:41:52 TP0] Decode batch. #running-req: 48, #token: 20320, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 358.41, #queue-req: 1805, 
[1,0]<stdout>:[2025-10-12 20:41:52 TP0] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1804, 
[1,0]<stdout>:[2025-10-12 20:41:52 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1803, 
[1,0]<stdout>:[2025-10-12 20:41:52 TP0] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1802, 
[1,0]<stdout>:[2025-10-12 20:41:52 TP0] Prefill batch. #new-seq: 2, #new-token: 75, #cached-token: 4, token usage: 0.07, #running-req: 46, #queue-req: 1800, 
[1,0]<stdout>:[2025-10-12 20:41:53 TP0] Prefill batch. #new-seq: 2, #new-token: 75, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 1798, 
[1,0]<stdout>:[2025-10-12 20:41:53 TP0] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 1797, 
[1,0]<stdout>:[2025-10-12 20:41:54 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1796, 
[1,0]<stdout>:[2025-10-12 20:41:54 TP0] Decode batch. #running-req: 48, #token: 19495, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 701.84, #queue-req: 1796, 
[1,0]<stdout>:[2025-10-12 20:41:54 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1795, 
[1,0]<stdout>:[2025-10-12 20:41:55 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1794, 
[1,0]<stdout>:[2025-10-12 20:41:55 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1793, 
[1,0]<stdout>:[2025-10-12 20:41:55 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1792, 
[1,0]<stdout>:[2025-10-12 20:41:56 TP0] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1791, 
[1,0]<stdout>:[2025-10-12 20:41:56 TP0] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1790, 
[1,0]<stdout>:[2025-10-12 20:41:57 TP0] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1789, 
[1,0]<stdout>:[2025-10-12 20:41:57 TP0] Decode batch. #running-req: 48, #token: 20005, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 713.80, #queue-req: 1789, 
[1,0]<stdout>:[2025-10-12 20:41:57 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1788, 
[1,0]<stdout>:[2025-10-12 20:41:58 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1787, 
[1,0]<stdout>:[2025-10-12 20:41:58 TP0] Prefill batch. #new-seq: 3, #new-token: 792, #cached-token: 4, token usage: 0.08, #running-req: 45, #queue-req: 1784, 
[1,0]<stdout>:[2025-10-12 20:41:58 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1783, 
[1,0]<stdout>:[2025-10-12 20:41:58 TP0] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1782, 
[1,0]<stdout>:[2025-10-12 20:41:59 TP0] Prefill batch. #new-seq: 2, #new-token: 631, #cached-token: 3, token usage: 0.07, #running-req: 46, #queue-req: 1780, 
[1,0]<stdout>:[2025-10-12 20:41:59 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 7, token usage: 0.07, #running-req: 47, #queue-req: 1779, 
[1,0]<stdout>:[2025-10-12 20:41:59 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1778, 
[1,0]<stdout>:[2025-10-12 20:42:00 TP0] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1777, 
[1,0]<stdout>:[2025-10-12 20:42:00 TP0] Prefill batch. #new-seq: 1, #new-token: 515, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1776, 
[1,0]<stdout>:[2025-10-12 20:42:00 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 8, token usage: 0.07, #running-req: 47, #queue-req: 1775, 
[1,0]<stdout>:[2025-10-12 20:42:01 TP0] Decode batch. #running-req: 47, #token: 17869, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 532.47, #queue-req: 1775, 
[1,0]<stdout>:[2025-10-12 20:42:01 TP0] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1774, 
[1,0]<stdout>:[2025-10-12 20:42:01 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1773, 
[1,0]<stdout>:[2025-10-12 20:42:01 TP0] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1772, 
[1,0]<stdout>:[2025-10-12 20:42:02 TP0] Prefill batch. #new-seq: 2, #new-token: 653, #cached-token: 2, token usage: 0.07, #running-req: 46, #queue-req: 1770, 
[1,0]<stdout>:[2025-10-12 20:42:02 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1769, 
[1,0]<stdout>:[2025-10-12 20:42:02 TP0] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1768, 
[1,0]<stdout>:[2025-10-12 20:42:03 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1767, 
[1,0]<stdout>:[2025-10-12 20:42:03 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1766, 
[1,0]<stdout>:[2025-10-12 20:42:03 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1765, 
[1,0]<stdout>:[2025-10-12 20:42:03 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1764, 
[1,0]<stdout>:[2025-10-12 20:42:04 TP0] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1763, 
[1,0]<stdout>:[2025-10-12 20:42:04 TP0] Prefill batch. #new-seq: 2, #new-token: 20, #cached-token: 5, token usage: 0.06, #running-req: 46, #queue-req: 1761, 
[1,0]<stdout>:[2025-10-12 20:42:04 TP0] Decode batch. #running-req: 48, #token: 16112, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 519.44, #queue-req: 1761, 
[1,0]<stdout>:[2025-10-12 20:42:05 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1760, 
[1,0]<stdout>:[2025-10-12 20:42:05 TP0] Prefill batch. #new-seq: 2, #new-token: 385, #cached-token: 5, token usage: 0.06, #running-req: 46, #queue-req: 1758, 
[1,0]<stdout>:[2025-10-12 20:42:05 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1757, 
[1,0]<stdout>:[2025-10-12 20:42:05 TP0] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1756, 
[1,0]<stdout>:[2025-10-12 20:42:06 TP0] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1755, 
[1,0]<stdout>:[2025-10-12 20:42:06 TP0] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1754, 
[1,0]<stdout>:[2025-10-12 20:42:07 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1753, 
[1,0]<stdout>:[2025-10-12 20:42:07 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1752, 
[1,0]<stdout>:[2025-10-12 20:42:07 TP0] Prefill batch. #new-seq: 1, #new-token: 430, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1751, 
[1,0]<stdout>:[2025-10-12 20:42:07 TP0] Decode batch. #running-req: 48, #token: 14299, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 617.87, #queue-req: 1751, 
[1,0]<stdout>:[2025-10-12 20:42:07 TP0] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1750, 
[1,0]<stdout>:[2025-10-12 20:42:08 TP0] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1749, 
[1,0]<stdout>:[2025-10-12 20:42:08 TP0] Prefill batch. #new-seq: 1, #new-token: 734, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1748, 
[1,0]<stdout>:[2025-10-12 20:42:08 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1747, 
[1,0]<stdout>:[2025-10-12 20:42:09 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1746, 
[1,0]<stdout>:[2025-10-12 20:42:09 TP0] Prefill batch. #new-seq: 1, #new-token: 401, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1745, 
[1,0]<stdout>:[2025-10-12 20:42:09 TP0] Prefill batch. #new-seq: 2, #new-token: 459, #cached-token: 3, token usage: 0.06, #running-req: 46, #queue-req: 1743, 
[1,0]<stdout>:[2025-10-12 20:42:10 TP0] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1742, 
[1,0]<stdout>:[2025-10-12 20:42:10 TP0] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1741, 
[1,0]<stdout>:[2025-10-12 20:42:10 TP0] Prefill batch. #new-seq: 1, #new-token: 923, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1740, 
[1,0]<stdout>:[2025-10-12 20:42:11 TP0] Decode batch. #running-req: 47, #token: 16510, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 559.44, #queue-req: 1740, 
[1,0]<stdout>:[2025-10-12 20:42:11 TP0] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1739, 
[1,0]<stdout>:[2025-10-12 20:42:11 TP0] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1738, 
[1,0]<stdout>:[2025-10-12 20:42:11 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1737, 
[1,0]<stdout>:[2025-10-12 20:42:12 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1736, 
[1,0]<stdout>:[2025-10-12 20:42:12 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1735, 
[1,0]<stdout>:[2025-10-12 20:42:12 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1734, 
[1,0]<stdout>:[2025-10-12 20:42:12 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1733, 
[1,0]<stdout>:[2025-10-12 20:42:13 TP0] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1732, 
[1,0]<stdout>:[2025-10-12 20:42:13 TP0] Prefill batch. #new-seq: 1, #new-token: 868, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1731, 
[1,0]<stdout>:[2025-10-12 20:42:13 TP0] Prefill batch. #new-seq: 1, #new-token: 673, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1730, 
[1,0]<stdout>:[2025-10-12 20:42:14 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1729, 
[1,0]<stdout>:[2025-10-12 20:42:14 TP0] Prefill batch. #new-seq: 3, #new-token: 858, #cached-token: 7, token usage: 0.06, #running-req: 45, #queue-req: 1726, 
[1,0]<stdout>:[2025-10-12 20:42:14 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1725, 
[1,0]<stdout>:[2025-10-12 20:42:15 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1724, 
[1,0]<stdout>:[2025-10-12 20:42:15 TP0] Prefill batch. #new-seq: 1, #new-token: 493, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1723, 
[1,0]<stdout>:[2025-10-12 20:42:15 TP0] Decode batch. #running-req: 48, #token: 15957, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 418.16, #queue-req: 1723, 
[1,0]<stdout>:[2025-10-12 20:42:15 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1722, 
[1,0]<stdout>:[2025-10-12 20:42:16 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1721, 
[1,0]<stdout>:[2025-10-12 20:42:16 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1720, 
[1,0]<stdout>:[2025-10-12 20:42:16 TP0] Prefill batch. #new-seq: 2, #new-token: 380, #cached-token: 6, token usage: 0.06, #running-req: 46, #queue-req: 1718, 
[1,0]<stdout>:[2025-10-12 20:42:17 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1717, 
[1,0]<stdout>:[2025-10-12 20:42:18 TP0] Decode batch. #running-req: 48, #token: 15599, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 845.78, #queue-req: 1717, 
[1,0]<stdout>:[2025-10-12 20:42:18 TP0] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1716, 
[1,0]<stdout>:[2025-10-12 20:42:18 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1715, 
[1,0]<stdout>:[2025-10-12 20:42:18 TP0] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 6, token usage: 0.06, #running-req: 47, #queue-req: 1714, 
[1,0]<stdout>:[2025-10-12 20:42:19 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1713, 
[1,0]<stdout>:[2025-10-12 20:42:19 TP0] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1712, 
[1,0]<stdout>:[2025-10-12 20:42:21 TP0] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1711, 
[1,0]<stdout>:[2025-10-12 20:42:21 TP0] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1710, 
[1,0]<stdout>:[2025-10-12 20:42:21 TP0] Decode batch. #running-req: 47, #token: 17766, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 491.28, #queue-req: 1710, 
[1,0]<stdout>:[2025-10-12 20:42:21 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1709, 
[1,0]<stdout>:[2025-10-12 20:42:22 TP0] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1708, 
[1,0]<stdout>:[2025-10-12 20:42:22 TP0] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 1707, 
[1,0]<stdout>:[2025-10-12 20:42:23 TP0] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1706, 
[1,0]<stdout>:[2025-10-12 20:42:23 TP0] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1705, 
[1,0]<stdout>:[2025-10-12 20:42:23 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 7, token usage: 0.08, #running-req: 47, #queue-req: 1704, 
[1,0]<stdout>:[2025-10-12 20:42:23 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1703, 
[1,0]<stdout>:[2025-10-12 20:42:24 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1702, 
[1,0]<stdout>:[2025-10-12 20:42:24 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1701, 
[1,0]<stdout>:[2025-10-12 20:42:24 TP0] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1700, 
[1,0]<stdout>:[2025-10-12 20:42:25 TP0] Decode batch. #running-req: 46, #token: 18151, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 584.04, #queue-req: 1700, 
[1,0]<stdout>:[2025-10-12 20:42:25 TP0] Prefill batch. #new-seq: 2, #new-token: 125, #cached-token: 2, token usage: 0.07, #running-req: 46, #queue-req: 1698, 
[1,0]<stdout>:[2025-10-12 20:42:25 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1697, 
[1,0]<stdout>:[2025-10-12 20:42:26 TP0] Prefill batch. #new-seq: 2, #new-token: 987, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 1695, 
[1,0]<stdout>:[2025-10-12 20:42:26 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1694, 
[1,0]<stdout>:[2025-10-12 20:42:26 TP0] Prefill batch. #new-seq: 3, #new-token: 1064, #cached-token: 12, token usage: 0.07, #running-req: 45, #queue-req: 1691, 
[1,0]<stdout>:[2025-10-12 20:42:27 TP0] Decode batch. #running-req: 48, #token: 19435, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 852.35, #queue-req: 1691, 
[1,0]<stdout>:[2025-10-12 20:42:27 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1690, 
[1,0]<stdout>:[2025-10-12 20:42:27 TP0] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1689, 
[1,0]<stdout>:[2025-10-12 20:42:28 TP0] Prefill batch. #new-seq: 1, #new-token: 762, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1688, 
[1,0]<stdout>:[2025-10-12 20:42:28 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1687, 
[1,0]<stdout>:[2025-10-12 20:42:28 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1686, 
[1,0]<stdout>:[2025-10-12 20:42:29 TP0] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1685, 
[1,0]<stdout>:[2025-10-12 20:42:29 TP0] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1684, 
[1,0]<stdout>:[2025-10-12 20:42:29 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1683, 
[1,0]<stdout>:[2025-10-12 20:42:29 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1682, 
[1,0]<stdout>:[2025-10-12 20:42:30 TP0] Prefill batch. #new-seq: 2, #new-token: 987, #cached-token: 9, token usage: 0.07, #running-req: 46, #queue-req: 1680, 
[1,0]<stdout>:[2025-10-12 20:42:30 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1679, 
[1,0]<stdout>:[2025-10-12 20:42:30 TP0] Decode batch. #running-req: 48, #token: 19381, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 549.35, #queue-req: 1679, 
[1,0]<stdout>:[2025-10-12 20:42:30 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1678, 
[1,0]<stdout>:[2025-10-12 20:42:31 TP0] Prefill batch. #new-seq: 1, #new-token: 903, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1677, 
[1,0]<stdout>:[2025-10-12 20:42:32 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1676, 
[1,0]<stdout>:[2025-10-12 20:42:32 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1675, 
[1,0]<stdout>:[2025-10-12 20:42:32 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1674, 
[1,0]<stdout>:[2025-10-12 20:42:33 TP0] Decode batch. #running-req: 48, #token: 20681, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 850.67, #queue-req: 1674, 
[1,0]<stdout>:[2025-10-12 20:42:33 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1673, 
[1,0]<stdout>:[2025-10-12 20:42:33 TP0] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1672, 
[1,0]<stdout>:[2025-10-12 20:42:33 TP0] Prefill batch. #new-seq: 2, #new-token: 269, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 1670, 
[1,0]<stdout>:[2025-10-12 20:42:34 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1669, 
[1,0]<stdout>:[2025-10-12 20:42:34 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1668, 
[1,0]<stdout>:[2025-10-12 20:42:35 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1667, 
[1,0]<stdout>:[2025-10-12 20:42:35 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1666, 
[1,0]<stdout>:[2025-10-12 20:42:35 TP0] Decode batch. #running-req: 48, #token: 19210, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 702.76, #queue-req: 1666, 
[1,0]<stdout>:[2025-10-12 20:42:36 TP0] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1665, 
[1,0]<stdout>:[2025-10-12 20:42:36 TP0] Prefill batch. #new-seq: 2, #new-token: 503, #cached-token: 2, token usage: 0.08, #running-req: 46, #queue-req: 1663, 
[1,0]<stdout>:[2025-10-12 20:42:36 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1662, 
[1,0]<stdout>:[2025-10-12 20:42:37 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1661, 
[1,0]<stdout>:[2025-10-12 20:42:37 TP0] Prefill batch. #new-seq: 1, #new-token: 670, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1660, 
[1,0]<stdout>:[2025-10-12 20:42:37 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1659, 
[1,0]<stdout>:[2025-10-12 20:42:37 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1658, 
[1,0]<stdout>:[2025-10-12 20:42:38 TP0] Prefill batch. #new-seq: 1, #new-token: 463, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1657, 
[1,0]<stdout>:[2025-10-12 20:42:38 TP0] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1656, 
[1,0]<stdout>:[2025-10-12 20:42:38 TP0] Decode batch. #running-req: 48, #token: 19125, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 618.09, #queue-req: 1656, 
[1,0]<stdout>:[2025-10-12 20:42:39 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1655, 
[1,0]<stdout>:[2025-10-12 20:42:39 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1654, 
[1,0]<stdout>:[2025-10-12 20:42:39 TP0] Prefill batch. #new-seq: 1, #new-token: 822, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 1653, 
[1,0]<stdout>:[2025-10-12 20:42:39 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1652, 
[1,0]<stdout>:[2025-10-12 20:42:40 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1651, 
[1,0]<stdout>:[2025-10-12 20:42:40 TP0] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 7, token usage: 0.08, #running-req: 47, #queue-req: 1650, 
[1,0]<stdout>:[2025-10-12 20:42:41 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1649, 
[1,0]<stdout>:[2025-10-12 20:42:41 TP0] Prefill batch. #new-seq: 3, #new-token: 1679, #cached-token: 11, token usage: 0.07, #running-req: 45, #queue-req: 1646, 
[1,0]<stdout>:[2025-10-12 20:42:41 TP0] Prefill batch. #new-seq: 1, #new-token: 735, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1645, 
[1,0]<stdout>:[2025-10-12 20:42:41 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1644, 
[1,0]<stdout>:[2025-10-12 20:42:42 TP0] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1643, 
[1,0]<stdout>:[2025-10-12 20:42:42 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1642, 
[1,0]<stdout>:[2025-10-12 20:42:42 TP0] Decode batch. #running-req: 47, #token: 19923, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 506.29, #queue-req: 1642, 
[1,0]<stdout>:[2025-10-12 20:42:42 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1641, 
[1,0]<stdout>:[2025-10-12 20:42:43 TP0] Prefill batch. #new-seq: 2, #new-token: 2489, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1639, 
[1,0]<stdout>:[2025-10-12 20:42:43 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1638, 
[1,0]<stdout>:[2025-10-12 20:42:44 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1637, 
[1,0]<stdout>:[2025-10-12 20:42:44 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1636, 
[1,0]<stdout>:[2025-10-12 20:42:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1231, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1635, 
[1,0]<stdout>:[2025-10-12 20:42:45 TP0] Decode batch. #running-req: 48, #token: 22950, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 776.98, #queue-req: 1635, 
[1,0]<stdout>:[2025-10-12 20:42:45 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1634, 
[1,0]<stdout>:[2025-10-12 20:42:45 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1633, 
[1,0]<stdout>:[2025-10-12 20:42:46 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1632, 
[1,0]<stdout>:[2025-10-12 20:42:46 TP0] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 1631, 
[1,0]<stdout>:[2025-10-12 20:42:46 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1630, 
[1,0]<stdout>:[2025-10-12 20:42:47 TP0] Decode batch. #running-req: 48, #token: 24879, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 849.90, #queue-req: 1630, 
[1,0]<stdout>:[2025-10-12 20:42:48 TP0] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1629, 
[1,0]<stdout>:[2025-10-12 20:42:48 TP0] Prefill batch. #new-seq: 2, #new-token: 739, #cached-token: 11, token usage: 0.09, #running-req: 46, #queue-req: 1627, 
[1,0]<stdout>:[2025-10-12 20:42:48 TP0] Prefill batch. #new-seq: 3, #new-token: 1240, #cached-token: 6, token usage: 0.10, #running-req: 45, #queue-req: 1624, 
[1,0]<stdout>:[2025-10-12 20:42:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1623, 
[1,0]<stdout>:[2025-10-12 20:42:49 TP0] Decode batch. #running-req: 48, #token: 27123, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 938.77, #queue-req: 1623, 
[1,0]<stdout>:[2025-10-12 20:42:49 TP0] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1622, 
[1,0]<stdout>:[2025-10-12 20:42:50 TP0] Prefill batch. #new-seq: 2, #new-token: 994, #cached-token: 4, token usage: 0.10, #running-req: 46, #queue-req: 1620, 
[1,0]<stdout>:[2025-10-12 20:42:50 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1619, 
[1,0]<stdout>:[2025-10-12 20:42:51 TP0] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1618, 
[1,0]<stdout>:[2025-10-12 20:42:51 TP0] Decode batch. #running-req: 48, #token: 26777, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 920.13, #queue-req: 1618, 
[1,0]<stdout>:[2025-10-12 20:42:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1940, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1617, 
[1,0]<stdout>:[2025-10-12 20:42:51 TP0] Prefill batch. #new-seq: 2, #new-token: 1482, #cached-token: 7, token usage: 0.11, #running-req: 46, #queue-req: 1615, 
[1,0]<stdout>:[2025-10-12 20:42:52 TP0] Prefill batch. #new-seq: 1, #new-token: 833, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1614, 
[1,0]<stdout>:[2025-10-12 20:42:52 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1613, 
[1,0]<stdout>:[2025-10-12 20:42:53 TP0] Prefill batch. #new-seq: 1, #new-token: 755, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1612, 
[1,0]<stdout>:[2025-10-12 20:42:53 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1611, 
[1,0]<stdout>:[2025-10-12 20:42:53 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1610, 
[1,0]<stdout>:[2025-10-12 20:42:54 TP0] Decode batch. #running-req: 47, #token: 27395, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 715.76, #queue-req: 1610, 
[1,0]<stdout>:[2025-10-12 20:42:54 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1609, 
[1,0]<stdout>:[2025-10-12 20:42:54 TP0] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1608, 
[1,0]<stdout>:[2025-10-12 20:42:54 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1607, 
[1,0]<stdout>:[2025-10-12 20:42:54 TP0] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1606, 
[1,0]<stdout>:[2025-10-12 20:42:55 TP0] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1605, 
[1,0]<stdout>:[2025-10-12 20:42:55 TP0] Prefill batch. #new-seq: 2, #new-token: 311, #cached-token: 9, token usage: 0.11, #running-req: 46, #queue-req: 1603, 
[1,0]<stdout>:[2025-10-12 20:42:55 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1602, 
[1,0]<stdout>:[2025-10-12 20:42:56 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1601, 
[1,0]<stdout>:[2025-10-12 20:42:56 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1600, 
[1,0]<stdout>:[2025-10-12 20:42:56 TP0] Prefill batch. #new-seq: 1, #new-token: 447, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1599, 
[1,0]<stdout>:[2025-10-12 20:42:57 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1598, 
[1,0]<stdout>:[2025-10-12 20:42:57 TP0] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1597, 
[1,0]<stdout>:[2025-10-12 20:42:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1044, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1596, 
[1,0]<stdout>:[2025-10-12 20:42:58 TP0] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1595, 
[1,0]<stdout>:[2025-10-12 20:42:58 TP0] Decode batch. #running-req: 48, #token: 28457, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 459.56, #queue-req: 1595, 
[1,0]<stdout>:[2025-10-12 20:42:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1051, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1594, 
[1,0]<stdout>:[2025-10-12 20:42:58 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1593, 
[1,0]<stdout>:[2025-10-12 20:42:59 TP0] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1592, 
[1,0]<stdout>:[2025-10-12 20:42:59 TP0] Prefill batch. #new-seq: 1, #new-token: 759, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1591, 
[1,0]<stdout>:[2025-10-12 20:42:59 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1590, 
[1,0]<stdout>:[2025-10-12 20:43:00 TP0] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1589, 
[1,0]<stdout>:[2025-10-12 20:43:00 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1588, 
[1,0]<stdout>:[2025-10-12 20:43:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1587, 
[1,0]<stdout>:[2025-10-12 20:43:01 TP0] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1586, 
[1,0]<stdout>:[2025-10-12 20:43:01 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1585, 
[1,0]<stdout>:[2025-10-12 20:43:01 TP0] Decode batch. #running-req: 47, #token: 27663, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 568.91, #queue-req: 1585, 
[1,0]<stdout>:[2025-10-12 20:43:01 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1584, 
[1,0]<stdout>:[2025-10-12 20:43:02 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1583, 
[1,0]<stdout>:[2025-10-12 20:43:02 TP0] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 7, token usage: 0.11, #running-req: 47, #queue-req: 1582, 
[1,0]<stdout>:[2025-10-12 20:43:02 TP0] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1581, 
[1,0]<stdout>:[2025-10-12 20:43:03 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1580, 
[1,0]<stdout>:[2025-10-12 20:43:03 TP0] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1579, 
[1,0]<stdout>:[2025-10-12 20:43:03 TP0] Prefill batch. #new-seq: 2, #new-token: 562, #cached-token: 3, token usage: 0.10, #running-req: 46, #queue-req: 1577, 
[1,0]<stdout>:[2025-10-12 20:43:04 TP0] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1576, 
[1,0]<stdout>:[2025-10-12 20:43:04 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1575, 
[1,0]<stdout>:[2025-10-12 20:43:04 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1574, 
[1,0]<stdout>:[2025-10-12 20:43:04 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1573, 
[1,0]<stdout>:[2025-10-12 20:43:05 TP0] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1572, 
[1,0]<stdout>:[2025-10-12 20:43:05 TP0] Decode batch. #running-req: 47, #token: 25309, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 513.27, #queue-req: 1572, 
[1,0]<stdout>:[2025-10-12 20:43:05 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1571, 
[1,0]<stdout>:[2025-10-12 20:43:05 TP0] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1570, 
[1,0]<stdout>:[2025-10-12 20:43:06 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1569, 
[1,0]<stdout>:[2025-10-12 20:43:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1568, 
[1,0]<stdout>:[2025-10-12 20:43:06 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1567, 
[1,0]<stdout>:[2025-10-12 20:43:06 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1566, 
[1,0]<stdout>:[2025-10-12 20:43:07 TP0] Prefill batch. #new-seq: 1, #new-token: 774, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1565, 
[1,0]<stdout>:[2025-10-12 20:43:07 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1564, 
[1,0]<stdout>:[2025-10-12 20:43:07 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1563, 
[1,0]<stdout>:[2025-10-12 20:43:08 TP0] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1562, 
[1,0]<stdout>:[2025-10-12 20:43:08 TP0] Decode batch. #running-req: 48, #token: 23715, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 578.62, #queue-req: 1562, 
[1,0]<stdout>:[2025-10-12 20:43:09 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1561, 
[1,0]<stdout>:[2025-10-12 20:43:09 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1560, 
[1,0]<stdout>:[2025-10-12 20:43:09 TP0] Prefill batch. #new-seq: 1, #new-token: 832, #cached-token: 7, token usage: 0.09, #running-req: 47, #queue-req: 1559, 
[1,0]<stdout>:[2025-10-12 20:43:10 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1558, 
[1,0]<stdout>:[2025-10-12 20:43:10 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 8, token usage: 0.09, #running-req: 47, #queue-req: 1557, 
[1,0]<stdout>:[2025-10-12 20:43:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1414, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1556, 
[1,0]<stdout>:[2025-10-12 20:43:11 TP0] Decode batch. #running-req: 48, #token: 23539, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 774.76, #queue-req: 1556, 
[1,0]<stdout>:[2025-10-12 20:43:11 TP0] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1555, 
[1,0]<stdout>:[2025-10-12 20:43:11 TP0] Prefill batch. #new-seq: 2, #new-token: 285, #cached-token: 9, token usage: 0.09, #running-req: 46, #queue-req: 1553, 
[1,0]<stdout>:[2025-10-12 20:43:12 TP0] Prefill batch. #new-seq: 1, #new-token: 706, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1552, 
[1,0]<stdout>:[2025-10-12 20:43:12 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1551, 
[1,0]<stdout>:[2025-10-12 20:43:12 TP0] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1550, 
[1,0]<stdout>:[2025-10-12 20:43:13 TP0] Prefill batch. #new-seq: 2, #new-token: 36, #cached-token: 5, token usage: 0.09, #running-req: 46, #queue-req: 1548, 
[1,0]<stdout>:[2025-10-12 20:43:13 TP0] Decode batch. #running-req: 48, #token: 22689, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 783.18, #queue-req: 1548, 
[1,0]<stdout>:[2025-10-12 20:43:13 TP0] Prefill batch. #new-seq: 2, #new-token: 182, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 1546, 
[1,0]<stdout>:[2025-10-12 20:43:14 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1545, 
[1,0]<stdout>:[2025-10-12 20:43:14 TP0] Prefill batch. #new-seq: 1, #new-token: 2564, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1544, 
[1,0]<stdout>:[2025-10-12 20:43:14 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1543, 
[1,0]<stdout>:[2025-10-12 20:43:15 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1542, 
[1,0]<stdout>:[2025-10-12 20:43:15 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1541, 
[1,0]<stdout>:[2025-10-12 20:43:16 TP0] Decode batch. #running-req: 46, #token: 22176, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 780.66, #queue-req: 1541, 
[1,0]<stdout>:[2025-10-12 20:43:16 TP0] Prefill batch. #new-seq: 2, #new-token: 13, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1539, 
[1,0]<stdout>:[2025-10-12 20:43:16 TP0] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1538, 
[1,0]<stdout>:[2025-10-12 20:43:17 TP0] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1537, 
[1,0]<stdout>:[2025-10-12 20:43:17 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1536, 
[1,0]<stdout>:[2025-10-12 20:43:18 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1535, 
[1,0]<stdout>:[2025-10-12 20:43:18 TP0] Decode batch. #running-req: 48, #token: 23267, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 842.54, #queue-req: 1535, 
[1,0]<stdout>:[2025-10-12 20:43:18 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1534, 
[1,0]<stdout>:[2025-10-12 20:43:18 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1533, 
[1,0]<stdout>:[2025-10-12 20:43:19 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1532, 
[1,0]<stdout>:[2025-10-12 20:43:19 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1531, 
[1,0]<stdout>:[2025-10-12 20:43:20 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1530, 
[1,0]<stdout>:[2025-10-12 20:43:20 TP0] Prefill batch. #new-seq: 2, #new-token: 29, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 1528, 
[1,0]<stdout>:[2025-10-12 20:43:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1527, 
[1,0]<stdout>:[2025-10-12 20:43:21 TP0] Decode batch. #running-req: 48, #token: 21519, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 718.45, #queue-req: 1527, 
[1,0]<stdout>:[2025-10-12 20:43:21 TP0] Prefill batch. #new-seq: 2, #new-token: 2001, #cached-token: 8, token usage: 0.08, #running-req: 46, #queue-req: 1525, 
[1,0]<stdout>:[2025-10-12 20:43:21 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1524, 
[1,0]<stdout>:[2025-10-12 20:43:21 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1523, 
[1,0]<stdout>:[2025-10-12 20:43:22 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1522, 
[1,0]<stdout>:[2025-10-12 20:43:22 TP0] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1521, 
[1,0]<stdout>:[2025-10-12 20:43:22 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1520, 
[1,0]<stdout>:[2025-10-12 20:43:22 TP0] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1519, 
[1,0]<stdout>:[2025-10-12 20:43:23 TP0] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1518, 
[1,0]<stdout>:[2025-10-12 20:43:23 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1517, 
[1,0]<stdout>:[2025-10-12 20:43:24 TP0] Prefill batch. #new-seq: 2, #new-token: 1437, #cached-token: 7, token usage: 0.08, #running-req: 46, #queue-req: 1515, 
[1,0]<stdout>:[2025-10-12 20:43:24 TP0] Decode batch. #running-req: 48, #token: 22580, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 577.91, #queue-req: 1515, 
[1,0]<stdout>:[2025-10-12 20:43:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1514, 
[1,0]<stdout>:[2025-10-12 20:43:24 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1513, 
[1,0]<stdout>:[2025-10-12 20:43:25 TP0] Prefill batch. #new-seq: 1, #new-token: 849, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1512, 
[1,0]<stdout>:[2025-10-12 20:43:25 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1511, 
[1,0]<stdout>:[2025-10-12 20:43:25 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1510, 
[1,0]<stdout>:[2025-10-12 20:43:26 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1509, 
[1,0]<stdout>:[2025-10-12 20:43:26 TP0] Decode batch. #running-req: 48, #token: 23256, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 783.49, #queue-req: 1509, 
[1,0]<stdout>:[2025-10-12 20:43:26 TP0] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1508, 
[1,0]<stdout>:[2025-10-12 20:43:27 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1507, 
[1,0]<stdout>:[2025-10-12 20:43:27 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1506, 
[1,0]<stdout>:[2025-10-12 20:43:27 TP0] Prefill batch. #new-seq: 3, #new-token: 824, #cached-token: 6, token usage: 0.09, #running-req: 45, #queue-req: 1503, 
[1,0]<stdout>:[2025-10-12 20:43:28 TP0] Prefill batch. #new-seq: 1, #new-token: 581, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1502, 
[1,0]<stdout>:[2025-10-12 20:43:28 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1501, 
[1,0]<stdout>:[2025-10-12 20:43:29 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1500, 
[1,0]<stdout>:[2025-10-12 20:43:29 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1499, 
[1,0]<stdout>:[2025-10-12 20:43:29 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1498, 
[1,0]<stdout>:[2025-10-12 20:43:29 TP0] Decode batch. #running-req: 48, #token: 22641, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 609.48, #queue-req: 1498, 
[1,0]<stdout>:[2025-10-12 20:43:30 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1497, 
[1,0]<stdout>:[2025-10-12 20:43:30 TP0] Prefill batch. #new-seq: 1, #new-token: 570, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1496, 
[1,0]<stdout>:[2025-10-12 20:43:30 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1495, 
[1,0]<stdout>:[2025-10-12 20:43:30 TP0] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1494, 
[1,0]<stdout>:[2025-10-12 20:43:31 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1493, 
[1,0]<stdout>:[2025-10-12 20:43:31 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1492, 
[1,0]<stdout>:[2025-10-12 20:43:32 TP0] Prefill batch. #new-seq: 1, #new-token: 817, #cached-token: 10, token usage: 0.08, #running-req: 47, #queue-req: 1491, 
[1,0]<stdout>:[2025-10-12 20:43:32 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1490, 
[1,0]<stdout>:[2025-10-12 20:43:32 TP0] Decode batch. #running-req: 48, #token: 21654, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 657.14, #queue-req: 1490, 
[1,0]<stdout>:[2025-10-12 20:43:32 TP0] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1489, 
[1,0]<stdout>:[2025-10-12 20:43:33 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1488, 
[1,0]<stdout>:[2025-10-12 20:43:33 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1487, 
[1,0]<stdout>:[2025-10-12 20:43:34 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1486, 
[1,0]<stdout>:[2025-10-12 20:43:34 TP0] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1485, 
[1,0]<stdout>:[2025-10-12 20:43:34 TP0] Prefill batch. #new-seq: 2, #new-token: 950, #cached-token: 3, token usage: 0.08, #running-req: 46, #queue-req: 1483, 
[1,0]<stdout>:[2025-10-12 20:43:35 TP0] Decode batch. #running-req: 47, #token: 20990, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 776.42, #queue-req: 1483, 
[1,0]<stdout>:[2025-10-12 20:43:35 TP0] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1482, 
[1,0]<stdout>:[2025-10-12 20:43:35 TP0] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1481, 
[1,0]<stdout>:[2025-10-12 20:43:36 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1480, 
[1,0]<stdout>:[2025-10-12 20:43:36 TP0] Prefill batch. #new-seq: 2, #new-token: 68, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1478, 
[1,0]<stdout>:[2025-10-12 20:43:36 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1477, 
[1,0]<stdout>:[2025-10-12 20:43:37 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1476, 
[1,0]<stdout>:[2025-10-12 20:43:37 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1475, 
[1,0]<stdout>:[2025-10-12 20:43:37 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1474, 
[1,0]<stdout>:[2025-10-12 20:43:37 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1473, 
[1,0]<stdout>:[2025-10-12 20:43:38 TP0] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1472, 
[1,0]<stdout>:[2025-10-12 20:43:38 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1471, 
[1,0]<stdout>:[2025-10-12 20:43:38 TP0] Decode batch. #running-req: 48, #token: 19041, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 543.37, #queue-req: 1471, 
[1,0]<stdout>:[2025-10-12 20:43:38 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1470, 
[1,0]<stdout>:[2025-10-12 20:43:39 TP0] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1469, 
[1,0]<stdout>:[2025-10-12 20:43:39 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1468, 
[1,0]<stdout>:[2025-10-12 20:43:39 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1467, 
[1,0]<stdout>:[2025-10-12 20:43:39 TP0] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1466, 
[1,0]<stdout>:[2025-10-12 20:43:40 TP0] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 7, token usage: 0.07, #running-req: 47, #queue-req: 1465, 
[1,0]<stdout>:[2025-10-12 20:43:40 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1464, 
[1,0]<stdout>:[2025-10-12 20:43:40 TP0] Prefill batch. #new-seq: 1, #new-token: 513, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1463, 
[1,0]<stdout>:[2025-10-12 20:43:41 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1462, 
[1,0]<stdout>:[2025-10-12 20:43:41 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1461, 
[1,0]<stdout>:[2025-10-12 20:43:41 TP0] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1460, 
[1,0]<stdout>:[2025-10-12 20:43:42 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1459, 
[1,0]<stdout>:[2025-10-12 20:43:42 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1458, 
[1,0]<stdout>:[2025-10-12 20:43:42 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1457, 
[1,0]<stdout>:[2025-10-12 20:43:42 TP0] Decode batch. #running-req: 48, #token: 18677, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 456.73, #queue-req: 1457, 
[1,0]<stdout>:[2025-10-12 20:43:43 TP0] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1456, 
[1,0]<stdout>:[2025-10-12 20:43:43 TP0] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1455, 
[1,0]<stdout>:[2025-10-12 20:43:43 TP0] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1454, 
[1,0]<stdout>:[2025-10-12 20:43:44 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1453, 
[1,0]<stdout>:[2025-10-12 20:43:44 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1452, 
[1,0]<stdout>:[2025-10-12 20:43:45 TP0] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 8, token usage: 0.08, #running-req: 47, #queue-req: 1451, 
[1,0]<stdout>:[2025-10-12 20:43:45 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1450, 
[1,0]<stdout>:[2025-10-12 20:43:45 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1449, 
[1,0]<stdout>:[2025-10-12 20:43:45 TP0] Prefill batch. #new-seq: 1, #new-token: 720, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1448, 
[1,0]<stdout>:[2025-10-12 20:43:46 TP0] Decode batch. #running-req: 47, #token: 20388, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 610.74, #queue-req: 1448, 
[1,0]<stdout>:[2025-10-12 20:43:46 TP0] Prefill batch. #new-seq: 1, #new-token: 795, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1447, 
[1,0]<stdout>:[2025-10-12 20:43:46 TP0] Prefill batch. #new-seq: 2, #new-token: 1263, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1445, 
[1,0]<stdout>:[2025-10-12 20:43:46 TP0] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 8, token usage: 0.09, #running-req: 47, #queue-req: 1444, 
[1,0]<stdout>:[2025-10-12 20:43:46 TP0] Prefill batch. #new-seq: 2, #new-token: 465, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1442, 
[1,0]<stdout>:[2025-10-12 20:43:47 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1441, 
[1,0]<stdout>:[2025-10-12 20:43:47 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1440, 
[1,0]<stdout>:[2025-10-12 20:43:48 TP0] Prefill batch. #new-seq: 1, #new-token: 479, #cached-token: 7, token usage: 0.08, #running-req: 47, #queue-req: 1439, 
[1,0]<stdout>:[2025-10-12 20:43:48 TP0] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1438, 
[1,0]<stdout>:[2025-10-12 20:43:48 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1437, 
[1,0]<stdout>:[2025-10-12 20:43:48 TP0] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1436, 
[1,0]<stdout>:[2025-10-12 20:43:49 TP0] Decode batch. #running-req: 48, #token: 21786, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 575.46, #queue-req: 1436, 
[1,0]<stdout>:[2025-10-12 20:43:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1595, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1435, 
[1,0]<stdout>:[2025-10-12 20:43:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1292, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1434, 
[1,0]<stdout>:[2025-10-12 20:43:50 TP0] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1433, 
[1,0]<stdout>:[2025-10-12 20:43:50 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1432, 
[1,0]<stdout>:[2025-10-12 20:43:51 TP0] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1431, 
[1,0]<stdout>:[2025-10-12 20:43:51 TP0] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1430, 
[1,0]<stdout>:[2025-10-12 20:43:51 TP0] Decode batch. #running-req: 47, #token: 23988, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 759.92, #queue-req: 1430, 
[1,0]<stdout>:[2025-10-12 20:43:51 TP0] Prefill batch. #new-seq: 1, #new-token: 3194, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1429, 
[1,0]<stdout>:[2025-10-12 20:43:52 TP0] Prefill batch. #new-seq: 2, #new-token: 378, #cached-token: 2, token usage: 0.11, #running-req: 46, #queue-req: 1427, 
[1,0]<stdout>:[2025-10-12 20:43:53 TP0] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 6, token usage: 0.11, #running-req: 47, #queue-req: 1426, 
[1,0]<stdout>:[2025-10-12 20:43:53 TP0] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 1425, 
[1,0]<stdout>:[2025-10-12 20:43:53 TP0] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1424, 
[1,0]<stdout>:[2025-10-12 20:43:54 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1423, 
[1,0]<stdout>:[2025-10-12 20:43:54 TP0] Prefill batch. #new-seq: 2, #new-token: 755, #cached-token: 8, token usage: 0.10, #running-req: 46, #queue-req: 1421, 
[1,0]<stdout>:[2025-10-12 20:43:54 TP0] Decode batch. #running-req: 48, #token: 26799, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 698.09, #queue-req: 1421, 
[1,0]<stdout>:[2025-10-12 20:43:54 TP0] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 5, token usage: 0.11, #running-req: 47, #queue-req: 1420, 
[1,0]<stdout>:[2025-10-12 20:43:55 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 1419, 
[1,0]<stdout>:[2025-10-12 20:43:55 TP0] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1418, 
[1,0]<stdout>:[2025-10-12 20:43:55 TP0] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1417, 
[1,0]<stdout>:[2025-10-12 20:43:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1416, 
[1,0]<stdout>:[2025-10-12 20:43:56 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1415, 
[1,0]<stdout>:[2025-10-12 20:43:56 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1414, 
[1,0]<stdout>:[2025-10-12 20:43:57 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1413, 
[1,0]<stdout>:[2025-10-12 20:43:57 TP0] Prefill batch. #new-seq: 2, #new-token: 319, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1411, 
[1,0]<stdout>:[2025-10-12 20:43:57 TP0] Prefill batch. #new-seq: 2, #new-token: 794, #cached-token: 12, token usage: 0.09, #running-req: 46, #queue-req: 1409, 
[1,0]<stdout>:[2025-10-12 20:43:57 TP0] Decode batch. #running-req: 48, #token: 24190, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 577.17, #queue-req: 1409, 
[1,0]<stdout>:[2025-10-12 20:43:58 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1408, 
[1,0]<stdout>:[2025-10-12 20:43:58 TP0] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 1407, 
[1,0]<stdout>:[2025-10-12 20:43:58 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1406, 
[1,0]<stdout>:[2025-10-12 20:43:58 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 14, token usage: 0.10, #running-req: 47, #queue-req: 1405, 
[1,0]<stdout>:[2025-10-12 20:43:59 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1404, 
[1,0]<stdout>:[2025-10-12 20:43:59 TP0] Prefill batch. #new-seq: 2, #new-token: 824, #cached-token: 7, token usage: 0.10, #running-req: 46, #queue-req: 1402, 
[1,0]<stdout>:[2025-10-12 20:44:00 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1401, 
[1,0]<stdout>:[2025-10-12 20:44:00 TP0] Prefill batch. #new-seq: 3, #new-token: 1531, #cached-token: 10, token usage: 0.09, #running-req: 45, #queue-req: 1398, 
[1,0]<stdout>:[2025-10-12 20:44:00 TP0] Prefill batch. #new-seq: 1, #new-token: 930, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1397, 
[1,0]<stdout>:[2025-10-12 20:44:00 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1396, 
[1,0]<stdout>:[2025-10-12 20:44:01 TP0] Decode batch. #running-req: 48, #token: 25382, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 587.31, #queue-req: 1396, 
[1,0]<stdout>:[2025-10-12 20:44:01 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1395, 
[1,0]<stdout>:[2025-10-12 20:44:01 TP0] Prefill batch. #new-seq: 3, #new-token: 1575, #cached-token: 10, token usage: 0.10, #running-req: 45, #queue-req: 1392, 
[1,0]<stdout>:[2025-10-12 20:44:01 TP0] Prefill batch. #new-seq: 2, #new-token: 435, #cached-token: 6, token usage: 0.10, #running-req: 46, #queue-req: 1390, 
[1,0]<stdout>:[2025-10-12 20:44:02 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1389, 
[1,0]<stdout>:[2025-10-12 20:44:02 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1388, 
[1,0]<stdout>:[2025-10-12 20:44:02 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1387, 
[1,0]<stdout>:[2025-10-12 20:44:03 TP0] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1386, 
[1,0]<stdout>:[2025-10-12 20:44:03 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1385, 
[1,0]<stdout>:[2025-10-12 20:44:03 TP0] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1384, 
[1,0]<stdout>:[2025-10-12 20:44:04 TP0] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1383, 
[1,0]<stdout>:[2025-10-12 20:44:04 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1382, 
[1,0]<stdout>:[2025-10-12 20:44:04 TP0] Decode batch. #running-req: 48, #token: 24711, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 538.13, #queue-req: 1382, 
[1,0]<stdout>:[2025-10-12 20:44:04 TP0] Prefill batch. #new-seq: 1, #new-token: 958, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1381, 
[1,0]<stdout>:[2025-10-12 20:44:05 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1380, 
[1,0]<stdout>:[2025-10-12 20:44:05 TP0] Prefill batch. #new-seq: 1, #new-token: 245, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1379, 
[1,0]<stdout>:[2025-10-12 20:44:05 TP0] Prefill batch. #new-seq: 2, #new-token: 772, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1377, 
[1,0]<stdout>:[2025-10-12 20:44:06 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1376, 
[1,0]<stdout>:[2025-10-12 20:44:06 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1375, 
[1,0]<stdout>:[2025-10-12 20:44:06 TP0] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1374, 
[1,0]<stdout>:[2025-10-12 20:44:06 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1373, 
[1,0]<stdout>:[2025-10-12 20:44:07 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1372, 
[1,0]<stdout>:[2025-10-12 20:44:07 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1371, 
[1,0]<stdout>:[2025-10-12 20:44:07 TP0] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1370, 
[1,0]<stdout>:[2025-10-12 20:44:08 TP0] Decode batch. #running-req: 48, #token: 22555, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 543.34, #queue-req: 1370, 
[1,0]<stdout>:[2025-10-12 20:44:08 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1369, 
[1,0]<stdout>:[2025-10-12 20:44:08 TP0] Prefill batch. #new-seq: 1, #new-token: 885, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1368, 
[1,0]<stdout>:[2025-10-12 20:44:09 TP0] Prefill batch. #new-seq: 1, #new-token: 930, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 1367, 
[1,0]<stdout>:[2025-10-12 20:44:09 TP0] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1366, 
[1,0]<stdout>:[2025-10-12 20:44:10 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1365, 
[1,0]<stdout>:[2025-10-12 20:44:10 TP0] Prefill batch. #new-seq: 2, #new-token: 248, #cached-token: 10, token usage: 0.09, #running-req: 46, #queue-req: 1363, 
[1,0]<stdout>:[2025-10-12 20:44:10 TP0] Decode batch. #running-req: 48, #token: 24177, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 787.01, #queue-req: 1363, 
[1,0]<stdout>:[2025-10-12 20:44:10 TP0] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1362, 
[1,0]<stdout>:[2025-10-12 20:44:11 TP0] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1361, 
[1,0]<stdout>:[2025-10-12 20:44:11 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1360, 
[1,0]<stdout>:[2025-10-12 20:44:11 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1359, 
[1,0]<stdout>:[2025-10-12 20:44:12 TP0] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1358, 
[1,0]<stdout>:[2025-10-12 20:44:12 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1357, 
[1,0]<stdout>:[2025-10-12 20:44:12 TP0] Prefill batch. #new-seq: 2, #new-token: 981, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 1355, 
[1,0]<stdout>:[2025-10-12 20:44:13 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1354, 
[1,0]<stdout>:[2025-10-12 20:44:13 TP0] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 1353, 
[1,0]<stdout>:[2025-10-12 20:44:13 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1352, 
[1,0]<stdout>:[2025-10-12 20:44:13 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1351, 
[1,0]<stdout>:[2025-10-12 20:44:14 TP0] Decode batch. #running-req: 48, #token: 23377, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 550.80, #queue-req: 1351, 
[1,0]<stdout>:[2025-10-12 20:44:14 TP0] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1350, 
[1,0]<stdout>:[2025-10-12 20:44:14 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1349, 
[1,0]<stdout>:[2025-10-12 20:44:14 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1348, 
[1,0]<stdout>:[2025-10-12 20:44:15 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1347, 
[1,0]<stdout>:[2025-10-12 20:44:15 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1346, 
[1,0]<stdout>:[2025-10-12 20:44:15 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1345, 
[1,0]<stdout>:[2025-10-12 20:44:16 TP0] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1344, 
[1,0]<stdout>:[2025-10-12 20:44:16 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 7, token usage: 0.09, #running-req: 47, #queue-req: 1343, 
[1,0]<stdout>:[2025-10-12 20:44:16 TP0] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1342, 
[1,0]<stdout>:[2025-10-12 20:44:17 TP0] Prefill batch. #new-seq: 1, #new-token: 765, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1341, 
[1,0]<stdout>:[2025-10-12 20:44:17 TP0] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1340, 
[1,0]<stdout>:[2025-10-12 20:44:17 TP0] Decode batch. #running-req: 47, #token: 24643, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 549.14, #queue-req: 1340, 
[1,0]<stdout>:[2025-10-12 20:44:17 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1339, 
[1,0]<stdout>:[2025-10-12 20:44:17 TP0] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1338, 
[1,0]<stdout>:[2025-10-12 20:44:18 TP0] Prefill batch. #new-seq: 3, #new-token: 234, #cached-token: 12, token usage: 0.09, #running-req: 45, #queue-req: 1335, 
[1,0]<stdout>:[2025-10-12 20:44:18 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 12, token usage: 0.09, #running-req: 47, #queue-req: 1334, 
[1,0]<stdout>:[2025-10-12 20:44:19 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1333, 
[1,0]<stdout>:[2025-10-12 20:44:19 TP0] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 1332, 
[1,0]<stdout>:[2025-10-12 20:44:19 TP0] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1331, 
[1,0]<stdout>:[2025-10-12 20:44:20 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1330, 
[1,0]<stdout>:[2025-10-12 20:44:20 TP0] Decode batch. #running-req: 48, #token: 24826, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 677.92, #queue-req: 1330, 
[1,0]<stdout>:[2025-10-12 20:44:20 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1329, 
[1,0]<stdout>:[2025-10-12 20:44:20 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1328, 
[1,0]<stdout>:[2025-10-12 20:44:21 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1327, 
[1,0]<stdout>:[2025-10-12 20:44:21 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1326, 
[1,0]<stdout>:[2025-10-12 20:44:21 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1325, 
[1,0]<stdout>:[2025-10-12 20:44:22 TP0] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1324, 
[1,0]<stdout>:[2025-10-12 20:44:22 TP0] Prefill batch. #new-seq: 3, #new-token: 608, #cached-token: 5, token usage: 0.09, #running-req: 45, #queue-req: 1321, 
[1,0]<stdout>:[2025-10-12 20:44:22 TP0] Prefill batch. #new-seq: 1, #new-token: 407, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1320, 
[1,0]<stdout>:[2025-10-12 20:44:23 TP0] Decode batch. #running-req: 47, #token: 22849, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 684.63, #queue-req: 1320, 
[1,0]<stdout>:[2025-10-12 20:44:23 TP0] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1319, 
[1,0]<stdout>:[2025-10-12 20:44:23 TP0] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1318, 
[1,0]<stdout>:[2025-10-12 20:44:23 TP0] Prefill batch. #new-seq: 1, #new-token: 794, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1317, 
[1,0]<stdout>:[2025-10-12 20:44:24 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1316, 
[1,0]<stdout>:[2025-10-12 20:44:24 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1315, 
[1,0]<stdout>:[2025-10-12 20:44:24 TP0] Prefill batch. #new-seq: 2, #new-token: 275, #cached-token: 5, token usage: 0.09, #running-req: 46, #queue-req: 1313, 
[1,0]<stdout>:[2025-10-12 20:44:25 TP0] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1312, 
[1,0]<stdout>:[2025-10-12 20:44:25 TP0] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1311, 
[1,0]<stdout>:[2025-10-12 20:44:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1310, 
[1,0]<stdout>:[2025-10-12 20:44:26 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1309, 
[1,0]<stdout>:[2025-10-12 20:44:26 TP0] Prefill batch. #new-seq: 1, #new-token: 892, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1308, 
[1,0]<stdout>:[2025-10-12 20:44:26 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1307, 
[1,0]<stdout>:[2025-10-12 20:44:26 TP0] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1306, 
[1,0]<stdout>:[2025-10-12 20:44:27 TP0] Decode batch. #running-req: 47, #token: 23059, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 490.17, #queue-req: 1306, 
[1,0]<stdout>:[2025-10-12 20:44:27 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1305, 
[1,0]<stdout>:[2025-10-12 20:44:27 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1304, 
[1,0]<stdout>:[2025-10-12 20:44:27 TP0] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1303, 
[1,0]<stdout>:[2025-10-12 20:44:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1021, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1302, 
[1,0]<stdout>:[2025-10-12 20:44:28 TP0] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1301, 
[1,0]<stdout>:[2025-10-12 20:44:28 TP0] Prefill batch. #new-seq: 2, #new-token: 761, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1299, 
[1,0]<stdout>:[2025-10-12 20:44:28 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1298, 
[1,0]<stdout>:[2025-10-12 20:44:29 TP0] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1297, 
[1,0]<stdout>:[2025-10-12 20:44:29 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1296, 
[1,0]<stdout>:[2025-10-12 20:44:29 TP0] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1295, 
[1,0]<stdout>:[2025-10-12 20:44:30 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1294, 
[1,0]<stdout>:[2025-10-12 20:44:30 TP0] Prefill batch. #new-seq: 1, #new-token: 789, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1293, 
[1,0]<stdout>:[2025-10-12 20:44:30 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1292, 
[1,0]<stdout>:[2025-10-12 20:44:31 TP0] Decode batch. #running-req: 48, #token: 22513, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 491.11, #queue-req: 1292, 
[1,0]<stdout>:[2025-10-12 20:44:31 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1291, 
[1,0]<stdout>:[2025-10-12 20:44:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1386, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1290, 
[1,0]<stdout>:[2025-10-12 20:44:31 TP0] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1289, 
[1,0]<stdout>:[2025-10-12 20:44:32 TP0] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1288, 
[1,0]<stdout>:[2025-10-12 20:44:32 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1287, 
[1,0]<stdout>:[2025-10-12 20:44:32 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1286, 
[1,0]<stdout>:[2025-10-12 20:44:33 TP0] Prefill batch. #new-seq: 2, #new-token: 947, #cached-token: 8, token usage: 0.09, #running-req: 46, #queue-req: 1284, 
[1,0]<stdout>:[2025-10-12 20:44:33 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1283, 
[1,0]<stdout>:[2025-10-12 20:44:33 TP0] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1282, 
[1,0]<stdout>:[2025-10-12 20:44:34 TP0] Decode batch. #running-req: 48, #token: 24273, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 619.82, #queue-req: 1282, 
[1,0]<stdout>:[2025-10-12 20:44:34 TP0] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1281, 
[1,0]<stdout>:[2025-10-12 20:44:34 TP0] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1280, 
[1,0]<stdout>:[2025-10-12 20:44:34 TP0] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1279, 
[1,0]<stdout>:[2025-10-12 20:44:35 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1278, 
[1,0]<stdout>:[2025-10-12 20:44:35 TP0] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1277, 
[1,0]<stdout>:[2025-10-12 20:44:35 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1276, 
[1,0]<stdout>:[2025-10-12 20:44:36 TP0] Prefill batch. #new-seq: 1, #new-token: 862, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 1275, 
[1,0]<stdout>:[2025-10-12 20:44:36 TP0] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1274, 
[1,0]<stdout>:[2025-10-12 20:44:36 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1273, 
[1,0]<stdout>:[2025-10-12 20:44:37 TP0] Decode batch. #running-req: 48, #token: 25153, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 600.66, #queue-req: 1273, 
[1,0]<stdout>:[2025-10-12 20:44:37 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1272, 
[1,0]<stdout>:[2025-10-12 20:44:37 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1271, 
[1,0]<stdout>:[2025-10-12 20:44:37 TP0] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1270, 
[1,0]<stdout>:[2025-10-12 20:44:38 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1269, 
[1,0]<stdout>:[2025-10-12 20:44:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1268, 
[1,0]<stdout>:[2025-10-12 20:44:39 TP0] Prefill batch. #new-seq: 1, #new-token: 6399, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1267, 
[1,0]<stdout>:[2025-10-12 20:44:39 TP0] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1266, 
[1,0]<stdout>:[2025-10-12 20:44:39 TP0] Prefill batch. #new-seq: 2, #new-token: 372, #cached-token: 6, token usage: 0.11, #running-req: 46, #queue-req: 1264, 
[1,0]<stdout>:[2025-10-12 20:44:40 TP0] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1263, 
[1,0]<stdout>:[2025-10-12 20:44:40 TP0] Decode batch. #running-req: 48, #token: 28818, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 582.69, #queue-req: 1263, 
[1,0]<stdout>:[2025-10-12 20:44:40 TP0] Prefill batch. #new-seq: 2, #new-token: 143, #cached-token: 8, token usage: 0.11, #running-req: 46, #queue-req: 1261, 
[1,0]<stdout>:[2025-10-12 20:44:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1260, 
[1,0]<stdout>:[2025-10-12 20:44:41 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1259, 
[1,0]<stdout>:[2025-10-12 20:44:41 TP0] Prefill batch. #new-seq: 2, #new-token: 166, #cached-token: 9, token usage: 0.11, #running-req: 46, #queue-req: 1257, 
[1,0]<stdout>:[2025-10-12 20:44:42 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1256, 
[1,0]<stdout>:[2025-10-12 20:44:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1966, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1255, 
[1,0]<stdout>:[2025-10-12 20:44:42 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1254, 
[1,0]<stdout>:[2025-10-12 20:44:42 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 1253, 
[1,0]<stdout>:[2025-10-12 20:44:43 TP0] Prefill batch. #new-seq: 1, #new-token: 749, #cached-token: 6, token usage: 0.12, #running-req: 47, #queue-req: 1252, 
[1,0]<stdout>:[2025-10-12 20:44:43 TP0] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1251, 
[1,0]<stdout>:[2025-10-12 20:44:43 TP0] Decode batch. #running-req: 48, #token: 30262, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 573.67, #queue-req: 1251, 
[1,0]<stdout>:[2025-10-12 20:44:43 TP0] Prefill batch. #new-seq: 1, #new-token: 781, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1250, 
[1,0]<stdout>:[2025-10-12 20:44:44 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1249, 
[1,0]<stdout>:[2025-10-12 20:44:45 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1248, 
[1,0]<stdout>:[2025-10-12 20:44:45 TP0] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 6, token usage: 0.12, #running-req: 47, #queue-req: 1247, 
[1,0]<stdout>:[2025-10-12 20:44:45 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1246, 
[1,0]<stdout>:[2025-10-12 20:44:45 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1245, 
[1,0]<stdout>:[2025-10-12 20:44:46 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1244, 
[1,0]<stdout>:[2025-10-12 20:44:46 TP0] Prefill batch. #new-seq: 2, #new-token: 2304, #cached-token: 5, token usage: 0.12, #running-req: 46, #queue-req: 1242, 
[1,0]<stdout>:[2025-10-12 20:44:46 TP0] Decode batch. #running-req: 48, #token: 32604, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 654.78, #queue-req: 1242, 
[1,0]<stdout>:[2025-10-12 20:44:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1012, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1241, 
[1,0]<stdout>:[2025-10-12 20:44:47 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1240, 
[1,0]<stdout>:[2025-10-12 20:44:47 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1239, 
[1,0]<stdout>:[2025-10-12 20:44:48 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1238, 
[1,0]<stdout>:[2025-10-12 20:44:48 TP0] Prefill batch. #new-seq: 2, #new-token: 23, #cached-token: 3, token usage: 0.13, #running-req: 46, #queue-req: 1236, 
[1,0]<stdout>:[2025-10-12 20:44:48 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1235, 
[1,0]<stdout>:[2025-10-12 20:44:48 TP0] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1234, 
[1,0]<stdout>:[2025-10-12 20:44:49 TP0] Prefill batch. #new-seq: 2, #new-token: 296, #cached-token: 2, token usage: 0.12, #running-req: 46, #queue-req: 1232, 
[1,0]<stdout>:[2025-10-12 20:44:49 TP0] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1231, 
[1,0]<stdout>:[2025-10-12 20:44:49 TP0] Decode batch. #running-req: 47, #token: 31373, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 617.06, #queue-req: 1231, 
[1,0]<stdout>:[2025-10-12 20:44:49 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1230, 
[1,0]<stdout>:[2025-10-12 20:44:50 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1229, 
[1,0]<stdout>:[2025-10-12 20:44:50 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 1228, 
[1,0]<stdout>:[2025-10-12 20:44:50 TP0] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1227, 
[1,0]<stdout>:[2025-10-12 20:44:51 TP0] Prefill batch. #new-seq: 1, #new-token: 820, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1226, 
[1,0]<stdout>:[2025-10-12 20:44:51 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 1225, 
[1,0]<stdout>:[2025-10-12 20:44:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1898, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1224, 
[1,0]<stdout>:[2025-10-12 20:44:52 TP0] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1223, 
[1,0]<stdout>:[2025-10-12 20:44:52 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.13, #running-req: 47, #queue-req: 1222, 
[1,0]<stdout>:[2025-10-12 20:44:52 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1221, 
[1,0]<stdout>:[2025-10-12 20:44:52 TP0] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1220, 
[1,0]<stdout>:[2025-10-12 20:44:53 TP0] Decode batch. #running-req: 48, #token: 32414, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 551.67, #queue-req: 1220, 
[1,0]<stdout>:[2025-10-12 20:44:53 TP0] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1219, 
[1,0]<stdout>:[2025-10-12 20:44:53 TP0] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1218, 
[1,0]<stdout>:[2025-10-12 20:44:53 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1217, 
[1,0]<stdout>:[2025-10-12 20:44:54 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1216, 
[1,0]<stdout>:[2025-10-12 20:44:54 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1215, 
[1,0]<stdout>:[2025-10-12 20:44:54 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1214, 
[1,0]<stdout>:[2025-10-12 20:44:55 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1213, 
[1,0]<stdout>:[2025-10-12 20:44:55 TP0] Prefill batch. #new-seq: 2, #new-token: 826, #cached-token: 5, token usage: 0.11, #running-req: 46, #queue-req: 1211, 
[1,0]<stdout>:[2025-10-12 20:44:55 TP0] Prefill batch. #new-seq: 1, #new-token: 2044, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1210, 
[1,0]<stdout>:[2025-10-12 20:44:55 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1209, 
[1,0]<stdout>:[2025-10-12 20:44:56 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1208, 
[1,0]<stdout>:[2025-10-12 20:44:56 TP0] Prefill batch. #new-seq: 2, #new-token: 1408, #cached-token: 7, token usage: 0.12, #running-req: 46, #queue-req: 1206, 
[1,0]<stdout>:[2025-10-12 20:44:56 TP0] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1205, 
[1,0]<stdout>:[2025-10-12 20:44:57 TP0] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 8, token usage: 0.13, #running-req: 47, #queue-req: 1204, 
[1,0]<stdout>:[2025-10-12 20:44:57 TP0] Decode batch. #running-req: 48, #token: 31733, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 471.44, #queue-req: 1204, 
[1,0]<stdout>:[2025-10-12 20:44:57 TP0] Prefill batch. #new-seq: 2, #new-token: 744, #cached-token: 10, token usage: 0.13, #running-req: 46, #queue-req: 1202, 
[1,0]<stdout>:[2025-10-12 20:44:57 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1201, 
[1,0]<stdout>:[2025-10-12 20:44:58 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1200, 
[1,0]<stdout>:[2025-10-12 20:44:58 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1199, 
[1,0]<stdout>:[2025-10-12 20:44:58 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 6, token usage: 0.13, #running-req: 47, #queue-req: 1198, 
[1,0]<stdout>:[2025-10-12 20:44:59 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 8, token usage: 0.13, #running-req: 47, #queue-req: 1197, 
[1,0]<stdout>:[2025-10-12 20:44:59 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1196, 
[1,0]<stdout>:[2025-10-12 20:44:59 TP0] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1195, 
[1,0]<stdout>:[2025-10-12 20:44:59 TP0] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1194, 
[1,0]<stdout>:[2025-10-12 20:45:00 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1193, 
[1,0]<stdout>:[2025-10-12 20:45:00 TP0] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1192, 
[1,0]<stdout>:[2025-10-12 20:45:00 TP0] Prefill batch. #new-seq: 2, #new-token: 1139, #cached-token: 6, token usage: 0.12, #running-req: 46, #queue-req: 1190, 
[1,0]<stdout>:[2025-10-12 20:45:01 TP0] Decode batch. #running-req: 48, #token: 31515, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 517.09, #queue-req: 1190, 
[1,0]<stdout>:[2025-10-12 20:45:01 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1189, 
[1,0]<stdout>:[2025-10-12 20:45:01 TP0] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 1188, 
[1,0]<stdout>:[2025-10-12 20:45:01 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1187, 
[1,0]<stdout>:[2025-10-12 20:45:02 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1186, 
[1,0]<stdout>:[2025-10-12 20:45:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1538, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1185, 
[1,0]<stdout>:[2025-10-12 20:45:04 TP0] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 2, token usage: 0.14, #running-req: 47, #queue-req: 1184, 
[1,0]<stdout>:[2025-10-12 20:45:05 TP0] Decode batch. #running-req: 48, #token: 34634, token usage: 0.14, accept len: 1.00, cuda graph: True, gen throughput (token/s): 480.54, #queue-req: 1184, 
[1,0]<stdout>:[2025-10-12 20:45:05 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 11, token usage: 0.14, #running-req: 47, #queue-req: 1183, 
[1,0]<stdout>:[2025-10-12 20:45:05 TP0] Prefill batch. #new-seq: 2, #new-token: 27, #cached-token: 5, token usage: 0.13, #running-req: 46, #queue-req: 1181, 
[1,0]<stdout>:[2025-10-12 20:45:05 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1180, 
[1,0]<stdout>:[2025-10-12 20:45:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1474, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1179, 
[1,0]<stdout>:[2025-10-12 20:45:06 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1178, 
[1,0]<stdout>:[2025-10-12 20:45:06 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 8, token usage: 0.14, #running-req: 47, #queue-req: 1177, 
[1,0]<stdout>:[2025-10-12 20:45:07 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1176, 
[1,0]<stdout>:[2025-10-12 20:45:07 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1175, 
[1,0]<stdout>:[2025-10-12 20:45:07 TP0] Decode batch. #running-req: 48, #token: 31763, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 664.08, #queue-req: 1175, 
[1,0]<stdout>:[2025-10-12 20:45:08 TP0] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1174, 
[1,0]<stdout>:[2025-10-12 20:45:08 TP0] Prefill batch. #new-seq: 2, #new-token: 12, #cached-token: 6, token usage: 0.13, #running-req: 46, #queue-req: 1172, 
[1,0]<stdout>:[2025-10-12 20:45:08 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1171, 
[1,0]<stdout>:[2025-10-12 20:45:09 TP0] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1170, 
[1,0]<stdout>:[2025-10-12 20:45:09 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 4, token usage: 0.13, #running-req: 47, #queue-req: 1169, 
[1,0]<stdout>:[2025-10-12 20:45:10 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1168, 
[1,0]<stdout>:[2025-10-12 20:45:10 TP0] Prefill batch. #new-seq: 1, #new-token: 691, #cached-token: 6, token usage: 0.13, #running-req: 47, #queue-req: 1167, 
[1,0]<stdout>:[2025-10-12 20:45:10 TP0] Decode batch. #running-req: 48, #token: 32241, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 711.30, #queue-req: 1167, 
[1,0]<stdout>:[2025-10-12 20:45:10 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 1166, 
[1,0]<stdout>:[2025-10-12 20:45:11 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1165, 
[1,0]<stdout>:[2025-10-12 20:45:11 TP0] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1164, 
[1,0]<stdout>:[2025-10-12 20:45:11 TP0] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1163, 
[1,0]<stdout>:[2025-10-12 20:45:12 TP0] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1162, 
[1,0]<stdout>:[2025-10-12 20:45:12 TP0] Prefill batch. #new-seq: 1, #new-token: 2423, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1161, 
[1,0]<stdout>:[2025-10-12 20:45:12 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1160, 
[1,0]<stdout>:[2025-10-12 20:45:13 TP0] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1159, 
[1,0]<stdout>:[2025-10-12 20:45:13 TP0] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1158, 
[1,0]<stdout>:[2025-10-12 20:45:13 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1157, 
[1,0]<stdout>:[2025-10-12 20:45:13 TP0] Decode batch. #running-req: 48, #token: 26782, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 579.12, #queue-req: 1157, 
[1,0]<stdout>:[2025-10-12 20:45:14 TP0] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1156, 
[1,0]<stdout>:[2025-10-12 20:45:14 TP0] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 8, token usage: 0.10, #running-req: 47, #queue-req: 1155, 
[1,0]<stdout>:[2025-10-12 20:45:14 TP0] Prefill batch. #new-seq: 1, #new-token: 844, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1154, 
[1,0]<stdout>:[2025-10-12 20:45:14 TP0] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1153, 
[1,0]<stdout>:[2025-10-12 20:45:15 TP0] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1152, 
[1,0]<stdout>:[2025-10-12 20:45:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1151, 
[1,0]<stdout>:[2025-10-12 20:45:15 TP0] Prefill batch. #new-seq: 2, #new-token: 535, #cached-token: 11, token usage: 0.10, #running-req: 46, #queue-req: 1149, 
[1,0]<stdout>:[2025-10-12 20:45:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 393, token usage: 0.10, #running-req: 47, #queue-req: 1148, 
[1,0]<stdout>:[2025-10-12 20:45:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1734, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1147, 
[1,0]<stdout>:[2025-10-12 20:45:16 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1146, 
[1,0]<stdout>:[2025-10-12 20:45:17 TP0] Decode batch. #running-req: 47, #token: 27155, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 577.54, #queue-req: 1146, 
[1,0]<stdout>:[2025-10-12 20:45:17 TP0] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 7, token usage: 0.11, #running-req: 47, #queue-req: 1145, 
[1,0]<stdout>:[2025-10-12 20:45:17 TP0] Prefill batch. #new-seq: 2, #new-token: 189, #cached-token: 4, token usage: 0.11, #running-req: 46, #queue-req: 1143, 
[1,0]<stdout>:[2025-10-12 20:45:17 TP0] Prefill batch. #new-seq: 2, #new-token: 138, #cached-token: 2, token usage: 0.11, #running-req: 46, #queue-req: 1141, 
[1,0]<stdout>:[2025-10-12 20:45:18 TP0] Prefill batch. #new-seq: 2, #new-token: 636, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 1139, 
[1,0]<stdout>:[2025-10-12 20:45:18 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1138, 
[1,0]<stdout>:[2025-10-12 20:45:18 TP0] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1137, 
[1,0]<stdout>:[2025-10-12 20:45:19 TP0] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1136, 
[1,0]<stdout>:[2025-10-12 20:45:19 TP0] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1135, 
[1,0]<stdout>:[2025-10-12 20:45:20 TP0] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1134, 
[1,0]<stdout>:[2025-10-12 20:45:20 TP0] Decode batch. #running-req: 48, #token: 25119, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 611.78, #queue-req: 1134, 
[1,0]<stdout>:[2025-10-12 20:45:20 TP0] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1133, 
[1,0]<stdout>:[2025-10-12 20:45:20 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1132, 
[1,0]<stdout>:[2025-10-12 20:45:21 TP0] Prefill batch. #new-seq: 2, #new-token: 415, #cached-token: 11, token usage: 0.10, #running-req: 46, #queue-req: 1130, 
[1,0]<stdout>:[2025-10-12 20:45:21 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1129, 
[1,0]<stdout>:[2025-10-12 20:45:22 TP0] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1128, 
[1,0]<stdout>:[2025-10-12 20:45:22 TP0] Prefill batch. #new-seq: 2, #new-token: 325, #cached-token: 4, token usage: 0.10, #running-req: 46, #queue-req: 1126, 
[1,0]<stdout>:[2025-10-12 20:45:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 359, token usage: 0.10, #running-req: 47, #queue-req: 1125, 
[1,0]<stdout>:[2025-10-12 20:45:23 TP0] Decode batch. #running-req: 48, #token: 25146, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 708.52, #queue-req: 1125, 
[1,0]<stdout>:[2025-10-12 20:45:23 TP0] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1124, 
[1,0]<stdout>:[2025-10-12 20:45:23 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1123, 
[1,0]<stdout>:[2025-10-12 20:45:23 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1122, 
[1,0]<stdout>:[2025-10-12 20:45:24 TP0] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1121, 
[1,0]<stdout>:[2025-10-12 20:45:24 TP0] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1120, 
[1,0]<stdout>:[2025-10-12 20:45:24 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1119, 
[1,0]<stdout>:[2025-10-12 20:45:25 TP0] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1118, 
[1,0]<stdout>:[2025-10-12 20:45:25 TP0] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1117, 
[1,0]<stdout>:[2025-10-12 20:45:25 TP0] Decode batch. #running-req: 48, #token: 21830, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 658.11, #queue-req: 1117, 
[1,0]<stdout>:[2025-10-12 20:45:26 TP0] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1116, 
[1,0]<stdout>:[2025-10-12 20:45:26 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1115, 
[1,0]<stdout>:[2025-10-12 20:45:26 TP0] Prefill batch. #new-seq: 2, #new-token: 577, #cached-token: 8, token usage: 0.08, #running-req: 46, #queue-req: 1113, 
[1,0]<stdout>:[2025-10-12 20:45:27 TP0] Prefill batch. #new-seq: 1, #new-token: 986, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1112, 
[1,0]<stdout>:[2025-10-12 20:45:27 TP0] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1111, 
[1,0]<stdout>:[2025-10-12 20:45:27 TP0] Prefill batch. #new-seq: 1, #new-token: 738, #cached-token: 8, token usage: 0.08, #running-req: 47, #queue-req: 1110, 
[1,0]<stdout>:[2025-10-12 20:45:27 TP0] Prefill batch. #new-seq: 3, #new-token: 702, #cached-token: 9, token usage: 0.09, #running-req: 45, #queue-req: 1107, 
[1,0]<stdout>:[2025-10-12 20:45:28 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1106, 
[1,0]<stdout>:[2025-10-12 20:45:28 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1105, 
[1,0]<stdout>:[2025-10-12 20:45:29 TP0] Decode batch. #running-req: 48, #token: 22807, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 609.29, #queue-req: 1105, 
[1,0]<stdout>:[2025-10-12 20:45:29 TP0] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1104, 
[1,0]<stdout>:[2025-10-12 20:45:29 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1103, 
[1,0]<stdout>:[2025-10-12 20:45:30 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1102, 
[1,0]<stdout>:[2025-10-12 20:45:30 TP0] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1101, 
[1,0]<stdout>:[2025-10-12 20:45:31 TP0] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1100, 
[1,0]<stdout>:[2025-10-12 20:45:31 TP0] Decode batch. #running-req: 47, #token: 20439, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 831.21, #queue-req: 1100, 
[1,0]<stdout>:[2025-10-12 20:45:31 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1099, 
[1,0]<stdout>:[2025-10-12 20:45:32 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1098, 
[1,0]<stdout>:[2025-10-12 20:45:33 TP0] Decode batch. #running-req: 48, #token: 20411, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1160.77, #queue-req: 1098, 
[1,0]<stdout>:[2025-10-12 20:45:33 TP0] Prefill batch. #new-seq: 2, #new-token: 21, #cached-token: 2, token usage: 0.08, #running-req: 46, #queue-req: 1096, 
[1,0]<stdout>:[2025-10-12 20:45:33 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1095, 
[1,0]<stdout>:[2025-10-12 20:45:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 376, token usage: 0.08, #running-req: 47, #queue-req: 1094, 
[1,0]<stdout>:[2025-10-12 20:45:34 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1093, 
[1,0]<stdout>:[2025-10-12 20:45:34 TP0] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1092, 
[1,0]<stdout>:[2025-10-12 20:45:34 TP0] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1091, 
[1,0]<stdout>:[2025-10-12 20:45:35 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 15, token usage: 0.07, #running-req: 46, #queue-req: 1089, 
[1,0]<stdout>:[2025-10-12 20:45:35 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1088, 
[1,0]<stdout>:[2025-10-12 20:45:36 TP0] Decode batch. #running-req: 48, #token: 19978, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 644.56, #queue-req: 1088, 
[1,0]<stdout>:[2025-10-12 20:45:36 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1087, 
[1,0]<stdout>:[2025-10-12 20:45:36 TP0] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1086, 
[1,0]<stdout>:[2025-10-12 20:45:36 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1085, 
[1,0]<stdout>:[2025-10-12 20:45:37 TP0] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 8, token usage: 0.08, #running-req: 47, #queue-req: 1084, 
[1,0]<stdout>:[2025-10-12 20:45:37 TP0] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1083, 
[1,0]<stdout>:[2025-10-12 20:45:37 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1082, 
[1,0]<stdout>:[2025-10-12 20:45:38 TP0] Decode batch. #running-req: 48, #token: 20810, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 777.50, #queue-req: 1082, 
[1,0]<stdout>:[2025-10-12 20:45:38 TP0] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 10, token usage: 0.08, #running-req: 47, #queue-req: 1081, 
[1,0]<stdout>:[2025-10-12 20:45:39 TP0] Prefill batch. #new-seq: 1, #new-token: 238, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1080, 
[1,0]<stdout>:[2025-10-12 20:45:39 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1079, 
[1,0]<stdout>:[2025-10-12 20:45:39 TP0] Prefill batch. #new-seq: 2, #new-token: 328, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1077, 
[1,0]<stdout>:[2025-10-12 20:45:39 TP0] Prefill batch. #new-seq: 3, #new-token: 561, #cached-token: 8, token usage: 0.08, #running-req: 45, #queue-req: 1074, 
[1,0]<stdout>:[2025-10-12 20:45:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1427, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1073, 
[1,0]<stdout>:[2025-10-12 20:45:40 TP0] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1072, 
[1,0]<stdout>:[2025-10-12 20:45:40 TP0] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1071, 
[1,0]<stdout>:[2025-10-12 20:45:41 TP0] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1070, 
[1,0]<stdout>:[2025-10-12 20:45:41 TP0] Decode batch. #running-req: 48, #token: 22085, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 613.26, #queue-req: 1070, 
[1,0]<stdout>:[2025-10-12 20:45:41 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1069, 
[1,0]<stdout>:[2025-10-12 20:45:41 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1068, 
[1,0]<stdout>:[2025-10-12 20:45:42 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1067, 
[1,0]<stdout>:[2025-10-12 20:45:42 TP0] Prefill batch. #new-seq: 2, #new-token: 625, #cached-token: 8, token usage: 0.09, #running-req: 46, #queue-req: 1065, 
[1,0]<stdout>:[2025-10-12 20:45:42 TP0] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1064, 
[1,0]<stdout>:[2025-10-12 20:45:43 TP0] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1063, 
[1,0]<stdout>:[2025-10-12 20:45:43 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1062, 
[1,0]<stdout>:[2025-10-12 20:45:43 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1061, 
[1,0]<stdout>:[2025-10-12 20:45:44 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1060, 
[1,0]<stdout>:[2025-10-12 20:45:44 TP0] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1059, 
[1,0]<stdout>:[2025-10-12 20:45:44 TP0] Prefill batch. #new-seq: 2, #new-token: 583, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1057, 
[1,0]<stdout>:[2025-10-12 20:45:45 TP0] Decode batch. #running-req: 48, #token: 23063, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 544.14, #queue-req: 1057, 
[1,0]<stdout>:[2025-10-12 20:45:45 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1056, 
[1,0]<stdout>:[2025-10-12 20:45:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1055, 
[1,0]<stdout>:[2025-10-12 20:45:45 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1054, 
[1,0]<stdout>:[2025-10-12 20:45:46 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1053, 
[1,0]<stdout>:[2025-10-12 20:45:46 TP0] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 9, token usage: 0.09, #running-req: 47, #queue-req: 1052, 
[1,0]<stdout>:[2025-10-12 20:45:46 TP0] Prefill batch. #new-seq: 1, #new-token: 829, #cached-token: 10, token usage: 0.09, #running-req: 47, #queue-req: 1051, 
[1,0]<stdout>:[2025-10-12 20:45:47 TP0] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1050, 
[1,0]<stdout>:[2025-10-12 20:45:47 TP0] Decode batch. #running-req: 47, #token: 23441, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 715.75, #queue-req: 1050, 
[1,0]<stdout>:[2025-10-12 20:45:47 TP0] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1049, 
[1,0]<stdout>:[2025-10-12 20:45:48 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1048, 
[1,0]<stdout>:[2025-10-12 20:45:48 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1047, 
[1,0]<stdout>:[2025-10-12 20:45:48 TP0] Prefill batch. #new-seq: 2, #new-token: 388, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 1045, 
[1,0]<stdout>:[2025-10-12 20:45:49 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1044, 
[1,0]<stdout>:[2025-10-12 20:45:49 TP0] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1043, 
[1,0]<stdout>:[2025-10-12 20:45:49 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1042, 
[1,0]<stdout>:[2025-10-12 20:45:50 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1041, 
[1,0]<stdout>:[2025-10-12 20:45:50 TP0] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1040, 
[1,0]<stdout>:[2025-10-12 20:45:50 TP0] Decode batch. #running-req: 47, #token: 22606, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 613.27, #queue-req: 1040, 
[1,0]<stdout>:[2025-10-12 20:45:50 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1039, 
[1,0]<stdout>:[2025-10-12 20:45:51 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1038, 
[1,0]<stdout>:[2025-10-12 20:45:51 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1037, 
[1,0]<stdout>:[2025-10-12 20:45:51 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1036, 
[1,0]<stdout>:[2025-10-12 20:45:52 TP0] Prefill batch. #new-seq: 2, #new-token: 1018, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1034, 
[1,0]<stdout>:[2025-10-12 20:45:52 TP0] Prefill batch. #new-seq: 2, #new-token: 336, #cached-token: 3, token usage: 0.09, #running-req: 46, #queue-req: 1032, 
[1,0]<stdout>:[2025-10-12 20:45:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1031, 
[1,0]<stdout>:[2025-10-12 20:45:53 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1030, 
[1,0]<stdout>:[2025-10-12 20:45:53 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1029, 
[1,0]<stdout>:[2025-10-12 20:45:53 TP0] Decode batch. #running-req: 48, #token: 23701, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 624.15, #queue-req: 1029, 
[1,0]<stdout>:[2025-10-12 20:45:54 TP0] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1028, 
[1,0]<stdout>:[2025-10-12 20:45:54 TP0] Prefill batch. #new-seq: 1, #new-token: 3215, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1027, 
[1,0]<stdout>:[2025-10-12 20:45:54 TP0] Prefill batch. #new-seq: 2, #new-token: 519, #cached-token: 7, token usage: 0.11, #running-req: 46, #queue-req: 1025, 
[1,0]<stdout>:[2025-10-12 20:45:55 TP0] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1024, 
[1,0]<stdout>:[2025-10-12 20:45:55 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1023, 
[1,0]<stdout>:[2025-10-12 20:45:55 TP0] Prefill batch. #new-seq: 3, #new-token: 925, #cached-token: 6, token usage: 0.11, #running-req: 45, #queue-req: 1020, 
[1,0]<stdout>:[2025-10-12 20:45:56 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1019, 
[1,0]<stdout>:[2025-10-12 20:45:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1018, 
[1,0]<stdout>:[2025-10-12 20:45:56 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1017, 
[1,0]<stdout>:[2025-10-12 20:45:56 TP0] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1016, 
[1,0]<stdout>:[2025-10-12 20:45:57 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1015, 
[1,0]<stdout>:[2025-10-12 20:45:57 TP0] Decode batch. #running-req: 48, #token: 27646, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 542.71, #queue-req: 1015, 
[1,0]<stdout>:[2025-10-12 20:45:57 TP0] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1014, 
[1,0]<stdout>:[2025-10-12 20:45:57 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1013, 
[1,0]<stdout>:[2025-10-12 20:45:58 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1012, 
[1,0]<stdout>:[2025-10-12 20:45:58 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1011, 
[1,0]<stdout>:[2025-10-12 20:45:58 TP0] Prefill batch. #new-seq: 2, #new-token: 2516, #cached-token: 5, token usage: 0.10, #running-req: 46, #queue-req: 1009, 
[1,0]<stdout>:[2025-10-12 20:45:58 TP0] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1008, 
[1,0]<stdout>:[2025-10-12 20:45:59 TP0] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1007, 
[1,0]<stdout>:[2025-10-12 20:45:59 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1006, 
[1,0]<stdout>:[2025-10-12 20:45:59 TP0] Prefill batch. #new-seq: 2, #new-token: 641, #cached-token: 8, token usage: 0.10, #running-req: 46, #queue-req: 1004, 
[1,0]<stdout>:[2025-10-12 20:46:00 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1003, 
[1,0]<stdout>:[2025-10-12 20:46:00 TP0] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1002, 
[1,0]<stdout>:[2025-10-12 20:46:00 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1001, 
[1,0]<stdout>:[2025-10-12 20:46:01 TP0] Decode batch. #running-req: 48, #token: 27382, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 508.43, #queue-req: 1001, 
[1,0]<stdout>:[2025-10-12 20:46:01 TP0] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1000, 
[1,0]<stdout>:[2025-10-12 20:46:01 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 999, 
[1,0]<stdout>:[2025-10-12 20:46:02 TP0] Prefill batch. #new-seq: 1, #new-token: 779, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 998, 
[1,0]<stdout>:[2025-10-12 20:46:02 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 997, 
[1,0]<stdout>:[2025-10-12 20:46:02 TP0] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 996, 
[1,0]<stdout>:[2025-10-12 20:46:02 TP0] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 995, 
[1,0]<stdout>:[2025-10-12 20:46:03 TP0] Prefill batch. #new-seq: 2, #new-token: 2881, #cached-token: 9, token usage: 0.11, #running-req: 46, #queue-req: 993, 
[1,0]<stdout>:[2025-10-12 20:46:03 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 992, 
[1,0]<stdout>:[2025-10-12 20:46:04 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 991, 
[1,0]<stdout>:[2025-10-12 20:46:04 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 990, 
[1,0]<stdout>:[2025-10-12 20:46:04 TP0] Decode batch. #running-req: 48, #token: 27553, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 555.84, #queue-req: 990, 
[1,0]<stdout>:[2025-10-12 20:46:04 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 989, 
[1,0]<stdout>:[2025-10-12 20:46:05 TP0] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 988, 
[1,0]<stdout>:[2025-10-12 20:46:05 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 987, 
[1,0]<stdout>:[2025-10-12 20:46:05 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 986, 
[1,0]<stdout>:[2025-10-12 20:46:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 985, 
[1,0]<stdout>:[2025-10-12 20:46:06 TP0] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 984, 
[1,0]<stdout>:[2025-10-12 20:46:06 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 983, 
[1,0]<stdout>:[2025-10-12 20:46:07 TP0] Decode batch. #running-req: 48, #token: 27853, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 727.16, #queue-req: 983, 
[1,0]<stdout>:[2025-10-12 20:46:07 TP0] Prefill batch. #new-seq: 1, #new-token: 661, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 982, 
[1,0]<stdout>:[2025-10-12 20:46:07 TP0] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 7, token usage: 0.11, #running-req: 47, #queue-req: 981, 
[1,0]<stdout>:[2025-10-12 20:46:08 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 980, 
[1,0]<stdout>:[2025-10-12 20:46:08 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 979, 
[1,0]<stdout>:[2025-10-12 20:46:08 TP0] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 978, 
[1,0]<stdout>:[2025-10-12 20:46:08 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 977, 
[1,0]<stdout>:[2025-10-12 20:46:09 TP0] Prefill batch. #new-seq: 1, #new-token: 2428, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 976, 
[1,0]<stdout>:[2025-10-12 20:46:09 TP0] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 975, 
[1,0]<stdout>:[2025-10-12 20:46:09 TP0] Prefill batch. #new-seq: 1, #new-token: 480, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 974, 
[1,0]<stdout>:[2025-10-12 20:46:10 TP0] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 973, 
[1,0]<stdout>:[2025-10-12 20:46:10 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 972, 
[1,0]<stdout>:[2025-10-12 20:46:10 TP0] Prefill batch. #new-seq: 2, #new-token: 315, #cached-token: 4, token usage: 0.11, #running-req: 46, #queue-req: 970, 
[1,0]<stdout>:[2025-10-12 20:46:10 TP0] Decode batch. #running-req: 48, #token: 28818, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 512.80, #queue-req: 970, 
[1,0]<stdout>:[2025-10-12 20:46:11 TP0] Prefill batch. #new-seq: 2, #new-token: 809, #cached-token: 6, token usage: 0.11, #running-req: 46, #queue-req: 968, 
[1,0]<stdout>:[2025-10-12 20:46:11 TP0] Prefill batch. #new-seq: 2, #new-token: 26, #cached-token: 7, token usage: 0.11, #running-req: 46, #queue-req: 966, 
[1,0]<stdout>:[2025-10-12 20:46:11 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 965, 
[1,0]<stdout>:[2025-10-12 20:46:12 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 964, 
[1,0]<stdout>:[2025-10-12 20:46:12 TP0] Prefill batch. #new-seq: 1, #new-token: 2032, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 963, 
[1,0]<stdout>:[2025-10-12 20:46:12 TP0] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 962, 
[1,0]<stdout>:[2025-10-12 20:46:13 TP0] Prefill batch. #new-seq: 1, #new-token: 619, #cached-token: 8, token usage: 0.12, #running-req: 47, #queue-req: 961, 
[1,0]<stdout>:[2025-10-12 20:46:13 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 960, 
[1,0]<stdout>:[2025-10-12 20:46:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1101, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 959, 
[1,0]<stdout>:[2025-10-12 20:46:14 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 958, 
[1,0]<stdout>:[2025-10-12 20:46:14 TP0] Decode batch. #running-req: 48, #token: 30143, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 565.87, #queue-req: 958, 
[1,0]<stdout>:[2025-10-12 20:46:14 TP0] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 957, 
[1,0]<stdout>:[2025-10-12 20:46:14 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 956, 
[1,0]<stdout>:[2025-10-12 20:46:15 TP0] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 955, 
[1,0]<stdout>:[2025-10-12 20:46:15 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 954, 
[1,0]<stdout>:[2025-10-12 20:46:16 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 953, 
[1,0]<stdout>:[2025-10-12 20:46:16 TP0] Decode batch. #running-req: 48, #token: 30986, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 847.56, #queue-req: 953, 
[1,0]<stdout>:[2025-10-12 20:46:16 TP0] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 952, 
[1,0]<stdout>:[2025-10-12 20:46:17 TP0] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 951, 
[1,0]<stdout>:[2025-10-12 20:46:17 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 950, 
[1,0]<stdout>:[2025-10-12 20:46:17 TP0] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 949, 
[1,0]<stdout>:[2025-10-12 20:46:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1424, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 948, 
[1,0]<stdout>:[2025-10-12 20:46:18 TP0] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 947, 
[1,0]<stdout>:[2025-10-12 20:46:18 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 946, 
[1,0]<stdout>:[2025-10-12 20:46:18 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 945, 
[1,0]<stdout>:[2025-10-12 20:46:19 TP0] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 944, 
[1,0]<stdout>:[2025-10-12 20:46:19 TP0] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 4, token usage: 0.13, #running-req: 47, #queue-req: 943, 
[1,0]<stdout>:[2025-10-12 20:46:19 TP0] Decode batch. #running-req: 48, #token: 33265, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 577.60, #queue-req: 943, 
[1,0]<stdout>:[2025-10-12 20:46:20 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 19, token usage: 0.13, #running-req: 47, #queue-req: 942, 
[1,0]<stdout>:[2025-10-12 20:46:20 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 941, 
[1,0]<stdout>:[2025-10-12 20:46:21 TP0] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 940, 
[1,0]<stdout>:[2025-10-12 20:46:21 TP0] Prefill batch. #new-seq: 1, #new-token: 564, #cached-token: 3, token usage: 0.14, #running-req: 47, #queue-req: 939, 
[1,0]<stdout>:[2025-10-12 20:46:21 TP0] Decode batch. #running-req: 48, #token: 35176, token usage: 0.14, accept len: 1.00, cuda graph: True, gen throughput (token/s): 927.76, #queue-req: 939, 
[1,0]<stdout>:[2025-10-12 20:46:22 TP0] Prefill batch. #new-seq: 2, #new-token: 17, #cached-token: 3, token usage: 0.14, #running-req: 46, #queue-req: 937, 
[1,0]<stdout>:[2025-10-12 20:46:22 TP0] Prefill batch. #new-seq: 2, #new-token: 1448, #cached-token: 3, token usage: 0.13, #running-req: 46, #queue-req: 935, 
[1,0]<stdout>:[2025-10-12 20:46:23 TP0] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 3, token usage: 0.14, #running-req: 47, #queue-req: 934, 
[1,0]<stdout>:[2025-10-12 20:46:23 TP0] Prefill batch. #new-seq: 2, #new-token: 398, #cached-token: 4, token usage: 0.13, #running-req: 46, #queue-req: 932, 
[1,0]<stdout>:[2025-10-12 20:46:23 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 931, 
[1,0]<stdout>:[2025-10-12 20:46:23 TP0] Prefill batch. #new-seq: 1, #new-token: 419, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 930, 
[1,0]<stdout>:[2025-10-12 20:46:23 TP0] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 929, 
[1,0]<stdout>:[2025-10-12 20:46:24 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 928, 
[1,0]<stdout>:[2025-10-12 20:46:24 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 927, 
[1,0]<stdout>:[2025-10-12 20:46:25 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 926, 
[1,0]<stdout>:[2025-10-12 20:46:25 TP0] Decode batch. #running-req: 48, #token: 32290, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 577.04, #queue-req: 926, 
[1,0]<stdout>:[2025-10-12 20:46:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1324, #cached-token: 12, token usage: 0.13, #running-req: 47, #queue-req: 925, 
[1,0]<stdout>:[2025-10-12 20:46:25 TP0] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 924, 
[1,0]<stdout>:[2025-10-12 20:46:26 TP0] Prefill batch. #new-seq: 2, #new-token: 153, #cached-token: 4, token usage: 0.13, #running-req: 46, #queue-req: 922, 
[1,0]<stdout>:[2025-10-12 20:46:26 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 921, 
[1,0]<stdout>:[2025-10-12 20:46:26 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 920, 
[1,0]<stdout>:[2025-10-12 20:46:27 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 919, 
[1,0]<stdout>:[2025-10-12 20:46:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1779, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 918, 
[1,0]<stdout>:[2025-10-12 20:46:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1558, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 917, 
[1,0]<stdout>:[2025-10-12 20:46:28 TP0] Prefill batch. #new-seq: 1, #new-token: 597, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 916, 
[1,0]<stdout>:[2025-10-12 20:46:28 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 915, 
[1,0]<stdout>:[2025-10-12 20:46:28 TP0] Decode batch. #running-req: 48, #token: 31891, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 579.12, #queue-req: 915, 
[1,0]<stdout>:[2025-10-12 20:46:28 TP0] Prefill batch. #new-seq: 1, #new-token: 812, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 914, 
[1,0]<stdout>:[2025-10-12 20:46:29 TP0] Prefill batch. #new-seq: 2, #new-token: 3422, #cached-token: 6, token usage: 0.12, #running-req: 46, #queue-req: 912, 
[1,0]<stdout>:[2025-10-12 20:46:29 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.14, #running-req: 47, #queue-req: 911, 
[1,0]<stdout>:[2025-10-12 20:46:29 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 1, token usage: 0.14, #running-req: 47, #queue-req: 910, 
[1,0]<stdout>:[2025-10-12 20:46:29 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 909, 
[1,0]<stdout>:[2025-10-12 20:46:30 TP0] Prefill batch. #new-seq: 1, #new-token: 727, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 908, 
[1,0]<stdout>:[2025-10-12 20:46:30 TP0] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 907, 
[1,0]<stdout>:[2025-10-12 20:46:30 TP0] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 906, 
[1,0]<stdout>:[2025-10-12 20:46:31 TP0] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 905, 
[1,0]<stdout>:[2025-10-12 20:46:31 TP0] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 904, 
[1,0]<stdout>:[2025-10-12 20:46:31 TP0] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 903, 
[1,0]<stdout>:[2025-10-12 20:46:32 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 4, token usage: 0.13, #running-req: 47, #queue-req: 902, 
[1,0]<stdout>:[2025-10-12 20:46:32 TP0] Decode batch. #running-req: 47, #token: 31618, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 515.64, #queue-req: 902, 
[1,0]<stdout>:[2025-10-12 20:46:32 TP0] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 901, 
[1,0]<stdout>:[2025-10-12 20:46:32 TP0] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 900, 
[1,0]<stdout>:[2025-10-12 20:46:32 TP0] Prefill batch. #new-seq: 2, #new-token: 24, #cached-token: 3, token usage: 0.13, #running-req: 46, #queue-req: 898, 
[1,0]<stdout>:[2025-10-12 20:46:33 TP0] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 897, 
[1,0]<stdout>:[2025-10-12 20:46:33 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 896, 
[1,0]<stdout>:[2025-10-12 20:46:33 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 895, 
[1,0]<stdout>:[2025-10-12 20:46:33 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 894, 
[1,0]<stdout>:[2025-10-12 20:46:34 TP0] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 893, 
[1,0]<stdout>:[2025-10-12 20:46:34 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 892, 
[1,0]<stdout>:[2025-10-12 20:46:35 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 891, 
[1,0]<stdout>:[2025-10-12 20:46:35 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 890, 
[1,0]<stdout>:[2025-10-12 20:46:35 TP0] Decode batch. #running-req: 47, #token: 27170, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 547.34, #queue-req: 890, 
[1,0]<stdout>:[2025-10-12 20:46:35 TP0] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 889, 
[1,0]<stdout>:[2025-10-12 20:46:36 TP0] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 888, 
[1,0]<stdout>:[2025-10-12 20:46:36 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 887, 
[1,0]<stdout>:[2025-10-12 20:46:36 TP0] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 886, 
[1,0]<stdout>:[2025-10-12 20:46:37 TP0] Prefill batch. #new-seq: 2, #new-token: 1105, #cached-token: 5, token usage: 0.11, #running-req: 46, #queue-req: 884, 
[1,0]<stdout>:[2025-10-12 20:46:37 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 883, 
[1,0]<stdout>:[2025-10-12 20:46:38 TP0] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 6, token usage: 0.11, #running-req: 47, #queue-req: 882, 
[1,0]<stdout>:[2025-10-12 20:46:38 TP0] Decode batch. #running-req: 48, #token: 28010, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 721.01, #queue-req: 882, 
[1,0]<stdout>:[2025-10-12 20:46:38 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 6, token usage: 0.11, #running-req: 47, #queue-req: 881, 
[1,0]<stdout>:[2025-10-12 20:46:39 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 880, 
[1,0]<stdout>:[2025-10-12 20:46:39 TP0] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 879, 
[1,0]<stdout>:[2025-10-12 20:46:39 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 878, 
[1,0]<stdout>:[2025-10-12 20:46:40 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 877, 
[1,0]<stdout>:[2025-10-12 20:46:40 TP0] Decode batch. #running-req: 48, #token: 26983, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 852.93, #queue-req: 877, 
[1,0]<stdout>:[2025-10-12 20:46:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1080, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 876, 
[1,0]<stdout>:[2025-10-12 20:46:41 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 875, 
[1,0]<stdout>:[2025-10-12 20:46:41 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 874, 
[1,0]<stdout>:[2025-10-12 20:46:41 TP0] Prefill batch. #new-seq: 2, #new-token: 3992, #cached-token: 5, token usage: 0.10, #running-req: 46, #queue-req: 872, 
[1,0]<stdout>:[2025-10-12 20:46:42 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 871, 
[1,0]<stdout>:[2025-10-12 20:46:42 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 870, 
[1,0]<stdout>:[2025-10-12 20:46:42 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 869, 
[1,0]<stdout>:[2025-10-12 20:46:43 TP0] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 868, 
[1,0]<stdout>:[2025-10-12 20:46:43 TP0] Decode batch. #running-req: 48, #token: 26724, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 661.51, #queue-req: 868, 
[1,0]<stdout>:[2025-10-12 20:46:43 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 867, 
[1,0]<stdout>:[2025-10-12 20:46:44 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 866, 
[1,0]<stdout>:[2025-10-12 20:46:45 TP0] Decode batch. #running-req: 48, #token: 27722, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1179.04, #queue-req: 866, 
[1,0]<stdout>:[2025-10-12 20:46:45 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 865, 
[1,0]<stdout>:[2025-10-12 20:46:45 TP0] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 864, 
[1,0]<stdout>:[2025-10-12 20:46:45 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 863, 
[1,0]<stdout>:[2025-10-12 20:46:46 TP0] Prefill batch. #new-seq: 2, #new-token: 812, #cached-token: 12, token usage: 0.11, #running-req: 46, #queue-req: 861, 
[1,0]<stdout>:[2025-10-12 20:46:46 TP0] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 860, 
[1,0]<stdout>:[2025-10-12 20:46:47 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 859, 
[1,0]<stdout>:[2025-10-12 20:46:47 TP0] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 858, 
[1,0]<stdout>:[2025-10-12 20:46:47 TP0] Decode batch. #running-req: 48, #token: 29057, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 706.82, #queue-req: 858, 
[1,0]<stdout>:[2025-10-12 20:46:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 857, 
[1,0]<stdout>:[2025-10-12 20:46:48 TP0] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 5, token usage: 0.11, #running-req: 47, #queue-req: 856, 
[1,0]<stdout>:[2025-10-12 20:46:48 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 855, 
[1,0]<stdout>:[2025-10-12 20:46:48 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 854, 
[1,0]<stdout>:[2025-10-12 20:46:49 TP0] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 853, 
[1,0]<stdout>:[2025-10-12 20:46:49 TP0] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 852, 
[1,0]<stdout>:[2025-10-12 20:46:49 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 851, 
[1,0]<stdout>:[2025-10-12 20:46:50 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 850, 
[1,0]<stdout>:[2025-10-12 20:46:50 TP0] Prefill batch. #new-seq: 2, #new-token: 528, #cached-token: 5, token usage: 0.12, #running-req: 46, #queue-req: 848, 
[1,0]<stdout>:[2025-10-12 20:46:50 TP0] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 847, 
[1,0]<stdout>:[2025-10-12 20:46:51 TP0] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 846, 
[1,0]<stdout>:[2025-10-12 20:46:51 TP0] Decode batch. #running-req: 48, #token: 29859, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 538.73, #queue-req: 846, 
[1,0]<stdout>:[2025-10-12 20:46:51 TP0] Prefill batch. #new-seq: 1, #new-token: 674, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 845, 
[1,0]<stdout>:[2025-10-12 20:46:51 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 844, 
[1,0]<stdout>:[2025-10-12 20:46:52 TP0] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 843, 
[1,0]<stdout>:[2025-10-12 20:46:52 TP0] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 842, 
[1,0]<stdout>:[2025-10-12 20:46:52 TP0] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 841, 
[1,0]<stdout>:[2025-10-12 20:46:53 TP0] Prefill batch. #new-seq: 1, #new-token: 871, #cached-token: 7, token usage: 0.11, #running-req: 47, #queue-req: 840, 
[1,0]<stdout>:[2025-10-12 20:46:53 TP0] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 839, 
[1,0]<stdout>:[2025-10-12 20:46:53 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 838, 
[1,0]<stdout>:[2025-10-12 20:46:53 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 837, 
[1,0]<stdout>:[2025-10-12 20:46:54 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 836, 
[1,0]<stdout>:[2025-10-12 20:46:54 TP0] Decode batch. #running-req: 48, #token: 27928, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 568.82, #queue-req: 836, 
[1,0]<stdout>:[2025-10-12 20:46:54 TP0] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 835, 
[1,0]<stdout>:[2025-10-12 20:46:55 TP0] Prefill batch. #new-seq: 1, #new-token: 984, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 834, 
[1,0]<stdout>:[2025-10-12 20:46:55 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 833, 
[1,0]<stdout>:[2025-10-12 20:46:55 TP0] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 832, 
[1,0]<stdout>:[2025-10-12 20:46:56 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 831, 
[1,0]<stdout>:[2025-10-12 20:46:56 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 830, 
[1,0]<stdout>:[2025-10-12 20:46:56 TP0] Prefill batch. #new-seq: 2, #new-token: 485, #cached-token: 4, token usage: 0.11, #running-req: 46, #queue-req: 828, 
[1,0]<stdout>:[2025-10-12 20:46:56 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 827, 
[1,0]<stdout>:[2025-10-12 20:46:57 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 826, 
[1,0]<stdout>:[2025-10-12 20:46:57 TP0] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 825, 
[1,0]<stdout>:[2025-10-12 20:46:57 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 824, 
[1,0]<stdout>:[2025-10-12 20:46:58 TP0] Decode batch. #running-req: 48, #token: 26560, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 551.66, #queue-req: 824, 
[1,0]<stdout>:[2025-10-12 20:46:58 TP0] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 823, 
[1,0]<stdout>:[2025-10-12 20:46:58 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 822, 
[1,0]<stdout>:[2025-10-12 20:46:58 TP0] Prefill batch. #new-seq: 1, #new-token: 840, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 821, 
[1,0]<stdout>:[2025-10-12 20:46:59 TP0] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 820, 
[1,0]<stdout>:[2025-10-12 20:46:59 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 819, 
[1,0]<stdout>:[2025-10-12 20:47:00 TP0] Prefill batch. #new-seq: 2, #new-token: 964, #cached-token: 4, token usage: 0.10, #running-req: 46, #queue-req: 817, 
[1,0]<stdout>:[2025-10-12 20:47:00 TP0] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 816, 
[1,0]<stdout>:[2025-10-12 20:47:00 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 815, 
[1,0]<stdout>:[2025-10-12 20:47:01 TP0] Prefill batch. #new-seq: 1, #new-token: 798, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 814, 
[1,0]<stdout>:[2025-10-12 20:47:01 TP0] Decode batch. #running-req: 46, #token: 23247, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 614.14, #queue-req: 814, 
[1,0]<stdout>:[2025-10-12 20:47:01 TP0] Prefill batch. #new-seq: 2, #new-token: 805, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 812, 
[1,0]<stdout>:[2025-10-12 20:47:01 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 811, 
[1,0]<stdout>:[2025-10-12 20:47:01 TP0] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 810, 
[1,0]<stdout>:[2025-10-12 20:47:02 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 809, 
[1,0]<stdout>:[2025-10-12 20:47:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 808, 
[1,0]<stdout>:[2025-10-12 20:47:03 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 807, 
[1,0]<stdout>:[2025-10-12 20:47:03 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 806, 
[1,0]<stdout>:[2025-10-12 20:47:03 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 805, 
[1,0]<stdout>:[2025-10-12 20:47:04 TP0] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 20:47:04 TP0] Decode batch. #running-req: 48, #token: 25009, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 626.63, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 20:47:04 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 803, 
[1,0]<stdout>:[2025-10-12 20:47:04 TP0] Prefill batch. #new-seq: 1, #new-token: 723, #cached-token: 8, token usage: 0.10, #running-req: 47, #queue-req: 802, 
[1,0]<stdout>:[2025-10-12 20:47:05 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 801, 
[1,0]<stdout>:[2025-10-12 20:47:05 TP0] Prefill batch. #new-seq: 1, #new-token: 804, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 800, 
[1,0]<stdout>:[2025-10-12 20:47:06 TP0] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 9, token usage: 0.11, #running-req: 47, #queue-req: 799, 
[1,0]<stdout>:[2025-10-12 20:47:06 TP0] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 798, 
[1,0]<stdout>:[2025-10-12 20:47:06 TP0] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 797, 
=>> PBS: job killed: walltime 602 exceeded limit 600
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-12 20:47:22.780502:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 97324.pbs111
	Project: 50000128
	Exit Status: -29
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 01:32:10
	Memory: Requested(3760gb), Used(33908056kb)
	Vmem Used: 69475188264kb
	Walltime: Requested(00:10:00), Used(00:10:15)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx002:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx013:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 10.39mins
	GPU Power Consumed: 355.6W
	GPU Max GPU Memory Used: 1.04TB
	Memory Throughput Rate (Average): a2ap-dgx002:(gpu1:3%+gpu0:4%+gpu2:3%+gpu3:3%+gpu5:3%+gpu4:4%+gpu6:3%+gpu7:3%)+a2ap-dgx013:(gpu1:4%+gpu0:3%+gpu2:3%+gpu3:3%+gpu5:3%+gpu4:4%+gpu6:4%+gpu7:4%)
	Memory Throughput Rate (Max): a2ap-dgx002:(gpu1:18%+gpu0:24%+gpu2:12%+gpu3:12%+gpu5:11%+gpu4:24%+gpu6:13%+gpu7:12%)+a2ap-dgx013:(gpu1:19%+gpu0:23%+gpu2:22%+gpu3:12%+gpu5:13%+gpu4:17%+gpu6:24%+gpu7:19%)
	Memory Throughput Rate (Min): a2ap-dgx002:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx013:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx002:(gpu1:35%+gpu0:60%+gpu2:54%+gpu3:49%+gpu5:56%+gpu4:52%+gpu6:55%+gpu7:56%)+a2ap-dgx013:(gpu1:58%+gpu0:62%+gpu2:62%+gpu3:61%+gpu5:59%+gpu4:62%+gpu6:64%+gpu7:63%)
	GPU SM Utilization (Max): a2ap-dgx002:(gpu1:95%+gpu0:100%+gpu2:100%+gpu3:95%+gpu5:100%+gpu4:100%+gpu6:100%+gpu7:99%)+a2ap-dgx013:(gpu1:100%+gpu0:100%+gpu2:100%+gpu3:100%+gpu5:100%+gpu4:100%+gpu6:100%+gpu7:100%)
	GPU SM Utilization (Min): a2ap-dgx002:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx013:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: None
GPU application profile: Medium
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

