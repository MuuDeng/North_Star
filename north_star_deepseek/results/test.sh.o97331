?? 2-NODE TP16+DP2 - OPTIMIZED PRODUCTION VERSION
========== OPTIMIZED 2-NODE TP16+DP2 ==========
Target: ~5min | Est. SU: 170.666 | Balance: 37392.432
N/A
Job ID: 97331.pbs111 | GPUs: 16 | Master: a2ap-dgx013.asp2p.nscc.sg:5000
Config: TP16+DP2+FA3+EAGLE | Model: DeepSeek-R1 671B
================================================
[21:01:18] Validating setup...
[21:01:18] ? Validation passed
[21:01:18] Launching optimized 2-node benchmark...
[1,0]<stdout>:[RANK 0] Starting optimized benchmark...
[1,0]<stdout>:[RANK 0] DIST_INIT_ADDR: a2ap-dgx013.asp2p.nscc.sg:5000
[1,1]<stdout>:[RANK 1] Starting optimized benchmark...
[1,1]<stdout>:[RANK 1] DIST_INIT_ADDR: a2ap-dgx013.asp2p.nscc.sg:5000
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,0]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,0]<stdout>:[2025-10-12 21:01:38] Using default HuggingFace chat template with detected content format: string
[1,0]<stdout>:[2025-10-12 21:01:59 TP0] MLA optimization is turned on. Use fa3 backend.
[1,0]<stdout>:[2025-10-12 21:01:59 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-12 21:01:59 TP0] Init torch distributed begin.
[1,0]<stdout>:[W1012 21:02:01.297420702 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 21:02:03.725335322 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 21:02:03.796997049 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 21:02:03.797131466 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 21:02:03.797243099 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 21:02:03.797258119 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 21:02:03.826882891 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
[1,1]<stdout>:WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[1,1]<stdout>:[W1012 21:02:54.916769974 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 21:02:56.462354482 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 21:02:58.149274027 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 21:03:00.659801359 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 21:03:00.686015129 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 21:03:00.719073156 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 21:03:00.732901202 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,1]<stdout>:[W1012 21:03:00.072202864 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[W1012 21:03:00.870718362 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 21:03:00 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 21:03:10 TP1] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 21:03:10 TP0] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 21:03:10 TP2] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 21:03:10 TP4] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 21:03:10 TP5] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 21:03:10 TP3] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 21:03:10 TP6] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 21:03:10 TP15] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 21:03:10 TP12] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 21:03:10 TP11] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 21:03:10 TP9] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 21:03:10 TP14] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 21:03:10 TP13] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 21:03:10 TP10] Custom allreduce is disabled because this process group spans across nodes.
[1,1]<stdout>:[2025-10-12 21:03:10 TP8] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[2025-10-12 21:03:10 TP7] Custom allreduce is disabled because this process group spans across nodes.
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 21:03:10 TP0] sglang is using nccl==2.27.3
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,0]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1,1]<stdout>:[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,1]<stdout>:[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1,0]<stdout>:[2025-10-12 21:03:12 TP0] Init torch distributed ends. mem usage=1.75 GB
[1,0]<stdout>:[2025-10-12 21:03:13 TP1] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 21:03:13 TP2] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 21:03:13 TP5] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 21:03:13 TP4] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 21:03:13 TP6] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 21:03:13 TP0] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 21:03:13 TP7] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 21:03:13 TP3] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 21:03:13 TP12] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 21:03:13 TP10] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 21:03:13 TP8] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 21:03:13 TP13] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 21:03:13 TP15] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 21:03:13 TP11] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 21:03:13 TP9] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,1]<stdout>:[2025-10-12 21:03:13 TP14] Ignore import error when loading sglang.srt.models.glm4v_moe: No module named 'transformers.models.glm4v_moe'
[1,0]<stdout>:[2025-10-12 21:03:14 TP0] Load weight begin. avail mem=76.79 GB
[1,0]<stdout>:[2025-10-12 21:03:14 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-12 21:03:20 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=35.23 GB, mem usage=41.56 GB.
[1,0]<stdout>:[2025-10-12 21:03:32 TP1] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:32 TP5] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:32 TP6] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:32 TP3] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:33 TP4] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:33 TP0] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:33 TP0] Memory pool end. avail mem=18.04 GB
[1,0]<stdout>:[2025-10-12 21:03:33 TP7] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:33 TP2] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:34 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.99 GB
[1,1]<stdout>:[2025-10-12 21:03:34 TP9] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 21:03:34 TP13] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 21:03:34 TP14] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 21:03:34 TP12] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 21:03:34 TP10] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 21:03:34 TP8] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,1]<stdout>:[2025-10-12 21:03:35 TP11] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:35 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 40, 48]
[1,0]<stdout>:  0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=17.78 GB):   0% 0/22 [00:00<?, ?it/s][1,1]<stdout>:[2025-10-12 21:03:39 TP15] KV Cache is allocated. #tokens: 250610, KV size: 16.40 GB
[1,0]<stdout>:[2025-10-12 21:03:41 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 21:03:41 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:41 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:41 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:41 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:41 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:41 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 21:03:41 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:41 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:41 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:41 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 4692.57it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 5201.90it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 5309.86it/s]
[1,0]<stdout>:[2025-10-12 21:03:41 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:[A[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 4652.97it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 5371.47it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 4546.90it/s]
[1,0]<stdout>:100% 33/33 [00:00<00:00, 5296.24it/s]
[1,0]<stdout>:[2025-10-12 21:03:41 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:41 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 21:03:41 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:100% 33/33 [00:00<00:00, 4878.64it/s]
[1,0]<stdout>:[2025-10-12 21:03:42 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:42 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-12 21:03:42 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 33/33 [00:00<00:00, 1699.10it/s]
[1,1]<stdout>:[2025-10-12 21:03:42 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 4254.90it/s]
[1,1]<stdout>:[2025-10-12 21:03:42 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 4272.11it/s]
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 3581.26it/s]
[1,1]<stdout>:[2025-10-12 21:03:42 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:100% 33/33 [00:00<00:00, 3672.77it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 2180.16it/s]
[1,1]<stdout>:100% 33/33 [00:00<00:00, 3784.13it/s]
[1,1]<stdout>:  0% 0/33 [00:00<?, ?it/s][1,1]<stdout>:[2025-10-12 21:03:42 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 33/33 [00:00<00:00, 3772.58it/s]
[1,1]<stdout>:[2025-10-12 21:03:42 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:100% 44/44 [00:00<00:00, 12827.51it/s]
[1,0]<stdout>:100% 44/44 [00:00<00:00, 14682.90it/s]
[1,0]<stdout>:100% 44/44 [00:00<00:00, 13099.76it/s]
[1,1]<stdout>:[2025-10-12 21:03:42 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][A[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:100% 44/44 [00:00<00:00, 12222.62it/s]
[1,0]<stdout>:100% 44/44 [00:00<00:00, 14270.75it/s]
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:100% 44/44 [00:00<00:00, 10620.94it/s][1,0]<stdout>:
[1,0]<stdout>:100% 44/44 [00:00<00:00, 12258.34it/s]
[1,1]<stdout>:[2025-10-12 21:03:42 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 21:03:42 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:42 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=1536, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:100% 44/44 [00:00<00:00, 13832.21it/s]
[1,0]<stdout>:[2025-10-12 21:03:42 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:42 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:42 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:100% 44/44 [00:00<00:00, 4582.80it/s]
[1,0]<stdout>:[2025-10-12 21:03:42 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:42 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 21:03:42 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:42 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:42 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:42 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:100% 44/44 [00:00<00:00, 8514.78it/s]
[1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:100% 44/44 [00:00<00:00, 7250.31it/s]
[1,1]<stdout>:[2025-10-12 21:03:43 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:43 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 25333.66it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15370.79it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15360.23it/s]
[1,0]<stdout>:[2025-10-12 21:03:43 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-12 21:03:43 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:43 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 44/44 [00:00<00:00, 7464.08it/s]
[1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:100% 44/44 [00:00<00:00, 8198.91it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 16998.19it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15286.76it/s]
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:[A[1,0]<stdout>:100% 16/16 [00:00<00:00, 17730.22it/s]
[1,0]<stdout>:[2025-10-12 21:03:43 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:43 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:[2025-10-12 21:03:43 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 16/16 [00:00<00:00, 15445.08it/s]
[1,0]<stdout>:[2025-10-12 21:03:43 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 21:03:43 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:43 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:43 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15709.00it/s]
[1,1]<stdout>:[2025-10-12 21:03:43 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:43 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:100% 44/44 [00:00<00:00, 8032.27it/s]
[1,1]<stdout>:[2025-10-12 21:03:43 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 44/44 [00:00<00:00, 4806.35it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s]100% 16/16 [00:00<00:00, 4634.91it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 9110.63it/s]
[1,1]<stdout>:[2025-10-12 21:03:43 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/44 [00:00<?, ?it/s][1,1]<stdout>:[2025-10-12 21:03:43 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:100% 44/44 [00:00<00:00, 7689.56it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 16568.04it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 13591.67it/s]
[1,0]<stdout>:100% 32/32 [00:00<00:00, 13781.47it/s]
[1,1]<stdout>:[2025-10-12 21:03:43 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:43 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 21:03:43 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1024, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 14758.93it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 14733.01it/s]
[1,0]<stdout>:
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][A[1,0]<stdout>:100% 32/32 [00:00<00:00, 13852.59it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 5895.53it/s]
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:[2025-10-12 21:03:43 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:100% 32/32 [00:00<00:00, 13388.30it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 6300.71it/s]
[1,1]<stdout>:[2025-10-12 21:03:43 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,0]<stdout>:100% 32/32 [00:00<00:00, 14079.27it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 7073.77it/s]
[1,1]<stdout>:[2025-10-12 21:03:44 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 3352.09it/s]
[1,1]<stdout>:[2025-10-12 21:03:44 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 4451.52it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 8592.68it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 8069.36it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 7635.55it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 7682.75it/s]
[1,1]<stdout>:[2025-10-12 21:03:44 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 8184.01it/s]
[1,1]<stdout>:[2025-10-12 21:03:44 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 21:03:44 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2304, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:44 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:44 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:44 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:44 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:44 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:44 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:44 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:03:44 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,0]<stdout>:[2025-10-12 21:03:44 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:44 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:44 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:44 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:03:44 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 7711.89it/s]
[1,1]<stdout>:[2025-10-12 21:03:44 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 8951.43it/s]
[1,1]<stdout>:[2025-10-12 21:03:45 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 8260.06it/s]
[1,1]<stdout>:[2025-10-12 21:03:45 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 22332.40it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 16756.27it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 10751.18it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 4065.97it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 6604.55it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 6615.62it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 15332.16it/s]
[1,1]<stdout>:100% 16/16 [00:00<00:00, 6905.63it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][A[1,0]<stdout>:100% 16/16 [00:00<00:00, 16027.91it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 14302.83it/s]
[1,0]<stdout>:100% 16/16 [00:00<00:00, 16225.55it/s]
[1,0]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,0]<stdout>:100% 16/16 [00:00<00:00, 16424.10it/s]
[1,1]<stdout>:  0% 0/32 [00:00<?, ?it/s][1,1]<stdout>:100% 32/32 [00:00<00:00, 8468.00it/s]
[1,1]<stdout>:[2025-10-12 21:03:45 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 21:03:45 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=7168, K=1152, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 7173.58it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 7301.58it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 5645.57it/s]
[1,1]<stdout>:  0% 0/16 [00:00<?, ?it/s][1,1]<stdout>:100% 16/16 [00:00<00:00, 7029.31it/s]
[1,0]<stdout>:[2025-10-12 21:03:46 TP1] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 21:03:46 TP6] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 21:03:46 TP0] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 21:03:46 TP5] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 21:03:46 TP3] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 21:03:46 TP2] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 21:03:46 TP7] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:[2025-10-12 21:03:46 TP4] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 21:03:46 TP15] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 21:03:46 TP8] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 21:03:46 TP13] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 21:03:46 TP14] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 21:03:46 TP10] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 21:03:46 TP11] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 21:03:46 TP12] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,1]<stdout>:[2025-10-12 21:03:46 TP9] Config file not found at /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.2.0 and use MoE kernel config from /scratch/users/industry/ai-hpc/apacsc34/tanathep/py312/lib/python3.12/site-packages/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[1,0]<stdout>:Capturing batches (bs=48 avail_mem=17.78 GB):   5% 1/22 [00:11<04:03, 11.61s/it][1,0]<stdout>:Capturing batches (bs=40 avail_mem=17.52 GB):   5% 1/22 [00:11<04:03, 11.61s/it][1,0]<stdout>:Capturing batches (bs=40 avail_mem=17.52 GB):   9% 2/22 [00:12<01:44,  5.24s/it][1,0]<stdout>:Capturing batches (bs=32 avail_mem=17.50 GB):   9% 2/22 [00:12<01:44,  5.24s/it][1,0]<stdout>:Capturing batches (bs=32 avail_mem=17.50 GB):  14% 3/22 [00:13<01:00,  3.20s/it][1,0]<stdout>:Capturing batches (bs=30 avail_mem=17.47 GB):  14% 3/22 [00:13<01:00,  3.20s/it][1,0]<stdout>:Capturing batches (bs=30 avail_mem=17.47 GB):  18% 4/22 [00:14<00:40,  2.27s/it][1,0]<stdout>:Capturing batches (bs=28 avail_mem=17.44 GB):  18% 4/22 [00:14<00:40,  2.27s/it][1,0]<stdout>:Capturing batches (bs=28 avail_mem=17.44 GB):  23% 5/22 [00:14<00:28,  1.69s/it][1,0]<stdout>:Capturing batches (bs=26 avail_mem=17.41 GB):  23% 5/22 [00:14<00:28,  1.69s/it][1,0]<stdout>:Capturing batches (bs=26 avail_mem=17.41 GB):  27% 6/22 [00:15<00:23,  1.50s/it][1,0]<stdout>:Capturing batches (bs=24 avail_mem=17.39 GB):  27% 6/22 [00:15<00:23,  1.50s/it][1,0]<stdout>:Capturing batches (bs=24 avail_mem=17.39 GB):  32% 7/22 [00:16<00:19,  1.31s/it][1,0]<stdout>:Capturing batches (bs=22 avail_mem=17.36 GB):  32% 7/22 [00:16<00:19,  1.31s/it][1,0]<stdout>:Capturing batches (bs=22 avail_mem=17.36 GB):  36% 8/22 [00:17<00:16,  1.18s/it][1,0]<stdout>:Capturing batches (bs=20 avail_mem=17.33 GB):  36% 8/22 [00:17<00:16,  1.18s/it][1,0]<stdout>:Capturing batches (bs=20 avail_mem=17.33 GB):  41% 9/22 [00:18<00:14,  1.15s/it]Capturing batches (bs=18 avail_mem=17.30 GB):  41% 9/22 [00:18<00:14,  1.15s/it][1,0]<stdout>:Capturing batches (bs=18 avail_mem=17.30 GB):  45% 10/22 [00:19<00:12,  1.06s/it][1,0]<stdout>:Capturing batches (bs=16 avail_mem=17.27 GB):  45% 10/22 [00:19<00:12,  1.06s/it][1,0]<stdout>:Capturing batches (bs=16 avail_mem=17.27 GB):  50% 11/22 [00:20<00:10,  1.02it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=17.25 GB):  50% 11/22 [00:20<00:10,  1.02it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=17.25 GB):  55% 12/22 [00:21<00:09,  1.07it/s]Capturing batches (bs=12 avail_mem=17.22 GB):  55% 12/22 [00:21<00:09,  1.07it/s][1,0]<stdout>:Capturing batches (bs=12 avail_mem=17.22 GB):  59% 13/22 [00:22<00:08,  1.08it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=17.19 GB):  59% 13/22 [00:22<00:08,  1.08it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=17.19 GB):  64% 14/22 [00:22<00:06,  1.21it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=17.17 GB):  64% 14/22 [00:22<00:06,  1.21it/s] [1,0]<stdout>:Capturing batches (bs=8 avail_mem=17.17 GB):  68% 15/22 [00:23<00:05,  1.22it/s][1,0]<stdout>:Capturing batches (bs=7 avail_mem=17.14 GB):  68% 15/22 [00:23<00:05,  1.22it/s][1,0]<stdout>:Capturing batches (bs=7 avail_mem=17.14 GB):  73% 16/22 [00:24<00:04,  1.26it/s][1,0]<stdout>:Capturing batches (bs=6 avail_mem=17.11 GB):  73% 16/22 [00:24<00:04,  1.26it/s][1,0]<stdout>:Capturing batches (bs=6 avail_mem=17.11 GB):  77% 17/22 [00:24<00:03,  1.33it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=17.09 GB):  77% 17/22 [00:24<00:03,  1.33it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=17.09 GB):  82% 18/22 [00:25<00:02,  1.34it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=17.06 GB):  82% 18/22 [00:25<00:02,  1.34it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=17.06 GB):  86% 19/22 [00:26<00:02,  1.41it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=17.04 GB):  86% 19/22 [00:26<00:02,  1.41it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=17.04 GB):  91% 20/22 [00:27<00:01,  1.31it/s][1,0]<stdout>:Capturing batches (bs=2 avail_mem=17.01 GB):  91% 20/22 [00:27<00:01,  1.31it/s][1,0]<stdout>:Capturing batches (bs=2 avail_mem=17.01 GB):  95% 21/22 [00:27<00:00,  1.29it/s][1,0]<stdout>:Capturing batches (bs=1 avail_mem=16.98 GB):  95% 21/22 [00:27<00:00,  1.29it/s][1,0]<stdout>:Capturing batches (bs=1 avail_mem=16.98 GB): 100% 22/22 [00:28<00:00,  1.32it/s][1,0]<stdout>:Capturing batches (bs=1 avail_mem=16.98 GB): 100% 22/22 [00:28<00:00,  1.30s/it]
[1,0]<stdout>:[2025-10-12 21:04:04 TP0] Capture cuda graph end. Time elapsed: 30.15 s. mem usage=1.04 GB. avail mem=16.96 GB.
[1,0]<stdout>:[2025-10-12 21:04:04 TP0] MLA optimization is turned on. Use fa3 backend.
[1,0]<stdout>:[2025-10-12 21:04:04 TP0] Chunked prefix cache is turned on.
[1,0]<stdout>:[2025-10-12 21:04:04 TP0] Init torch distributed begin.
[1,0]<stdout>:[2025-10-12 21:04:04 TP0] Init torch distributed ends. mem usage=0.00 GB
[1,0]<stdout>:[2025-10-12 21:04:04 TP0] Load weight begin. avail mem=16.96 GB
[1,0]<stdout>:[2025-10-12 21:04:04 TP0] Detected fp8 checkpoint.
[1,0]<stdout>:[2025-10-12 21:04:05 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.84 GB, mem usage=1.12 GB.
[1,0]<stdout>:[2025-10-12 21:04:06 TP5] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP6] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP7] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP3] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP1] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP0] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP2] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP0] Memory pool end. avail mem=15.56 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP4] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP10] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP15] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP14] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP13] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP12] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP8] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP11] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP9] KV Cache is allocated. #tokens: 250610, KV size: 0.27 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP8] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP10] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.75 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.74 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.72 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP12] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,1]<stdout>:[2025-10-12 21:04:06 TP11] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.74 GB
[1,0]<stdout>:[2025-10-12 21:04:06 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.74 GB
[1,1]<stdout>:[2025-10-12 21:04:07 TP13] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.75 GB
[1,1]<stdout>:[2025-10-12 21:04:07 TP15] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.75 GB
[1,0]<stdout>:[2025-10-12 21:04:07 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.75 GB
[1,1]<stdout>:[2025-10-12 21:04:07 TP9] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.74 GB
[1,1]<stdout>:[2025-10-12 21:04:07 TP14] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.71 GB
[1,0]<stdout>:  0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=15.60 GB):   0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=15.60 GB):   5% 1/22 [00:01<00:24,  1.15s/it][1,0]<stdout>:Capturing batches (bs=40 avail_mem=15.60 GB):   5% 1/22 [00:01<00:24,  1.15s/it][1,0]<stdout>:Capturing batches (bs=40 avail_mem=15.60 GB):   9% 2/22 [00:01<00:14,  1.41it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=15.60 GB):   9% 2/22 [00:01<00:14,  1.41it/s][1,0]<stdout>:Capturing batches (bs=30 avail_mem=15.60 GB):   9% 2/22 [00:01<00:14,  1.41it/s][1,0]<stdout>:Capturing batches (bs=30 avail_mem=15.60 GB):  18% 4/22 [00:01<00:05,  3.05it/s][1,0]<stdout>:Capturing batches (bs=28 avail_mem=15.60 GB):  18% 4/22 [00:01<00:05,  3.05it/s][1,0]<stdout>:Capturing batches (bs=26 avail_mem=15.60 GB):  18% 4/22 [00:01<00:05,  3.05it/s][1,0]<stdout>:Capturing batches (bs=26 avail_mem=15.60 GB):  27% 6/22 [00:01<00:03,  5.01it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=15.60 GB):  27% 6/22 [00:01<00:03,  5.01it/s][1,0]<stdout>:Capturing batches (bs=22 avail_mem=15.60 GB):  27% 6/22 [00:01<00:03,  5.01it/s][1,0]<stdout>:Capturing batches (bs=22 avail_mem=15.60 GB):  36% 8/22 [00:01<00:01,  7.04it/s]Capturing batches (bs=20 avail_mem=15.60 GB):  36% 8/22 [00:01<00:01,  7.04it/s][1,0]<stdout>:Capturing batches (bs=18 avail_mem=15.60 GB):  36% 8/22 [00:02<00:01,  7.04it/s][1,0]<stdout>:Capturing batches (bs=18 avail_mem=15.60 GB):  45% 10/22 [00:02<00:01,  7.79it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=15.60 GB):  45% 10/22 [00:02<00:01,  7.79it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=15.60 GB):  45% 10/22 [00:02<00:01,  7.79it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=15.60 GB):  55% 12/22 [00:02<00:01,  8.01it/s][1,0]<stdout>:Capturing batches (bs=12 avail_mem=15.60 GB):  55% 12/22 [00:02<00:01,  8.01it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=15.60 GB):  55% 12/22 [00:02<00:01,  8.01it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=15.60 GB):  64% 14/22 [00:02<00:00,  9.22it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=15.60 GB):  64% 14/22 [00:02<00:00,  9.22it/s] [1,0]<stdout>:Capturing batches (bs=7 avail_mem=15.60 GB):  64% 14/22 [00:02<00:00,  9.22it/s][1,0]<stdout>:Capturing batches (bs=7 avail_mem=15.60 GB):  73% 16/22 [00:02<00:00,  9.14it/s][1,0]<stdout>:Capturing batches (bs=6 avail_mem=15.60 GB):  73% 16/22 [00:02<00:00,  9.14it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=15.60 GB):  73% 16/22 [00:02<00:00,  9.14it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=15.60 GB):  82% 18/22 [00:03<00:00,  8.60it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=15.60 GB):  82% 18/22 [00:03<00:00,  8.60it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=15.60 GB):  86% 19/22 [00:03<00:00,  8.69it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=15.60 GB):  86% 19/22 [00:03<00:00,  8.69it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=15.60 GB):  91% 20/22 [00:03<00:00,  8.26it/s][1,0]<stdout>:Capturing batches (bs=2 avail_mem=15.60 GB):  91% 20/22 [00:03<00:00,  8.26it/s][1,0]<stdout>:Capturing batches (bs=2 avail_mem=15.60 GB):  95% 21/22 [00:03<00:00,  8.52it/s][1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.60 GB):  95% 21/22 [00:03<00:00,  8.52it/s][1,0]<stdout>:[2025-10-12 21:04:12 TP6] Capture draft cuda graph end. Time elapsed: 5.20 s. mem usage=0.14 GB. avail mem=15.61 GB.
[1,0]<stdout>:[2025-10-12 21:04:12 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.61 GB
[1,0]<stdout>:[2025-10-12 21:04:12 TP3] Capture draft cuda graph end. Time elapsed: 5.33 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,0]<stdout>:[2025-10-12 21:04:12 TP1] Capture draft cuda graph end. Time elapsed: 5.33 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,0]<stdout>:[2025-10-12 21:04:12 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,0]<stdout>:[2025-10-12 21:04:12 TP7] Capture draft cuda graph end. Time elapsed: 5.33 s. mem usage=0.14 GB. avail mem=15.58 GB.
[1,0]<stdout>:[2025-10-12 21:04:12 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,0]<stdout>:[2025-10-12 21:04:12 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.58 GB
[1,0]<stdout>:[2025-10-12 21:04:12 TP2] Capture draft cuda graph end. Time elapsed: 5.24 s. mem usage=0.14 GB. avail mem=15.60 GB.
[1,0]<stdout>:[2025-10-12 21:04:12 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.60 GB
[1,0]<stdout>:[2025-10-12 21:04:12 TP5] Capture draft cuda graph end. Time elapsed: 5.34 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,0]<stdout>:[2025-10-12 21:04:12 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.60 GB): 100% 22/22 [00:03<00:00,  5.94it/s][1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.60 GB): 100% 22/22 [00:03<00:00,  5.88it/s]
[1,0]<stdout>:[2025-10-12 21:04:12 TP4] Capture draft cuda graph end. Time elapsed: 5.42 s. mem usage=0.14 GB. avail mem=15.61 GB.
[1,0]<stdout>:[2025-10-12 21:04:12 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.61 GB
[1,0]<stdout>:[2025-10-12 21:04:12 TP0] Capture draft cuda graph end. Time elapsed: 5.34 s. mem usage=0.14 GB. avail mem=15.60 GB.
[1,0]<stdout>:[2025-10-12 21:04:12 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.60 GB
[1,1]<stdout>:[2025-10-12 21:04:12 TP10] Capture draft cuda graph end. Time elapsed: 5.47 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,1]<stdout>:[2025-10-12 21:04:12 TP11] Capture draft cuda graph end. Time elapsed: 5.24 s. mem usage=0.14 GB. avail mem=15.60 GB.
[1,1]<stdout>:[2025-10-12 21:04:12 TP12] Capture draft cuda graph end. Time elapsed: 5.28 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,1]<stdout>:[2025-10-12 21:04:12 TP15] Capture draft cuda graph end. Time elapsed: 5.21 s. mem usage=0.14 GB. avail mem=15.61 GB.
[1,1]<stdout>:[2025-10-12 21:04:12 TP14] Capture draft cuda graph end. Time elapsed: 5.14 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,1]<stdout>:[2025-10-12 21:04:12 TP13] Capture draft cuda graph end. Time elapsed: 5.22 s. mem usage=0.14 GB. avail mem=15.61 GB.
[1,1]<stdout>:[2025-10-12 21:04:12 TP12] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,1]<stdout>:[2025-10-12 21:04:12 TP10] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,1]<stdout>:[2025-10-12 21:04:12 TP13] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.61 GB
[1,1]<stdout>:[2025-10-12 21:04:12 TP11] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.60 GB
[1,1]<stdout>:[2025-10-12 21:04:12 TP9] Capture draft cuda graph end. Time elapsed: 5.22 s. mem usage=0.14 GB. avail mem=15.60 GB.
[1,1]<stdout>:[2025-10-12 21:04:12 TP9] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.60 GB
[1,1]<stdout>:[2025-10-12 21:04:12 TP14] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,1]<stdout>:[2025-10-12 21:04:12 TP15] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.61 GB
[1,1]<stdout>:[2025-10-12 21:04:12 TP8] Capture draft cuda graph end. Time elapsed: 5.47 s. mem usage=0.14 GB. avail mem=15.57 GB.
[1,1]<stdout>:[2025-10-12 21:04:12 TP8] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.57 GB
[1,0]<stdout>:  0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=15.40 GB):   0% 0/22 [00:00<?, ?it/s][1,0]<stdout>:Capturing batches (bs=48 avail_mem=15.40 GB):   5% 1/22 [00:00<00:12,  1.65it/s][1,0]<stdout>:Capturing batches (bs=40 avail_mem=15.18 GB):   5% 1/22 [00:00<00:12,  1.65it/s][1,0]<stdout>:Capturing batches (bs=40 avail_mem=15.18 GB):   9% 2/22 [00:00<00:06,  3.01it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=15.18 GB):   9% 2/22 [00:00<00:06,  3.01it/s][1,0]<stdout>:Capturing batches (bs=32 avail_mem=15.18 GB):  14% 3/22 [00:00<00:04,  4.20it/s]Capturing batches (bs=30 avail_mem=15.18 GB):  14% 3/22 [00:00<00:04,  4.20it/s][1,0]<stdout>:Capturing batches (bs=28 avail_mem=15.18 GB):  14% 3/22 [00:00<00:04,  4.20it/s][1,0]<stdout>:Capturing batches (bs=28 avail_mem=15.18 GB):  23% 5/22 [00:01<00:02,  6.26it/s][1,0]<stdout>:Capturing batches (bs=26 avail_mem=15.17 GB):  23% 5/22 [00:01<00:02,  6.26it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=15.17 GB):  23% 5/22 [00:01<00:02,  6.26it/s][1,0]<stdout>:Capturing batches (bs=24 avail_mem=15.17 GB):  32% 7/22 [00:01<00:02,  7.09it/s][1,0]<stdout>:Capturing batches (bs=22 avail_mem=15.17 GB):  32% 7/22 [00:01<00:02,  7.09it/s][1,0]<stdout>:Capturing batches (bs=22 avail_mem=15.17 GB):  36% 8/22 [00:01<00:02,  6.70it/s][1,0]<stdout>:Capturing batches (bs=20 avail_mem=15.17 GB):  36% 8/22 [00:01<00:02,  6.70it/s][1,0]<stdout>:Capturing batches (bs=20 avail_mem=15.17 GB):  41% 9/22 [00:01<00:02,  5.66it/s][1,0]<stdout>:Capturing batches (bs=18 avail_mem=15.17 GB):  41% 9/22 [00:01<00:02,  5.66it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=15.17 GB):  41% 9/22 [00:01<00:02,  5.66it/s][1,0]<stdout>:Capturing batches (bs=16 avail_mem=15.17 GB):  50% 11/22 [00:02<00:01,  6.12it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=15.17 GB):  50% 11/22 [00:02<00:01,  6.12it/s][1,0]<stdout>:Capturing batches (bs=14 avail_mem=15.17 GB):  55% 12/22 [00:02<00:01,  6.52it/s]Capturing batches (bs=12 avail_mem=15.17 GB):  55% 12/22 [00:02<00:01,  6.52it/s][1,0]<stdout>:Capturing batches (bs=12 avail_mem=15.17 GB):  59% 13/22 [00:02<00:01,  6.65it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=15.17 GB):  59% 13/22 [00:02<00:01,  6.65it/s][1,0]<stdout>:Capturing batches (bs=10 avail_mem=15.17 GB):  64% 14/22 [00:02<00:01,  7.01it/s][1,0]<stdout>:Capturing batches (bs=8 avail_mem=15.16 GB):  64% 14/22 [00:02<00:01,  7.01it/s] [1,0]<stdout>:Capturing batches (bs=7 avail_mem=15.16 GB):  64% 14/22 [00:02<00:01,  7.01it/s][1,0]<stdout>:Capturing batches (bs=7 avail_mem=15.16 GB):  73% 16/22 [00:02<00:00,  7.78it/s][1,0]<stdout>:Capturing batches (bs=6 avail_mem=15.16 GB):  73% 16/22 [00:02<00:00,  7.78it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=15.16 GB):  73% 16/22 [00:02<00:00,  7.78it/s][1,0]<stdout>:Capturing batches (bs=5 avail_mem=15.16 GB):  82% 18/22 [00:02<00:00,  9.40it/s][1,0]<stdout>:Capturing batches (bs=4 avail_mem=15.16 GB):  82% 18/22 [00:02<00:00,  9.40it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=15.16 GB):  82% 18/22 [00:02<00:00,  9.40it/s][1,0]<stdout>:Capturing batches (bs=3 avail_mem=15.16 GB):  91% 20/22 [00:02<00:00, 11.04it/s][1,0]<stdout>:Capturing batches (bs=2 avail_mem=15.16 GB):  91% 20/22 [00:02<00:00, 11.04it/s][1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.16 GB):  91% 20/22 [00:02<00:00, 11.04it/s][1,0]<stdout>:[2025-10-12 21:04:16 TP7] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.14 GB.
[1,1]<stdout>:[2025-10-12 21:04:16 TP15] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.17 GB.
[1,1]<stdout>:[2025-10-12 21:04:16 TP14] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.13 GB.
[1,1]<stdout>:[2025-10-12 21:04:16 TP12] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.13 GB.
[1,0]<stdout>:[2025-10-12 21:04:16 TP5] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.13 GB.
[1,0]<stdout>:[2025-10-12 21:04:16 TP4] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:[2025-10-12 21:04:16 TP6] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:[2025-10-12 21:04:16 TP3] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.12 GB.
[1,1]<stdout>:[2025-10-12 21:04:16 TP13] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.16 GB): 100% 22/22 [00:03<00:00, 12.13it/s][2025-10-12 21:04:16 TP2] Capture draft extend cuda graph end. Time elapsed: 4.51 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:Capturing batches (bs=1 avail_mem=15.16 GB): 100% 22/22 [00:03<00:00,  7.27it/s]
[1,0]<stdout>:[2025-10-12 21:04:16 TP1] Capture draft extend cuda graph end. Time elapsed: 4.51 s. mem usage=0.44 GB. avail mem=15.12 GB.
[1,0]<stdout>:[2025-10-12 21:04:16 TP0] Capture draft extend cuda graph end. Time elapsed: 4.50 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,0]<stdout>:[2025-10-12 21:04:16 TP0] max_total_num_tokens=250610, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=48, context_len=163840, available_gpu_mem=15.16 GB
[1,1]<stdout>:[2025-10-12 21:04:16 TP10] Capture draft extend cuda graph end. Time elapsed: 4.51 s. mem usage=0.44 GB. avail mem=15.12 GB.
[1,1]<stdout>:[2025-10-12 21:04:16 TP8] Capture draft extend cuda graph end. Time elapsed: 4.51 s. mem usage=0.44 GB. avail mem=15.12 GB.
[1,1]<stdout>:[2025-10-12 21:04:16 TP9] Capture draft extend cuda graph end. Time elapsed: 4.51 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,1]<stdout>:[2025-10-12 21:04:16 TP11] Capture draft extend cuda graph end. Time elapsed: 4.52 s. mem usage=0.44 GB. avail mem=15.16 GB.
[1,1]<stdout>:[2025-10-12 21:04:17] Starting dummy health check server at 127.0.0.1:30000
[1,0]<stdout>:#Input tokens: 626729
[1,0]<stdout>:#Output tokens: 388685
[1,0]<stdout>:#Input tokens: 4096
[1,0]<stdout>:#Output tokens: 256
[1,0]<stdout>:[2025-10-12 21:04:31] 
[1,0]<stdout>:Warmup...
[1,0]<stdout>:[2025-10-12 21:04:31 TP0] Prefill batch. #new-seq: 16, #new-token: 4112, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,1]<stdout>:[2025-10-12 21:04:34 TP15] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:04:34 TP8] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 21:04:34 TP8] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:04:34 TP12] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:04:34 TP11] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:04:34 TP9] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:04:34 TP5] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:04:34 TP3] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:04:34 TP6] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:04:34 TP1] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:04:34 TP10] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:04:34 TP0] Entering DeepGEMM JIT Pre-Compile session. It may takes a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[1,1]<stdout>:[2025-10-12 21:04:34 TP13] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:04:34 TP0] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:[2025-10-12 21:04:34 TP14] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:04:34 TP4] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:04:34 TP2] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,0]<stdout>:[2025-10-12 21:04:34 TP7] Try DeepGEMM JIT Compiling for <gemm_fp8_fp8_bf16_nt> N=2048, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
[1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:100% 35/35 [00:00<00:00, 4403.80it/s]
[1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 13597.69it/s]
[1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 13124.78it/s]
[1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 11737.48it/s]
[1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:100% 35/35 [00:00<00:00, 7666.63it/s]
[1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:100% 35/35 [00:00<00:00, 7042.49it/s]
[1,0]<stdout>:100% 35/35 [00:00<00:00, 12474.56it/s]
[1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:100% 35/35 [00:00<00:00, 7671.84it/s]
[1,0]<stdout>:100% 35/35 [00:00<00:00, 12745.32it/s]
[1,0]<stdout>:100% 35/35 [00:00<00:00, 11500.25it/s]
[1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 12332.04it/s][1,0]<stdout>:
[1,1]<stdout>:100% 35/35 [00:00<00:00, 7915.91it/s]
[1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:100% 35/35 [00:00<00:00, 7756.56it/s]
[1,0]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,0]<stdout>:100% 35/35 [00:00<00:00, 11236.18it/s]
[1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:100% 35/35 [00:00<00:00, 7134.90it/s]
[1,1]<stdout>:  0% 0/35 [00:00<?, ?it/s][1,1]<stdout>:100% 35/35 [00:00<00:00, 8217.68it/s]
[1,0]<stdout>:[2025-10-12 21:04:36] 
[1,0]<stdout>:Benchmark...
[1,0]<stdout>:[2025-10-12 21:04:36 TP0] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:04:37 TP0] Prefill batch. #new-seq: 30, #new-token: 8192, #cached-token: 35, token usage: 0.00, #running-req: 1, #queue-req: 362, 
[1,0]<stdout>:[2025-10-12 21:04:37 TP0] Prefill batch. #new-seq: 18, #new-token: 5613, #cached-token: 22, token usage: 0.03, #running-req: 30, #queue-req: 1052, 
[1,0]<stdout>:[2025-10-12 21:04:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1904, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1951, 
[1,0]<stdout>:[2025-10-12 21:04:39 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1950, 
[1,0]<stdout>:[2025-10-12 21:04:39 TP0] Prefill batch. #new-seq: 3, #new-token: 1140, #cached-token: 8, token usage: 0.06, #running-req: 45, #queue-req: 1947, 
[1,0]<stdout>:[2025-10-12 21:04:40 TP0] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1946, 
[1,0]<stdout>:[2025-10-12 21:04:40 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1945, 
[1,0]<stdout>:[2025-10-12 21:04:40 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1944, 
[1,0]<stdout>:[2025-10-12 21:04:40 TP0] Prefill batch. #new-seq: 2, #new-token: 17, #cached-token: 3, token usage: 0.05, #running-req: 46, #queue-req: 1942, 
[1,0]<stdout>:[2025-10-12 21:04:41 TP0] Prefill batch. #new-seq: 2, #new-token: 61, #cached-token: 2, token usage: 0.05, #running-req: 46, #queue-req: 1940, 
[1,0]<stdout>:[2025-10-12 21:04:41 TP0] Decode batch. #running-req: 48, #token: 13877, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 57.10, #queue-req: 1940, 
[1,0]<stdout>:[2025-10-12 21:04:41 TP0] Prefill batch. #new-seq: 2, #new-token: 51, #cached-token: 3, token usage: 0.05, #running-req: 46, #queue-req: 1938, 
[1,0]<stdout>:[2025-10-12 21:04:42 TP0] Prefill batch. #new-seq: 2, #new-token: 349, #cached-token: 3, token usage: 0.05, #running-req: 46, #queue-req: 1936, 
[1,0]<stdout>:[2025-10-12 21:04:43 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1935, 
[1,0]<stdout>:[2025-10-12 21:04:43 TP0] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1934, 
[1,0]<stdout>:[2025-10-12 21:04:43 TP0] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1933, 
[1,0]<stdout>:[2025-10-12 21:04:43 TP0] Decode batch. #running-req: 48, #token: 14598, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 855.71, #queue-req: 1933, 
[1,0]<stdout>:[2025-10-12 21:04:44 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1932, 
[1,0]<stdout>:[2025-10-12 21:04:44 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1931, 
[1,0]<stdout>:[2025-10-12 21:04:45 TP0] Prefill batch. #new-seq: 2, #new-token: 572, #cached-token: 4, token usage: 0.06, #running-req: 46, #queue-req: 1929, 
[1,0]<stdout>:[2025-10-12 21:04:45 TP0] Decode batch. #running-req: 47, #token: 14800, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1047.03, #queue-req: 1929, 
[1,0]<stdout>:[2025-10-12 21:04:45 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1928, 
[1,0]<stdout>:[2025-10-12 21:04:46 TP0] Prefill batch. #new-seq: 1, #new-token: 771, #cached-token: 7, token usage: 0.06, #running-req: 47, #queue-req: 1927, 
[1,0]<stdout>:[2025-10-12 21:04:46 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1926, 
[1,0]<stdout>:[2025-10-12 21:04:46 TP0] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1925, 
[1,0]<stdout>:[2025-10-12 21:04:47 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1924, 
[1,0]<stdout>:[2025-10-12 21:04:47 TP0] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 6, token usage: 0.06, #running-req: 47, #queue-req: 1923, 
[1,0]<stdout>:[2025-10-12 21:04:47 TP0] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1922, 
[1,0]<stdout>:[2025-10-12 21:04:47 TP0] Prefill batch. #new-seq: 2, #new-token: 884, #cached-token: 3, token usage: 0.06, #running-req: 46, #queue-req: 1920, 
[1,0]<stdout>:[2025-10-12 21:04:48 TP0] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1919, 
[1,0]<stdout>:[2025-10-12 21:04:48 TP0] Prefill batch. #new-seq: 1, #new-token: 3866, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1918, 
[1,0]<stdout>:[2025-10-12 21:04:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1381, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1917, 
[1,0]<stdout>:[2025-10-12 21:04:49 TP0] Prefill batch. #new-seq: 1, #new-token: 621, #cached-token: 9, token usage: 0.07, #running-req: 47, #queue-req: 1916, 
[1,0]<stdout>:[2025-10-12 21:04:49 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1915, 
[1,0]<stdout>:[2025-10-12 21:04:49 TP0] Decode batch. #running-req: 48, #token: 17697, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 478.97, #queue-req: 1915, 
[1,0]<stdout>:[2025-10-12 21:04:49 TP0] Prefill batch. #new-seq: 2, #new-token: 487, #cached-token: 3, token usage: 0.07, #running-req: 46, #queue-req: 1913, 
[1,0]<stdout>:[2025-10-12 21:04:50 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1912, 
[1,0]<stdout>:[2025-10-12 21:04:50 TP0] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 1911, 
[1,0]<stdout>:[2025-10-12 21:04:51 TP0] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1910, 
[1,0]<stdout>:[2025-10-12 21:04:51 TP0] Prefill batch. #new-seq: 1, #new-token: 773, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1909, 
[1,0]<stdout>:[2025-10-12 21:04:51 TP0] Decode batch. #running-req: 47, #token: 17383, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 879.58, #queue-req: 1909, 
[1,0]<stdout>:[2025-10-12 21:04:51 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1908, 
[1,0]<stdout>:[2025-10-12 21:04:52 TP0] Prefill batch. #new-seq: 2, #new-token: 76, #cached-token: 3, token usage: 0.07, #running-req: 46, #queue-req: 1906, 
[1,0]<stdout>:[2025-10-12 21:04:52 TP0] Prefill batch. #new-seq: 2, #new-token: 267, #cached-token: 4, token usage: 0.07, #running-req: 46, #queue-req: 1904, 
[1,0]<stdout>:[2025-10-12 21:04:52 TP0] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1903, 
[1,0]<stdout>:[2025-10-12 21:04:53 TP0] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1902, 
[1,0]<stdout>:[2025-10-12 21:04:53 TP0] Prefill batch. #new-seq: 2, #new-token: 360, #cached-token: 2, token usage: 0.06, #running-req: 46, #queue-req: 1900, 
[1,0]<stdout>:[2025-10-12 21:04:53 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1899, 
[1,0]<stdout>:[2025-10-12 21:04:54 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1898, 
[1,0]<stdout>:[2025-10-12 21:04:54 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1897, 
[1,0]<stdout>:[2025-10-12 21:04:54 TP0] Decode batch. #running-req: 48, #token: 15165, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 639.37, #queue-req: 1897, 
[1,0]<stdout>:[2025-10-12 21:04:55 TP0] Prefill batch. #new-seq: 1, #new-token: 574, #cached-token: 6, token usage: 0.06, #running-req: 47, #queue-req: 1896, 
[1,0]<stdout>:[2025-10-12 21:04:55 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1895, 
[1,0]<stdout>:[2025-10-12 21:04:55 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1894, 
[1,0]<stdout>:[2025-10-12 21:04:56 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1893, 
[1,0]<stdout>:[2025-10-12 21:04:56 TP0] Decode batch. #running-req: 48, #token: 17051, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 978.13, #queue-req: 1893, 
[1,0]<stdout>:[2025-10-12 21:04:56 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1892, 
[1,0]<stdout>:[2025-10-12 21:04:57 TP0] Prefill batch. #new-seq: 2, #new-token: 86, #cached-token: 3, token usage: 0.06, #running-req: 46, #queue-req: 1890, 
[1,0]<stdout>:[2025-10-12 21:04:57 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1889, 
[1,0]<stdout>:[2025-10-12 21:04:58 TP0] Prefill batch. #new-seq: 1, #new-token: 2415, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1888, 
[1,0]<stdout>:[2025-10-12 21:04:58 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1887, 
[1,0]<stdout>:[2025-10-12 21:04:58 TP0] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 7, token usage: 0.06, #running-req: 47, #queue-req: 1886, 
[1,0]<stdout>:[2025-10-12 21:04:59 TP0] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 11, token usage: 0.06, #running-req: 47, #queue-req: 1885, 
[1,0]<stdout>:[2025-10-12 21:04:59 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1884, 
[1,0]<stdout>:[2025-10-12 21:04:59 TP0] Decode batch. #running-req: 48, #token: 16005, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 683.27, #queue-req: 1884, 
[1,0]<stdout>:[2025-10-12 21:04:59 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1883, 
[1,0]<stdout>:[2025-10-12 21:05:00 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1882, 
[1,0]<stdout>:[2025-10-12 21:05:00 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1881, 
[1,0]<stdout>:[2025-10-12 21:05:00 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1880, 
[1,0]<stdout>:[2025-10-12 21:05:01 TP0] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 5, token usage: 0.05, #running-req: 47, #queue-req: 1879, 
[1,0]<stdout>:[2025-10-12 21:05:01 TP0] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1878, 
[1,0]<stdout>:[2025-10-12 21:05:02 TP0] Decode batch. #running-req: 48, #token: 14801, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 817.12, #queue-req: 1878, 
[1,0]<stdout>:[2025-10-12 21:05:02 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1877, 
[1,0]<stdout>:[2025-10-12 21:05:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1876, 
[1,0]<stdout>:[2025-10-12 21:05:03 TP0] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1875, 
[1,0]<stdout>:[2025-10-12 21:05:03 TP0] Prefill batch. #new-seq: 1, #new-token: 429, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1874, 
[1,0]<stdout>:[2025-10-12 21:05:04 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1873, 
[1,0]<stdout>:[2025-10-12 21:05:04 TP0] Decode batch. #running-req: 48, #token: 17169, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 875.67, #queue-req: 1873, 
[1,0]<stdout>:[2025-10-12 21:05:04 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1872, 
[1,0]<stdout>:[2025-10-12 21:05:04 TP0] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1871, 
[1,0]<stdout>:[2025-10-12 21:05:04 TP0] Prefill batch. #new-seq: 2, #new-token: 820, #cached-token: 5, token usage: 0.06, #running-req: 46, #queue-req: 1869, 
[1,0]<stdout>:[2025-10-12 21:05:05 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1868, 
[1,0]<stdout>:[2025-10-12 21:05:05 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1867, 
[1,0]<stdout>:[2025-10-12 21:05:05 TP0] Prefill batch. #new-seq: 2, #new-token: 113, #cached-token: 5, token usage: 0.06, #running-req: 46, #queue-req: 1865, 
[1,0]<stdout>:[2025-10-12 21:05:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1978, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1864, 
[1,0]<stdout>:[2025-10-12 21:05:06 TP0] Prefill batch. #new-seq: 1, #new-token: 804, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1863, 
[1,0]<stdout>:[2025-10-12 21:05:06 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1862, 
[1,0]<stdout>:[2025-10-12 21:05:06 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1861, 
[1,0]<stdout>:[2025-10-12 21:05:07 TP0] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1860, 
[1,0]<stdout>:[2025-10-12 21:05:07 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1859, 
[1,0]<stdout>:[2025-10-12 21:05:07 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1858, 
[1,0]<stdout>:[2025-10-12 21:05:08 TP0] Decode batch. #running-req: 48, #token: 17805, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 493.26, #queue-req: 1858, 
[1,0]<stdout>:[2025-10-12 21:05:08 TP0] Prefill batch. #new-seq: 1, #new-token: 615, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1857, 
[1,0]<stdout>:[2025-10-12 21:05:08 TP0] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1856, 
[1,0]<stdout>:[2025-10-12 21:05:08 TP0] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1855, 
[1,0]<stdout>:[2025-10-12 21:05:09 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1854, 
[1,0]<stdout>:[2025-10-12 21:05:09 TP0] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1853, 
[1,0]<stdout>:[2025-10-12 21:05:09 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1852, 
[1,0]<stdout>:[2025-10-12 21:05:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1389, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1851, 
[1,0]<stdout>:[2025-10-12 21:05:10 TP0] Prefill batch. #new-seq: 1, #new-token: 703, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1850, 
[1,0]<stdout>:[2025-10-12 21:05:10 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1849, 
[1,0]<stdout>:[2025-10-12 21:05:11 TP0] Decode batch. #running-req: 47, #token: 17947, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 629.10, #queue-req: 1849, 
[1,0]<stdout>:[2025-10-12 21:05:11 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1848, 
[1,0]<stdout>:[2025-10-12 21:05:11 TP0] Prefill batch. #new-seq: 1, #new-token: 699, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1847, 
[1,0]<stdout>:[2025-10-12 21:05:11 TP0] Prefill batch. #new-seq: 2, #new-token: 314, #cached-token: 9, token usage: 0.07, #running-req: 46, #queue-req: 1845, 
[1,0]<stdout>:[2025-10-12 21:05:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1844, 
[1,0]<stdout>:[2025-10-12 21:05:12 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1843, 
[1,0]<stdout>:[2025-10-12 21:05:13 TP0] Prefill batch. #new-seq: 1, #new-token: 810, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1842, 
[1,0]<stdout>:[2025-10-12 21:05:13 TP0] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1841, 
[1,0]<stdout>:[2025-10-12 21:05:13 TP0] Prefill batch. #new-seq: 1, #new-token: 515, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1840, 
[1,0]<stdout>:[2025-10-12 21:05:14 TP0] Decode batch. #running-req: 48, #token: 19331, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 631.11, #queue-req: 1840, 
[1,0]<stdout>:[2025-10-12 21:05:14 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1839, 
[1,0]<stdout>:[2025-10-12 21:05:14 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1838, 
[1,0]<stdout>:[2025-10-12 21:05:14 TP0] Prefill batch. #new-seq: 2, #new-token: 13, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 1836, 
[1,0]<stdout>:[2025-10-12 21:05:15 TP0] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1835, 
[1,0]<stdout>:[2025-10-12 21:05:15 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1834, 
[1,0]<stdout>:[2025-10-12 21:05:15 TP0] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1833, 
[1,0]<stdout>:[2025-10-12 21:05:16 TP0] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1832, 
[1,0]<stdout>:[2025-10-12 21:05:16 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1831, 
[1,0]<stdout>:[2025-10-12 21:05:16 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1830, 
[1,0]<stdout>:[2025-10-12 21:05:16 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1829, 
[1,0]<stdout>:[2025-10-12 21:05:17 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1828, 
[1,0]<stdout>:[2025-10-12 21:05:17 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1827, 
[1,0]<stdout>:[2025-10-12 21:05:17 TP0] Decode batch. #running-req: 47, #token: 16998, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 534.93, #queue-req: 1827, 
[1,0]<stdout>:[2025-10-12 21:05:17 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1826, 
[1,0]<stdout>:[2025-10-12 21:05:17 TP0] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1825, 
[1,0]<stdout>:[2025-10-12 21:05:18 TP0] Prefill batch. #new-seq: 1, #new-token: 712, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1824, 
[1,0]<stdout>:[2025-10-12 21:05:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1065, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1823, 
[1,0]<stdout>:[2025-10-12 21:05:18 TP0] Prefill batch. #new-seq: 2, #new-token: 517, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 1821, 
[1,0]<stdout>:[2025-10-12 21:05:19 TP0] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1820, 
[1,0]<stdout>:[2025-10-12 21:05:19 TP0] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1819, 
[1,0]<stdout>:[2025-10-12 21:05:20 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1818, 
[1,0]<stdout>:[2025-10-12 21:05:20 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1817, 
[1,0]<stdout>:[2025-10-12 21:05:20 TP0] Decode batch. #running-req: 48, #token: 19556, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 641.29, #queue-req: 1817, 
[1,0]<stdout>:[2025-10-12 21:05:20 TP0] Prefill batch. #new-seq: 1, #new-token: 764, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1816, 
[1,0]<stdout>:[2025-10-12 21:05:20 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1815, 
[1,0]<stdout>:[2025-10-12 21:05:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1228, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1814, 
[1,0]<stdout>:[2025-10-12 21:05:21 TP0] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1813, 
[1,0]<stdout>:[2025-10-12 21:05:22 TP0] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1812, 
[1,0]<stdout>:[2025-10-12 21:05:22 TP0] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1811, 
[1,0]<stdout>:[2025-10-12 21:05:22 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1810, 
[1,0]<stdout>:[2025-10-12 21:05:22 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1809, 
[1,0]<stdout>:[2025-10-12 21:05:23 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1808, 
[1,0]<stdout>:[2025-10-12 21:05:23 TP0] Prefill batch. #new-seq: 1, #new-token: 466, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1807, 
[1,0]<stdout>:[2025-10-12 21:05:23 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1806, 
[1,0]<stdout>:[2025-10-12 21:05:24 TP0] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1805, 
[1,0]<stdout>:[2025-10-12 21:05:24 TP0] Decode batch. #running-req: 48, #token: 20320, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 527.02, #queue-req: 1805, 
[1,0]<stdout>:[2025-10-12 21:05:24 TP0] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1804, 
[1,0]<stdout>:[2025-10-12 21:05:24 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1803, 
[1,0]<stdout>:[2025-10-12 21:05:24 TP0] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1802, 
[1,0]<stdout>:[2025-10-12 21:05:25 TP0] Prefill batch. #new-seq: 2, #new-token: 75, #cached-token: 4, token usage: 0.07, #running-req: 46, #queue-req: 1800, 
[1,0]<stdout>:[2025-10-12 21:05:25 TP0] Prefill batch. #new-seq: 2, #new-token: 75, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 1798, 
[1,0]<stdout>:[2025-10-12 21:05:26 TP0] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 1797, 
[1,0]<stdout>:[2025-10-12 21:05:26 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1796, 
[1,0]<stdout>:[2025-10-12 21:05:26 TP0] Decode batch. #running-req: 48, #token: 19495, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 741.96, #queue-req: 1796, 
[1,0]<stdout>:[2025-10-12 21:05:27 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1795, 
[1,0]<stdout>:[2025-10-12 21:05:27 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1794, 
[1,0]<stdout>:[2025-10-12 21:05:27 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1793, 
[1,0]<stdout>:[2025-10-12 21:05:27 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1792, 
[1,0]<stdout>:[2025-10-12 21:05:28 TP0] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1791, 
[1,0]<stdout>:[2025-10-12 21:05:28 TP0] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1790, 
[1,0]<stdout>:[2025-10-12 21:05:29 TP0] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1789, 
[1,0]<stdout>:[2025-10-12 21:05:29 TP0] Decode batch. #running-req: 48, #token: 20005, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 752.16, #queue-req: 1789, 
[1,0]<stdout>:[2025-10-12 21:05:29 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1788, 
[1,0]<stdout>:[2025-10-12 21:05:30 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1787, 
[1,0]<stdout>:[2025-10-12 21:05:30 TP0] Prefill batch. #new-seq: 3, #new-token: 792, #cached-token: 4, token usage: 0.08, #running-req: 45, #queue-req: 1784, 
[1,0]<stdout>:[2025-10-12 21:05:30 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1783, 
[1,0]<stdout>:[2025-10-12 21:05:30 TP0] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1782, 
[1,0]<stdout>:[2025-10-12 21:05:31 TP0] Prefill batch. #new-seq: 2, #new-token: 631, #cached-token: 3, token usage: 0.07, #running-req: 46, #queue-req: 1780, 
[1,0]<stdout>:[2025-10-12 21:05:31 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 7, token usage: 0.07, #running-req: 47, #queue-req: 1779, 
[1,0]<stdout>:[2025-10-12 21:05:31 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1778, 
[1,0]<stdout>:[2025-10-12 21:05:31 TP0] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1777, 
[1,0]<stdout>:[2025-10-12 21:05:32 TP0] Prefill batch. #new-seq: 1, #new-token: 515, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1776, 
[1,0]<stdout>:[2025-10-12 21:05:32 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 8, token usage: 0.07, #running-req: 47, #queue-req: 1775, 
[1,0]<stdout>:[2025-10-12 21:05:32 TP0] Decode batch. #running-req: 47, #token: 17869, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 560.13, #queue-req: 1775, 
[1,0]<stdout>:[2025-10-12 21:05:32 TP0] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1774, 
[1,0]<stdout>:[2025-10-12 21:05:33 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1773, 
[1,0]<stdout>:[2025-10-12 21:05:33 TP0] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1772, 
[1,0]<stdout>:[2025-10-12 21:05:33 TP0] Prefill batch. #new-seq: 2, #new-token: 653, #cached-token: 2, token usage: 0.07, #running-req: 46, #queue-req: 1770, 
[1,0]<stdout>:[2025-10-12 21:05:34 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1769, 
[1,0]<stdout>:[2025-10-12 21:05:34 TP0] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1768, 
[1,0]<stdout>:[2025-10-12 21:05:34 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1767, 
[1,0]<stdout>:[2025-10-12 21:05:35 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1766, 
[1,0]<stdout>:[2025-10-12 21:05:35 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1765, 
[1,0]<stdout>:[2025-10-12 21:05:35 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1764, 
[1,0]<stdout>:[2025-10-12 21:05:35 TP0] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1763, 
[1,0]<stdout>:[2025-10-12 21:05:36 TP0] Prefill batch. #new-seq: 2, #new-token: 20, #cached-token: 5, token usage: 0.06, #running-req: 46, #queue-req: 1761, 
[1,0]<stdout>:[2025-10-12 21:05:36 TP0] Decode batch. #running-req: 48, #token: 16112, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 540.71, #queue-req: 1761, 
[1,0]<stdout>:[2025-10-12 21:05:36 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1760, 
[1,0]<stdout>:[2025-10-12 21:05:36 TP0] Prefill batch. #new-seq: 2, #new-token: 385, #cached-token: 5, token usage: 0.06, #running-req: 46, #queue-req: 1758, 
[1,0]<stdout>:[2025-10-12 21:05:37 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1757, 
[1,0]<stdout>:[2025-10-12 21:05:37 TP0] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1756, 
[1,0]<stdout>:[2025-10-12 21:05:37 TP0] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1755, 
[1,0]<stdout>:[2025-10-12 21:05:38 TP0] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1754, 
[1,0]<stdout>:[2025-10-12 21:05:38 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1753, 
[1,0]<stdout>:[2025-10-12 21:05:38 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1752, 
[1,0]<stdout>:[2025-10-12 21:05:39 TP0] Prefill batch. #new-seq: 1, #new-token: 430, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1751, 
[1,0]<stdout>:[2025-10-12 21:05:39 TP0] Decode batch. #running-req: 48, #token: 14299, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 642.85, #queue-req: 1751, 
[1,0]<stdout>:[2025-10-12 21:05:39 TP0] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1750, 
[1,0]<stdout>:[2025-10-12 21:05:39 TP0] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1749, 
[1,0]<stdout>:[2025-10-12 21:05:40 TP0] Prefill batch. #new-seq: 1, #new-token: 734, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1748, 
[1,0]<stdout>:[2025-10-12 21:05:40 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1747, 
[1,0]<stdout>:[2025-10-12 21:05:40 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1746, 
[1,0]<stdout>:[2025-10-12 21:05:40 TP0] Prefill batch. #new-seq: 1, #new-token: 401, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1745, 
[1,0]<stdout>:[2025-10-12 21:05:41 TP0] Prefill batch. #new-seq: 2, #new-token: 459, #cached-token: 3, token usage: 0.06, #running-req: 46, #queue-req: 1743, 
[1,0]<stdout>:[2025-10-12 21:05:41 TP0] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1742, 
[1,0]<stdout>:[2025-10-12 21:05:41 TP0] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1741, 
[1,0]<stdout>:[2025-10-12 21:05:42 TP0] Prefill batch. #new-seq: 1, #new-token: 923, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1740, 
[1,0]<stdout>:[2025-10-12 21:05:42 TP0] Decode batch. #running-req: 47, #token: 16510, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 584.74, #queue-req: 1740, 
[1,0]<stdout>:[2025-10-12 21:05:42 TP0] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1739, 
[1,0]<stdout>:[2025-10-12 21:05:42 TP0] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1738, 
[1,0]<stdout>:[2025-10-12 21:05:43 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1737, 
[1,0]<stdout>:[2025-10-12 21:05:43 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1736, 
[1,0]<stdout>:[2025-10-12 21:05:43 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1735, 
[1,0]<stdout>:[2025-10-12 21:05:43 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1734, 
[1,0]<stdout>:[2025-10-12 21:05:44 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1733, 
[1,0]<stdout>:[2025-10-12 21:05:44 TP0] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1732, 
[1,0]<stdout>:[2025-10-12 21:05:44 TP0] Prefill batch. #new-seq: 1, #new-token: 868, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1731, 
[1,0]<stdout>:[2025-10-12 21:05:45 TP0] Prefill batch. #new-seq: 1, #new-token: 673, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1730, 
[1,0]<stdout>:[2025-10-12 21:05:45 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1729, 
[1,0]<stdout>:[2025-10-12 21:05:45 TP0] Prefill batch. #new-seq: 3, #new-token: 858, #cached-token: 7, token usage: 0.06, #running-req: 45, #queue-req: 1726, 
[1,0]<stdout>:[2025-10-12 21:05:45 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1725, 
[1,0]<stdout>:[2025-10-12 21:05:46 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 1724, 
[1,0]<stdout>:[2025-10-12 21:05:46 TP0] Prefill batch. #new-seq: 1, #new-token: 493, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1723, 
[1,0]<stdout>:[2025-10-12 21:05:46 TP0] Decode batch. #running-req: 48, #token: 15957, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 450.21, #queue-req: 1723, 
[1,0]<stdout>:[2025-10-12 21:05:47 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1722, 
[1,0]<stdout>:[2025-10-12 21:05:47 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 1721, 
[1,0]<stdout>:[2025-10-12 21:05:47 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1720, 
[1,0]<stdout>:[2025-10-12 21:05:47 TP0] Prefill batch. #new-seq: 2, #new-token: 380, #cached-token: 6, token usage: 0.06, #running-req: 46, #queue-req: 1718, 
[1,0]<stdout>:[2025-10-12 21:05:48 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1717, 
[1,0]<stdout>:[2025-10-12 21:05:49 TP0] Decode batch. #running-req: 48, #token: 15599, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 878.65, #queue-req: 1717, 
[1,0]<stdout>:[2025-10-12 21:05:49 TP0] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1716, 
[1,0]<stdout>:[2025-10-12 21:05:49 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 1715, 
[1,0]<stdout>:[2025-10-12 21:05:49 TP0] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 6, token usage: 0.06, #running-req: 47, #queue-req: 1714, 
[1,0]<stdout>:[2025-10-12 21:05:50 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 1713, 
[1,0]<stdout>:[2025-10-12 21:05:50 TP0] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1712, 
[1,0]<stdout>:[2025-10-12 21:05:50 TP0] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1711, 
[1,0]<stdout>:[2025-10-12 21:05:51 TP0] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1710, 
[1,0]<stdout>:[2025-10-12 21:05:51 TP0] Decode batch. #running-req: 47, #token: 17766, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 720.26, #queue-req: 1710, 
[1,0]<stdout>:[2025-10-12 21:05:51 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1709, 
[1,0]<stdout>:[2025-10-12 21:05:52 TP0] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1708, 
[1,0]<stdout>:[2025-10-12 21:05:52 TP0] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 1707, 
[1,0]<stdout>:[2025-10-12 21:05:52 TP0] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1706, 
[1,0]<stdout>:[2025-10-12 21:05:53 TP0] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1705, 
[1,0]<stdout>:[2025-10-12 21:05:53 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 7, token usage: 0.08, #running-req: 47, #queue-req: 1704, 
[1,0]<stdout>:[2025-10-12 21:05:53 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1703, 
[1,0]<stdout>:[2025-10-12 21:05:53 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1702, 
[1,0]<stdout>:[2025-10-12 21:05:54 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1701, 
[1,0]<stdout>:[2025-10-12 21:05:54 TP0] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1700, 
[1,0]<stdout>:[2025-10-12 21:05:54 TP0] Decode batch. #running-req: 46, #token: 18151, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 601.66, #queue-req: 1700, 
[1,0]<stdout>:[2025-10-12 21:05:54 TP0] Prefill batch. #new-seq: 2, #new-token: 125, #cached-token: 2, token usage: 0.07, #running-req: 46, #queue-req: 1698, 
[1,0]<stdout>:[2025-10-12 21:05:55 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1697, 
[1,0]<stdout>:[2025-10-12 21:05:55 TP0] Prefill batch. #new-seq: 2, #new-token: 987, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 1695, 
[1,0]<stdout>:[2025-10-12 21:05:55 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1694, 
[1,0]<stdout>:[2025-10-12 21:05:56 TP0] Prefill batch. #new-seq: 3, #new-token: 1064, #cached-token: 12, token usage: 0.07, #running-req: 45, #queue-req: 1691, 
[1,0]<stdout>:[2025-10-12 21:05:56 TP0] Decode batch. #running-req: 48, #token: 19435, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 892.01, #queue-req: 1691, 
[1,0]<stdout>:[2025-10-12 21:05:57 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1690, 
[1,0]<stdout>:[2025-10-12 21:05:57 TP0] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1689, 
[1,0]<stdout>:[2025-10-12 21:05:57 TP0] Prefill batch. #new-seq: 1, #new-token: 762, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1688, 
[1,0]<stdout>:[2025-10-12 21:05:58 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1687, 
[1,0]<stdout>:[2025-10-12 21:05:58 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1686, 
[1,0]<stdout>:[2025-10-12 21:05:58 TP0] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1685, 
[1,0]<stdout>:[2025-10-12 21:05:58 TP0] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1684, 
[1,0]<stdout>:[2025-10-12 21:05:59 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1683, 
[1,0]<stdout>:[2025-10-12 21:05:59 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1682, 
[1,0]<stdout>:[2025-10-12 21:05:59 TP0] Prefill batch. #new-seq: 2, #new-token: 987, #cached-token: 9, token usage: 0.07, #running-req: 46, #queue-req: 1680, 
[1,0]<stdout>:[2025-10-12 21:05:59 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1679, 
[1,0]<stdout>:[2025-10-12 21:06:00 TP0] Decode batch. #running-req: 48, #token: 19381, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 567.11, #queue-req: 1679, 
[1,0]<stdout>:[2025-10-12 21:06:00 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1678, 
[1,0]<stdout>:[2025-10-12 21:06:00 TP0] Prefill batch. #new-seq: 1, #new-token: 903, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1677, 
[1,0]<stdout>:[2025-10-12 21:06:01 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1676, 
[1,0]<stdout>:[2025-10-12 21:06:01 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1675, 
[1,0]<stdout>:[2025-10-12 21:06:02 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1674, 
[1,0]<stdout>:[2025-10-12 21:06:02 TP0] Decode batch. #running-req: 48, #token: 20681, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 888.62, #queue-req: 1674, 
[1,0]<stdout>:[2025-10-12 21:06:02 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1673, 
[1,0]<stdout>:[2025-10-12 21:06:02 TP0] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1672, 
[1,0]<stdout>:[2025-10-12 21:06:03 TP0] Prefill batch. #new-seq: 2, #new-token: 269, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 1670, 
[1,0]<stdout>:[2025-10-12 21:06:03 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1669, 
[1,0]<stdout>:[2025-10-12 21:06:04 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1668, 
[1,0]<stdout>:[2025-10-12 21:06:04 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1667, 
[1,0]<stdout>:[2025-10-12 21:06:04 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1666, 
[1,0]<stdout>:[2025-10-12 21:06:05 TP0] Decode batch. #running-req: 48, #token: 19210, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 742.46, #queue-req: 1666, 
[1,0]<stdout>:[2025-10-12 21:06:05 TP0] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1665, 
[1,0]<stdout>:[2025-10-12 21:06:05 TP0] Prefill batch. #new-seq: 2, #new-token: 503, #cached-token: 2, token usage: 0.08, #running-req: 46, #queue-req: 1663, 
[1,0]<stdout>:[2025-10-12 21:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1662, 
[1,0]<stdout>:[2025-10-12 21:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1661, 
[1,0]<stdout>:[2025-10-12 21:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 670, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1660, 
[1,0]<stdout>:[2025-10-12 21:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1659, 
[1,0]<stdout>:[2025-10-12 21:06:07 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1658, 
[1,0]<stdout>:[2025-10-12 21:06:07 TP0] Prefill batch. #new-seq: 1, #new-token: 463, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1657, 
[1,0]<stdout>:[2025-10-12 21:06:07 TP0] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1656, 
[1,0]<stdout>:[2025-10-12 21:06:08 TP0] Decode batch. #running-req: 48, #token: 19125, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 648.73, #queue-req: 1656, 
[1,0]<stdout>:[2025-10-12 21:06:08 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1655, 
[1,0]<stdout>:[2025-10-12 21:06:08 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1654, 
[1,0]<stdout>:[2025-10-12 21:06:08 TP0] Prefill batch. #new-seq: 1, #new-token: 822, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 1653, 
[1,0]<stdout>:[2025-10-12 21:06:08 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1652, 
[1,0]<stdout>:[2025-10-12 21:06:09 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1651, 
[1,0]<stdout>:[2025-10-12 21:06:09 TP0] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 7, token usage: 0.08, #running-req: 47, #queue-req: 1650, 
[1,0]<stdout>:[2025-10-12 21:06:10 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1649, 
[1,0]<stdout>:[2025-10-12 21:06:10 TP0] Prefill batch. #new-seq: 3, #new-token: 1679, #cached-token: 11, token usage: 0.07, #running-req: 45, #queue-req: 1646, 
[1,0]<stdout>:[2025-10-12 21:06:10 TP0] Prefill batch. #new-seq: 1, #new-token: 735, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1645, 
[1,0]<stdout>:[2025-10-12 21:06:10 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1644, 
[1,0]<stdout>:[2025-10-12 21:06:10 TP0] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1643, 
[1,0]<stdout>:[2025-10-12 21:06:11 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1642, 
[1,0]<stdout>:[2025-10-12 21:06:11 TP0] Decode batch. #running-req: 47, #token: 19923, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 538.74, #queue-req: 1642, 
[1,0]<stdout>:[2025-10-12 21:06:11 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1641, 
[1,0]<stdout>:[2025-10-12 21:06:11 TP0] Prefill batch. #new-seq: 2, #new-token: 2489, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1639, 
[1,0]<stdout>:[2025-10-12 21:06:12 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1638, 
[1,0]<stdout>:[2025-10-12 21:06:12 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1637, 
[1,0]<stdout>:[2025-10-12 21:06:13 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1636, 
[1,0]<stdout>:[2025-10-12 21:06:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1231, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1635, 
[1,0]<stdout>:[2025-10-12 21:06:13 TP0] Decode batch. #running-req: 48, #token: 22950, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 818.36, #queue-req: 1635, 
[1,0]<stdout>:[2025-10-12 21:06:14 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1634, 
[1,0]<stdout>:[2025-10-12 21:06:14 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1633, 
[1,0]<stdout>:[2025-10-12 21:06:15 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1632, 
[1,0]<stdout>:[2025-10-12 21:06:15 TP0] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 1631, 
[1,0]<stdout>:[2025-10-12 21:06:15 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1630, 
[1,0]<stdout>:[2025-10-12 21:06:16 TP0] Decode batch. #running-req: 48, #token: 24879, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 869.46, #queue-req: 1630, 
[1,0]<stdout>:[2025-10-12 21:06:16 TP0] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1629, 
[1,0]<stdout>:[2025-10-12 21:06:17 TP0] Prefill batch. #new-seq: 2, #new-token: 739, #cached-token: 11, token usage: 0.09, #running-req: 46, #queue-req: 1627, 
[1,0]<stdout>:[2025-10-12 21:06:17 TP0] Prefill batch. #new-seq: 3, #new-token: 1240, #cached-token: 6, token usage: 0.10, #running-req: 45, #queue-req: 1624, 
[1,0]<stdout>:[2025-10-12 21:06:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1623, 
[1,0]<stdout>:[2025-10-12 21:06:18 TP0] Decode batch. #running-req: 48, #token: 27123, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 940.05, #queue-req: 1623, 
[1,0]<stdout>:[2025-10-12 21:06:18 TP0] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1622, 
[1,0]<stdout>:[2025-10-12 21:06:18 TP0] Prefill batch. #new-seq: 2, #new-token: 994, #cached-token: 4, token usage: 0.10, #running-req: 46, #queue-req: 1620, 
[1,0]<stdout>:[2025-10-12 21:06:19 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1619, 
[1,0]<stdout>:[2025-10-12 21:06:19 TP0] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1618, 
[1,0]<stdout>:[2025-10-12 21:06:20 TP0] Decode batch. #running-req: 48, #token: 26777, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 945.68, #queue-req: 1618, 
[1,0]<stdout>:[2025-10-12 21:06:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1940, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1617, 
[1,0]<stdout>:[2025-10-12 21:06:20 TP0] Prefill batch. #new-seq: 2, #new-token: 1482, #cached-token: 7, token usage: 0.11, #running-req: 46, #queue-req: 1615, 
[1,0]<stdout>:[2025-10-12 21:06:21 TP0] Prefill batch. #new-seq: 1, #new-token: 833, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1614, 
[1,0]<stdout>:[2025-10-12 21:06:21 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1613, 
[1,0]<stdout>:[2025-10-12 21:06:21 TP0] Prefill batch. #new-seq: 1, #new-token: 755, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1612, 
[1,0]<stdout>:[2025-10-12 21:06:21 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1611, 
[1,0]<stdout>:[2025-10-12 21:06:22 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1610, 
[1,0]<stdout>:[2025-10-12 21:06:22 TP0] Decode batch. #running-req: 47, #token: 27395, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 730.91, #queue-req: 1610, 
[1,0]<stdout>:[2025-10-12 21:06:22 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1609, 
[1,0]<stdout>:[2025-10-12 21:06:22 TP0] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1608, 
[1,0]<stdout>:[2025-10-12 21:06:23 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1607, 
[1,0]<stdout>:[2025-10-12 21:06:23 TP0] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1606, 
[1,0]<stdout>:[2025-10-12 21:06:23 TP0] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1605, 
[1,0]<stdout>:[2025-10-12 21:06:24 TP0] Prefill batch. #new-seq: 2, #new-token: 311, #cached-token: 9, token usage: 0.11, #running-req: 46, #queue-req: 1603, 
[1,0]<stdout>:[2025-10-12 21:06:24 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1602, 
[1,0]<stdout>:[2025-10-12 21:06:24 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1601, 
[1,0]<stdout>:[2025-10-12 21:06:25 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1600, 
[1,0]<stdout>:[2025-10-12 21:06:25 TP0] Prefill batch. #new-seq: 1, #new-token: 447, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1599, 
[1,0]<stdout>:[2025-10-12 21:06:25 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1598, 
[1,0]<stdout>:[2025-10-12 21:06:25 TP0] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1597, 
[1,0]<stdout>:[2025-10-12 21:06:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1044, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1596, 
[1,0]<stdout>:[2025-10-12 21:06:26 TP0] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1595, 
[1,0]<stdout>:[2025-10-12 21:06:26 TP0] Decode batch. #running-req: 48, #token: 28457, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 473.33, #queue-req: 1595, 
[1,0]<stdout>:[2025-10-12 21:06:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1051, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1594, 
[1,0]<stdout>:[2025-10-12 21:06:27 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1593, 
[1,0]<stdout>:[2025-10-12 21:06:27 TP0] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1592, 
[1,0]<stdout>:[2025-10-12 21:06:27 TP0] Prefill batch. #new-seq: 1, #new-token: 759, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1591, 
[1,0]<stdout>:[2025-10-12 21:06:28 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1590, 
[1,0]<stdout>:[2025-10-12 21:06:28 TP0] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1589, 
[1,0]<stdout>:[2025-10-12 21:06:28 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1588, 
[1,0]<stdout>:[2025-10-12 21:06:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1587, 
[1,0]<stdout>:[2025-10-12 21:06:29 TP0] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1586, 
[1,0]<stdout>:[2025-10-12 21:06:29 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1585, 
[1,0]<stdout>:[2025-10-12 21:06:30 TP0] Decode batch. #running-req: 47, #token: 27663, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 591.65, #queue-req: 1585, 
[1,0]<stdout>:[2025-10-12 21:06:30 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1584, 
[1,0]<stdout>:[2025-10-12 21:06:30 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1583, 
[1,0]<stdout>:[2025-10-12 21:06:30 TP0] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 7, token usage: 0.11, #running-req: 47, #queue-req: 1582, 
[1,0]<stdout>:[2025-10-12 21:06:31 TP0] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1581, 
[1,0]<stdout>:[2025-10-12 21:06:31 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1580, 
[1,0]<stdout>:[2025-10-12 21:06:31 TP0] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1579, 
[1,0]<stdout>:[2025-10-12 21:06:32 TP0] Prefill batch. #new-seq: 2, #new-token: 562, #cached-token: 3, token usage: 0.10, #running-req: 46, #queue-req: 1577, 
[1,0]<stdout>:[2025-10-12 21:06:32 TP0] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1576, 
[1,0]<stdout>:[2025-10-12 21:06:32 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1575, 
[1,0]<stdout>:[2025-10-12 21:06:32 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1574, 
[1,0]<stdout>:[2025-10-12 21:06:33 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1573, 
[1,0]<stdout>:[2025-10-12 21:06:33 TP0] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1572, 
[1,0]<stdout>:[2025-10-12 21:06:33 TP0] Decode batch. #running-req: 47, #token: 25309, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 523.85, #queue-req: 1572, 
[1,0]<stdout>:[2025-10-12 21:06:33 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1571, 
[1,0]<stdout>:[2025-10-12 21:06:34 TP0] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1570, 
[1,0]<stdout>:[2025-10-12 21:06:34 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1569, 
[1,0]<stdout>:[2025-10-12 21:06:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1568, 
[1,0]<stdout>:[2025-10-12 21:06:34 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1567, 
[1,0]<stdout>:[2025-10-12 21:06:35 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1566, 
[1,0]<stdout>:[2025-10-12 21:06:35 TP0] Prefill batch. #new-seq: 1, #new-token: 774, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1565, 
[1,0]<stdout>:[2025-10-12 21:06:35 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1564, 
[1,0]<stdout>:[2025-10-12 21:06:36 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1563, 
[1,0]<stdout>:[2025-10-12 21:06:36 TP0] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1562, 
[1,0]<stdout>:[2025-10-12 21:06:36 TP0] Decode batch. #running-req: 48, #token: 23715, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 595.12, #queue-req: 1562, 
[1,0]<stdout>:[2025-10-12 21:06:37 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1561, 
[1,0]<stdout>:[2025-10-12 21:06:37 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1560, 
[1,0]<stdout>:[2025-10-12 21:06:37 TP0] Prefill batch. #new-seq: 1, #new-token: 832, #cached-token: 7, token usage: 0.09, #running-req: 47, #queue-req: 1559, 
[1,0]<stdout>:[2025-10-12 21:06:38 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1558, 
[1,0]<stdout>:[2025-10-12 21:06:38 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 8, token usage: 0.09, #running-req: 47, #queue-req: 1557, 
[1,0]<stdout>:[2025-10-12 21:06:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1414, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1556, 
[1,0]<stdout>:[2025-10-12 21:06:39 TP0] Decode batch. #running-req: 48, #token: 23539, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 785.46, #queue-req: 1556, 
[1,0]<stdout>:[2025-10-12 21:06:39 TP0] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1555, 
[1,0]<stdout>:[2025-10-12 21:06:39 TP0] Prefill batch. #new-seq: 2, #new-token: 285, #cached-token: 9, token usage: 0.09, #running-req: 46, #queue-req: 1553, 
[1,0]<stdout>:[2025-10-12 21:06:40 TP0] Prefill batch. #new-seq: 1, #new-token: 706, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1552, 
[1,0]<stdout>:[2025-10-12 21:06:40 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1551, 
[1,0]<stdout>:[2025-10-12 21:06:41 TP0] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1550, 
[1,0]<stdout>:[2025-10-12 21:06:41 TP0] Prefill batch. #new-seq: 2, #new-token: 36, #cached-token: 5, token usage: 0.09, #running-req: 46, #queue-req: 1548, 
[1,0]<stdout>:[2025-10-12 21:06:41 TP0] Decode batch. #running-req: 48, #token: 22689, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 787.77, #queue-req: 1548, 
[1,0]<stdout>:[2025-10-12 21:06:41 TP0] Prefill batch. #new-seq: 2, #new-token: 182, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 1546, 
[1,0]<stdout>:[2025-10-12 21:06:42 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1545, 
[1,0]<stdout>:[2025-10-12 21:06:42 TP0] Prefill batch. #new-seq: 1, #new-token: 2564, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1544, 
[1,0]<stdout>:[2025-10-12 21:06:42 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1543, 
[1,0]<stdout>:[2025-10-12 21:06:43 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1542, 
[1,0]<stdout>:[2025-10-12 21:06:43 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1541, 
[1,0]<stdout>:[2025-10-12 21:06:44 TP0] Decode batch. #running-req: 46, #token: 22176, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 798.35, #queue-req: 1541, 
[1,0]<stdout>:[2025-10-12 21:06:44 TP0] Prefill batch. #new-seq: 2, #new-token: 13, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1539, 
[1,0]<stdout>:[2025-10-12 21:06:44 TP0] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1538, 
[1,0]<stdout>:[2025-10-12 21:06:45 TP0] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1537, 
[1,0]<stdout>:[2025-10-12 21:06:45 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1536, 
[1,0]<stdout>:[2025-10-12 21:06:46 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1535, 
[1,0]<stdout>:[2025-10-12 21:06:46 TP0] Decode batch. #running-req: 48, #token: 23267, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 863.79, #queue-req: 1535, 
[1,0]<stdout>:[2025-10-12 21:06:46 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1534, 
[1,0]<stdout>:[2025-10-12 21:06:46 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1533, 
[1,0]<stdout>:[2025-10-12 21:06:46 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1532, 
[1,0]<stdout>:[2025-10-12 21:06:47 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1531, 
[1,0]<stdout>:[2025-10-12 21:06:47 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1530, 
[1,0]<stdout>:[2025-10-12 21:06:48 TP0] Prefill batch. #new-seq: 2, #new-token: 29, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 1528, 
[1,0]<stdout>:[2025-10-12 21:06:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1527, 
[1,0]<stdout>:[2025-10-12 21:06:48 TP0] Decode batch. #running-req: 48, #token: 21519, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 741.70, #queue-req: 1527, 
[1,0]<stdout>:[2025-10-12 21:06:49 TP0] Prefill batch. #new-seq: 2, #new-token: 2001, #cached-token: 8, token usage: 0.08, #running-req: 46, #queue-req: 1525, 
[1,0]<stdout>:[2025-10-12 21:06:49 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1524, 
[1,0]<stdout>:[2025-10-12 21:06:49 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1523, 
[1,0]<stdout>:[2025-10-12 21:06:49 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1522, 
[1,0]<stdout>:[2025-10-12 21:06:50 TP0] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1521, 
[1,0]<stdout>:[2025-10-12 21:06:50 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1520, 
[1,0]<stdout>:[2025-10-12 21:06:50 TP0] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1519, 
[1,0]<stdout>:[2025-10-12 21:06:51 TP0] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1518, 
[1,0]<stdout>:[2025-10-12 21:06:51 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1517, 
[1,0]<stdout>:[2025-10-12 21:06:51 TP0] Prefill batch. #new-seq: 2, #new-token: 1437, #cached-token: 7, token usage: 0.08, #running-req: 46, #queue-req: 1515, 
[1,0]<stdout>:[2025-10-12 21:06:52 TP0] Decode batch. #running-req: 48, #token: 22580, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 596.01, #queue-req: 1515, 
[1,0]<stdout>:[2025-10-12 21:06:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1514, 
[1,0]<stdout>:[2025-10-12 21:06:52 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1513, 
[1,0]<stdout>:[2025-10-12 21:06:53 TP0] Prefill batch. #new-seq: 1, #new-token: 849, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1512, 
[1,0]<stdout>:[2025-10-12 21:06:53 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1511, 
[1,0]<stdout>:[2025-10-12 21:06:53 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1510, 
[1,0]<stdout>:[2025-10-12 21:06:54 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1509, 
[1,0]<stdout>:[2025-10-12 21:06:54 TP0] Decode batch. #running-req: 48, #token: 23256, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 815.14, #queue-req: 1509, 
[1,0]<stdout>:[2025-10-12 21:06:54 TP0] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1508, 
[1,0]<stdout>:[2025-10-12 21:06:54 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1507, 
[1,0]<stdout>:[2025-10-12 21:06:55 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1506, 
[1,0]<stdout>:[2025-10-12 21:06:55 TP0] Prefill batch. #new-seq: 3, #new-token: 824, #cached-token: 6, token usage: 0.09, #running-req: 45, #queue-req: 1503, 
[1,0]<stdout>:[2025-10-12 21:06:56 TP0] Prefill batch. #new-seq: 1, #new-token: 581, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1502, 
[1,0]<stdout>:[2025-10-12 21:06:56 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1501, 
[1,0]<stdout>:[2025-10-12 21:06:56 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1500, 
[1,0]<stdout>:[2025-10-12 21:06:56 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1499, 
[1,0]<stdout>:[2025-10-12 21:06:57 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1498, 
[1,0]<stdout>:[2025-10-12 21:06:57 TP0] Decode batch. #running-req: 48, #token: 22641, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 633.35, #queue-req: 1498, 
[1,0]<stdout>:[2025-10-12 21:06:57 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1497, 
[1,0]<stdout>:[2025-10-12 21:06:57 TP0] Prefill batch. #new-seq: 1, #new-token: 570, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1496, 
[1,0]<stdout>:[2025-10-12 21:06:58 TP0] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1495, 
[1,0]<stdout>:[2025-10-12 21:06:58 TP0] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1494, 
[1,0]<stdout>:[2025-10-12 21:06:59 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1493, 
[1,0]<stdout>:[2025-10-12 21:06:59 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1492, 
[1,0]<stdout>:[2025-10-12 21:06:59 TP0] Prefill batch. #new-seq: 1, #new-token: 817, #cached-token: 10, token usage: 0.08, #running-req: 47, #queue-req: 1491, 
[1,0]<stdout>:[2025-10-12 21:07:00 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1490, 
[1,0]<stdout>:[2025-10-12 21:07:00 TP0] Decode batch. #running-req: 48, #token: 21654, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 682.20, #queue-req: 1490, 
[1,0]<stdout>:[2025-10-12 21:07:00 TP0] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1489, 
[1,0]<stdout>:[2025-10-12 21:07:01 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1488, 
[1,0]<stdout>:[2025-10-12 21:07:01 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1487, 
[1,0]<stdout>:[2025-10-12 21:07:01 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1486, 
[1,0]<stdout>:[2025-10-12 21:07:01 TP0] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1485, 
[1,0]<stdout>:[2025-10-12 21:07:02 TP0] Prefill batch. #new-seq: 2, #new-token: 950, #cached-token: 3, token usage: 0.08, #running-req: 46, #queue-req: 1483, 
[1,0]<stdout>:[2025-10-12 21:07:02 TP0] Decode batch. #running-req: 47, #token: 20990, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 806.83, #queue-req: 1483, 
[1,0]<stdout>:[2025-10-12 21:07:02 TP0] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1482, 
[1,0]<stdout>:[2025-10-12 21:07:03 TP0] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 1481, 
[1,0]<stdout>:[2025-10-12 21:07:03 TP0] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1480, 
[1,0]<stdout>:[2025-10-12 21:07:03 TP0] Prefill batch. #new-seq: 2, #new-token: 68, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1478, 
[1,0]<stdout>:[2025-10-12 21:07:04 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1477, 
[1,0]<stdout>:[2025-10-12 21:07:04 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1476, 
[1,0]<stdout>:[2025-10-12 21:07:04 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1475, 
[1,0]<stdout>:[2025-10-12 21:07:04 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1474, 
[1,0]<stdout>:[2025-10-12 21:07:05 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1473, 
[1,0]<stdout>:[2025-10-12 21:07:05 TP0] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1472, 
[1,0]<stdout>:[2025-10-12 21:07:05 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1471, 
[1,0]<stdout>:[2025-10-12 21:07:06 TP0] Decode batch. #running-req: 48, #token: 19041, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 565.13, #queue-req: 1471, 
[1,0]<stdout>:[2025-10-12 21:07:06 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1470, 
[1,0]<stdout>:[2025-10-12 21:07:06 TP0] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1469, 
[1,0]<stdout>:[2025-10-12 21:07:06 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1468, 
[1,0]<stdout>:[2025-10-12 21:07:06 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1467, 
[1,0]<stdout>:[2025-10-12 21:07:07 TP0] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1466, 
[1,0]<stdout>:[2025-10-12 21:07:07 TP0] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 7, token usage: 0.07, #running-req: 47, #queue-req: 1465, 
[1,0]<stdout>:[2025-10-12 21:07:07 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1464, 
[1,0]<stdout>:[2025-10-12 21:07:07 TP0] Prefill batch. #new-seq: 1, #new-token: 513, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 1463, 
[1,0]<stdout>:[2025-10-12 21:07:08 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1462, 
[1,0]<stdout>:[2025-10-12 21:07:08 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1461, 
[1,0]<stdout>:[2025-10-12 21:07:08 TP0] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1460, 
[1,0]<stdout>:[2025-10-12 21:07:09 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1459, 
[1,0]<stdout>:[2025-10-12 21:07:09 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 1458, 
[1,0]<stdout>:[2025-10-12 21:07:09 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1457, 
[1,0]<stdout>:[2025-10-12 21:07:10 TP0] Decode batch. #running-req: 48, #token: 18677, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 478.41, #queue-req: 1457, 
[1,0]<stdout>:[2025-10-12 21:07:10 TP0] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 1456, 
[1,0]<stdout>:[2025-10-12 21:07:10 TP0] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1455, 
[1,0]<stdout>:[2025-10-12 21:07:10 TP0] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1454, 
[1,0]<stdout>:[2025-10-12 21:07:11 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1453, 
[1,0]<stdout>:[2025-10-12 21:07:11 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1452, 
[1,0]<stdout>:[2025-10-12 21:07:12 TP0] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 8, token usage: 0.08, #running-req: 47, #queue-req: 1451, 
[1,0]<stdout>:[2025-10-12 21:07:12 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1450, 
[1,0]<stdout>:[2025-10-12 21:07:12 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1449, 
[1,0]<stdout>:[2025-10-12 21:07:12 TP0] Prefill batch. #new-seq: 1, #new-token: 720, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1448, 
[1,0]<stdout>:[2025-10-12 21:07:13 TP0] Decode batch. #running-req: 47, #token: 20388, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 623.81, #queue-req: 1448, 
[1,0]<stdout>:[2025-10-12 21:07:13 TP0] Prefill batch. #new-seq: 1, #new-token: 795, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1447, 
[1,0]<stdout>:[2025-10-12 21:07:13 TP0] Prefill batch. #new-seq: 2, #new-token: 1263, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1445, 
[1,0]<stdout>:[2025-10-12 21:07:13 TP0] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 8, token usage: 0.09, #running-req: 47, #queue-req: 1444, 
[1,0]<stdout>:[2025-10-12 21:07:13 TP0] Prefill batch. #new-seq: 2, #new-token: 465, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1442, 
[1,0]<stdout>:[2025-10-12 21:07:14 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1441, 
[1,0]<stdout>:[2025-10-12 21:07:14 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1440, 
[1,0]<stdout>:[2025-10-12 21:07:14 TP0] Prefill batch. #new-seq: 1, #new-token: 479, #cached-token: 7, token usage: 0.08, #running-req: 47, #queue-req: 1439, 
[1,0]<stdout>:[2025-10-12 21:07:15 TP0] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1438, 
[1,0]<stdout>:[2025-10-12 21:07:15 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1437, 
[1,0]<stdout>:[2025-10-12 21:07:15 TP0] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1436, 
[1,0]<stdout>:[2025-10-12 21:07:16 TP0] Decode batch. #running-req: 48, #token: 21786, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 591.37, #queue-req: 1436, 
[1,0]<stdout>:[2025-10-12 21:07:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1595, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1435, 
[1,0]<stdout>:[2025-10-12 21:07:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1292, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1434, 
[1,0]<stdout>:[2025-10-12 21:07:17 TP0] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1433, 
[1,0]<stdout>:[2025-10-12 21:07:17 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1432, 
[1,0]<stdout>:[2025-10-12 21:07:17 TP0] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1431, 
[1,0]<stdout>:[2025-10-12 21:07:18 TP0] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1430, 
[1,0]<stdout>:[2025-10-12 21:07:18 TP0] Decode batch. #running-req: 47, #token: 23988, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 801.03, #queue-req: 1430, 
[1,0]<stdout>:[2025-10-12 21:07:18 TP0] Prefill batch. #new-seq: 1, #new-token: 3194, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1429, 
[1,0]<stdout>:[2025-10-12 21:07:19 TP0] Prefill batch. #new-seq: 2, #new-token: 378, #cached-token: 2, token usage: 0.11, #running-req: 46, #queue-req: 1427, 
[1,0]<stdout>:[2025-10-12 21:07:19 TP0] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 6, token usage: 0.11, #running-req: 47, #queue-req: 1426, 
[1,0]<stdout>:[2025-10-12 21:07:20 TP0] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 1425, 
[1,0]<stdout>:[2025-10-12 21:07:20 TP0] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1424, 
[1,0]<stdout>:[2025-10-12 21:07:20 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1423, 
[1,0]<stdout>:[2025-10-12 21:07:21 TP0] Prefill batch. #new-seq: 2, #new-token: 755, #cached-token: 8, token usage: 0.10, #running-req: 46, #queue-req: 1421, 
[1,0]<stdout>:[2025-10-12 21:07:21 TP0] Decode batch. #running-req: 48, #token: 26799, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 742.76, #queue-req: 1421, 
[1,0]<stdout>:[2025-10-12 21:07:21 TP0] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 5, token usage: 0.11, #running-req: 47, #queue-req: 1420, 
[1,0]<stdout>:[2025-10-12 21:07:21 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 1419, 
[1,0]<stdout>:[2025-10-12 21:07:22 TP0] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1418, 
[1,0]<stdout>:[2025-10-12 21:07:22 TP0] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1417, 
[1,0]<stdout>:[2025-10-12 21:07:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1416, 
[1,0]<stdout>:[2025-10-12 21:07:22 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1415, 
[1,0]<stdout>:[2025-10-12 21:07:23 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1414, 
[1,0]<stdout>:[2025-10-12 21:07:23 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1413, 
[1,0]<stdout>:[2025-10-12 21:07:23 TP0] Prefill batch. #new-seq: 2, #new-token: 319, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1411, 
[1,0]<stdout>:[2025-10-12 21:07:24 TP0] Prefill batch. #new-seq: 2, #new-token: 794, #cached-token: 12, token usage: 0.09, #running-req: 46, #queue-req: 1409, 
[1,0]<stdout>:[2025-10-12 21:07:24 TP0] Decode batch. #running-req: 48, #token: 24190, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 603.15, #queue-req: 1409, 
[1,0]<stdout>:[2025-10-12 21:07:24 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1408, 
[1,0]<stdout>:[2025-10-12 21:07:24 TP0] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 1407, 
[1,0]<stdout>:[2025-10-12 21:07:25 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1406, 
[1,0]<stdout>:[2025-10-12 21:07:25 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 14, token usage: 0.10, #running-req: 47, #queue-req: 1405, 
[1,0]<stdout>:[2025-10-12 21:07:25 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1404, 
[1,0]<stdout>:[2025-10-12 21:07:26 TP0] Prefill batch. #new-seq: 2, #new-token: 824, #cached-token: 7, token usage: 0.10, #running-req: 46, #queue-req: 1402, 
[1,0]<stdout>:[2025-10-12 21:07:26 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1401, 
[1,0]<stdout>:[2025-10-12 21:07:26 TP0] Prefill batch. #new-seq: 3, #new-token: 1531, #cached-token: 10, token usage: 0.09, #running-req: 45, #queue-req: 1398, 
[1,0]<stdout>:[2025-10-12 21:07:26 TP0] Prefill batch. #new-seq: 1, #new-token: 930, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1397, 
[1,0]<stdout>:[2025-10-12 21:07:27 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1396, 
[1,0]<stdout>:[2025-10-12 21:07:27 TP0] Decode batch. #running-req: 48, #token: 25382, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 610.04, #queue-req: 1396, 
[1,0]<stdout>:[2025-10-12 21:07:27 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1395, 
[1,0]<stdout>:[2025-10-12 21:07:27 TP0] Prefill batch. #new-seq: 3, #new-token: 1575, #cached-token: 10, token usage: 0.10, #running-req: 45, #queue-req: 1392, 
[1,0]<stdout>:[2025-10-12 21:07:28 TP0] Prefill batch. #new-seq: 2, #new-token: 435, #cached-token: 6, token usage: 0.10, #running-req: 46, #queue-req: 1390, 
[1,0]<stdout>:[2025-10-12 21:07:28 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1389, 
[1,0]<stdout>:[2025-10-12 21:07:28 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1388, 
[1,0]<stdout>:[2025-10-12 21:07:28 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1387, 
[1,0]<stdout>:[2025-10-12 21:07:29 TP0] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1386, 
[1,0]<stdout>:[2025-10-12 21:07:29 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1385, 
[1,0]<stdout>:[2025-10-12 21:07:29 TP0] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1384, 
[1,0]<stdout>:[2025-10-12 21:07:30 TP0] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1383, 
[1,0]<stdout>:[2025-10-12 21:07:30 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1382, 
[1,0]<stdout>:[2025-10-12 21:07:30 TP0] Decode batch. #running-req: 48, #token: 24711, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 567.42, #queue-req: 1382, 
[1,0]<stdout>:[2025-10-12 21:07:31 TP0] Prefill batch. #new-seq: 1, #new-token: 958, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1381, 
[1,0]<stdout>:[2025-10-12 21:07:31 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1380, 
[1,0]<stdout>:[2025-10-12 21:07:31 TP0] Prefill batch. #new-seq: 1, #new-token: 245, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1379, 
[1,0]<stdout>:[2025-10-12 21:07:31 TP0] Prefill batch. #new-seq: 2, #new-token: 772, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1377, 
[1,0]<stdout>:[2025-10-12 21:07:32 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1376, 
[1,0]<stdout>:[2025-10-12 21:07:32 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1375, 
[1,0]<stdout>:[2025-10-12 21:07:32 TP0] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1374, 
[1,0]<stdout>:[2025-10-12 21:07:32 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1373, 
[1,0]<stdout>:[2025-10-12 21:07:33 TP0] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1372, 
[1,0]<stdout>:[2025-10-12 21:07:33 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1371, 
[1,0]<stdout>:[2025-10-12 21:07:33 TP0] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1370, 
[1,0]<stdout>:[2025-10-12 21:07:34 TP0] Decode batch. #running-req: 48, #token: 22555, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 570.08, #queue-req: 1370, 
[1,0]<stdout>:[2025-10-12 21:07:34 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1369, 
[1,0]<stdout>:[2025-10-12 21:07:34 TP0] Prefill batch. #new-seq: 1, #new-token: 885, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1368, 
[1,0]<stdout>:[2025-10-12 21:07:35 TP0] Prefill batch. #new-seq: 1, #new-token: 930, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 1367, 
[1,0]<stdout>:[2025-10-12 21:07:35 TP0] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1366, 
[1,0]<stdout>:[2025-10-12 21:07:36 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1365, 
[1,0]<stdout>:[2025-10-12 21:07:36 TP0] Prefill batch. #new-seq: 2, #new-token: 248, #cached-token: 10, token usage: 0.09, #running-req: 46, #queue-req: 1363, 
[1,0]<stdout>:[2025-10-12 21:07:36 TP0] Decode batch. #running-req: 48, #token: 24177, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 808.30, #queue-req: 1363, 
[1,0]<stdout>:[2025-10-12 21:07:36 TP0] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1362, 
[1,0]<stdout>:[2025-10-12 21:07:36 TP0] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1361, 
[1,0]<stdout>:[2025-10-12 21:07:37 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1360, 
[1,0]<stdout>:[2025-10-12 21:07:37 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1359, 
[1,0]<stdout>:[2025-10-12 21:07:38 TP0] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1358, 
[1,0]<stdout>:[2025-10-12 21:07:38 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1357, 
[1,0]<stdout>:[2025-10-12 21:07:38 TP0] Prefill batch. #new-seq: 2, #new-token: 981, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 1355, 
[1,0]<stdout>:[2025-10-12 21:07:38 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1354, 
[1,0]<stdout>:[2025-10-12 21:07:39 TP0] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 1353, 
[1,0]<stdout>:[2025-10-12 21:07:39 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1352, 
[1,0]<stdout>:[2025-10-12 21:07:39 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1351, 
[1,0]<stdout>:[2025-10-12 21:07:40 TP0] Decode batch. #running-req: 48, #token: 23377, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 563.56, #queue-req: 1351, 
[1,0]<stdout>:[2025-10-12 21:07:40 TP0] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1350, 
[1,0]<stdout>:[2025-10-12 21:07:40 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1349, 
[1,0]<stdout>:[2025-10-12 21:07:40 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1348, 
[1,0]<stdout>:[2025-10-12 21:07:41 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1347, 
[1,0]<stdout>:[2025-10-12 21:07:41 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1346, 
[1,0]<stdout>:[2025-10-12 21:07:41 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1345, 
[1,0]<stdout>:[2025-10-12 21:07:41 TP0] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1344, 
[1,0]<stdout>:[2025-10-12 21:07:42 TP0] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 7, token usage: 0.09, #running-req: 47, #queue-req: 1343, 
[1,0]<stdout>:[2025-10-12 21:07:42 TP0] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1342, 
[1,0]<stdout>:[2025-10-12 21:07:42 TP0] Prefill batch. #new-seq: 1, #new-token: 765, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1341, 
[1,0]<stdout>:[2025-10-12 21:07:43 TP0] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1340, 
[1,0]<stdout>:[2025-10-12 21:07:43 TP0] Decode batch. #running-req: 47, #token: 24643, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 565.03, #queue-req: 1340, 
[1,0]<stdout>:[2025-10-12 21:07:43 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1339, 
[1,0]<stdout>:[2025-10-12 21:07:43 TP0] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1338, 
[1,0]<stdout>:[2025-10-12 21:07:44 TP0] Prefill batch. #new-seq: 3, #new-token: 234, #cached-token: 12, token usage: 0.09, #running-req: 45, #queue-req: 1335, 
[1,0]<stdout>:[2025-10-12 21:07:44 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 12, token usage: 0.09, #running-req: 47, #queue-req: 1334, 
[1,0]<stdout>:[2025-10-12 21:07:44 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1333, 
[1,0]<stdout>:[2025-10-12 21:07:45 TP0] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 1332, 
[1,0]<stdout>:[2025-10-12 21:07:45 TP0] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1331, 
[1,0]<stdout>:[2025-10-12 21:07:45 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1330, 
[1,0]<stdout>:[2025-10-12 21:07:46 TP0] Decode batch. #running-req: 48, #token: 24826, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 685.17, #queue-req: 1330, 
[1,0]<stdout>:[2025-10-12 21:07:46 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1329, 
[1,0]<stdout>:[2025-10-12 21:07:46 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1328, 
[1,0]<stdout>:[2025-10-12 21:07:46 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1327, 
[1,0]<stdout>:[2025-10-12 21:07:47 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1326, 
[1,0]<stdout>:[2025-10-12 21:07:47 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1325, 
[1,0]<stdout>:[2025-10-12 21:07:47 TP0] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1324, 
[1,0]<stdout>:[2025-10-12 21:07:48 TP0] Prefill batch. #new-seq: 3, #new-token: 608, #cached-token: 5, token usage: 0.09, #running-req: 45, #queue-req: 1321, 
[1,0]<stdout>:[2025-10-12 21:07:48 TP0] Prefill batch. #new-seq: 1, #new-token: 407, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1320, 
[1,0]<stdout>:[2025-10-12 21:07:48 TP0] Decode batch. #running-req: 47, #token: 22849, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 688.57, #queue-req: 1320, 
[1,0]<stdout>:[2025-10-12 21:07:48 TP0] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1319, 
[1,0]<stdout>:[2025-10-12 21:07:49 TP0] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1318, 
[1,0]<stdout>:[2025-10-12 21:07:49 TP0] Prefill batch. #new-seq: 1, #new-token: 794, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1317, 
[1,0]<stdout>:[2025-10-12 21:07:49 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1316, 
[1,0]<stdout>:[2025-10-12 21:07:50 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1315, 
[1,0]<stdout>:[2025-10-12 21:07:50 TP0] Prefill batch. #new-seq: 2, #new-token: 275, #cached-token: 5, token usage: 0.09, #running-req: 46, #queue-req: 1313, 
[1,0]<stdout>:[2025-10-12 21:07:50 TP0] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1312, 
[1,0]<stdout>:[2025-10-12 21:07:51 TP0] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1311, 
[1,0]<stdout>:[2025-10-12 21:07:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1310, 
[1,0]<stdout>:[2025-10-12 21:07:51 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1309, 
[1,0]<stdout>:[2025-10-12 21:07:51 TP0] Prefill batch. #new-seq: 1, #new-token: 892, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1308, 
[1,0]<stdout>:[2025-10-12 21:07:52 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1307, 
[1,0]<stdout>:[2025-10-12 21:07:52 TP0] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1306, 
[1,0]<stdout>:[2025-10-12 21:07:52 TP0] Decode batch. #running-req: 47, #token: 23059, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 504.63, #queue-req: 1306, 
[1,0]<stdout>:[2025-10-12 21:07:52 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1305, 
[1,0]<stdout>:[2025-10-12 21:07:52 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1304, 
[1,0]<stdout>:[2025-10-12 21:07:53 TP0] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1303, 
[1,0]<stdout>:[2025-10-12 21:07:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1021, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1302, 
[1,0]<stdout>:[2025-10-12 21:07:53 TP0] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1301, 
[1,0]<stdout>:[2025-10-12 21:07:54 TP0] Prefill batch. #new-seq: 2, #new-token: 761, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1299, 
[1,0]<stdout>:[2025-10-12 21:07:54 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1298, 
[1,0]<stdout>:[2025-10-12 21:07:54 TP0] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1297, 
[1,0]<stdout>:[2025-10-12 21:07:55 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1296, 
[1,0]<stdout>:[2025-10-12 21:07:55 TP0] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1295, 
[1,0]<stdout>:[2025-10-12 21:07:55 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1294, 
[1,0]<stdout>:[2025-10-12 21:07:55 TP0] Prefill batch. #new-seq: 1, #new-token: 789, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1293, 
[1,0]<stdout>:[2025-10-12 21:07:56 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1292, 
[1,0]<stdout>:[2025-10-12 21:07:56 TP0] Decode batch. #running-req: 48, #token: 22513, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 509.04, #queue-req: 1292, 
[1,0]<stdout>:[2025-10-12 21:07:56 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1291, 
[1,0]<stdout>:[2025-10-12 21:07:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1386, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1290, 
[1,0]<stdout>:[2025-10-12 21:07:57 TP0] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1289, 
[1,0]<stdout>:[2025-10-12 21:07:57 TP0] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1288, 
[1,0]<stdout>:[2025-10-12 21:07:57 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1287, 
[1,0]<stdout>:[2025-10-12 21:07:58 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1286, 
[1,0]<stdout>:[2025-10-12 21:07:58 TP0] Prefill batch. #new-seq: 2, #new-token: 947, #cached-token: 8, token usage: 0.09, #running-req: 46, #queue-req: 1284, 
[1,0]<stdout>:[2025-10-12 21:07:58 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1283, 
[1,0]<stdout>:[2025-10-12 21:07:59 TP0] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1282, 
[1,0]<stdout>:[2025-10-12 21:07:59 TP0] Decode batch. #running-req: 48, #token: 24273, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 642.09, #queue-req: 1282, 
[1,0]<stdout>:[2025-10-12 21:07:59 TP0] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 1281, 
[1,0]<stdout>:[2025-10-12 21:07:59 TP0] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1280, 
[1,0]<stdout>:[2025-10-12 21:08:00 TP0] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1279, 
[1,0]<stdout>:[2025-10-12 21:08:00 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1278, 
[1,0]<stdout>:[2025-10-12 21:08:00 TP0] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1277, 
[1,0]<stdout>:[2025-10-12 21:08:00 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1276, 
[1,0]<stdout>:[2025-10-12 21:08:01 TP0] Prefill batch. #new-seq: 1, #new-token: 862, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 1275, 
[1,0]<stdout>:[2025-10-12 21:08:01 TP0] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1274, 
[1,0]<stdout>:[2025-10-12 21:08:02 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1273, 
[1,0]<stdout>:[2025-10-12 21:08:02 TP0] Decode batch. #running-req: 48, #token: 25153, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 640.20, #queue-req: 1273, 
[1,0]<stdout>:[2025-10-12 21:08:02 TP0] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1272, 
[1,0]<stdout>:[2025-10-12 21:08:02 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1271, 
[1,0]<stdout>:[2025-10-12 21:08:03 TP0] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1270, 
[1,0]<stdout>:[2025-10-12 21:08:03 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1269, 
[1,0]<stdout>:[2025-10-12 21:08:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1268, 
[1,0]<stdout>:[2025-10-12 21:08:04 TP0] Prefill batch. #new-seq: 1, #new-token: 6399, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1267, 
[1,0]<stdout>:[2025-10-12 21:08:04 TP0] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1266, 
[1,0]<stdout>:[2025-10-12 21:08:04 TP0] Prefill batch. #new-seq: 2, #new-token: 372, #cached-token: 6, token usage: 0.11, #running-req: 46, #queue-req: 1264, 
[1,0]<stdout>:[2025-10-12 21:08:05 TP0] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1263, 
[1,0]<stdout>:[2025-10-12 21:08:05 TP0] Decode batch. #running-req: 48, #token: 28818, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 623.27, #queue-req: 1263, 
[1,0]<stdout>:[2025-10-12 21:08:05 TP0] Prefill batch. #new-seq: 2, #new-token: 143, #cached-token: 8, token usage: 0.11, #running-req: 46, #queue-req: 1261, 
[1,0]<stdout>:[2025-10-12 21:08:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1260, 
[1,0]<stdout>:[2025-10-12 21:08:06 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1259, 
[1,0]<stdout>:[2025-10-12 21:08:06 TP0] Prefill batch. #new-seq: 2, #new-token: 166, #cached-token: 9, token usage: 0.11, #running-req: 46, #queue-req: 1257, 
[1,0]<stdout>:[2025-10-12 21:08:06 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1256, 
[1,0]<stdout>:[2025-10-12 21:08:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1966, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1255, 
[1,0]<stdout>:[2025-10-12 21:08:07 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1254, 
[1,0]<stdout>:[2025-10-12 21:08:07 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 1253, 
[1,0]<stdout>:[2025-10-12 21:08:08 TP0] Prefill batch. #new-seq: 1, #new-token: 749, #cached-token: 6, token usage: 0.12, #running-req: 47, #queue-req: 1252, 
[1,0]<stdout>:[2025-10-12 21:08:08 TP0] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1251, 
[1,0]<stdout>:[2025-10-12 21:08:08 TP0] Decode batch. #running-req: 48, #token: 30262, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 590.51, #queue-req: 1251, 
[1,0]<stdout>:[2025-10-12 21:08:08 TP0] Prefill batch. #new-seq: 1, #new-token: 781, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1250, 
[1,0]<stdout>:[2025-10-12 21:08:09 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1249, 
[1,0]<stdout>:[2025-10-12 21:08:09 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1248, 
[1,0]<stdout>:[2025-10-12 21:08:10 TP0] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 6, token usage: 0.12, #running-req: 47, #queue-req: 1247, 
[1,0]<stdout>:[2025-10-12 21:08:10 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1246, 
[1,0]<stdout>:[2025-10-12 21:08:10 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1245, 
[1,0]<stdout>:[2025-10-12 21:08:11 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1244, 
[1,0]<stdout>:[2025-10-12 21:08:11 TP0] Prefill batch. #new-seq: 2, #new-token: 2304, #cached-token: 5, token usage: 0.12, #running-req: 46, #queue-req: 1242, 
[1,0]<stdout>:[2025-10-12 21:08:11 TP0] Decode batch. #running-req: 48, #token: 32604, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 680.26, #queue-req: 1242, 
[1,0]<stdout>:[2025-10-12 21:08:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1012, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1241, 
[1,0]<stdout>:[2025-10-12 21:08:12 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1240, 
[1,0]<stdout>:[2025-10-12 21:08:12 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1239, 
[1,0]<stdout>:[2025-10-12 21:08:12 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1238, 
[1,0]<stdout>:[2025-10-12 21:08:13 TP0] Prefill batch. #new-seq: 2, #new-token: 23, #cached-token: 3, token usage: 0.13, #running-req: 46, #queue-req: 1236, 
[1,0]<stdout>:[2025-10-12 21:08:13 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1235, 
[1,0]<stdout>:[2025-10-12 21:08:13 TP0] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1234, 
[1,0]<stdout>:[2025-10-12 21:08:14 TP0] Prefill batch. #new-seq: 2, #new-token: 296, #cached-token: 2, token usage: 0.12, #running-req: 46, #queue-req: 1232, 
[1,0]<stdout>:[2025-10-12 21:08:14 TP0] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1231, 
[1,0]<stdout>:[2025-10-12 21:08:14 TP0] Decode batch. #running-req: 47, #token: 31373, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 636.62, #queue-req: 1231, 
[1,0]<stdout>:[2025-10-12 21:08:14 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1230, 
[1,0]<stdout>:[2025-10-12 21:08:14 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1229, 
[1,0]<stdout>:[2025-10-12 21:08:15 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 1228, 
[1,0]<stdout>:[2025-10-12 21:08:15 TP0] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1227, 
[1,0]<stdout>:[2025-10-12 21:08:15 TP0] Prefill batch. #new-seq: 1, #new-token: 820, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 1226, 
[1,0]<stdout>:[2025-10-12 21:08:16 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 1225, 
[1,0]<stdout>:[2025-10-12 21:08:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1898, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1224, 
[1,0]<stdout>:[2025-10-12 21:08:16 TP0] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1223, 
[1,0]<stdout>:[2025-10-12 21:08:16 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.13, #running-req: 47, #queue-req: 1222, 
[1,0]<stdout>:[2025-10-12 21:08:17 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1221, 
[1,0]<stdout>:[2025-10-12 21:08:17 TP0] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1220, 
[1,0]<stdout>:[2025-10-12 21:08:17 TP0] Decode batch. #running-req: 48, #token: 32414, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 562.84, #queue-req: 1220, 
[1,0]<stdout>:[2025-10-12 21:08:17 TP0] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1219, 
[1,0]<stdout>:[2025-10-12 21:08:18 TP0] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1218, 
[1,0]<stdout>:[2025-10-12 21:08:18 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1217, 
[1,0]<stdout>:[2025-10-12 21:08:18 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1216, 
[1,0]<stdout>:[2025-10-12 21:08:19 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1215, 
[1,0]<stdout>:[2025-10-12 21:08:19 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1214, 
[1,0]<stdout>:[2025-10-12 21:08:19 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1213, 
[1,0]<stdout>:[2025-10-12 21:08:19 TP0] Prefill batch. #new-seq: 2, #new-token: 826, #cached-token: 5, token usage: 0.11, #running-req: 46, #queue-req: 1211, 
[1,0]<stdout>:[2025-10-12 21:08:20 TP0] Prefill batch. #new-seq: 1, #new-token: 2044, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1210, 
[1,0]<stdout>:[2025-10-12 21:08:20 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1209, 
[1,0]<stdout>:[2025-10-12 21:08:20 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1208, 
[1,0]<stdout>:[2025-10-12 21:08:21 TP0] Prefill batch. #new-seq: 2, #new-token: 1408, #cached-token: 7, token usage: 0.12, #running-req: 46, #queue-req: 1206, 
[1,0]<stdout>:[2025-10-12 21:08:21 TP0] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1205, 
[1,0]<stdout>:[2025-10-12 21:08:21 TP0] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 8, token usage: 0.13, #running-req: 47, #queue-req: 1204, 
[1,0]<stdout>:[2025-10-12 21:08:21 TP0] Decode batch. #running-req: 48, #token: 31733, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 482.10, #queue-req: 1204, 
[1,0]<stdout>:[2025-10-12 21:08:22 TP0] Prefill batch. #new-seq: 2, #new-token: 744, #cached-token: 10, token usage: 0.13, #running-req: 46, #queue-req: 1202, 
[1,0]<stdout>:[2025-10-12 21:08:22 TP0] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1201, 
[1,0]<stdout>:[2025-10-12 21:08:22 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1200, 
[1,0]<stdout>:[2025-10-12 21:08:22 TP0] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1199, 
[1,0]<stdout>:[2025-10-12 21:08:23 TP0] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 6, token usage: 0.13, #running-req: 47, #queue-req: 1198, 
[1,0]<stdout>:[2025-10-12 21:08:23 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 8, token usage: 0.13, #running-req: 47, #queue-req: 1197, 
[1,0]<stdout>:[2025-10-12 21:08:23 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1196, 
[1,0]<stdout>:[2025-10-12 21:08:23 TP0] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1195, 
[1,0]<stdout>:[2025-10-12 21:08:24 TP0] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1194, 
[1,0]<stdout>:[2025-10-12 21:08:24 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1193, 
[1,0]<stdout>:[2025-10-12 21:08:24 TP0] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 1192, 
[1,0]<stdout>:[2025-10-12 21:08:25 TP0] Prefill batch. #new-seq: 2, #new-token: 1139, #cached-token: 6, token usage: 0.12, #running-req: 46, #queue-req: 1190, 
[1,0]<stdout>:[2025-10-12 21:08:25 TP0] Decode batch. #running-req: 48, #token: 31515, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 535.46, #queue-req: 1190, 
[1,0]<stdout>:[2025-10-12 21:08:25 TP0] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1189, 
[1,0]<stdout>:[2025-10-12 21:08:26 TP0] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 1188, 
[1,0]<stdout>:[2025-10-12 21:08:26 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1187, 
[1,0]<stdout>:[2025-10-12 21:08:26 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1186, 
[1,0]<stdout>:[2025-10-12 21:08:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1538, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1185, 
[1,0]<stdout>:[2025-10-12 21:08:27 TP0] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 2, token usage: 0.14, #running-req: 47, #queue-req: 1184, 
[1,0]<stdout>:[2025-10-12 21:08:27 TP0] Decode batch. #running-req: 48, #token: 34634, token usage: 0.14, accept len: 1.00, cuda graph: True, gen throughput (token/s): 797.38, #queue-req: 1184, 
[1,0]<stdout>:[2025-10-12 21:08:27 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 11, token usage: 0.14, #running-req: 47, #queue-req: 1183, 
[1,0]<stdout>:[2025-10-12 21:08:28 TP0] Prefill batch. #new-seq: 2, #new-token: 27, #cached-token: 5, token usage: 0.13, #running-req: 46, #queue-req: 1181, 
[1,0]<stdout>:[2025-10-12 21:08:28 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1180, 
[1,0]<stdout>:[2025-10-12 21:08:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1474, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1179, 
[1,0]<stdout>:[2025-10-12 21:08:29 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1178, 
[1,0]<stdout>:[2025-10-12 21:08:29 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 8, token usage: 0.14, #running-req: 47, #queue-req: 1177, 
[1,0]<stdout>:[2025-10-12 21:08:29 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 1176, 
[1,0]<stdout>:[2025-10-12 21:08:30 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1175, 
[1,0]<stdout>:[2025-10-12 21:08:30 TP0] Decode batch. #running-req: 48, #token: 31763, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 692.73, #queue-req: 1175, 
[1,0]<stdout>:[2025-10-12 21:08:30 TP0] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1174, 
[1,0]<stdout>:[2025-10-12 21:08:31 TP0] Prefill batch. #new-seq: 2, #new-token: 12, #cached-token: 6, token usage: 0.13, #running-req: 46, #queue-req: 1172, 
[1,0]<stdout>:[2025-10-12 21:08:31 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 1171, 
[1,0]<stdout>:[2025-10-12 21:08:31 TP0] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 1170, 
[1,0]<stdout>:[2025-10-12 21:08:32 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 4, token usage: 0.13, #running-req: 47, #queue-req: 1169, 
[1,0]<stdout>:[2025-10-12 21:08:32 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1168, 
[1,0]<stdout>:[2025-10-12 21:08:32 TP0] Prefill batch. #new-seq: 1, #new-token: 691, #cached-token: 6, token usage: 0.13, #running-req: 47, #queue-req: 1167, 
[1,0]<stdout>:[2025-10-12 21:08:33 TP0] Decode batch. #running-req: 48, #token: 32241, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 742.15, #queue-req: 1167, 
[1,0]<stdout>:[2025-10-12 21:08:33 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 1166, 
[1,0]<stdout>:[2025-10-12 21:08:33 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1165, 
[1,0]<stdout>:[2025-10-12 21:08:33 TP0] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 1164, 
[1,0]<stdout>:[2025-10-12 21:08:34 TP0] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 1163, 
[1,0]<stdout>:[2025-10-12 21:08:34 TP0] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1162, 
[1,0]<stdout>:[2025-10-12 21:08:34 TP0] Prefill batch. #new-seq: 1, #new-token: 2423, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1161, 
[1,0]<stdout>:[2025-10-12 21:08:35 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1160, 
[1,0]<stdout>:[2025-10-12 21:08:35 TP0] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1159, 
[1,0]<stdout>:[2025-10-12 21:08:35 TP0] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1158, 
[1,0]<stdout>:[2025-10-12 21:08:36 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1157, 
[1,0]<stdout>:[2025-10-12 21:08:36 TP0] Decode batch. #running-req: 48, #token: 26782, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 600.80, #queue-req: 1157, 
[1,0]<stdout>:[2025-10-12 21:08:36 TP0] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1156, 
[1,0]<stdout>:[2025-10-12 21:08:36 TP0] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 8, token usage: 0.10, #running-req: 47, #queue-req: 1155, 
[1,0]<stdout>:[2025-10-12 21:08:36 TP0] Prefill batch. #new-seq: 1, #new-token: 844, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1154, 
[1,0]<stdout>:[2025-10-12 21:08:37 TP0] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1153, 
[1,0]<stdout>:[2025-10-12 21:08:37 TP0] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1152, 
[1,0]<stdout>:[2025-10-12 21:08:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1151, 
[1,0]<stdout>:[2025-10-12 21:08:38 TP0] Prefill batch. #new-seq: 2, #new-token: 535, #cached-token: 11, token usage: 0.10, #running-req: 46, #queue-req: 1149, 
[1,0]<stdout>:[2025-10-12 21:08:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 393, token usage: 0.10, #running-req: 47, #queue-req: 1148, 
[1,0]<stdout>:[2025-10-12 21:08:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1734, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1147, 
[1,0]<stdout>:[2025-10-12 21:08:39 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1146, 
[1,0]<stdout>:[2025-10-12 21:08:39 TP0] Decode batch. #running-req: 47, #token: 27155, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 603.43, #queue-req: 1146, 
[1,0]<stdout>:[2025-10-12 21:08:39 TP0] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 7, token usage: 0.11, #running-req: 47, #queue-req: 1145, 
[1,0]<stdout>:[2025-10-12 21:08:39 TP0] Prefill batch. #new-seq: 2, #new-token: 189, #cached-token: 4, token usage: 0.11, #running-req: 46, #queue-req: 1143, 
[1,0]<stdout>:[2025-10-12 21:08:40 TP0] Prefill batch. #new-seq: 2, #new-token: 138, #cached-token: 2, token usage: 0.11, #running-req: 46, #queue-req: 1141, 
[1,0]<stdout>:[2025-10-12 21:08:40 TP0] Prefill batch. #new-seq: 2, #new-token: 636, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 1139, 
[1,0]<stdout>:[2025-10-12 21:08:40 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1138, 
[1,0]<stdout>:[2025-10-12 21:08:41 TP0] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1137, 
[1,0]<stdout>:[2025-10-12 21:08:41 TP0] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1136, 
[1,0]<stdout>:[2025-10-12 21:08:42 TP0] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1135, 
[1,0]<stdout>:[2025-10-12 21:08:42 TP0] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1134, 
[1,0]<stdout>:[2025-10-12 21:08:42 TP0] Decode batch. #running-req: 48, #token: 25119, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 631.93, #queue-req: 1134, 
[1,0]<stdout>:[2025-10-12 21:08:42 TP0] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1133, 
[1,0]<stdout>:[2025-10-12 21:08:43 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1132, 
[1,0]<stdout>:[2025-10-12 21:08:43 TP0] Prefill batch. #new-seq: 2, #new-token: 415, #cached-token: 11, token usage: 0.10, #running-req: 46, #queue-req: 1130, 
[1,0]<stdout>:[2025-10-12 21:08:43 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 1129, 
[1,0]<stdout>:[2025-10-12 21:08:44 TP0] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1128, 
[1,0]<stdout>:[2025-10-12 21:08:44 TP0] Prefill batch. #new-seq: 2, #new-token: 325, #cached-token: 4, token usage: 0.10, #running-req: 46, #queue-req: 1126, 
[1,0]<stdout>:[2025-10-12 21:08:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 359, token usage: 0.10, #running-req: 47, #queue-req: 1125, 
[1,0]<stdout>:[2025-10-12 21:08:45 TP0] Decode batch. #running-req: 48, #token: 25146, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 724.41, #queue-req: 1125, 
[1,0]<stdout>:[2025-10-12 21:08:45 TP0] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1124, 
[1,0]<stdout>:[2025-10-12 21:08:45 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1123, 
[1,0]<stdout>:[2025-10-12 21:08:45 TP0] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 1122, 
[1,0]<stdout>:[2025-10-12 21:08:46 TP0] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1121, 
[1,0]<stdout>:[2025-10-12 21:08:46 TP0] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1120, 
[1,0]<stdout>:[2025-10-12 21:08:46 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1119, 
[1,0]<stdout>:[2025-10-12 21:08:47 TP0] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1118, 
[1,0]<stdout>:[2025-10-12 21:08:47 TP0] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1117, 
[1,0]<stdout>:[2025-10-12 21:08:47 TP0] Decode batch. #running-req: 48, #token: 21830, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 682.01, #queue-req: 1117, 
[1,0]<stdout>:[2025-10-12 21:08:48 TP0] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1116, 
[1,0]<stdout>:[2025-10-12 21:08:48 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1115, 
[1,0]<stdout>:[2025-10-12 21:08:48 TP0] Prefill batch. #new-seq: 2, #new-token: 577, #cached-token: 8, token usage: 0.08, #running-req: 46, #queue-req: 1113, 
[1,0]<stdout>:[2025-10-12 21:08:49 TP0] Prefill batch. #new-seq: 1, #new-token: 986, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1112, 
[1,0]<stdout>:[2025-10-12 21:08:49 TP0] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1111, 
[1,0]<stdout>:[2025-10-12 21:08:49 TP0] Prefill batch. #new-seq: 1, #new-token: 738, #cached-token: 8, token usage: 0.08, #running-req: 47, #queue-req: 1110, 
[1,0]<stdout>:[2025-10-12 21:08:49 TP0] Prefill batch. #new-seq: 3, #new-token: 702, #cached-token: 9, token usage: 0.09, #running-req: 45, #queue-req: 1107, 
[1,0]<stdout>:[2025-10-12 21:08:50 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1106, 
[1,0]<stdout>:[2025-10-12 21:08:50 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1105, 
[1,0]<stdout>:[2025-10-12 21:08:50 TP0] Decode batch. #running-req: 48, #token: 22807, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 640.03, #queue-req: 1105, 
[1,0]<stdout>:[2025-10-12 21:08:51 TP0] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1104, 
[1,0]<stdout>:[2025-10-12 21:08:51 TP0] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1103, 
[1,0]<stdout>:[2025-10-12 21:08:52 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1102, 
[1,0]<stdout>:[2025-10-12 21:08:52 TP0] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1101, 
[1,0]<stdout>:[2025-10-12 21:08:52 TP0] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 1100, 
[1,0]<stdout>:[2025-10-12 21:08:53 TP0] Decode batch. #running-req: 47, #token: 20439, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 876.34, #queue-req: 1100, 
[1,0]<stdout>:[2025-10-12 21:08:53 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1099, 
[1,0]<stdout>:[2025-10-12 21:08:54 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1098, 
[1,0]<stdout>:[2025-10-12 21:08:54 TP0] Decode batch. #running-req: 48, #token: 20411, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1222.05, #queue-req: 1098, 
[1,0]<stdout>:[2025-10-12 21:08:54 TP0] Prefill batch. #new-seq: 2, #new-token: 21, #cached-token: 2, token usage: 0.08, #running-req: 46, #queue-req: 1096, 
[1,0]<stdout>:[2025-10-12 21:08:55 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 1095, 
[1,0]<stdout>:[2025-10-12 21:08:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 376, token usage: 0.08, #running-req: 47, #queue-req: 1094, 
[1,0]<stdout>:[2025-10-12 21:08:55 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1093, 
[1,0]<stdout>:[2025-10-12 21:08:55 TP0] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 1092, 
[1,0]<stdout>:[2025-10-12 21:08:56 TP0] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 1091, 
[1,0]<stdout>:[2025-10-12 21:08:56 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 15, token usage: 0.07, #running-req: 46, #queue-req: 1089, 
[1,0]<stdout>:[2025-10-12 21:08:56 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1088, 
[1,0]<stdout>:[2025-10-12 21:08:57 TP0] Decode batch. #running-req: 48, #token: 19978, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 696.63, #queue-req: 1088, 
[1,0]<stdout>:[2025-10-12 21:08:57 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1087, 
[1,0]<stdout>:[2025-10-12 21:08:57 TP0] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1086, 
[1,0]<stdout>:[2025-10-12 21:08:58 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1085, 
[1,0]<stdout>:[2025-10-12 21:08:58 TP0] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 8, token usage: 0.08, #running-req: 47, #queue-req: 1084, 
[1,0]<stdout>:[2025-10-12 21:08:59 TP0] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1083, 
[1,0]<stdout>:[2025-10-12 21:08:59 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1082, 
[1,0]<stdout>:[2025-10-12 21:08:59 TP0] Decode batch. #running-req: 48, #token: 20810, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 807.93, #queue-req: 1082, 
[1,0]<stdout>:[2025-10-12 21:08:59 TP0] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 10, token usage: 0.08, #running-req: 47, #queue-req: 1081, 
[1,0]<stdout>:[2025-10-12 21:09:00 TP0] Prefill batch. #new-seq: 1, #new-token: 238, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 1080, 
[1,0]<stdout>:[2025-10-12 21:09:00 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 1079, 
[1,0]<stdout>:[2025-10-12 21:09:00 TP0] Prefill batch. #new-seq: 2, #new-token: 328, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 1077, 
[1,0]<stdout>:[2025-10-12 21:09:01 TP0] Prefill batch. #new-seq: 3, #new-token: 561, #cached-token: 8, token usage: 0.08, #running-req: 45, #queue-req: 1074, 
[1,0]<stdout>:[2025-10-12 21:09:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1427, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1073, 
[1,0]<stdout>:[2025-10-12 21:09:01 TP0] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1072, 
[1,0]<stdout>:[2025-10-12 21:09:02 TP0] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 1071, 
[1,0]<stdout>:[2025-10-12 21:09:02 TP0] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1070, 
[1,0]<stdout>:[2025-10-12 21:09:02 TP0] Decode batch. #running-req: 48, #token: 22085, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 631.20, #queue-req: 1070, 
[1,0]<stdout>:[2025-10-12 21:09:02 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1069, 
[1,0]<stdout>:[2025-10-12 21:09:03 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1068, 
[1,0]<stdout>:[2025-10-12 21:09:03 TP0] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1067, 
[1,0]<stdout>:[2025-10-12 21:09:03 TP0] Prefill batch. #new-seq: 2, #new-token: 625, #cached-token: 8, token usage: 0.09, #running-req: 46, #queue-req: 1065, 
[1,0]<stdout>:[2025-10-12 21:09:04 TP0] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1064, 
[1,0]<stdout>:[2025-10-12 21:09:04 TP0] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1063, 
[1,0]<stdout>:[2025-10-12 21:09:04 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1062, 
[1,0]<stdout>:[2025-10-12 21:09:04 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1061, 
[1,0]<stdout>:[2025-10-12 21:09:05 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1060, 
[1,0]<stdout>:[2025-10-12 21:09:05 TP0] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 1059, 
[1,0]<stdout>:[2025-10-12 21:09:06 TP0] Prefill batch. #new-seq: 2, #new-token: 583, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1057, 
[1,0]<stdout>:[2025-10-12 21:09:06 TP0] Decode batch. #running-req: 48, #token: 23063, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 563.83, #queue-req: 1057, 
[1,0]<stdout>:[2025-10-12 21:09:06 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1056, 
[1,0]<stdout>:[2025-10-12 21:09:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1055, 
[1,0]<stdout>:[2025-10-12 21:09:06 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1054, 
[1,0]<stdout>:[2025-10-12 21:09:07 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1053, 
[1,0]<stdout>:[2025-10-12 21:09:07 TP0] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 9, token usage: 0.09, #running-req: 47, #queue-req: 1052, 
[1,0]<stdout>:[2025-10-12 21:09:07 TP0] Prefill batch. #new-seq: 1, #new-token: 829, #cached-token: 10, token usage: 0.09, #running-req: 47, #queue-req: 1051, 
[1,0]<stdout>:[2025-10-12 21:09:08 TP0] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1050, 
[1,0]<stdout>:[2025-10-12 21:09:08 TP0] Decode batch. #running-req: 47, #token: 23441, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 745.64, #queue-req: 1050, 
[1,0]<stdout>:[2025-10-12 21:09:08 TP0] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1049, 
[1,0]<stdout>:[2025-10-12 21:09:09 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1048, 
[1,0]<stdout>:[2025-10-12 21:09:09 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1047, 
[1,0]<stdout>:[2025-10-12 21:09:09 TP0] Prefill batch. #new-seq: 2, #new-token: 388, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 1045, 
[1,0]<stdout>:[2025-10-12 21:09:10 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1044, 
[1,0]<stdout>:[2025-10-12 21:09:10 TP0] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1043, 
[1,0]<stdout>:[2025-10-12 21:09:10 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 1042, 
[1,0]<stdout>:[2025-10-12 21:09:11 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1041, 
[1,0]<stdout>:[2025-10-12 21:09:11 TP0] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1040, 
[1,0]<stdout>:[2025-10-12 21:09:11 TP0] Decode batch. #running-req: 47, #token: 22606, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 641.72, #queue-req: 1040, 
[1,0]<stdout>:[2025-10-12 21:09:11 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1039, 
[1,0]<stdout>:[2025-10-12 21:09:12 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1038, 
[1,0]<stdout>:[2025-10-12 21:09:12 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 1037, 
[1,0]<stdout>:[2025-10-12 21:09:12 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1036, 
[1,0]<stdout>:[2025-10-12 21:09:13 TP0] Prefill batch. #new-seq: 2, #new-token: 1018, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 1034, 
[1,0]<stdout>:[2025-10-12 21:09:13 TP0] Prefill batch. #new-seq: 2, #new-token: 336, #cached-token: 3, token usage: 0.09, #running-req: 46, #queue-req: 1032, 
[1,0]<stdout>:[2025-10-12 21:09:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 1031, 
[1,0]<stdout>:[2025-10-12 21:09:13 TP0] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1030, 
[1,0]<stdout>:[2025-10-12 21:09:14 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1029, 
[1,0]<stdout>:[2025-10-12 21:09:14 TP0] Decode batch. #running-req: 48, #token: 23701, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 654.04, #queue-req: 1029, 
[1,0]<stdout>:[2025-10-12 21:09:14 TP0] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 1028, 
[1,0]<stdout>:[2025-10-12 21:09:15 TP0] Prefill batch. #new-seq: 1, #new-token: 3215, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1027, 
[1,0]<stdout>:[2025-10-12 21:09:15 TP0] Prefill batch. #new-seq: 2, #new-token: 519, #cached-token: 7, token usage: 0.11, #running-req: 46, #queue-req: 1025, 
[1,0]<stdout>:[2025-10-12 21:09:15 TP0] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1024, 
[1,0]<stdout>:[2025-10-12 21:09:16 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1023, 
[1,0]<stdout>:[2025-10-12 21:09:16 TP0] Prefill batch. #new-seq: 3, #new-token: 925, #cached-token: 6, token usage: 0.11, #running-req: 45, #queue-req: 1020, 
[1,0]<stdout>:[2025-10-12 21:09:16 TP0] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1019, 
[1,0]<stdout>:[2025-10-12 21:09:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1018, 
[1,0]<stdout>:[2025-10-12 21:09:17 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1017, 
[1,0]<stdout>:[2025-10-12 21:09:17 TP0] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 1016, 
[1,0]<stdout>:[2025-10-12 21:09:17 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1015, 
[1,0]<stdout>:[2025-10-12 21:09:18 TP0] Decode batch. #running-req: 48, #token: 27646, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 564.14, #queue-req: 1015, 
[1,0]<stdout>:[2025-10-12 21:09:18 TP0] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1014, 
[1,0]<stdout>:[2025-10-12 21:09:18 TP0] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1013, 
[1,0]<stdout>:[2025-10-12 21:09:18 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1012, 
[1,0]<stdout>:[2025-10-12 21:09:19 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 1011, 
[1,0]<stdout>:[2025-10-12 21:09:19 TP0] Prefill batch. #new-seq: 2, #new-token: 2516, #cached-token: 5, token usage: 0.10, #running-req: 46, #queue-req: 1009, 
[1,0]<stdout>:[2025-10-12 21:09:19 TP0] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1008, 
[1,0]<stdout>:[2025-10-12 21:09:19 TP0] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 1007, 
[1,0]<stdout>:[2025-10-12 21:09:20 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 1006, 
[1,0]<stdout>:[2025-10-12 21:09:20 TP0] Prefill batch. #new-seq: 2, #new-token: 641, #cached-token: 8, token usage: 0.10, #running-req: 46, #queue-req: 1004, 
[1,0]<stdout>:[2025-10-12 21:09:20 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1003, 
[1,0]<stdout>:[2025-10-12 21:09:21 TP0] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1002, 
[1,0]<stdout>:[2025-10-12 21:09:21 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 1001, 
[1,0]<stdout>:[2025-10-12 21:09:21 TP0] Decode batch. #running-req: 48, #token: 27382, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 527.22, #queue-req: 1001, 
[1,0]<stdout>:[2025-10-12 21:09:21 TP0] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 1000, 
[1,0]<stdout>:[2025-10-12 21:09:22 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 999, 
[1,0]<stdout>:[2025-10-12 21:09:22 TP0] Prefill batch. #new-seq: 1, #new-token: 779, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 998, 
[1,0]<stdout>:[2025-10-12 21:09:22 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 997, 
[1,0]<stdout>:[2025-10-12 21:09:23 TP0] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 996, 
[1,0]<stdout>:[2025-10-12 21:09:23 TP0] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 995, 
[1,0]<stdout>:[2025-10-12 21:09:23 TP0] Prefill batch. #new-seq: 2, #new-token: 2881, #cached-token: 9, token usage: 0.11, #running-req: 46, #queue-req: 993, 
[1,0]<stdout>:[2025-10-12 21:09:24 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 992, 
[1,0]<stdout>:[2025-10-12 21:09:24 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 991, 
[1,0]<stdout>:[2025-10-12 21:09:24 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 990, 
[1,0]<stdout>:[2025-10-12 21:09:24 TP0] Decode batch. #running-req: 48, #token: 27553, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 641.98, #queue-req: 990, 
[1,0]<stdout>:[2025-10-12 21:09:24 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 989, 
[1,0]<stdout>:[2025-10-12 21:09:24 TP0] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 988, 
[1,0]<stdout>:[2025-10-12 21:09:25 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 987, 
[1,0]<stdout>:[2025-10-12 21:09:25 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 986, 
[1,0]<stdout>:[2025-10-12 21:09:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 985, 
[1,0]<stdout>:[2025-10-12 21:09:25 TP0] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 984, 
[1,0]<stdout>:[2025-10-12 21:09:26 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 983, 
[1,0]<stdout>:[2025-10-12 21:09:26 TP0] Decode batch. #running-req: 48, #token: 27853, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 927.38, #queue-req: 983, 
[1,0]<stdout>:[2025-10-12 21:09:26 TP0] Prefill batch. #new-seq: 1, #new-token: 661, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 982, 
[1,0]<stdout>:[2025-10-12 21:09:27 TP0] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 7, token usage: 0.11, #running-req: 47, #queue-req: 981, 
[1,0]<stdout>:[2025-10-12 21:09:27 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 980, 
[1,0]<stdout>:[2025-10-12 21:09:27 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 979, 
[1,0]<stdout>:[2025-10-12 21:09:27 TP0] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 978, 
[1,0]<stdout>:[2025-10-12 21:09:27 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 977, 
[1,0]<stdout>:[2025-10-12 21:09:28 TP0] Prefill batch. #new-seq: 1, #new-token: 2428, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 976, 
[1,0]<stdout>:[2025-10-12 21:09:28 TP0] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 975, 
[1,0]<stdout>:[2025-10-12 21:09:28 TP0] Prefill batch. #new-seq: 1, #new-token: 480, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 974, 
[1,0]<stdout>:[2025-10-12 21:09:28 TP0] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 973, 
[1,0]<stdout>:[2025-10-12 21:09:28 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 972, 
[1,0]<stdout>:[2025-10-12 21:09:29 TP0] Prefill batch. #new-seq: 2, #new-token: 315, #cached-token: 4, token usage: 0.11, #running-req: 46, #queue-req: 970, 
[1,0]<stdout>:[2025-10-12 21:09:29 TP0] Decode batch. #running-req: 48, #token: 28818, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 693.04, #queue-req: 970, 
[1,0]<stdout>:[2025-10-12 21:09:29 TP0] Prefill batch. #new-seq: 2, #new-token: 809, #cached-token: 6, token usage: 0.11, #running-req: 46, #queue-req: 968, 
[1,0]<stdout>:[2025-10-12 21:09:29 TP0] Prefill batch. #new-seq: 2, #new-token: 26, #cached-token: 7, token usage: 0.11, #running-req: 46, #queue-req: 966, 
[1,0]<stdout>:[2025-10-12 21:09:30 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 965, 
[1,0]<stdout>:[2025-10-12 21:09:30 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 964, 
[1,0]<stdout>:[2025-10-12 21:09:30 TP0] Prefill batch. #new-seq: 1, #new-token: 2032, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 963, 
[1,0]<stdout>:[2025-10-12 21:09:31 TP0] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 962, 
[1,0]<stdout>:[2025-10-12 21:09:31 TP0] Prefill batch. #new-seq: 1, #new-token: 619, #cached-token: 8, token usage: 0.12, #running-req: 47, #queue-req: 961, 
[1,0]<stdout>:[2025-10-12 21:09:31 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 960, 
[1,0]<stdout>:[2025-10-12 21:09:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1101, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 959, 
[1,0]<stdout>:[2025-10-12 21:09:31 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 958, 
[1,0]<stdout>:[2025-10-12 21:09:31 TP0] Decode batch. #running-req: 48, #token: 30143, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 764.75, #queue-req: 958, 
[1,0]<stdout>:[2025-10-12 21:09:32 TP0] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 957, 
[1,0]<stdout>:[2025-10-12 21:09:32 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 956, 
[1,0]<stdout>:[2025-10-12 21:09:32 TP0] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 955, 
[1,0]<stdout>:[2025-10-12 21:09:33 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 954, 
[1,0]<stdout>:[2025-10-12 21:09:33 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 953, 
[1,0]<stdout>:[2025-10-12 21:09:33 TP0] Decode batch. #running-req: 48, #token: 30986, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1046.86, #queue-req: 953, 
[1,0]<stdout>:[2025-10-12 21:09:34 TP0] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 952, 
[1,0]<stdout>:[2025-10-12 21:09:34 TP0] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 951, 
[1,0]<stdout>:[2025-10-12 21:09:34 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 950, 
[1,0]<stdout>:[2025-10-12 21:09:34 TP0] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 949, 
[1,0]<stdout>:[2025-10-12 21:09:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1424, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 948, 
[1,0]<stdout>:[2025-10-12 21:09:35 TP0] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 947, 
[1,0]<stdout>:[2025-10-12 21:09:35 TP0] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 946, 
[1,0]<stdout>:[2025-10-12 21:09:35 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 945, 
[1,0]<stdout>:[2025-10-12 21:09:35 TP0] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 944, 
[1,0]<stdout>:[2025-10-12 21:09:36 TP0] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 4, token usage: 0.13, #running-req: 47, #queue-req: 943, 
[1,0]<stdout>:[2025-10-12 21:09:36 TP0] Decode batch. #running-req: 48, #token: 33265, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 753.50, #queue-req: 943, 
[1,0]<stdout>:[2025-10-12 21:09:36 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 19, token usage: 0.13, #running-req: 47, #queue-req: 942, 
[1,0]<stdout>:[2025-10-12 21:09:37 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 941, 
[1,0]<stdout>:[2025-10-12 21:09:37 TP0] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 940, 
[1,0]<stdout>:[2025-10-12 21:09:37 TP0] Prefill batch. #new-seq: 1, #new-token: 564, #cached-token: 3, token usage: 0.14, #running-req: 47, #queue-req: 939, 
[1,0]<stdout>:[2025-10-12 21:09:38 TP0] Decode batch. #running-req: 48, #token: 35176, token usage: 0.14, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1116.33, #queue-req: 939, 
[1,0]<stdout>:[2025-10-12 21:09:38 TP0] Prefill batch. #new-seq: 2, #new-token: 17, #cached-token: 3, token usage: 0.14, #running-req: 46, #queue-req: 937, 
[1,0]<stdout>:[2025-10-12 21:09:38 TP0] Prefill batch. #new-seq: 2, #new-token: 1448, #cached-token: 3, token usage: 0.13, #running-req: 46, #queue-req: 935, 
[1,0]<stdout>:[2025-10-12 21:09:38 TP0] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 3, token usage: 0.14, #running-req: 47, #queue-req: 934, 
[1,0]<stdout>:[2025-10-12 21:09:39 TP0] Prefill batch. #new-seq: 2, #new-token: 398, #cached-token: 4, token usage: 0.13, #running-req: 46, #queue-req: 932, 
[1,0]<stdout>:[2025-10-12 21:09:39 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 931, 
[1,0]<stdout>:[2025-10-12 21:09:39 TP0] Prefill batch. #new-seq: 1, #new-token: 419, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 930, 
[1,0]<stdout>:[2025-10-12 21:09:39 TP0] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 929, 
[1,0]<stdout>:[2025-10-12 21:09:39 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 928, 
[1,0]<stdout>:[2025-10-12 21:09:40 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 927, 
[1,0]<stdout>:[2025-10-12 21:09:40 TP0] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 926, 
[1,0]<stdout>:[2025-10-12 21:09:40 TP0] Decode batch. #running-req: 48, #token: 32290, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 763.85, #queue-req: 926, 
[1,0]<stdout>:[2025-10-12 21:09:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1324, #cached-token: 12, token usage: 0.13, #running-req: 47, #queue-req: 925, 
[1,0]<stdout>:[2025-10-12 21:09:41 TP0] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 924, 
[1,0]<stdout>:[2025-10-12 21:09:41 TP0] Prefill batch. #new-seq: 2, #new-token: 153, #cached-token: 4, token usage: 0.13, #running-req: 46, #queue-req: 922, 
[1,0]<stdout>:[2025-10-12 21:09:41 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 921, 
[1,0]<stdout>:[2025-10-12 21:09:41 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 920, 
[1,0]<stdout>:[2025-10-12 21:09:42 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 919, 
[1,0]<stdout>:[2025-10-12 21:09:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1779, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 918, 
[1,0]<stdout>:[2025-10-12 21:09:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1558, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 917, 
[1,0]<stdout>:[2025-10-12 21:09:42 TP0] Prefill batch. #new-seq: 1, #new-token: 597, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 916, 
[1,0]<stdout>:[2025-10-12 21:09:42 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 915, 
[1,0]<stdout>:[2025-10-12 21:09:43 TP0] Decode batch. #running-req: 48, #token: 31891, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 765.21, #queue-req: 915, 
[1,0]<stdout>:[2025-10-12 21:09:43 TP0] Prefill batch. #new-seq: 1, #new-token: 812, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 914, 
[1,0]<stdout>:[2025-10-12 21:09:43 TP0] Prefill batch. #new-seq: 2, #new-token: 3422, #cached-token: 6, token usage: 0.12, #running-req: 46, #queue-req: 912, 
[1,0]<stdout>:[2025-10-12 21:09:43 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.14, #running-req: 47, #queue-req: 911, 
[1,0]<stdout>:[2025-10-12 21:09:43 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 1, token usage: 0.14, #running-req: 47, #queue-req: 910, 
[1,0]<stdout>:[2025-10-12 21:09:44 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 909, 
[1,0]<stdout>:[2025-10-12 21:09:44 TP0] Prefill batch. #new-seq: 1, #new-token: 727, #cached-token: 3, token usage: 0.13, #running-req: 47, #queue-req: 908, 
[1,0]<stdout>:[2025-10-12 21:09:44 TP0] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 2, token usage: 0.13, #running-req: 47, #queue-req: 907, 
[1,0]<stdout>:[2025-10-12 21:09:44 TP0] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 906, 
[1,0]<stdout>:[2025-10-12 21:09:44 TP0] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 905, 
[1,0]<stdout>:[2025-10-12 21:09:45 TP0] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 904, 
[1,0]<stdout>:[2025-10-12 21:09:45 TP0] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 903, 
[1,0]<stdout>:[2025-10-12 21:09:45 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 4, token usage: 0.13, #running-req: 47, #queue-req: 902, 
[1,0]<stdout>:[2025-10-12 21:09:45 TP0] Decode batch. #running-req: 47, #token: 31618, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 672.98, #queue-req: 902, 
[1,0]<stdout>:[2025-10-12 21:09:45 TP0] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 5, token usage: 0.13, #running-req: 47, #queue-req: 901, 
[1,0]<stdout>:[2025-10-12 21:09:46 TP0] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 1, token usage: 0.13, #running-req: 47, #queue-req: 900, 
[1,0]<stdout>:[2025-10-12 21:09:46 TP0] Prefill batch. #new-seq: 2, #new-token: 24, #cached-token: 3, token usage: 0.13, #running-req: 46, #queue-req: 898, 
[1,0]<stdout>:[2025-10-12 21:09:46 TP0] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 897, 
[1,0]<stdout>:[2025-10-12 21:09:46 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 896, 
[1,0]<stdout>:[2025-10-12 21:09:46 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 895, 
[1,0]<stdout>:[2025-10-12 21:09:47 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 894, 
[1,0]<stdout>:[2025-10-12 21:09:47 TP0] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 893, 
[1,0]<stdout>:[2025-10-12 21:09:47 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 892, 
[1,0]<stdout>:[2025-10-12 21:09:47 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 891, 
[1,0]<stdout>:[2025-10-12 21:09:48 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 890, 
[1,0]<stdout>:[2025-10-12 21:09:48 TP0] Decode batch. #running-req: 47, #token: 27170, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 690.97, #queue-req: 890, 
[1,0]<stdout>:[2025-10-12 21:09:48 TP0] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 889, 
[1,0]<stdout>:[2025-10-12 21:09:48 TP0] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 888, 
[1,0]<stdout>:[2025-10-12 21:09:49 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 887, 
[1,0]<stdout>:[2025-10-12 21:09:49 TP0] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 886, 
[1,0]<stdout>:[2025-10-12 21:09:50 TP0] Prefill batch. #new-seq: 2, #new-token: 1105, #cached-token: 5, token usage: 0.11, #running-req: 46, #queue-req: 884, 
[1,0]<stdout>:[2025-10-12 21:09:50 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 883, 
[1,0]<stdout>:[2025-10-12 21:09:50 TP0] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 6, token usage: 0.11, #running-req: 47, #queue-req: 882, 
[1,0]<stdout>:[2025-10-12 21:09:51 TP0] Decode batch. #running-req: 48, #token: 28010, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 743.59, #queue-req: 882, 
[1,0]<stdout>:[2025-10-12 21:09:51 TP0] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 6, token usage: 0.11, #running-req: 47, #queue-req: 881, 
[1,0]<stdout>:[2025-10-12 21:09:51 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 880, 
[1,0]<stdout>:[2025-10-12 21:09:52 TP0] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 879, 
[1,0]<stdout>:[2025-10-12 21:09:52 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 878, 
[1,0]<stdout>:[2025-10-12 21:09:53 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 877, 
[1,0]<stdout>:[2025-10-12 21:09:53 TP0] Decode batch. #running-req: 48, #token: 26983, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 877.61, #queue-req: 877, 
[1,0]<stdout>:[2025-10-12 21:09:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1080, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 876, 
[1,0]<stdout>:[2025-10-12 21:09:53 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 875, 
[1,0]<stdout>:[2025-10-12 21:09:54 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 874, 
[1,0]<stdout>:[2025-10-12 21:09:54 TP0] Prefill batch. #new-seq: 2, #new-token: 3992, #cached-token: 5, token usage: 0.10, #running-req: 46, #queue-req: 872, 
[1,0]<stdout>:[2025-10-12 21:09:54 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 871, 
[1,0]<stdout>:[2025-10-12 21:09:55 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 870, 
[1,0]<stdout>:[2025-10-12 21:09:55 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 869, 
[1,0]<stdout>:[2025-10-12 21:09:55 TP0] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 868, 
[1,0]<stdout>:[2025-10-12 21:09:56 TP0] Decode batch. #running-req: 48, #token: 26724, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 685.30, #queue-req: 868, 
[1,0]<stdout>:[2025-10-12 21:09:56 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 867, 
[1,0]<stdout>:[2025-10-12 21:09:57 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 866, 
[1,0]<stdout>:[2025-10-12 21:09:57 TP0] Decode batch. #running-req: 48, #token: 27722, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1225.76, #queue-req: 866, 
[1,0]<stdout>:[2025-10-12 21:09:57 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 865, 
[1,0]<stdout>:[2025-10-12 21:09:58 TP0] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 864, 
[1,0]<stdout>:[2025-10-12 21:09:58 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 863, 
[1,0]<stdout>:[2025-10-12 21:09:58 TP0] Prefill batch. #new-seq: 2, #new-token: 812, #cached-token: 12, token usage: 0.11, #running-req: 46, #queue-req: 861, 
[1,0]<stdout>:[2025-10-12 21:09:59 TP0] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 860, 
[1,0]<stdout>:[2025-10-12 21:09:59 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 859, 
[1,0]<stdout>:[2025-10-12 21:09:59 TP0] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 858, 
[1,0]<stdout>:[2025-10-12 21:10:00 TP0] Decode batch. #running-req: 48, #token: 29057, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 743.86, #queue-req: 858, 
[1,0]<stdout>:[2025-10-12 21:10:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 857, 
[1,0]<stdout>:[2025-10-12 21:10:00 TP0] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 5, token usage: 0.11, #running-req: 47, #queue-req: 856, 
[1,0]<stdout>:[2025-10-12 21:10:00 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 855, 
[1,0]<stdout>:[2025-10-12 21:10:01 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 854, 
[1,0]<stdout>:[2025-10-12 21:10:01 TP0] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 853, 
[1,0]<stdout>:[2025-10-12 21:10:01 TP0] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 852, 
[1,0]<stdout>:[2025-10-12 21:10:02 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 851, 
[1,0]<stdout>:[2025-10-12 21:10:02 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 850, 
[1,0]<stdout>:[2025-10-12 21:10:02 TP0] Prefill batch. #new-seq: 2, #new-token: 528, #cached-token: 5, token usage: 0.12, #running-req: 46, #queue-req: 848, 
[1,0]<stdout>:[2025-10-12 21:10:03 TP0] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 847, 
[1,0]<stdout>:[2025-10-12 21:10:03 TP0] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 846, 
[1,0]<stdout>:[2025-10-12 21:10:03 TP0] Decode batch. #running-req: 48, #token: 29859, token usage: 0.12, accept len: 1.00, cuda graph: True, gen throughput (token/s): 549.92, #queue-req: 846, 
[1,0]<stdout>:[2025-10-12 21:10:03 TP0] Prefill batch. #new-seq: 1, #new-token: 674, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 845, 
[1,0]<stdout>:[2025-10-12 21:10:04 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 844, 
[1,0]<stdout>:[2025-10-12 21:10:04 TP0] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 5, token usage: 0.12, #running-req: 47, #queue-req: 843, 
[1,0]<stdout>:[2025-10-12 21:10:04 TP0] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 842, 
[1,0]<stdout>:[2025-10-12 21:10:05 TP0] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 841, 
[1,0]<stdout>:[2025-10-12 21:10:05 TP0] Prefill batch. #new-seq: 1, #new-token: 871, #cached-token: 7, token usage: 0.11, #running-req: 47, #queue-req: 840, 
[1,0]<stdout>:[2025-10-12 21:10:05 TP0] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 839, 
[1,0]<stdout>:[2025-10-12 21:10:05 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 838, 
[1,0]<stdout>:[2025-10-12 21:10:06 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 837, 
[1,0]<stdout>:[2025-10-12 21:10:06 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 836, 
[1,0]<stdout>:[2025-10-12 21:10:07 TP0] Decode batch. #running-req: 48, #token: 27928, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 583.62, #queue-req: 836, 
[1,0]<stdout>:[2025-10-12 21:10:07 TP0] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 835, 
[1,0]<stdout>:[2025-10-12 21:10:07 TP0] Prefill batch. #new-seq: 1, #new-token: 984, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 834, 
[1,0]<stdout>:[2025-10-12 21:10:07 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 833, 
[1,0]<stdout>:[2025-10-12 21:10:08 TP0] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 832, 
[1,0]<stdout>:[2025-10-12 21:10:08 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 831, 
[1,0]<stdout>:[2025-10-12 21:10:08 TP0] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 830, 
[1,0]<stdout>:[2025-10-12 21:10:08 TP0] Prefill batch. #new-seq: 2, #new-token: 485, #cached-token: 4, token usage: 0.11, #running-req: 46, #queue-req: 828, 
[1,0]<stdout>:[2025-10-12 21:10:09 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 827, 
[1,0]<stdout>:[2025-10-12 21:10:09 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 826, 
[1,0]<stdout>:[2025-10-12 21:10:09 TP0] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 825, 
[1,0]<stdout>:[2025-10-12 21:10:10 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 824, 
[1,0]<stdout>:[2025-10-12 21:10:10 TP0] Decode batch. #running-req: 48, #token: 26560, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 573.83, #queue-req: 824, 
[1,0]<stdout>:[2025-10-12 21:10:10 TP0] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 823, 
[1,0]<stdout>:[2025-10-12 21:10:10 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 822, 
[1,0]<stdout>:[2025-10-12 21:10:11 TP0] Prefill batch. #new-seq: 1, #new-token: 840, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 821, 
[1,0]<stdout>:[2025-10-12 21:10:11 TP0] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 820, 
[1,0]<stdout>:[2025-10-12 21:10:11 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 819, 
[1,0]<stdout>:[2025-10-12 21:10:12 TP0] Prefill batch. #new-seq: 2, #new-token: 964, #cached-token: 4, token usage: 0.10, #running-req: 46, #queue-req: 817, 
[1,0]<stdout>:[2025-10-12 21:10:12 TP0] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 816, 
[1,0]<stdout>:[2025-10-12 21:10:12 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 815, 
[1,0]<stdout>:[2025-10-12 21:10:13 TP0] Prefill batch. #new-seq: 1, #new-token: 798, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 814, 
[1,0]<stdout>:[2025-10-12 21:10:13 TP0] Decode batch. #running-req: 46, #token: 23247, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 635.63, #queue-req: 814, 
[1,0]<stdout>:[2025-10-12 21:10:13 TP0] Prefill batch. #new-seq: 2, #new-token: 805, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 812, 
[1,0]<stdout>:[2025-10-12 21:10:13 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 811, 
[1,0]<stdout>:[2025-10-12 21:10:13 TP0] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 810, 
[1,0]<stdout>:[2025-10-12 21:10:14 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 809, 
[1,0]<stdout>:[2025-10-12 21:10:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 808, 
[1,0]<stdout>:[2025-10-12 21:10:15 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 807, 
[1,0]<stdout>:[2025-10-12 21:10:15 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 806, 
[1,0]<stdout>:[2025-10-12 21:10:15 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 805, 
[1,0]<stdout>:[2025-10-12 21:10:16 TP0] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 21:10:16 TP0] Decode batch. #running-req: 48, #token: 25009, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 637.54, #queue-req: 804, 
[1,0]<stdout>:[2025-10-12 21:10:16 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 803, 
[1,0]<stdout>:[2025-10-12 21:10:16 TP0] Prefill batch. #new-seq: 1, #new-token: 723, #cached-token: 8, token usage: 0.10, #running-req: 47, #queue-req: 802, 
[1,0]<stdout>:[2025-10-12 21:10:17 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 801, 
[1,0]<stdout>:[2025-10-12 21:10:17 TP0] Prefill batch. #new-seq: 1, #new-token: 804, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 800, 
[1,0]<stdout>:[2025-10-12 21:10:18 TP0] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 9, token usage: 0.11, #running-req: 47, #queue-req: 799, 
[1,0]<stdout>:[2025-10-12 21:10:18 TP0] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 8, token usage: 0.11, #running-req: 47, #queue-req: 798, 
[1,0]<stdout>:[2025-10-12 21:10:18 TP0] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 797, 
[1,0]<stdout>:[2025-10-12 21:10:18 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 796, 
[1,0]<stdout>:[2025-10-12 21:10:19 TP0] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 795, 
[1,0]<stdout>:[2025-10-12 21:10:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 794, 
[1,0]<stdout>:[2025-10-12 21:10:19 TP0] Decode batch. #running-req: 48, #token: 26556, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 586.86, #queue-req: 794, 
[1,0]<stdout>:[2025-10-12 21:10:19 TP0] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 793, 
[1,0]<stdout>:[2025-10-12 21:10:20 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 792, 
[1,0]<stdout>:[2025-10-12 21:10:20 TP0] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 791, 
[1,0]<stdout>:[2025-10-12 21:10:20 TP0] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 790, 
[1,0]<stdout>:[2025-10-12 21:10:21 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 789, 
[1,0]<stdout>:[2025-10-12 21:10:21 TP0] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 788, 
[1,0]<stdout>:[2025-10-12 21:10:21 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 787, 
[1,0]<stdout>:[2025-10-12 21:10:21 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 786, 
[1,0]<stdout>:[2025-10-12 21:10:22 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 785, 
[1,0]<stdout>:[2025-10-12 21:10:22 TP0] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 784, 
[1,0]<stdout>:[2025-10-12 21:10:22 TP0] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 783, 
[1,0]<stdout>:[2025-10-12 21:10:23 TP0] Decode batch. #running-req: 48, #token: 25390, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 556.57, #queue-req: 783, 
[1,0]<stdout>:[2025-10-12 21:10:23 TP0] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 782, 
[1,0]<stdout>:[2025-10-12 21:10:23 TP0] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 781, 
[1,0]<stdout>:[2025-10-12 21:10:23 TP0] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 780, 
[1,0]<stdout>:[2025-10-12 21:10:24 TP0] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 779, 
[1,0]<stdout>:[2025-10-12 21:10:24 TP0] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 778, 
[1,0]<stdout>:[2025-10-12 21:10:25 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 777, 
[1,0]<stdout>:[2025-10-12 21:10:25 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 776, 
[1,0]<stdout>:[2025-10-12 21:10:25 TP0] Decode batch. #running-req: 48, #token: 25608, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 726.77, #queue-req: 776, 
[1,0]<stdout>:[2025-10-12 21:10:25 TP0] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 775, 
[1,0]<stdout>:[2025-10-12 21:10:26 TP0] Prefill batch. #new-seq: 2, #new-token: 384, #cached-token: 5, token usage: 0.10, #running-req: 46, #queue-req: 773, 
[1,0]<stdout>:[2025-10-12 21:10:26 TP0] Prefill batch. #new-seq: 1, #new-token: 640, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 772, 
[1,0]<stdout>:[2025-10-12 21:10:26 TP0] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 771, 
[1,0]<stdout>:[2025-10-12 21:10:26 TP0] Prefill batch. #new-seq: 2, #new-token: 151, #cached-token: 7, token usage: 0.10, #running-req: 46, #queue-req: 769, 
[1,0]<stdout>:[2025-10-12 21:10:27 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 768, 
[1,0]<stdout>:[2025-10-12 21:10:27 TP0] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 17, token usage: 0.10, #running-req: 47, #queue-req: 767, 
[1,0]<stdout>:[2025-10-12 21:10:28 TP0] Prefill batch. #new-seq: 1, #new-token: 421, #cached-token: 9, token usage: 0.10, #running-req: 47, #queue-req: 766, 
[1,0]<stdout>:[2025-10-12 21:10:28 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 765, 
[1,0]<stdout>:[2025-10-12 21:10:28 TP0] Prefill batch. #new-seq: 1, #new-token: 749, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 764, 
[1,0]<stdout>:[2025-10-12 21:10:28 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 763, 
[1,0]<stdout>:[2025-10-12 21:10:29 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 762, 
[1,0]<stdout>:[2025-10-12 21:10:29 TP0] Decode batch. #running-req: 47, #token: 25689, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 518.74, #queue-req: 762, 
[1,0]<stdout>:[2025-10-12 21:10:29 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 761, 
[1,0]<stdout>:[2025-10-12 21:10:29 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 760, 
[1,0]<stdout>:[2025-10-12 21:10:30 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 759, 
[1,0]<stdout>:[2025-10-12 21:10:30 TP0] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 758, 
[1,0]<stdout>:[2025-10-12 21:10:30 TP0] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 757, 
[1,0]<stdout>:[2025-10-12 21:10:31 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 756, 
[1,0]<stdout>:[2025-10-12 21:10:31 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 755, 
[1,0]<stdout>:[2025-10-12 21:10:32 TP0] Decode batch. #running-req: 48, #token: 26381, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 722.24, #queue-req: 755, 
[1,0]<stdout>:[2025-10-12 21:10:32 TP0] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 754, 
[1,0]<stdout>:[2025-10-12 21:10:32 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 753, 
[1,0]<stdout>:[2025-10-12 21:10:33 TP0] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 752, 
[1,0]<stdout>:[2025-10-12 21:10:33 TP0] Prefill batch. #new-seq: 1, #new-token: 650, #cached-token: 5, token usage: 0.11, #running-req: 47, #queue-req: 751, 
[1,0]<stdout>:[2025-10-12 21:10:33 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 750, 
[1,0]<stdout>:[2025-10-12 21:10:34 TP0] Prefill batch. #new-seq: 1, #new-token: 655, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 749, 
[1,0]<stdout>:[2025-10-12 21:10:34 TP0] Decode batch. #running-req: 48, #token: 25586, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 782.35, #queue-req: 749, 
[1,0]<stdout>:[2025-10-12 21:10:34 TP0] Prefill batch. #new-seq: 2, #new-token: 620, #cached-token: 10, token usage: 0.10, #running-req: 46, #queue-req: 747, 
[1,0]<stdout>:[2025-10-12 21:10:34 TP0] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 746, 
[1,0]<stdout>:[2025-10-12 21:10:35 TP0] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 745, 
[1,0]<stdout>:[2025-10-12 21:10:35 TP0] Prefill batch. #new-seq: 2, #new-token: 208, #cached-token: 7, token usage: 0.10, #running-req: 46, #queue-req: 743, 
[1,0]<stdout>:[2025-10-12 21:10:35 TP0] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 742, 
[1,0]<stdout>:[2025-10-12 21:10:35 TP0] Prefill batch. #new-seq: 1, #new-token: 456, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 741, 
[1,0]<stdout>:[2025-10-12 21:10:36 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 740, 
[1,0]<stdout>:[2025-10-12 21:10:36 TP0] Prefill batch. #new-seq: 2, #new-token: 78, #cached-token: 4, token usage: 0.10, #running-req: 46, #queue-req: 738, 
[1,0]<stdout>:[2025-10-12 21:10:36 TP0] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 737, 
[1,0]<stdout>:[2025-10-12 21:10:37 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 736, 
[1,0]<stdout>:[2025-10-12 21:10:37 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 735, 
[1,0]<stdout>:[2025-10-12 21:10:37 TP0] Prefill batch. #new-seq: 2, #new-token: 1182, #cached-token: 5, token usage: 0.10, #running-req: 46, #queue-req: 733, 
[1,0]<stdout>:[2025-10-12 21:10:38 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 732, 
[1,0]<stdout>:[2025-10-12 21:10:38 TP0] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 731, 
[1,0]<stdout>:[2025-10-12 21:10:38 TP0] Decode batch. #running-req: 47, #token: 25639, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 463.62, #queue-req: 731, 
[1,0]<stdout>:[2025-10-12 21:10:38 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 730, 
[1,0]<stdout>:[2025-10-12 21:10:38 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 729, 
[1,0]<stdout>:[2025-10-12 21:10:39 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 728, 
[1,0]<stdout>:[2025-10-12 21:10:39 TP0] Prefill batch. #new-seq: 1, #new-token: 689, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 727, 
[1,0]<stdout>:[2025-10-12 21:10:40 TP0] Prefill batch. #new-seq: 2, #new-token: 566, #cached-token: 8, token usage: 0.10, #running-req: 46, #queue-req: 725, 
[1,0]<stdout>:[2025-10-12 21:10:40 TP0] Prefill batch. #new-seq: 1, #new-token: 902, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 724, 
[1,0]<stdout>:[2025-10-12 21:10:41 TP0] Decode batch. #running-req: 48, #token: 27314, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 789.61, #queue-req: 724, 
[1,0]<stdout>:[2025-10-12 21:10:41 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 723, 
[1,0]<stdout>:[2025-10-12 21:10:41 TP0] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 722, 
[1,0]<stdout>:[2025-10-12 21:10:41 TP0] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 721, 
[1,0]<stdout>:[2025-10-12 21:10:42 TP0] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 720, 
[1,0]<stdout>:[2025-10-12 21:10:42 TP0] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 719, 
[1,0]<stdout>:[2025-10-12 21:10:42 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 718, 
[1,0]<stdout>:[2025-10-12 21:10:43 TP0] Decode batch. #running-req: 48, #token: 24936, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 785.65, #queue-req: 718, 
[1,0]<stdout>:[2025-10-12 21:10:43 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 10, token usage: 0.10, #running-req: 47, #queue-req: 717, 
[1,0]<stdout>:[2025-10-12 21:10:44 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 716, 
[1,0]<stdout>:[2025-10-12 21:10:44 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 715, 
[1,0]<stdout>:[2025-10-12 21:10:44 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 714, 
[1,0]<stdout>:[2025-10-12 21:10:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 713, 
[1,0]<stdout>:[2025-10-12 21:10:45 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 712, 
[1,0]<stdout>:[2025-10-12 21:10:45 TP0] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 711, 
[1,0]<stdout>:[2025-10-12 21:10:45 TP0] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 710, 
[1,0]<stdout>:[2025-10-12 21:10:45 TP0] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 709, 
[1,0]<stdout>:[2025-10-12 21:10:46 TP0] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 708, 
[1,0]<stdout>:[2025-10-12 21:10:46 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 707, 
[1,0]<stdout>:[2025-10-12 21:10:46 TP0] Decode batch. #running-req: 48, #token: 23836, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 556.70, #queue-req: 707, 
[1,0]<stdout>:[2025-10-12 21:10:46 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 706, 
[1,0]<stdout>:[2025-10-12 21:10:47 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 705, 
[1,0]<stdout>:[2025-10-12 21:10:47 TP0] Prefill batch. #new-seq: 1, #new-token: 830, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 704, 
[1,0]<stdout>:[2025-10-12 21:10:47 TP0] Prefill batch. #new-seq: 2, #new-token: 976, #cached-token: 3, token usage: 0.08, #running-req: 46, #queue-req: 702, 
[1,0]<stdout>:[2025-10-12 21:10:48 TP0] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 701, 
[1,0]<stdout>:[2025-10-12 21:10:48 TP0] Prefill batch. #new-seq: 2, #new-token: 664, #cached-token: 3, token usage: 0.08, #running-req: 46, #queue-req: 699, 
[1,0]<stdout>:[2025-10-12 21:10:49 TP0] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 698, 
[1,0]<stdout>:[2025-10-12 21:10:49 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 697, 
[1,0]<stdout>:[2025-10-12 21:10:49 TP0] Prefill batch. #new-seq: 2, #new-token: 1829, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 695, 
[1,0]<stdout>:[2025-10-12 21:10:49 TP0] Decode batch. #running-req: 48, #token: 20997, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 627.31, #queue-req: 695, 
[1,0]<stdout>:[2025-10-12 21:10:49 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 694, 
[1,0]<stdout>:[2025-10-12 21:10:50 TP0] Prefill batch. #new-seq: 1, #new-token: 4374, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 693, 
[1,0]<stdout>:[2025-10-12 21:10:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1811, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 692, 
[1,0]<stdout>:[2025-10-12 21:10:50 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 691, 
[1,0]<stdout>:[2025-10-12 21:10:51 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 690, 
[1,0]<stdout>:[2025-10-12 21:10:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1098, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 689, 
[1,0]<stdout>:[2025-10-12 21:10:51 TP0] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 688, 
[1,0]<stdout>:[2025-10-12 21:10:52 TP0] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 687, 
[1,0]<stdout>:[2025-10-12 21:10:52 TP0] Prefill batch. #new-seq: 1, #new-token: 814, #cached-token: 10, token usage: 0.09, #running-req: 47, #queue-req: 686, 
[1,0]<stdout>:[2025-10-12 21:10:52 TP0] Prefill batch. #new-seq: 1, #new-token: 454, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 685, 
[1,0]<stdout>:[2025-10-12 21:10:53 TP0] Decode batch. #running-req: 48, #token: 23430, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 583.80, #queue-req: 685, 
[1,0]<stdout>:[2025-10-12 21:10:53 TP0] Prefill batch. #new-seq: 1, #new-token: 2073, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 684, 
[1,0]<stdout>:[2025-10-12 21:10:53 TP0] Prefill batch. #new-seq: 2, #new-token: 227, #cached-token: 5, token usage: 0.10, #running-req: 46, #queue-req: 682, 
[1,0]<stdout>:[2025-10-12 21:10:54 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 681, 
[1,0]<stdout>:[2025-10-12 21:10:54 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 680, 
[1,0]<stdout>:[2025-10-12 21:10:55 TP0] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 679, 
[1,0]<stdout>:[2025-10-12 21:10:55 TP0] Decode batch. #running-req: 48, #token: 25194, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 846.99, #queue-req: 679, 
[1,0]<stdout>:[2025-10-12 21:10:55 TP0] Prefill batch. #new-seq: 2, #new-token: 696, #cached-token: 7, token usage: 0.10, #running-req: 46, #queue-req: 677, 
[1,0]<stdout>:[2025-10-12 21:10:55 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 676, 
[1,0]<stdout>:[2025-10-12 21:10:56 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 675, 
[1,0]<stdout>:[2025-10-12 21:10:56 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 674, 
[1,0]<stdout>:[2025-10-12 21:10:56 TP0] Prefill batch. #new-seq: 1, #new-token: 401, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 673, 
[1,0]<stdout>:[2025-10-12 21:10:57 TP0] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 672, 
[1,0]<stdout>:[2025-10-12 21:10:57 TP0] Prefill batch. #new-seq: 1, #new-token: 551, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 671, 
[1,0]<stdout>:[2025-10-12 21:10:58 TP0] Decode batch. #running-req: 48, #token: 25440, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 726.30, #queue-req: 671, 
[1,0]<stdout>:[2025-10-12 21:10:58 TP0] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 670, 
[1,0]<stdout>:[2025-10-12 21:10:58 TP0] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 669, 
[1,0]<stdout>:[2025-10-12 21:10:58 TP0] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 8, token usage: 0.10, #running-req: 47, #queue-req: 668, 
[1,0]<stdout>:[2025-10-12 21:10:59 TP0] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 667, 
[1,0]<stdout>:[2025-10-12 21:10:59 TP0] Prefill batch. #new-seq: 2, #new-token: 357, #cached-token: 5, token usage: 0.10, #running-req: 46, #queue-req: 665, 
[1,0]<stdout>:[2025-10-12 21:10:59 TP0] Prefill batch. #new-seq: 2, #new-token: 358, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 663, 
[1,0]<stdout>:[2025-10-12 21:10:59 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 662, 
[1,0]<stdout>:[2025-10-12 21:11:00 TP0] Prefill batch. #new-seq: 2, #new-token: 1210, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 660, 
[1,0]<stdout>:[2025-10-12 21:11:00 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 659, 
[1,0]<stdout>:[2025-10-12 21:11:00 TP0] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 658, 
[1,0]<stdout>:[2025-10-12 21:11:01 TP0] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 657, 
[1,0]<stdout>:[2025-10-12 21:11:01 TP0] Decode batch. #running-req: 48, #token: 22437, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 554.50, #queue-req: 657, 
[1,0]<stdout>:[2025-10-12 21:11:01 TP0] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 656, 
[1,0]<stdout>:[2025-10-12 21:11:01 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 655, 
[1,0]<stdout>:[2025-10-12 21:11:02 TP0] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 654, 
[1,0]<stdout>:[2025-10-12 21:11:02 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 653, 
[1,0]<stdout>:[2025-10-12 21:11:03 TP0] Prefill batch. #new-seq: 1, #new-token: 777, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 652, 
[1,0]<stdout>:[2025-10-12 21:11:03 TP0] Decode batch. #running-req: 48, #token: 23826, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 859.80, #queue-req: 652, 
[1,0]<stdout>:[2025-10-12 21:11:03 TP0] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 651, 
[1,0]<stdout>:[2025-10-12 21:11:04 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 650, 
[1,0]<stdout>:[2025-10-12 21:11:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 649, 
[1,0]<stdout>:[2025-10-12 21:11:04 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 648, 
[1,0]<stdout>:[2025-10-12 21:11:05 TP0] Prefill batch. #new-seq: 1, #new-token: 2389, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 647, 
[1,0]<stdout>:[2025-10-12 21:11:05 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 646, 
[1,0]<stdout>:[2025-10-12 21:11:06 TP0] Decode batch. #running-req: 48, #token: 26453, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 786.58, #queue-req: 646, 
[1,0]<stdout>:[2025-10-12 21:11:06 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 645, 
[1,0]<stdout>:[2025-10-12 21:11:07 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 644, 
[1,0]<stdout>:[2025-10-12 21:11:07 TP0] Prefill batch. #new-seq: 3, #new-token: 274, #cached-token: 6, token usage: 0.10, #running-req: 45, #queue-req: 641, 
[1,0]<stdout>:[2025-10-12 21:11:07 TP0] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 640, 
[1,0]<stdout>:[2025-10-12 21:11:07 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 639, 
[1,0]<stdout>:[2025-10-12 21:11:08 TP0] Decode batch. #running-req: 48, #token: 25968, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 857.07, #queue-req: 639, 
[1,0]<stdout>:[2025-10-12 21:11:08 TP0] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 638, 
[1,0]<stdout>:[2025-10-12 21:11:09 TP0] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 637, 
[1,0]<stdout>:[2025-10-12 21:11:09 TP0] Prefill batch. #new-seq: 1, #new-token: 783, #cached-token: 5, token usage: 0.11, #running-req: 47, #queue-req: 636, 
[1,0]<stdout>:[2025-10-12 21:11:09 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 635, 
[1,0]<stdout>:[2025-10-12 21:11:09 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 634, 
[1,0]<stdout>:[2025-10-12 21:11:10 TP0] Prefill batch. #new-seq: 2, #new-token: 3034, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 632, 
[1,0]<stdout>:[2025-10-12 21:11:10 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 631, 
[1,0]<stdout>:[2025-10-12 21:11:10 TP0] Prefill batch. #new-seq: 1, #new-token: 236, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 630, 
[1,0]<stdout>:[2025-10-12 21:11:10 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 629, 
[1,0]<stdout>:[2025-10-12 21:11:11 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 628, 
[1,0]<stdout>:[2025-10-12 21:11:11 TP0] Decode batch. #running-req: 48, #token: 24779, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 589.10, #queue-req: 628, 
[1,0]<stdout>:[2025-10-12 21:11:11 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 627, 
[1,0]<stdout>:[2025-10-12 21:11:12 TP0] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 626, 
[1,0]<stdout>:[2025-10-12 21:11:12 TP0] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 625, 
[1,0]<stdout>:[2025-10-12 21:11:13 TP0] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 624, 
[1,0]<stdout>:[2025-10-12 21:11:13 TP0] Decode batch. #running-req: 48, #token: 25921, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 940.69, #queue-req: 624, 
[1,0]<stdout>:[2025-10-12 21:11:13 TP0] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 623, 
[1,0]<stdout>:[2025-10-12 21:11:14 TP0] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 622, 
[1,0]<stdout>:[2025-10-12 21:11:14 TP0] Prefill batch. #new-seq: 2, #new-token: 883, #cached-token: 9, token usage: 0.10, #running-req: 46, #queue-req: 620, 
[1,0]<stdout>:[2025-10-12 21:11:14 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 619, 
[1,0]<stdout>:[2025-10-12 21:11:14 TP0] Prefill batch. #new-seq: 2, #new-token: 32, #cached-token: 3, token usage: 0.09, #running-req: 46, #queue-req: 617, 
[1,0]<stdout>:[2025-10-12 21:11:15 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 616, 
[1,0]<stdout>:[2025-10-12 21:11:15 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 615, 
[1,0]<stdout>:[2025-10-12 21:11:15 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 614, 
[1,0]<stdout>:[2025-10-12 21:11:16 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 613, 
[1,0]<stdout>:[2025-10-12 21:11:16 TP0] Prefill batch. #new-seq: 1, #new-token: 623, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 612, 
[1,0]<stdout>:[2025-10-12 21:11:16 TP0] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 611, 
[1,0]<stdout>:[2025-10-12 21:11:17 TP0] Decode batch. #running-req: 48, #token: 22954, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 551.45, #queue-req: 611, 
[1,0]<stdout>:[2025-10-12 21:11:17 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 610, 
[1,0]<stdout>:[2025-10-12 21:11:17 TP0] Prefill batch. #new-seq: 3, #new-token: 361, #cached-token: 5, token usage: 0.08, #running-req: 45, #queue-req: 607, 
[1,0]<stdout>:[2025-10-12 21:11:17 TP0] Prefill batch. #new-seq: 2, #new-token: 34, #cached-token: 7, token usage: 0.08, #running-req: 46, #queue-req: 605, 
[1,0]<stdout>:[2025-10-12 21:11:18 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 604, 
[1,0]<stdout>:[2025-10-12 21:11:18 TP0] Prefill batch. #new-seq: 2, #new-token: 444, #cached-token: 7, token usage: 0.08, #running-req: 46, #queue-req: 602, 
[1,0]<stdout>:[2025-10-12 21:11:18 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 601, 
[1,0]<stdout>:[2025-10-12 21:11:19 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 600, 
[1,0]<stdout>:[2025-10-12 21:11:19 TP0] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 599, 
[1,0]<stdout>:[2025-10-12 21:11:19 TP0] Decode batch. #running-req: 47, #token: 18643, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 668.20, #queue-req: 599, 
[1,0]<stdout>:[2025-10-12 21:11:19 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 598, 
[1,0]<stdout>:[2025-10-12 21:11:20 TP0] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 597, 
[1,0]<stdout>:[2025-10-12 21:11:21 TP0] Prefill batch. #new-seq: 2, #new-token: 294, #cached-token: 3, token usage: 0.08, #running-req: 46, #queue-req: 595, 
[1,0]<stdout>:[2025-10-12 21:11:21 TP0] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 7, token usage: 0.08, #running-req: 47, #queue-req: 594, 
[1,0]<stdout>:[2025-10-12 21:11:21 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 593, 
[1,0]<stdout>:[2025-10-12 21:11:21 TP0] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 592, 
[1,0]<stdout>:[2025-10-12 21:11:22 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 591, 
[1,0]<stdout>:[2025-10-12 21:11:22 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 590, 
[1,0]<stdout>:[2025-10-12 21:11:22 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 589, 
[1,0]<stdout>:[2025-10-12 21:11:23 TP0] Decode batch. #running-req: 48, #token: 19097, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 629.13, #queue-req: 589, 
[1,0]<stdout>:[2025-10-12 21:11:23 TP0] Prefill batch. #new-seq: 2, #new-token: 209, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 587, 
[1,0]<stdout>:[2025-10-12 21:11:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1388, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 586, 
[1,0]<stdout>:[2025-10-12 21:11:23 TP0] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 585, 
[1,0]<stdout>:[2025-10-12 21:11:24 TP0] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 584, 
[1,0]<stdout>:[2025-10-12 21:11:25 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 583, 
[1,0]<stdout>:[2025-10-12 21:11:25 TP0] Decode batch. #running-req: 48, #token: 20601, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 851.16, #queue-req: 583, 
[1,0]<stdout>:[2025-10-12 21:11:25 TP0] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 582, 
[1,0]<stdout>:[2025-10-12 21:11:25 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 581, 
[1,0]<stdout>:[2025-10-12 21:11:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 877, token usage: 0.08, #running-req: 47, #queue-req: 580, 
[1,0]<stdout>:[2025-10-12 21:11:26 TP0] Prefill batch. #new-seq: 2, #new-token: 916, #cached-token: 7, token usage: 0.08, #running-req: 46, #queue-req: 578, 
[1,0]<stdout>:[2025-10-12 21:11:26 TP0] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 577, 
[1,0]<stdout>:[2025-10-12 21:11:27 TP0] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 576, 
[1,0]<stdout>:[2025-10-12 21:11:27 TP0] Prefill batch. #new-seq: 1, #new-token: 861, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 575, 
[1,0]<stdout>:[2025-10-12 21:11:27 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 574, 
[1,0]<stdout>:[2025-10-12 21:11:27 TP0] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 573, 
[1,0]<stdout>:[2025-10-12 21:11:28 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 572, 
[1,0]<stdout>:[2025-10-12 21:11:28 TP0] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 571, 
[1,0]<stdout>:[2025-10-12 21:11:28 TP0] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 570, 
[1,0]<stdout>:[2025-10-12 21:11:29 TP0] Prefill batch. #new-seq: 1, #new-token: 852, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 569, 
[1,0]<stdout>:[2025-10-12 21:11:29 TP0] Decode batch. #running-req: 48, #token: 17002, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 478.25, #queue-req: 569, 
[1,0]<stdout>:[2025-10-12 21:11:29 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 568, 
[1,0]<stdout>:[2025-10-12 21:11:29 TP0] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 567, 
[1,0]<stdout>:[2025-10-12 21:11:29 TP0] Prefill batch. #new-seq: 2, #new-token: 16, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 565, 
[1,0]<stdout>:[2025-10-12 21:11:30 TP0] Prefill batch. #new-seq: 1, #new-token: 843, #cached-token: 9, token usage: 0.07, #running-req: 47, #queue-req: 564, 
[1,0]<stdout>:[2025-10-12 21:11:30 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 563, 
[1,0]<stdout>:[2025-10-12 21:11:31 TP0] Prefill batch. #new-seq: 2, #new-token: 815, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 561, 
[1,0]<stdout>:[2025-10-12 21:11:31 TP0] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 560, 
[1,0]<stdout>:[2025-10-12 21:11:31 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 559, 
[1,0]<stdout>:[2025-10-12 21:11:31 TP0] Prefill batch. #new-seq: 2, #new-token: 2202, #cached-token: 3, token usage: 0.07, #running-req: 46, #queue-req: 557, 
[1,0]<stdout>:[2025-10-12 21:11:32 TP0] Decode batch. #running-req: 48, #token: 19284, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 628.86, #queue-req: 557, 
[1,0]<stdout>:[2025-10-12 21:11:32 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 556, 
[1,0]<stdout>:[2025-10-12 21:11:32 TP0] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 555, 
[1,0]<stdout>:[2025-10-12 21:11:33 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 554, 
[1,0]<stdout>:[2025-10-12 21:11:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 553, 
[1,0]<stdout>:[2025-10-12 21:11:33 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 552, 
[1,0]<stdout>:[2025-10-12 21:11:34 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 551, 
[1,0]<stdout>:[2025-10-12 21:11:34 TP0] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 550, 
[1,0]<stdout>:[2025-10-12 21:11:34 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 549, 
[1,0]<stdout>:[2025-10-12 21:11:35 TP0] Decode batch. #running-req: 48, #token: 16292, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 677.83, #queue-req: 549, 
[1,0]<stdout>:[2025-10-12 21:11:35 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 548, 
[1,0]<stdout>:[2025-10-12 21:11:35 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 547, 
[1,0]<stdout>:[2025-10-12 21:11:35 TP0] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 546, 
[1,0]<stdout>:[2025-10-12 21:11:36 TP0] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 545, 
[1,0]<stdout>:[2025-10-12 21:11:36 TP0] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 544, 
[1,0]<stdout>:[2025-10-12 21:11:37 TP0] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 543, 
[1,0]<stdout>:[2025-10-12 21:11:37 TP0] Decode batch. #running-req: 48, #token: 17022, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 782.75, #queue-req: 543, 
[1,0]<stdout>:[2025-10-12 21:11:37 TP0] Prefill batch. #new-seq: 1, #new-token: 193, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 542, 
[1,0]<stdout>:[2025-10-12 21:11:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1117, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 541, 
[1,0]<stdout>:[2025-10-12 21:11:38 TP0] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 540, 
[1,0]<stdout>:[2025-10-12 21:11:38 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 539, 
[1,0]<stdout>:[2025-10-12 21:11:39 TP0] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 538, 
[1,0]<stdout>:[2025-10-12 21:11:39 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 537, 
[1,0]<stdout>:[2025-10-12 21:11:39 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 536, 
[1,0]<stdout>:[2025-10-12 21:11:40 TP0] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 535, 
[1,0]<stdout>:[2025-10-12 21:11:40 TP0] Decode batch. #running-req: 48, #token: 17648, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 665.26, #queue-req: 535, 
[1,0]<stdout>:[2025-10-12 21:11:40 TP0] Prefill batch. #new-seq: 1, #new-token: 586, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 534, 
[1,0]<stdout>:[2025-10-12 21:11:40 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 533, 
[1,0]<stdout>:[2025-10-12 21:11:41 TP0] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 532, 
[1,0]<stdout>:[2025-10-12 21:11:41 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 531, 
[1,0]<stdout>:[2025-10-12 21:11:41 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 530, 
[1,0]<stdout>:[2025-10-12 21:11:42 TP0] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 529, 
[1,0]<stdout>:[2025-10-12 21:11:42 TP0] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 528, 
[1,0]<stdout>:[2025-10-12 21:11:43 TP0] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 527, 
[1,0]<stdout>:[2025-10-12 21:11:43 TP0] Decode batch. #running-req: 48, #token: 16293, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 652.93, #queue-req: 527, 
[1,0]<stdout>:[2025-10-12 21:11:43 TP0] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 526, 
[1,0]<stdout>:[2025-10-12 21:11:43 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 525, 
[1,0]<stdout>:[2025-10-12 21:11:44 TP0] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 524, 
[1,0]<stdout>:[2025-10-12 21:11:44 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 523, 
[1,0]<stdout>:[2025-10-12 21:11:44 TP0] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 4, token usage: 0.06, #running-req: 47, #queue-req: 522, 
[1,0]<stdout>:[2025-10-12 21:11:44 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 521, 
[1,0]<stdout>:[2025-10-12 21:11:45 TP0] Prefill batch. #new-seq: 2, #new-token: 169, #cached-token: 7, token usage: 0.06, #running-req: 46, #queue-req: 519, 
[1,0]<stdout>:[2025-10-12 21:11:45 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 518, 
[1,0]<stdout>:[2025-10-12 21:11:46 TP0] Decode batch. #running-req: 48, #token: 15971, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 675.56, #queue-req: 518, 
[1,0]<stdout>:[2025-10-12 21:11:46 TP0] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 517, 
[1,0]<stdout>:[2025-10-12 21:11:46 TP0] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 516, 
[1,0]<stdout>:[2025-10-12 21:11:47 TP0] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 515, 
[1,0]<stdout>:[2025-10-12 21:11:47 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 514, 
[1,0]<stdout>:[2025-10-12 21:11:47 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 513, 
[1,0]<stdout>:[2025-10-12 21:11:48 TP0] Decode batch. #running-req: 48, #token: 15070, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 861.20, #queue-req: 513, 
[1,0]<stdout>:[2025-10-12 21:11:48 TP0] Prefill batch. #new-seq: 2, #new-token: 2028, #cached-token: 3, token usage: 0.05, #running-req: 46, #queue-req: 511, 
[1,0]<stdout>:[2025-10-12 21:11:48 TP0] Prefill batch. #new-seq: 2, #new-token: 557, #cached-token: 3, token usage: 0.06, #running-req: 46, #queue-req: 509, 
[1,0]<stdout>:[2025-10-12 21:11:49 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 508, 
[1,0]<stdout>:[2025-10-12 21:11:49 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 507, 
[1,0]<stdout>:[2025-10-12 21:11:49 TP0] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 3, token usage: 0.06, #running-req: 47, #queue-req: 506, 
[1,0]<stdout>:[2025-10-12 21:11:50 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 505, 
[1,0]<stdout>:[2025-10-12 21:11:50 TP0] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 504, 
[1,0]<stdout>:[2025-10-12 21:11:50 TP0] Prefill batch. #new-seq: 2, #new-token: 598, #cached-token: 10, token usage: 0.06, #running-req: 46, #queue-req: 502, 
[1,0]<stdout>:[2025-10-12 21:11:51 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 1, token usage: 0.06, #running-req: 47, #queue-req: 501, 
[1,0]<stdout>:[2025-10-12 21:11:51 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 2, token usage: 0.06, #running-req: 47, #queue-req: 500, 
[1,0]<stdout>:[2025-10-12 21:11:51 TP0] Decode batch. #running-req: 48, #token: 15906, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 594.27, #queue-req: 500, 
[1,0]<stdout>:[2025-10-12 21:11:51 TP0] Prefill batch. #new-seq: 1, #new-token: 439, #cached-token: 6, token usage: 0.06, #running-req: 47, #queue-req: 499, 
[1,0]<stdout>:[2025-10-12 21:11:51 TP0] Prefill batch. #new-seq: 2, #new-token: 1236, #cached-token: 3, token usage: 0.06, #running-req: 46, #queue-req: 497, 
[1,0]<stdout>:[2025-10-12 21:11:52 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 496, 
[1,0]<stdout>:[2025-10-12 21:11:52 TP0] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 495, 
[1,0]<stdout>:[2025-10-12 21:11:52 TP0] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 494, 
[1,0]<stdout>:[2025-10-12 21:11:53 TP0] Prefill batch. #new-seq: 2, #new-token: 715, #cached-token: 3, token usage: 0.07, #running-req: 46, #queue-req: 492, 
[1,0]<stdout>:[2025-10-12 21:11:53 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 491, 
[1,0]<stdout>:[2025-10-12 21:11:53 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 490, 
[1,0]<stdout>:[2025-10-12 21:11:53 TP0] Prefill batch. #new-seq: 1, #new-token: 783, #cached-token: 10, token usage: 0.07, #running-req: 47, #queue-req: 489, 
[1,0]<stdout>:[2025-10-12 21:11:54 TP0] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 488, 
[1,0]<stdout>:[2025-10-12 21:11:54 TP0] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 487, 
[1,0]<stdout>:[2025-10-12 21:11:55 TP0] Decode batch. #running-req: 48, #token: 16995, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 555.49, #queue-req: 487, 
[1,0]<stdout>:[2025-10-12 21:11:55 TP0] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 486, 
[1,0]<stdout>:[2025-10-12 21:11:55 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 485, 
[1,0]<stdout>:[2025-10-12 21:11:55 TP0] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 484, 
[1,0]<stdout>:[2025-10-12 21:11:56 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 483, 
[1,0]<stdout>:[2025-10-12 21:11:56 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 482, 
[1,0]<stdout>:[2025-10-12 21:11:57 TP0] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 481, 
[1,0]<stdout>:[2025-10-12 21:11:57 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 480, 
[1,0]<stdout>:[2025-10-12 21:11:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 479, 
[1,0]<stdout>:[2025-10-12 21:11:57 TP0] Decode batch. #running-req: 48, #token: 18626, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 678.82, #queue-req: 479, 
[1,0]<stdout>:[2025-10-12 21:11:58 TP0] Prefill batch. #new-seq: 1, #new-token: 720, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 478, 
[1,0]<stdout>:[2025-10-12 21:11:58 TP0] Prefill batch. #new-seq: 1, #new-token: 2404, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 477, 
[1,0]<stdout>:[2025-10-12 21:11:58 TP0] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 476, 
[1,0]<stdout>:[2025-10-12 21:11:59 TP0] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 475, 
[1,0]<stdout>:[2025-10-12 21:11:59 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 474, 
[1,0]<stdout>:[2025-10-12 21:11:59 TP0] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 473, 
[1,0]<stdout>:[2025-10-12 21:12:00 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 472, 
[1,0]<stdout>:[2025-10-12 21:12:00 TP0] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 471, 
[1,0]<stdout>:[2025-10-12 21:12:00 TP0] Decode batch. #running-req: 48, #token: 21600, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 673.18, #queue-req: 471, 
[1,0]<stdout>:[2025-10-12 21:12:00 TP0] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 470, 
[1,0]<stdout>:[2025-10-12 21:12:00 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 469, 
[1,0]<stdout>:[2025-10-12 21:12:01 TP0] Prefill batch. #new-seq: 2, #new-token: 35, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 467, 
[1,0]<stdout>:[2025-10-12 21:12:01 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 466, 
[1,0]<stdout>:[2025-10-12 21:12:01 TP0] Prefill batch. #new-seq: 2, #new-token: 566, #cached-token: 3, token usage: 0.08, #running-req: 46, #queue-req: 464, 
[1,0]<stdout>:[2025-10-12 21:12:02 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 463, 
[1,0]<stdout>:[2025-10-12 21:12:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1426, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 462, 
[1,0]<stdout>:[2025-10-12 21:12:03 TP0] Decode batch. #running-req: 48, #token: 21210, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 730.11, #queue-req: 462, 
[1,0]<stdout>:[2025-10-12 21:12:03 TP0] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 461, 
[1,0]<stdout>:[2025-10-12 21:12:03 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 460, 
[1,0]<stdout>:[2025-10-12 21:12:04 TP0] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 459, 
[1,0]<stdout>:[2025-10-12 21:12:04 TP0] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 458, 
[1,0]<stdout>:[2025-10-12 21:12:05 TP0] Prefill batch. #new-seq: 2, #new-token: 22, #cached-token: 3, token usage: 0.07, #running-req: 46, #queue-req: 456, 
[1,0]<stdout>:[2025-10-12 21:12:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1958, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 455, 
[1,0]<stdout>:[2025-10-12 21:12:05 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 454, 
[1,0]<stdout>:[2025-10-12 21:12:05 TP0] Prefill batch. #new-seq: 2, #new-token: 16, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 452, 
[1,0]<stdout>:[2025-10-12 21:12:06 TP0] Decode batch. #running-req: 48, #token: 19413, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 674.71, #queue-req: 452, 
[1,0]<stdout>:[2025-10-12 21:12:06 TP0] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 451, 
[1,0]<stdout>:[2025-10-12 21:12:06 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 450, 
[1,0]<stdout>:[2025-10-12 21:12:06 TP0] Prefill batch. #new-seq: 2, #new-token: 176, #cached-token: 4, token usage: 0.07, #running-req: 46, #queue-req: 448, 
[1,0]<stdout>:[2025-10-12 21:12:07 TP0] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 447, 
[1,0]<stdout>:[2025-10-12 21:12:07 TP0] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 446, 
[1,0]<stdout>:[2025-10-12 21:12:07 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 445, 
[1,0]<stdout>:[2025-10-12 21:12:08 TP0] Prefill batch. #new-seq: 2, #new-token: 2646, #cached-token: 4, token usage: 0.08, #running-req: 46, #queue-req: 443, 
[1,0]<stdout>:[2025-10-12 21:12:08 TP0] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 442, 
[1,0]<stdout>:[2025-10-12 21:12:08 TP0] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 441, 
[1,0]<stdout>:[2025-10-12 21:12:09 TP0] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 8, token usage: 0.09, #running-req: 47, #queue-req: 440, 
[1,0]<stdout>:[2025-10-12 21:12:09 TP0] Decode batch. #running-req: 47, #token: 21071, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 593.32, #queue-req: 440, 
[1,0]<stdout>:[2025-10-12 21:12:09 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 439, 
[1,0]<stdout>:[2025-10-12 21:12:09 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 438, 
[1,0]<stdout>:[2025-10-12 21:12:09 TP0] Prefill batch. #new-seq: 2, #new-token: 251, #cached-token: 3, token usage: 0.08, #running-req: 46, #queue-req: 436, 
[1,0]<stdout>:[2025-10-12 21:12:10 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 435, 
[1,0]<stdout>:[2025-10-12 21:12:10 TP0] Prefill batch. #new-seq: 1, #new-token: 236, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 434, 
[1,0]<stdout>:[2025-10-12 21:12:11 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 433, 
[1,0]<stdout>:[2025-10-12 21:12:11 TP0] Prefill batch. #new-seq: 2, #new-token: 20, #cached-token: 405, token usage: 0.09, #running-req: 46, #queue-req: 431, 
[1,0]<stdout>:[2025-10-12 21:12:12 TP0] Decode batch. #running-req: 48, #token: 21346, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 723.44, #queue-req: 431, 
[1,0]<stdout>:[2025-10-12 21:12:12 TP0] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 430, 
[1,0]<stdout>:[2025-10-12 21:12:12 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 429, 
[1,0]<stdout>:[2025-10-12 21:12:12 TP0] Prefill batch. #new-seq: 2, #new-token: 789, #cached-token: 8, token usage: 0.08, #running-req: 46, #queue-req: 427, 
[1,0]<stdout>:[2025-10-12 21:12:12 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 426, 
[1,0]<stdout>:[2025-10-12 21:12:13 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 425, 
[1,0]<stdout>:[2025-10-12 21:12:13 TP0] Prefill batch. #new-seq: 2, #new-token: 52, #cached-token: 4, token usage: 0.07, #running-req: 46, #queue-req: 423, 
[1,0]<stdout>:[2025-10-12 21:12:13 TP0] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 422, 
[1,0]<stdout>:[2025-10-12 21:12:13 TP0] Prefill batch. #new-seq: 2, #new-token: 1392, #cached-token: 11, token usage: 0.07, #running-req: 46, #queue-req: 420, 
[1,0]<stdout>:[2025-10-12 21:12:14 TP0] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 419, 
[1,0]<stdout>:[2025-10-12 21:12:14 TP0] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 418, 
[1,0]<stdout>:[2025-10-12 21:12:14 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 417, 
[1,0]<stdout>:[2025-10-12 21:12:15 TP0] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 416, 
[1,0]<stdout>:[2025-10-12 21:12:15 TP0] Prefill batch. #new-seq: 1, #new-token: 452, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 415, 
[1,0]<stdout>:[2025-10-12 21:12:15 TP0] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 414, 
[1,0]<stdout>:[2025-10-12 21:12:15 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 413, 
[1,0]<stdout>:[2025-10-12 21:12:16 TP0] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 412, 
[1,0]<stdout>:[2025-10-12 21:12:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1014, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 411, 
[1,0]<stdout>:[2025-10-12 21:12:16 TP0] Decode batch. #running-req: 48, #token: 20044, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 404.68, #queue-req: 411, 
[1,0]<stdout>:[2025-10-12 21:12:16 TP0] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 410, 
[1,0]<stdout>:[2025-10-12 21:12:16 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 409, 
[1,0]<stdout>:[2025-10-12 21:12:17 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 408, 
[1,0]<stdout>:[2025-10-12 21:12:17 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 407, 
[1,0]<stdout>:[2025-10-12 21:12:17 TP0] Prefill batch. #new-seq: 1, #new-token: 2746, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 406, 
[1,0]<stdout>:[2025-10-12 21:12:18 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 405, 
[1,0]<stdout>:[2025-10-12 21:12:18 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 404, 
[1,0]<stdout>:[2025-10-12 21:12:19 TP0] Decode batch. #running-req: 47, #token: 22428, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 727.61, #queue-req: 404, 
[1,0]<stdout>:[2025-10-12 21:12:19 TP0] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 403, 
[1,0]<stdout>:[2025-10-12 21:12:19 TP0] Prefill batch. #new-seq: 1, #new-token: 851, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 402, 
[1,0]<stdout>:[2025-10-12 21:12:20 TP0] Prefill batch. #new-seq: 1, #new-token: 427, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 401, 
[1,0]<stdout>:[2025-10-12 21:12:20 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 400, 
[1,0]<stdout>:[2025-10-12 21:12:21 TP0] Prefill batch. #new-seq: 1, #new-token: 815, #cached-token: 12, token usage: 0.09, #running-req: 47, #queue-req: 399, 
[1,0]<stdout>:[2025-10-12 21:12:21 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 398, 
[1,0]<stdout>:[2025-10-12 21:12:21 TP0] Decode batch. #running-req: 47, #token: 21791, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 780.30, #queue-req: 398, 
[1,0]<stdout>:[2025-10-12 21:12:21 TP0] Prefill batch. #new-seq: 1, #new-token: 538, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 397, 
[1,0]<stdout>:[2025-10-12 21:12:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 396, 
[1,0]<stdout>:[2025-10-12 21:12:22 TP0] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 395, 
[1,0]<stdout>:[2025-10-12 21:12:22 TP0] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 394, 
[1,0]<stdout>:[2025-10-12 21:12:23 TP0] Prefill batch. #new-seq: 2, #new-token: 460, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 392, 
[1,0]<stdout>:[2025-10-12 21:12:23 TP0] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 391, 
[1,0]<stdout>:[2025-10-12 21:12:23 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 390, 
[1,0]<stdout>:[2025-10-12 21:12:24 TP0] Prefill batch. #new-seq: 2, #new-token: 1538, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 388, 
[1,0]<stdout>:[2025-10-12 21:12:24 TP0] Decode batch. #running-req: 48, #token: 23403, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 676.29, #queue-req: 388, 
[1,0]<stdout>:[2025-10-12 21:12:24 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 387, 
[1,0]<stdout>:[2025-10-12 21:12:24 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 386, 
[1,0]<stdout>:[2025-10-12 21:12:25 TP0] Prefill batch. #new-seq: 1, #new-token: 484, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 385, 
[1,0]<stdout>:[2025-10-12 21:12:25 TP0] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 384, 
[1,0]<stdout>:[2025-10-12 21:12:26 TP0] Prefill batch. #new-seq: 2, #new-token: 967, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 382, 
[1,0]<stdout>:[2025-10-12 21:12:26 TP0] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 381, 
[1,0]<stdout>:[2025-10-12 21:12:26 TP0] Prefill batch. #new-seq: 1, #new-token: 794, #cached-token: 7, token usage: 0.09, #running-req: 47, #queue-req: 380, 
[1,0]<stdout>:[2025-10-12 21:12:27 TP0] Decode batch. #running-req: 48, #token: 22699, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 720.94, #queue-req: 380, 
[1,0]<stdout>:[2025-10-12 21:12:27 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 379, 
[1,0]<stdout>:[2025-10-12 21:12:27 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 378, 
[1,0]<stdout>:[2025-10-12 21:12:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 377, 
[1,0]<stdout>:[2025-10-12 21:12:28 TP0] Prefill batch. #new-seq: 1, #new-token: 651, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 376, 
[1,0]<stdout>:[2025-10-12 21:12:28 TP0] Prefill batch. #new-seq: 1, #new-token: 833, #cached-token: 7, token usage: 0.09, #running-req: 47, #queue-req: 375, 
[1,0]<stdout>:[2025-10-12 21:12:29 TP0] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 374, 
[1,0]<stdout>:[2025-10-12 21:12:29 TP0] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 373, 
[1,0]<stdout>:[2025-10-12 21:12:29 TP0] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 372, 
[1,0]<stdout>:[2025-10-12 21:12:30 TP0] Decode batch. #running-req: 48, #token: 24595, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 682.10, #queue-req: 372, 
[1,0]<stdout>:[2025-10-12 21:12:30 TP0] Prefill batch. #new-seq: 1, #new-token: 656, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 371, 
[1,0]<stdout>:[2025-10-12 21:12:30 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 370, 
[1,0]<stdout>:[2025-10-12 21:12:30 TP0] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 7, token usage: 0.10, #running-req: 47, #queue-req: 369, 
[1,0]<stdout>:[2025-10-12 21:12:30 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 368, 
[1,0]<stdout>:[2025-10-12 21:12:31 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 367, 
[1,0]<stdout>:[2025-10-12 21:12:31 TP0] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 366, 
[1,0]<stdout>:[2025-10-12 21:12:31 TP0] Prefill batch. #new-seq: 2, #new-token: 30, #cached-token: 5, token usage: 0.09, #running-req: 46, #queue-req: 364, 
[1,0]<stdout>:[2025-10-12 21:12:32 TP0] Prefill batch. #new-seq: 3, #new-token: 1162, #cached-token: 9, token usage: 0.09, #running-req: 45, #queue-req: 361, 
[1,0]<stdout>:[2025-10-12 21:12:32 TP0] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 360, 
[1,0]<stdout>:[2025-10-12 21:12:33 TP0] Prefill batch. #new-seq: 2, #new-token: 315, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 358, 
[1,0]<stdout>:[2025-10-12 21:12:33 TP0] Decode batch. #running-req: 48, #token: 22753, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 589.67, #queue-req: 358, 
[1,0]<stdout>:[2025-10-12 21:12:33 TP0] Prefill batch. #new-seq: 1, #new-token: 810, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 357, 
[1,0]<stdout>:[2025-10-12 21:12:33 TP0] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 356, 
[1,0]<stdout>:[2025-10-12 21:12:33 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 355, 
[1,0]<stdout>:[2025-10-12 21:12:34 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 354, 
[1,0]<stdout>:[2025-10-12 21:12:34 TP0] Prefill batch. #new-seq: 1, #new-token: 382, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 353, 
[1,0]<stdout>:[2025-10-12 21:12:34 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 352, 
[1,0]<stdout>:[2025-10-12 21:12:34 TP0] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 351, 
[1,0]<stdout>:[2025-10-12 21:12:35 TP0] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 350, 
[1,0]<stdout>:[2025-10-12 21:12:35 TP0] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 5, token usage: 0.09, #running-req: 46, #queue-req: 348, 
[1,0]<stdout>:[2025-10-12 21:12:35 TP0] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 7, token usage: 0.09, #running-req: 47, #queue-req: 347, 
[1,0]<stdout>:[2025-10-12 21:12:36 TP0] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 346, 
[1,0]<stdout>:[2025-10-12 21:12:36 TP0] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 345, 
[1,0]<stdout>:[2025-10-12 21:12:36 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 344, 
[1,0]<stdout>:[2025-10-12 21:12:37 TP0] Decode batch. #running-req: 46, #token: 22944, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 501.86, #queue-req: 344, 
[1,0]<stdout>:[2025-10-12 21:12:37 TP0] Prefill batch. #new-seq: 2, #new-token: 1246, #cached-token: 11, token usage: 0.09, #running-req: 46, #queue-req: 342, 
[1,0]<stdout>:[2025-10-12 21:12:37 TP0] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 341, 
[1,0]<stdout>:[2025-10-12 21:12:37 TP0] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 340, 
[1,0]<stdout>:[2025-10-12 21:12:37 TP0] Prefill batch. #new-seq: 2, #new-token: 2123, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 338, 
[1,0]<stdout>:[2025-10-12 21:12:38 TP0] Prefill batch. #new-seq: 2, #new-token: 551, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 336, 
[1,0]<stdout>:[2025-10-12 21:12:38 TP0] Prefill batch. #new-seq: 2, #new-token: 322, #cached-token: 5, token usage: 0.09, #running-req: 46, #queue-req: 334, 
[1,0]<stdout>:[2025-10-12 21:12:38 TP0] Prefill batch. #new-seq: 1, #new-token: 444, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 333, 
[1,0]<stdout>:[2025-10-12 21:12:39 TP0] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 332, 
[1,0]<stdout>:[2025-10-12 21:12:39 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 331, 
[1,0]<stdout>:[2025-10-12 21:12:39 TP0] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 330, 
[1,0]<stdout>:[2025-10-12 21:12:40 TP0] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 329, 
[1,0]<stdout>:[2025-10-12 21:12:40 TP0] Prefill batch. #new-seq: 1, #new-token: 412, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 328, 
[1,0]<stdout>:[2025-10-12 21:12:40 TP0] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 8, token usage: 0.09, #running-req: 47, #queue-req: 327, 
[1,0]<stdout>:[2025-10-12 21:12:40 TP0] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 326, 
[1,0]<stdout>:[2025-10-12 21:12:41 TP0] Decode batch. #running-req: 48, #token: 20964, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 473.22, #queue-req: 326, 
[1,0]<stdout>:[2025-10-12 21:12:41 TP0] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 4, token usage: 0.08, #running-req: 47, #queue-req: 325, 
[1,0]<stdout>:[2025-10-12 21:12:41 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 324, 
[1,0]<stdout>:[2025-10-12 21:12:41 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 323, 
[1,0]<stdout>:[2025-10-12 21:12:42 TP0] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 322, 
[1,0]<stdout>:[2025-10-12 21:12:43 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 321, 
[1,0]<stdout>:[2025-10-12 21:12:43 TP0] Decode batch. #running-req: 48, #token: 21685, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 852.09, #queue-req: 321, 
[1,0]<stdout>:[2025-10-12 21:12:43 TP0] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 320, 
[1,0]<stdout>:[2025-10-12 21:12:44 TP0] Prefill batch. #new-seq: 2, #new-token: 1218, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 318, 
[1,0]<stdout>:[2025-10-12 21:12:44 TP0] Prefill batch. #new-seq: 2, #new-token: 77, #cached-token: 5, token usage: 0.09, #running-req: 46, #queue-req: 316, 
[1,0]<stdout>:[2025-10-12 21:12:45 TP0] Decode batch. #running-req: 48, #token: 23610, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1038.70, #queue-req: 316, 
[1,0]<stdout>:[2025-10-12 21:12:45 TP0] Prefill batch. #new-seq: 2, #new-token: 705, #cached-token: 8, token usage: 0.09, #running-req: 46, #queue-req: 314, 
[1,0]<stdout>:[2025-10-12 21:12:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1811, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 313, 
[1,0]<stdout>:[2025-10-12 21:12:46 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 312, 
[1,0]<stdout>:[2025-10-12 21:12:46 TP0] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 311, 
[1,0]<stdout>:[2025-10-12 21:12:47 TP0] Decode batch. #running-req: 48, #token: 25834, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 943.61, #queue-req: 311, 
[1,0]<stdout>:[2025-10-12 21:12:47 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 310, 
[1,0]<stdout>:[2025-10-12 21:12:47 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 309, 
[1,0]<stdout>:[2025-10-12 21:12:48 TP0] Prefill batch. #new-seq: 1, #new-token: 349, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 308, 
[1,0]<stdout>:[2025-10-12 21:12:48 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 307, 
[1,0]<stdout>:[2025-10-12 21:12:48 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 306, 
[1,0]<stdout>:[2025-10-12 21:12:48 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 305, 
[1,0]<stdout>:[2025-10-12 21:12:49 TP0] Prefill batch. #new-seq: 1, #new-token: 739, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 304, 
[1,0]<stdout>:[2025-10-12 21:12:49 TP0] Prefill batch. #new-seq: 2, #new-token: 631, #cached-token: 3, token usage: 0.09, #running-req: 46, #queue-req: 302, 
[1,0]<stdout>:[2025-10-12 21:12:49 TP0] Prefill batch. #new-seq: 1, #new-token: 756, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 301, 
[1,0]<stdout>:[2025-10-12 21:12:49 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 300, 
[1,0]<stdout>:[2025-10-12 21:12:50 TP0] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 299, 
[1,0]<stdout>:[2025-10-12 21:12:50 TP0] Decode batch. #running-req: 47, #token: 22979, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 554.60, #queue-req: 299, 
[1,0]<stdout>:[2025-10-12 21:12:50 TP0] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 298, 
[1,0]<stdout>:[2025-10-12 21:12:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 297, 
[1,0]<stdout>:[2025-10-12 21:12:51 TP0] Prefill batch. #new-seq: 1, #new-token: 785, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 296, 
[1,0]<stdout>:[2025-10-12 21:12:51 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 295, 
[1,0]<stdout>:[2025-10-12 21:12:51 TP0] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 294, 
[1,0]<stdout>:[2025-10-12 21:12:52 TP0] Prefill batch. #new-seq: 1, #new-token: 550, #cached-token: 8, token usage: 0.09, #running-req: 47, #queue-req: 293, 
[1,0]<stdout>:[2025-10-12 21:12:52 TP0] Prefill batch. #new-seq: 2, #new-token: 53, #cached-token: 4, token usage: 0.09, #running-req: 46, #queue-req: 291, 
[1,0]<stdout>:[2025-10-12 21:12:52 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 290, 
[1,0]<stdout>:[2025-10-12 21:12:53 TP0] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 289, 
[1,0]<stdout>:[2025-10-12 21:12:53 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 288, 
[1,0]<stdout>:[2025-10-12 21:12:53 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 287, 
[1,0]<stdout>:[2025-10-12 21:12:53 TP0] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 286, 
[1,0]<stdout>:[2025-10-12 21:12:54 TP0] Prefill batch. #new-seq: 2, #new-token: 301, #cached-token: 5, token usage: 0.09, #running-req: 46, #queue-req: 284, 
[1,0]<stdout>:[2025-10-12 21:12:54 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 283, 
[1,0]<stdout>:[2025-10-12 21:12:54 TP0] Prefill batch. #new-seq: 1, #new-token: 341, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 282, 
[1,0]<stdout>:[2025-10-12 21:12:54 TP0] Decode batch. #running-req: 48, #token: 22045, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 449.56, #queue-req: 282, 
[1,0]<stdout>:[2025-10-12 21:12:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1342, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 281, 
[1,0]<stdout>:[2025-10-12 21:12:55 TP0] Prefill batch. #new-seq: 1, #new-token: 2799, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 280, 
[1,0]<stdout>:[2025-10-12 21:12:55 TP0] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 279, 
[1,0]<stdout>:[2025-10-12 21:12:56 TP0] Prefill batch. #new-seq: 2, #new-token: 839, #cached-token: 7, token usage: 0.10, #running-req: 46, #queue-req: 277, 
[1,0]<stdout>:[2025-10-12 21:12:56 TP0] Prefill batch. #new-seq: 1, #new-token: 795, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 276, 
[1,0]<stdout>:[2025-10-12 21:12:56 TP0] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 275, 
[1,0]<stdout>:[2025-10-12 21:12:57 TP0] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 274, 
[1,0]<stdout>:[2025-10-12 21:12:57 TP0] Prefill batch. #new-seq: 1, #new-token: 2, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 273, 
[1,0]<stdout>:[2025-10-12 21:12:57 TP0] Decode batch. #running-req: 47, #token: 25578, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 676.07, #queue-req: 273, 
[1,0]<stdout>:[2025-10-12 21:12:57 TP0] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 272, 
[1,0]<stdout>:[2025-10-12 21:12:58 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 271, 
[1,0]<stdout>:[2025-10-12 21:12:58 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 270, 
[1,0]<stdout>:[2025-10-12 21:12:58 TP0] Prefill batch. #new-seq: 1, #new-token: 3486, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 269, 
[1,0]<stdout>:[2025-10-12 21:12:58 TP0] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 268, 
[1,0]<stdout>:[2025-10-12 21:12:59 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 267, 
[1,0]<stdout>:[2025-10-12 21:12:59 TP0] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 266, 
[1,0]<stdout>:[2025-10-12 21:12:59 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 265, 
[1,0]<stdout>:[2025-10-12 21:13:00 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 264, 
[1,0]<stdout>:[2025-10-12 21:13:00 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 263, 
[1,0]<stdout>:[2025-10-12 21:13:00 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 262, 
[1,0]<stdout>:[2025-10-12 21:13:01 TP0] Decode batch. #running-req: 48, #token: 23261, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 559.77, #queue-req: 262, 
[1,0]<stdout>:[2025-10-12 21:13:01 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 261, 
[1,0]<stdout>:[2025-10-12 21:13:01 TP0] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 260, 
[1,0]<stdout>:[2025-10-12 21:13:02 TP0] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 259, 
[1,0]<stdout>:[2025-10-12 21:13:02 TP0] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 258, 
[1,0]<stdout>:[2025-10-12 21:13:03 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 257, 
[1,0]<stdout>:[2025-10-12 21:13:03 TP0] Decode batch. #running-req: 47, #token: 24427, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 853.37, #queue-req: 257, 
[1,0]<stdout>:[2025-10-12 21:13:03 TP0] Prefill batch. #new-seq: 1, #new-token: 2036, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 256, 
[1,0]<stdout>:[2025-10-12 21:13:03 TP0] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 8, token usage: 0.10, #running-req: 47, #queue-req: 255, 
[1,0]<stdout>:[2025-10-12 21:13:04 TP0] Prefill batch. #new-seq: 1, #new-token: 2794, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 254, 
[1,0]<stdout>:[2025-10-12 21:13:04 TP0] Prefill batch. #new-seq: 1, #new-token: 345, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 253, 
[1,0]<stdout>:[2025-10-12 21:13:04 TP0] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 252, 
[1,0]<stdout>:[2025-10-12 21:13:05 TP0] Prefill batch. #new-seq: 2, #new-token: 162, #cached-token: 6, token usage: 0.11, #running-req: 46, #queue-req: 250, 
[1,0]<stdout>:[2025-10-12 21:13:05 TP0] Prefill batch. #new-seq: 1, #new-token: 591, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 249, 
[1,0]<stdout>:[2025-10-12 21:13:05 TP0] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 5, token usage: 0.11, #running-req: 47, #queue-req: 248, 
[1,0]<stdout>:[2025-10-12 21:13:06 TP0] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 247, 
[1,0]<stdout>:[2025-10-12 21:13:06 TP0] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 246, 
[1,0]<stdout>:[2025-10-12 21:13:06 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 245, 
[1,0]<stdout>:[2025-10-12 21:13:06 TP0] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 244, 
[1,0]<stdout>:[2025-10-12 21:13:07 TP0] Decode batch. #running-req: 48, #token: 24739, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 515.17, #queue-req: 244, 
[1,0]<stdout>:[2025-10-12 21:13:07 TP0] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 243, 
[1,0]<stdout>:[2025-10-12 21:13:07 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 242, 
[1,0]<stdout>:[2025-10-12 21:13:07 TP0] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 241, 
[1,0]<stdout>:[2025-10-12 21:13:08 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 240, 
[1,0]<stdout>:[2025-10-12 21:13:08 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 239, 
[1,0]<stdout>:[2025-10-12 21:13:08 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 238, 
[1,0]<stdout>:[2025-10-12 21:13:09 TP0] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 237, 
[1,0]<stdout>:[2025-10-12 21:13:09 TP0] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 236, 
[1,0]<stdout>:[2025-10-12 21:13:09 TP0] Decode batch. #running-req: 48, #token: 22907, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 681.98, #queue-req: 236, 
[1,0]<stdout>:[2025-10-12 21:13:10 TP0] Prefill batch. #new-seq: 2, #new-token: 892, #cached-token: 13, token usage: 0.09, #running-req: 46, #queue-req: 234, 
[1,0]<stdout>:[2025-10-12 21:13:10 TP0] Prefill batch. #new-seq: 1, #new-token: 837, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 233, 
[1,0]<stdout>:[2025-10-12 21:13:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 232, 
[1,0]<stdout>:[2025-10-12 21:13:11 TP0] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 231, 
[1,0]<stdout>:[2025-10-12 21:13:11 TP0] Prefill batch. #new-seq: 2, #new-token: 351, #cached-token: 3, token usage: 0.09, #running-req: 46, #queue-req: 229, 
[1,0]<stdout>:[2025-10-12 21:13:11 TP0] Prefill batch. #new-seq: 2, #new-token: 654, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 227, 
[1,0]<stdout>:[2025-10-12 21:13:12 TP0] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 226, 
[1,0]<stdout>:[2025-10-12 21:13:12 TP0] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 8, token usage: 0.09, #running-req: 47, #queue-req: 225, 
[1,0]<stdout>:[2025-10-12 21:13:12 TP0] Decode batch. #running-req: 48, #token: 23914, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 670.44, #queue-req: 225, 
[1,0]<stdout>:[2025-10-12 21:13:12 TP0] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 224, 
[1,0]<stdout>:[2025-10-12 21:13:13 TP0] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 223, 
[1,0]<stdout>:[2025-10-12 21:13:13 TP0] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 222, 
[1,0]<stdout>:[2025-10-12 21:13:13 TP0] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 221, 
[1,0]<stdout>:[2025-10-12 21:13:14 TP0] Prefill batch. #new-seq: 2, #new-token: 2546, #cached-token: 3, token usage: 0.09, #running-req: 46, #queue-req: 219, 
[1,0]<stdout>:[2025-10-12 21:13:14 TP0] Prefill batch. #new-seq: 1, #new-token: 624, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 218, 
[1,0]<stdout>:[2025-10-12 21:13:14 TP0] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 217, 
[1,0]<stdout>:[2025-10-12 21:13:14 TP0] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 216, 
[1,0]<stdout>:[2025-10-12 21:13:15 TP0] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5, token usage: 0.10, #running-req: 47, #queue-req: 215, 
[1,0]<stdout>:[2025-10-12 21:13:15 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 214, 
[1,0]<stdout>:[2025-10-12 21:13:16 TP0] Decode batch. #running-req: 48, #token: 24015, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 585.18, #queue-req: 214, 
[1,0]<stdout>:[2025-10-12 21:13:16 TP0] Prefill batch. #new-seq: 2, #new-token: 1171, #cached-token: 13, token usage: 0.09, #running-req: 46, #queue-req: 212, 
[1,0]<stdout>:[2025-10-12 21:13:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 211, 
[1,0]<stdout>:[2025-10-12 21:13:16 TP0] Prefill batch. #new-seq: 1, #new-token: 601, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 210, 
[1,0]<stdout>:[2025-10-12 21:13:16 TP0] Prefill batch. #new-seq: 2, #new-token: 492, #cached-token: 18, token usage: 0.10, #running-req: 46, #queue-req: 208, 
[1,0]<stdout>:[2025-10-12 21:13:17 TP0] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 207, 
[1,0]<stdout>:[2025-10-12 21:13:17 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 206, 
[1,0]<stdout>:[2025-10-12 21:13:17 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 205, 
[1,0]<stdout>:[2025-10-12 21:13:18 TP0] Prefill batch. #new-seq: 1, #new-token: 792, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 204, 
[1,0]<stdout>:[2025-10-12 21:13:18 TP0] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 203, 
[1,0]<stdout>:[2025-10-12 21:13:18 TP0] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 202, 
[1,0]<stdout>:[2025-10-12 21:13:19 TP0] Prefill batch. #new-seq: 2, #new-token: 112, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 200, 
[1,0]<stdout>:[2025-10-12 21:13:19 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 199, 
[1,0]<stdout>:[2025-10-12 21:13:19 TP0] Decode batch. #running-req: 48, #token: 22129, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 529.22, #queue-req: 199, 
[1,0]<stdout>:[2025-10-12 21:13:19 TP0] Prefill batch. #new-seq: 3, #new-token: 485, #cached-token: 11, token usage: 0.09, #running-req: 45, #queue-req: 196, 
[1,0]<stdout>:[2025-10-12 21:13:19 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 195, 
[1,0]<stdout>:[2025-10-12 21:13:20 TP0] Prefill batch. #new-seq: 1, #new-token: 785, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 194, 
[1,0]<stdout>:[2025-10-12 21:13:20 TP0] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 193, 
[1,0]<stdout>:[2025-10-12 21:13:20 TP0] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 192, 
[1,0]<stdout>:[2025-10-12 21:13:21 TP0] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 191, 
[1,0]<stdout>:[2025-10-12 21:13:21 TP0] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 190, 
[1,0]<stdout>:[2025-10-12 21:13:21 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 189, 
[1,0]<stdout>:[2025-10-12 21:13:21 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 188, 
[1,0]<stdout>:[2025-10-12 21:13:22 TP0] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 187, 
[1,0]<stdout>:[2025-10-12 21:13:22 TP0] Prefill batch. #new-seq: 1, #new-token: 529, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 186, 
[1,0]<stdout>:[2025-10-12 21:13:22 TP0] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 185, 
[1,0]<stdout>:[2025-10-12 21:13:22 TP0] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 184, 
[1,0]<stdout>:[2025-10-12 21:13:23 TP0] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 183, 
[1,0]<stdout>:[2025-10-12 21:13:23 TP0] Prefill batch. #new-seq: 2, #new-token: 335, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 181, 
[1,0]<stdout>:[2025-10-12 21:13:23 TP0] Prefill batch. #new-seq: 1, #new-token: 620, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 180, 
[1,0]<stdout>:[2025-10-12 21:13:24 TP0] Decode batch. #running-req: 48, #token: 23004, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 429.00, #queue-req: 180, 
[1,0]<stdout>:[2025-10-12 21:13:24 TP0] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 179, 
[1,0]<stdout>:[2025-10-12 21:13:24 TP0] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 178, 
[1,0]<stdout>:[2025-10-12 21:13:24 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 177, 
[1,0]<stdout>:[2025-10-12 21:13:24 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 176, 
[1,0]<stdout>:[2025-10-12 21:13:25 TP0] Prefill batch. #new-seq: 2, #new-token: 869, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 174, 
[1,0]<stdout>:[2025-10-12 21:13:25 TP0] Prefill batch. #new-seq: 1, #new-token: 866, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 173, 
[1,0]<stdout>:[2025-10-12 21:13:25 TP0] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 172, 
[1,0]<stdout>:[2025-10-12 21:13:25 TP0] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 171, 
[1,0]<stdout>:[2025-10-12 21:13:26 TP0] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 170, 
[1,0]<stdout>:[2025-10-12 21:13:26 TP0] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 169, 
[1,0]<stdout>:[2025-10-12 21:13:26 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 168, 
[1,0]<stdout>:[2025-10-12 21:13:26 TP0] Prefill batch. #new-seq: 3, #new-token: 553, #cached-token: 9, token usage: 0.08, #running-req: 45, #queue-req: 165, 
[1,0]<stdout>:[2025-10-12 21:13:27 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 164, 
[1,0]<stdout>:[2025-10-12 21:13:27 TP0] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 163, 
[1,0]<stdout>:[2025-10-12 21:13:27 TP0] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 3, token usage: 0.08, #running-req: 47, #queue-req: 162, 
[1,0]<stdout>:[2025-10-12 21:13:28 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 161, 
[1,0]<stdout>:[2025-10-12 21:13:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 160, 
[1,0]<stdout>:[2025-10-12 21:13:28 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.07, #running-req: 47, #queue-req: 159, 
[1,0]<stdout>:[2025-10-12 21:13:28 TP0] Decode batch. #running-req: 48, #token: 17460, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 396.93, #queue-req: 159, 
[1,0]<stdout>:[2025-10-12 21:13:28 TP0] Prefill batch. #new-seq: 1, #new-token: 381, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 158, 
[1,0]<stdout>:[2025-10-12 21:13:29 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 157, 
[1,0]<stdout>:[2025-10-12 21:13:29 TP0] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 156, 
[1,0]<stdout>:[2025-10-12 21:13:29 TP0] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 4, token usage: 0.07, #running-req: 47, #queue-req: 155, 
[1,0]<stdout>:[2025-10-12 21:13:29 TP0] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 154, 
[1,0]<stdout>:[2025-10-12 21:13:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1234, #cached-token: 3, token usage: 0.07, #running-req: 47, #queue-req: 153, 
[1,0]<stdout>:[2025-10-12 21:13:30 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 152, 
[1,0]<stdout>:[2025-10-12 21:13:31 TP0] Prefill batch. #new-seq: 1, #new-token: 2735, #cached-token: 2, token usage: 0.07, #running-req: 47, #queue-req: 151, 
[1,0]<stdout>:[2025-10-12 21:13:31 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 150, 
[1,0]<stdout>:[2025-10-12 21:13:31 TP0] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 149, 
[1,0]<stdout>:[2025-10-12 21:13:31 TP0] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 148, 
[1,0]<stdout>:[2025-10-12 21:13:32 TP0] Decode batch. #running-req: 47, #token: 21788, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 555.60, #queue-req: 148, 
[1,0]<stdout>:[2025-10-12 21:13:32 TP0] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 147, 
[1,0]<stdout>:[2025-10-12 21:13:32 TP0] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 146, 
[1,0]<stdout>:[2025-10-12 21:13:32 TP0] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 145, 
[1,0]<stdout>:[2025-10-12 21:13:33 TP0] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 144, 
[1,0]<stdout>:[2025-10-12 21:13:33 TP0] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 143, 
[1,0]<stdout>:[2025-10-12 21:13:33 TP0] Prefill batch. #new-seq: 1, #new-token: 665, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 142, 
[1,0]<stdout>:[2025-10-12 21:13:33 TP0] Prefill batch. #new-seq: 1, #new-token: 687, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 141, 
[1,0]<stdout>:[2025-10-12 21:13:34 TP0] Prefill batch. #new-seq: 1, #new-token: 574, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 140, 
[1,0]<stdout>:[2025-10-12 21:13:34 TP0] Prefill batch. #new-seq: 2, #new-token: 16, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 138, 
[1,0]<stdout>:[2025-10-12 21:13:34 TP0] Prefill batch. #new-seq: 1, #new-token: 638, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 137, 
[1,0]<stdout>:[2025-10-12 21:13:34 TP0] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 136, 
[1,0]<stdout>:[2025-10-12 21:13:35 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 135, 
[1,0]<stdout>:[2025-10-12 21:13:35 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 134, 
[1,0]<stdout>:[2025-10-12 21:13:35 TP0] Prefill batch. #new-seq: 1, #new-token: 602, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 133, 
[1,0]<stdout>:[2025-10-12 21:13:36 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 132, 
[1,0]<stdout>:[2025-10-12 21:13:36 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 131, 
[1,0]<stdout>:[2025-10-12 21:13:36 TP0] Decode batch. #running-req: 47, #token: 22369, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 429.01, #queue-req: 131, 
[1,0]<stdout>:[2025-10-12 21:13:36 TP0] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 130, 
[1,0]<stdout>:[2025-10-12 21:13:37 TP0] Prefill batch. #new-seq: 2, #new-token: 1409, #cached-token: 13, token usage: 0.09, #running-req: 46, #queue-req: 128, 
[1,0]<stdout>:[2025-10-12 21:13:37 TP0] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 127, 
[1,0]<stdout>:[2025-10-12 21:13:37 TP0] Prefill batch. #new-seq: 2, #new-token: 1398, #cached-token: 7, token usage: 0.09, #running-req: 46, #queue-req: 125, 
[1,0]<stdout>:[2025-10-12 21:13:38 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 124, 
[1,0]<stdout>:[2025-10-12 21:13:38 TP0] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 123, 
[1,0]<stdout>:[2025-10-12 21:13:38 TP0] Prefill batch. #new-seq: 1, #new-token: 3591, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 122, 
[1,0]<stdout>:[2025-10-12 21:13:39 TP0] Decode batch. #running-req: 47, #token: 28243, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 709.51, #queue-req: 122, 
[1,0]<stdout>:[2025-10-12 21:13:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1227, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 121, 
[1,0]<stdout>:[2025-10-12 21:13:39 TP0] Prefill batch. #new-seq: 1, #new-token: 391, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 120, 
[1,0]<stdout>:[2025-10-12 21:13:39 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 5, token usage: 0.11, #running-req: 47, #queue-req: 119, 
[1,0]<stdout>:[2025-10-12 21:13:40 TP0] Prefill batch. #new-seq: 1, #new-token: 236, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 118, 
[1,0]<stdout>:[2025-10-12 21:13:40 TP0] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 5, token usage: 0.11, #running-req: 47, #queue-req: 117, 
[1,0]<stdout>:[2025-10-12 21:13:41 TP0] Prefill batch. #new-seq: 1, #new-token: 3145, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 116, 
[1,0]<stdout>:[2025-10-12 21:13:41 TP0] Prefill batch. #new-seq: 2, #new-token: 1759, #cached-token: 4, token usage: 0.12, #running-req: 46, #queue-req: 114, 
[1,0]<stdout>:[2025-10-12 21:13:42 TP0] Decode batch. #running-req: 48, #token: 32386, token usage: 0.13, accept len: 1.00, cuda graph: True, gen throughput (token/s): 724.44, #queue-req: 114, 
[1,0]<stdout>:[2025-10-12 21:13:42 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 113, 
[1,0]<stdout>:[2025-10-12 21:13:42 TP0] Prefill batch. #new-seq: 1, #new-token: 451, #cached-token: 4, token usage: 0.12, #running-req: 47, #queue-req: 112, 
[1,0]<stdout>:[2025-10-12 21:13:42 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 111, 
[1,0]<stdout>:[2025-10-12 21:13:42 TP0] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 3, token usage: 0.12, #running-req: 47, #queue-req: 110, 
[1,0]<stdout>:[2025-10-12 21:13:43 TP0] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 2, token usage: 0.12, #running-req: 47, #queue-req: 109, 
[1,0]<stdout>:[2025-10-12 21:13:43 TP0] Prefill batch. #new-seq: 2, #new-token: 75, #cached-token: 2, token usage: 0.12, #running-req: 46, #queue-req: 107, 
[1,0]<stdout>:[2025-10-12 21:13:43 TP0] Prefill batch. #new-seq: 2, #new-token: 551, #cached-token: 6, token usage: 0.12, #running-req: 46, #queue-req: 105, 
[1,0]<stdout>:[2025-10-12 21:13:44 TP0] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 6, token usage: 0.12, #running-req: 47, #queue-req: 104, 
[1,0]<stdout>:[2025-10-12 21:13:44 TP0] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 103, 
[1,0]<stdout>:[2025-10-12 21:13:44 TP0] Prefill batch. #new-seq: 1, #new-token: 432, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 102, 
[1,0]<stdout>:[2025-10-12 21:13:45 TP0] Decode batch. #running-req: 48, #token: 28195, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 590.23, #queue-req: 102, 
[1,0]<stdout>:[2025-10-12 21:13:45 TP0] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 101, 
[1,0]<stdout>:[2025-10-12 21:13:45 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 100, 
[1,0]<stdout>:[2025-10-12 21:13:46 TP0] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 99, 
[1,0]<stdout>:[2025-10-12 21:13:46 TP0] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 98, 
[1,0]<stdout>:[2025-10-12 21:13:47 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 97, 
[1,0]<stdout>:[2025-10-12 21:13:48 TP0] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 96, 
[1,0]<stdout>:[2025-10-12 21:13:48 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 95, 
[1,0]<stdout>:[2025-10-12 21:13:49 TP0] Prefill batch. #new-seq: 1, #new-token: 784, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 94, 
[1,0]<stdout>:[2025-10-12 21:13:49 TP0] Decode batch. #running-req: 47, #token: 27591, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 474.36, #queue-req: 94, 
[1,0]<stdout>:[2025-10-12 21:13:49 TP0] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.11, #running-req: 47, #queue-req: 93, 
[1,0]<stdout>:[2025-10-12 21:13:49 TP0] Prefill batch. #new-seq: 1, #new-token: 2483, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 92, 
[1,0]<stdout>:[2025-10-12 21:13:50 TP0] Prefill batch. #new-seq: 2, #new-token: 17, #cached-token: 4, token usage: 0.12, #running-req: 46, #queue-req: 90, 
[1,0]<stdout>:[2025-10-12 21:13:50 TP0] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 1, token usage: 0.12, #running-req: 47, #queue-req: 89, 
[1,0]<stdout>:[2025-10-12 21:13:50 TP0] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 88, 
[1,0]<stdout>:[2025-10-12 21:13:51 TP0] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 87, 
[1,0]<stdout>:[2025-10-12 21:13:51 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 86, 
[1,0]<stdout>:[2025-10-12 21:13:51 TP0] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 85, 
[1,0]<stdout>:[2025-10-12 21:13:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1236, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 84, 
[1,0]<stdout>:[2025-10-12 21:13:52 TP0] Prefill batch. #new-seq: 2, #new-token: 1209, #cached-token: 6, token usage: 0.11, #running-req: 46, #queue-req: 82, 
[1,0]<stdout>:[2025-10-12 21:13:52 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 81, 
[1,0]<stdout>:[2025-10-12 21:13:52 TP0] Decode batch. #running-req: 48, #token: 28060, token usage: 0.11, accept len: 1.00, cuda graph: True, gen throughput (token/s): 558.50, #queue-req: 81, 
[1,0]<stdout>:[2025-10-12 21:13:52 TP0] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 80, 
[1,0]<stdout>:[2025-10-12 21:13:53 TP0] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 79, 
[1,0]<stdout>:[2025-10-12 21:13:53 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.11, #running-req: 47, #queue-req: 78, 
[1,0]<stdout>:[2025-10-12 21:13:53 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 1, token usage: 0.11, #running-req: 47, #queue-req: 77, 
[1,0]<stdout>:[2025-10-12 21:13:54 TP0] Prefill batch. #new-seq: 2, #new-token: 679, #cached-token: 6, token usage: 0.10, #running-req: 46, #queue-req: 75, 
[1,0]<stdout>:[2025-10-12 21:13:54 TP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 74, 
[1,0]<stdout>:[2025-10-12 21:13:54 TP0] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 73, 
[1,0]<stdout>:[2025-10-12 21:13:55 TP0] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 72, 
[1,0]<stdout>:[2025-10-12 21:13:55 TP0] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 2, token usage: 0.10, #running-req: 47, #queue-req: 71, 
[1,0]<stdout>:[2025-10-12 21:13:55 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 70, 
[1,0]<stdout>:[2025-10-12 21:13:55 TP0] Decode batch. #running-req: 48, #token: 23753, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 593.67, #queue-req: 70, 
[1,0]<stdout>:[2025-10-12 21:13:55 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 69, 
[1,0]<stdout>:[2025-10-12 21:13:56 TP0] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 68, 
[1,0]<stdout>:[2025-10-12 21:13:56 TP0] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 67, 
[1,0]<stdout>:[2025-10-12 21:13:56 TP0] Prefill batch. #new-seq: 1, #new-token: 309, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 66, 
[1,0]<stdout>:[2025-10-12 21:13:57 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 65, 
[1,0]<stdout>:[2025-10-12 21:13:57 TP0] Prefill batch. #new-seq: 2, #new-token: 1024, #cached-token: 10, token usage: 0.09, #running-req: 46, #queue-req: 63, 
[1,0]<stdout>:[2025-10-12 21:13:57 TP0] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 4, token usage: 0.10, #running-req: 47, #queue-req: 62, 
[1,0]<stdout>:[2025-10-12 21:13:58 TP0] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 61, 
[1,0]<stdout>:[2025-10-12 21:13:58 TP0] Decode batch. #running-req: 48, #token: 24174, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 673.08, #queue-req: 61, 
[1,0]<stdout>:[2025-10-12 21:13:58 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 60, 
[1,0]<stdout>:[2025-10-12 21:13:59 TP0] Prefill batch. #new-seq: 1, #new-token: 823, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 59, 
[1,0]<stdout>:[2025-10-12 21:13:59 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 6, token usage: 0.10, #running-req: 47, #queue-req: 58, 
[1,0]<stdout>:[2025-10-12 21:13:59 TP0] Prefill batch. #new-seq: 1, #new-token: 2187, #cached-token: 1, token usage: 0.10, #running-req: 47, #queue-req: 57, 
[1,0]<stdout>:[2025-10-12 21:14:00 TP0] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 4, token usage: 0.11, #running-req: 47, #queue-req: 56, 
[1,0]<stdout>:[2025-10-12 21:14:00 TP0] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 2, token usage: 0.11, #running-req: 47, #queue-req: 55, 
[1,0]<stdout>:[2025-10-12 21:14:00 TP0] Prefill batch. #new-seq: 2, #new-token: 322, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 53, 
[1,0]<stdout>:[2025-10-12 21:14:01 TP0] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 52, 
[1,0]<stdout>:[2025-10-12 21:14:01 TP0] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 51, 
[1,0]<stdout>:[2025-10-12 21:14:01 TP0] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 50, 
[1,0]<stdout>:[2025-10-12 21:14:01 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 49, 
[1,0]<stdout>:[2025-10-12 21:14:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 48, 
[1,0]<stdout>:[2025-10-12 21:14:02 TP0] Decode batch. #running-req: 48, #token: 21785, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 528.54, #queue-req: 48, 
[1,0]<stdout>:[2025-10-12 21:14:02 TP0] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 47, 
[1,0]<stdout>:[2025-10-12 21:14:02 TP0] Prefill batch. #new-seq: 2, #new-token: 150, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 45, 
[1,0]<stdout>:[2025-10-12 21:14:03 TP0] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 44, 
[1,0]<stdout>:[2025-10-12 21:14:03 TP0] Prefill batch. #new-seq: 2, #new-token: 32, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 42, 
[1,0]<stdout>:[2025-10-12 21:14:03 TP0] Prefill batch. #new-seq: 3, #new-token: 1605, #cached-token: 17, token usage: 0.07, #running-req: 45, #queue-req: 39, 
[1,0]<stdout>:[2025-10-12 21:14:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1886, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 38, 
[1,0]<stdout>:[2025-10-12 21:14:04 TP0] Prefill batch. #new-seq: 1, #new-token: 770, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 37, 
[1,0]<stdout>:[2025-10-12 21:14:04 TP0] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 36, 
[1,0]<stdout>:[2025-10-12 21:14:05 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 35, 
[1,0]<stdout>:[2025-10-12 21:14:05 TP0] Decode batch. #running-req: 47, #token: 20715, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 628.68, #queue-req: 35, 
[1,0]<stdout>:[2025-10-12 21:14:05 TP0] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 34, 
[1,0]<stdout>:[2025-10-12 21:14:05 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 33, 
[1,0]<stdout>:[2025-10-12 21:14:06 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.08, #running-req: 47, #queue-req: 32, 
[1,0]<stdout>:[2025-10-12 21:14:06 TP0] Prefill batch. #new-seq: 1, #new-token: 426, #cached-token: 2, token usage: 0.08, #running-req: 47, #queue-req: 31, 
[1,0]<stdout>:[2025-10-12 21:14:06 TP0] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 30, 
[1,0]<stdout>:[2025-10-12 21:14:06 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 29, 
[1,0]<stdout>:[2025-10-12 21:14:07 TP0] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 28, 
[1,0]<stdout>:[2025-10-12 21:14:07 TP0] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 27, 
[1,0]<stdout>:[2025-10-12 21:14:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1560, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 26, 
[1,0]<stdout>:[2025-10-12 21:14:08 TP0] Prefill batch. #new-seq: 1, #new-token: 4, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 25, 
[1,0]<stdout>:[2025-10-12 21:14:08 TP0] Prefill batch. #new-seq: 2, #new-token: 1435, #cached-token: 3, token usage: 0.09, #running-req: 46, #queue-req: 23, 
[1,0]<stdout>:[2025-10-12 21:14:08 TP0] Decode batch. #running-req: 48, #token: 23995, token usage: 0.10, accept len: 1.00, cuda graph: True, gen throughput (token/s): 559.16, #queue-req: 23, 
[1,0]<stdout>:[2025-10-12 21:14:08 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 3, token usage: 0.10, #running-req: 47, #queue-req: 22, 
[1,0]<stdout>:[2025-10-12 21:14:09 TP0] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 21, 
[1,0]<stdout>:[2025-10-12 21:14:09 TP0] Prefill batch. #new-seq: 1, #new-token: 865, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 20, 
[1,0]<stdout>:[2025-10-12 21:14:09 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 19, 
[1,0]<stdout>:[2025-10-12 21:14:10 TP0] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 18, 
[1,0]<stdout>:[2025-10-12 21:14:10 TP0] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 17, 
[1,0]<stdout>:[2025-10-12 21:14:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 16, 
[1,0]<stdout>:[2025-10-12 21:14:11 TP0] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 5, token usage: 0.09, #running-req: 47, #queue-req: 15, 
[1,0]<stdout>:[2025-10-12 21:14:11 TP0] Prefill batch. #new-seq: 2, #new-token: 522, #cached-token: 3, token usage: 0.08, #running-req: 46, #queue-req: 13, 
[1,0]<stdout>:[2025-10-12 21:14:11 TP0] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 12, 
[1,0]<stdout>:[2025-10-12 21:14:12 TP0] Decode batch. #running-req: 48, #token: 21920, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 594.81, #queue-req: 12, 
[1,0]<stdout>:[2025-10-12 21:14:12 TP0] Prefill batch. #new-seq: 1, #new-token: 830, #cached-token: 4, token usage: 0.09, #running-req: 47, #queue-req: 11, 
[1,0]<stdout>:[2025-10-12 21:14:12 TP0] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 10, 
[1,0]<stdout>:[2025-10-12 21:14:12 TP0] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 9, 
[1,0]<stdout>:[2025-10-12 21:14:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1220, #cached-token: 2, token usage: 0.09, #running-req: 47, #queue-req: 8, 
[1,0]<stdout>:[2025-10-12 21:14:13 TP0] Prefill batch. #new-seq: 2, #new-token: 232, #cached-token: 3, token usage: 0.09, #running-req: 46, #queue-req: 6, 
[1,0]<stdout>:[2025-10-12 21:14:13 TP0] Prefill batch. #new-seq: 1, #new-token: 345, #cached-token: 1, token usage: 0.09, #running-req: 47, #queue-req: 5, 
[1,0]<stdout>:[2025-10-12 21:14:14 TP0] Prefill batch. #new-seq: 2, #new-token: 197, #cached-token: 6, token usage: 0.09, #running-req: 46, #queue-req: 3, 
[1,0]<stdout>:[2025-10-12 21:14:14 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 2, 
[1,0]<stdout>:[2025-10-12 21:14:14 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 1, 
[1,0]<stdout>:[2025-10-12 21:14:14 TP0] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 3, token usage: 0.09, #running-req: 47, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:15 TP0] Decode batch. #running-req: 48, #token: 22135, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 594.02, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:16 TP0] Decode batch. #running-req: 43, #token: 22755, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1469.34, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:17 TP0] Decode batch. #running-req: 35, #token: 21256, token usage: 0.08, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1279.26, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:18 TP0] Decode batch. #running-req: 32, #token: 21649, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1074.81, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:20 TP0] Decode batch. #running-req: 31, #token: 22611, token usage: 0.09, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1118.36, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:21 TP0] Decode batch. #running-req: 26, #token: 17765, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 1000.62, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:22 TP0] Decode batch. #running-req: 23, #token: 17593, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 879.38, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:23 TP0] Decode batch. #running-req: 21, #token: 17854, token usage: 0.07, accept len: 1.00, cuda graph: True, gen throughput (token/s): 876.70, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:24 TP0] Decode batch. #running-req: 18, #token: 14880, token usage: 0.06, accept len: 1.00, cuda graph: True, gen throughput (token/s): 714.06, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:25 TP0] Decode batch. #running-req: 15, #token: 11568, token usage: 0.05, accept len: 1.00, cuda graph: True, gen throughput (token/s): 611.43, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:26 TP0] Decode batch. #running-req: 12, #token: 10159, token usage: 0.04, accept len: 1.00, cuda graph: True, gen throughput (token/s): 522.37, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:27 TP0] Decode batch. #running-req: 10, #token: 8416, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 412.90, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:28 TP0] Decode batch. #running-req: 9, #token: 8031, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 378.26, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:29 TP0] Decode batch. #running-req: 8, #token: 7564, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 275.03, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:31 TP0] Decode batch. #running-req: 7, #token: 7241, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 247.66, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:31 TP0] Decode batch. #running-req: 5, #token: 6111, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 243.07, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:32 TP0] Decode batch. #running-req: 5, #token: 6311, token usage: 0.03, accept len: 1.00, cuda graph: True, gen throughput (token/s): 221.53, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:33 TP0] Decode batch. #running-req: 4, #token: 4927, token usage: 0.02, accept len: 1.00, cuda graph: True, gen throughput (token/s): 171.41, #queue-req: 0, 
[1,0]<stdout>:[2025-10-12 21:14:34 TP0] Decode batch. #running-req: 1, #token: 2365, token usage: 0.01, accept len: 1.00, cuda graph: True, gen throughput (token/s): 106.08, #queue-req: 0, 
[1,0]<stdout>:
[1,0]<stdout>:====== Offline Throughput Benchmark Result =======
[1,0]<stdout>:Backend:                                 engine    
[1,0]<stdout>:Successful requests:                     2000      
[1,0]<stdout>:Benchmark duration (s):                  598.03    
[1,0]<stdout>:Total input tokens:                      626729    
[1,0]<stdout>:Total generated tokens:                  388685    
[1,0]<stdout>:Last generation throughput (tok/s):      106.08    
[1,0]<stdout>:Request throughput (req/s):              3.34      
[1,0]<stdout>:Input token throughput (tok/s):          1047.99   
[1,0]<stdout>:Output token throughput (tok/s):         649.95    
[1,0]<stdout>:Total token throughput (tok/s):          1697.94   
[1,0]<stdout>:==================================================
[1,1]<stdout>:[2025-10-12 21:14:35 TP11] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stdout>:    recv_reqs = broadcast_pyobj(
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.87]:1961
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 21:14:35 TP9] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stdout>:    recv_reqs = broadcast_pyobj(
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:535] Read error [10.104.4.87]:28580: Connection reset by peer
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 21:14:35 TP10] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stdout>:    recv_reqs = broadcast_pyobj(
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:535] Read error [10.104.4.87]:28076: Connection reset by peer
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 21:14:35 TP8] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stdout>:    recv_reqs = broadcast_pyobj(
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:535] Read error [10.104.4.87]:12702: Connection reset by peer
[1,1]<stdout>:
[1,1]<stdout>:[rank13]:[W1012 21:14:35.110650185 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:34850, remote=[a2ap-dgx013.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank15]:[W1012 21:14:35.110725603 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:40970, remote=[a2ap-dgx013.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_tr[1,1]<stdout>:aits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank11]:[W1012 21:14:35.110825881 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:40940, remote=[a2ap-dgx013.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank14]:[W1012 21:14:35.110805380 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:34880, remote=[a2ap-dgx013.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-package[1,1]<stdout>:s/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank9]:[W1012 21:14:35.110592244 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:40956, remote=[a2ap-dgx013.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank8]:[W1012 21:14:35.110795068 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:34864, remote=[a2ap-dgx013.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/pyth[1,1]<stdout>:on3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank12]:[W1012 21:14:35.110844532 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:34844, remote=[a2ap-dgx013.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[rank10]:[W1012 21:14:35.110610314 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=100, addr=[a2ap-dgx014.asp2p.nscc.sg]:34848, remote=[a2ap-dgx013.asp2p.nscc.sg]:5000): Connection reset by peer
[1,1]<stdout>:Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:679 (most recent call first):
[1,1]<stdout>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ffe750d9eb0 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libc10.so)
[1,1]<stdout>:frame #1: <unknown function> + 0x5d694d1 (0x7ffe591ef4d1 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #2: <unknown function> + 0x5d6a933 (0x7ffe591f0933 in /home/users/industry/ai-hpc/apacsc34/scra[1,1]<stdout>:tch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #3: <unknown function> + 0x5d6b47a (0x7ffe591f147a in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ffe591ec19e in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
[1,1]<stdout>:frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ffe186d1b18 in /home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
[1,1]<stdout>:frame #6: <unknown function> + 0xdc253 (0x7ffff50e0253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
[1,1]<stdout>:frame #7: <unknown function> + 0x94ac3 (0x7ffff7d1fac3 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:frame #8: <unknown function> + 0x126850 (0x7ffff7db1850 in /lib/x86_64-linux-gnu/libc.so.6)
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 21:14:35 TP12] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stdout>:    recv_reqs = broadcast_pyobj(
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.87]:16262
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 21:14:35 TP15] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stdout>:    recv_reqs = broadcast_pyobj(
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/t[1,1]<stdout>:orch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.87]:14736
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 21:14:35] Received sigquit from a child process. It usually means the child failed.
[1,1]<stdout>:[2025-10-12 21:14:35 TP14] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stdout>:    recv_reqs = broadcast_pyobj(
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.87]:37776
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 21:14:35] Received sigquit from a child process. It usually means the child failed.
[1,1]<stdout>:[2025-10-12 21:14:35] Received sigquit from a child process. It usually means the child failed.
[1,1]<stdout>:[2025-10-12 21:14:35 TP13] Scheduler hit an exception: Traceback (most recent call last):
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 2580, in run_scheduler_process
[1,1]<stdout>:    scheduler.event_loop_normal()
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 768, in event_loop_normal
[1,1]<stdout>:    recv_reqs = self.recv_requests()
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/managers/scheduler.py", line 1040, in recv_requests
[1,1]<stdout>:    recv_reqs = broadcast_pyobj(
[1,1]<stdout>:                ^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/sglang/srt/utils.py", line 1094, in broadcast_pyobj
[1,1]<stdout>:    dist.broadcast(tensor_size, src=src, group=dist_group)
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[1,1]<stdout>:    return func(*args, **kwargs)
[1,1]<stdout>:           ^^^^^^^^^^^^^^^^^^^^^
[1,1]<stdout>:  File "/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
[1,1]<stdout>:    work.wait()
[1,1]<stdout>:RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [10.104.4.87[1,1]<stdout>:]:63411
[1,1]<stdout>:
[1,1]<stdout>:[2025-10-12 21:14:35] Received sigquit from a child process. It usually means the child failed.
[1,1]<stdout>:[2025-10-12 21:14:35] Received sigquit from a child process. It usually means the child failed.
[1,1]<stdout>:[rank8]:[W1012 21:14:35.123023059 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 8] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank12]:[W1012 21:14:35.123051086 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 12] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank10]:[W1012 21:14:35.123045207 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 10] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank15]:[W1012 21:14:35.123055625 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 15] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank9]:[W1012 21:14:35.123047055 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 9] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank13]:[W1012 21:14:35.123072585 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 13] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank11]:[W1012 21:14:35.123060540 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 11] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stdout>:[rank14]:[W1012 21:14:35.123305206 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 14] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[1,1]<stderr>:bash: line 14: 589984 Killed                  '/home/users/industry/ai-hpc/apacsc34/scratch/tanathep/py312/bin/python3' -m sglang.bench_offline_throughput --model-path '/home/users/industry/ai-hpc/apacsc34/scratch/model/DeepSeek-R1' --dataset-path '/home/users/industry/ai-hpc/apacsc34/scratch/ShareGPT_V3_unfiltered_cleaned_split.json' --num-prompts 2000 --load-format dummy --seed 2025 --dtype bfloat16 --kv-cache-dtype auto --tensor-parallel-size 16 --nnodes 2 --node-rank ${OMPI_COMM_WORLD_RANK} --dist-init-addr ${DIST_INIT_ADDR}:5000 --trust-remote-code --attention-backend fa3 --prefill-attention-backend fa3 --decode-attention-backend fa3 --enable-p2p-check --speculative-algorithm EAGLE --speculative-num-steps 1 --speculative-eagle-topk 1 --speculative-num-draft-tokens 2 --schedule-conservativeness 1.0 --cuda-graph-max-bs 128 --num-continuous-decode-steps 1 --watchdog-timeout 900 2>&1
[1,1]<stderr>:
[1,1]<stderr>:real	13m16.666s
[1,1]<stderr>:user	0m25.204s
[1,1]<stderr>:sys	0m12.334s
[1,1]<stdout>:[RANK 1] Benchmark failed with exit code 137
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[52362,1],1]
  Exit code:    137
--------------------------------------------------------------------------

real	13m25.355s
user	0m0.044s
sys	0m0.274s
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-12 21:14:58.506765:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 97331.pbs111
	Project: 50000128
	Exit Status: 137
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(224), Used(224)
	CPU Time Used: 02:22:28
	Memory: Requested(3760gb), Used(31008092kb)
	Vmem Used: 69471096160kb
	Walltime: Requested(00:30:00), Used(00:13:34)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (a2ap-dgx013:ncpus=112:ngpus=8:mem=1971322880kb)+(a2ap-dgx014:ncpus=112:ngpus=8:mem=1971322880kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	GPU Duration: 13.78mins
	GPU Power Consumed: 400.02W
	GPU Max GPU Memory Used: 1.04TB
	Memory Throughput Rate (Average): a2ap-dgx013:(gpu1:5%+gpu0:5%+gpu2:5%+gpu3:4%+gpu5:5%+gpu4:5%+gpu6:5%+gpu7:4%)+a2ap-dgx014:(gpu1:4%+gpu0:5%+gpu2:5%+gpu3:5%+gpu5:4%+gpu4:5%+gpu6:4%+gpu7:4%)
	Memory Throughput Rate (Max): a2ap-dgx013:(gpu1:18%+gpu0:18%+gpu2:16%+gpu3:13%+gpu5:13%+gpu4:22%+gpu6:12%+gpu7:34%)+a2ap-dgx014:(gpu1:18%+gpu0:14%+gpu2:22%+gpu3:13%+gpu5:12%+gpu4:17%+gpu6:14%+gpu7:20%)
	Memory Throughput Rate (Min): a2ap-dgx013:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx014:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
	GPU SM Utilization (Average): a2ap-dgx013:(gpu1:72%+gpu0:73%+gpu2:74%+gpu3:74%+gpu5:71%+gpu4:74%+gpu6:71%+gpu7:70%)+a2ap-dgx014:(gpu1:69%+gpu0:69%+gpu2:69%+gpu3:67%+gpu5:47%+gpu4:64%+gpu6:49%+gpu7:60%)
	GPU SM Utilization (Max): a2ap-dgx013:(gpu1:100%+gpu0:100%+gpu2:100%+gpu3:100%+gpu5:100%+gpu4:100%+gpu6:100%+gpu7:99%)+a2ap-dgx014:(gpu1:100%+gpu0:100%+gpu2:99%+gpu3:99%+gpu5:99%+gpu4:100%+gpu6:97%+gpu7:99%)
	GPU SM Utilization (Min): a2ap-dgx013:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)+a2ap-dgx014:(gpu1:0%+gpu0:0%+gpu2:0%+gpu3:0%+gpu5:0%+gpu4:0%+gpu6:0%+gpu7:0%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Warning: None
GPU application profile: Medium
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

